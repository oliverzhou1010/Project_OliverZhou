job_title,company,job_location,job_link,first_seen,search_city,search_country,job level,job_type,job_summary,job_skills,job_summary_summary,rouge_score,relevancy_score
Technical Data Analyst,Jefferson Health Plans,"Philadelphia, PA",https://www.linkedin.com/jobs/view/technical-data-analyst-at-jefferson-health-plans-3773726907,2023-12-20,Phoenixville,United States,Associate,Remote,"Why Choose Jefferson Health Plans?
We are an award-winning, not-for-profit health maintenance organization. We are committed to creating a community where everyone belongs, acknowledges, and celebrates diversity and has opportunities to grow to their fullest potential.
While this job currently provides a flexible remote option, due to in-office meetings, training as required, or other business needs, our employees are to be residents of PA or the nearby states of DE or NJ.
Perks of JHP and why you will love it here:
Competitive Compensation Packages including 401(k) Savings Plan with Company Match and Profit Sharing
Flextime and Work-at-Home Options
Benefits & Wellness Program including generous Time Off
Impact on the communities we service
We are seeking a talented and enthusiastic Technical Data Analyst to join our team!
The Data Operations’ Team primary function is to provide access to various clinical and financial data to management to support the business decision process. Databases are maintained by this team for analyst use. Business users can access analyst data and analysis through the iQ portal which is also maintained by the Data Operations Team. This particular role will ensure consistent, accurate data for reporting. The technical data analyst will serve as the business lead for the corporate enterprise data warehouses project and software conversion efforts. They will work with IS, our consultants and other business users to verify the data model design, test data builds, verify algorithms and integrate the data using our new business intelligence reporting tool. The person will enable other Healthcare Economics analysts to use current and future data sources effectively.
As the Technical Data Analyst, your daily duties may include:
Use KNIME, QlikView, SQL, MS Access, MS Excel and other reporting tools as necessary to maintain Data Analytics Division databases.
Review logical and physical data model design. Make recommendations for improvement.
Review and publish application and analysis to user portal.
Extract, transform and load data from internal and external databases into Data Analytics Division databases.
Coordinate and conduct testing of data as it is loaded into databases by consultants, vendors and IS.
Be a key contributor to the Data Operations team. Model and verify data from business perspective.
Conduct trainings when appropriate for Data Analytics division staff.
Use appropriate business intelligence tools to obtain, validate and analyze relevant data.
Verify and analyze report data and prepare documentation of processes needed for development and improvement of applications.
Help determine optimal analysis and presentation of medical data to improve service quality.
Effectively communicate results of analysis.
Research issues to determine source of discrepancies.
Identify, communicate and monitor areas for improvement.
Share knowledge with other Data Analytics Division associates to improve processes, quality and data integrity.
Qualifications
B.S. or higher degree in computer science, information systems, statistics or other analytical field of study.
3 or more years of data reporting and analysis experience including report and dashboard development, database development, data connectivity and technical problem resolution.
Experience with delivery and reimbursement of medical services in a managed care environment.
Skills, We Value:
Strong problem-solving, quantitative and analytical skills
Proven skills in Hyperion or similar BI tool report and dashboard preparation
Ability to use computer spreadsheet (Excel) and database (Access and others) tools at advanced level
Ability to communicate effectively both orally and in writing
Ability to handle multiple responsibilities and changing priorities
Ability to quickly learn and implement knowledge of new technical processes
Must pay attention to details
Excellent organizational skills
Show more
Show less","KNIME, QlikView, SQL, MS Access, MS Excel, Logical data model design, Physical data model design, Data Analytics, Data Operations, Data Warehouse, Data Transformation, Data Loading, Business Intelligence, Report Development, Dashboard Development, Database Development, Data Connectivity, Technical Problem Resolution, Hyperion, BI tools, Computer Spreadsheets, Databases","Company: Jefferson Health Plans

Job Title: Technical Data Analyst

Experience: 3 or more years of data reporting and analysis experience including report and dashboard development, database development, data connectivity, and technical problem resolution. Experience with delivery and reimbursement of medical services in a managed care environment.

Skills Needed:
- Strong problem-solving, quantitative, and analytical skills
- Proven skills in Hyperion or similar BI tools for report and dashboard preparation
- Advanced proficiency in computer spreadsheet (Excel) and database (",0.2424242398180033,0.7023626
Data Center Engineer - Minneapolis,DeRisk Technologies,"Minneapolis, MN",https://www.linkedin.com/jobs/view/data-center-engineer-minneapolis-at-derisk-technologies-3766680776,2023-12-20,Minneapolis,United States,Associate,Onsite,"Job Responsibilities:
Deployment / In-Scope Configuration Items
Servers (Virtual & Physical)
Storage & Backup Devices
Server Appliances
Hyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)
Tape Storage Units
Power Distribution Units rated 3KVA and below
SAN Fabric Switches
Network Switches
KVM Units
WAN Optimization Devices
Firewalls
Access Points
Routers
Physical Cabling
Cable Management
Cables which connect the device to itself, a peripheral, or a power/network port Break-fix / Technical Tasks List
Power Cycling
Running Diagnostics Commands
Conducting whole unit replacement
Inserting/Removing Media
Replacing Defective Components
Assist with fault diagnosis and investigation
Configuring Remote Access
Basic Storage Array Configuration
Replacing faulty cables
Tape Management and Maintenance
Rebooting routers, servers, storage devices or other equipment
Operations Tasks List
Updating and Recording of activities in relevant IT Ticket Management System
Coordinating and agreeing attendance time and date with key stakeholders
Provide support either through phone, remote tools, or in person at onsite
Perform installation as needed either through physical or network medium
Coordinate actual activity date and timings including arrival and departure times
Carry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment
Labelling, Patching and Asset Tagging activities
Following specific task instructions and provision necessary reporting as necessary
Requirements
Job Requirements:
Technical Skills
Good general understanding of IT principles such as Networks, Hardware and Domains
Knowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support
Knowledge of server/client operations in a domain environment including Active Directory
Understanding of current and legacy hardware Infrastructure platforms
Hands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment/cable
Good Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment
Ability to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations
Knowledge of TCP/I P standards and networking
Experience with Tape Management activities
Excellent knowledge of best practices around management, control, and monitoring of server infrastructure
Familiarity with backup and recovery software and methodologies
Language skills needed
English Soft Skills
Exceptional customer facing skills
Able to communicate clearly and effectively both with Client and the Customer
Logical and analytical approach to work
Accurate record keeping
Able to work unsupervised
Good timekeeper
Intense focus on quality work
Productive and Efficient Academic Background
Bachelor of Engineering / Technology / Science or Equivalent Work Experience Overall Experience (in yrs.)
5 - 7 years (min
Benefits
Salary and Benefits as per market standard
Show more
Show less","Server, Storage, Backup, Networking, Virtualization, Hyper Converged Infrastructure, Tape Storage, Power Distribution, KVM, WAN Optimization, Firewall, Access Point, Router, Cabling, Cable Management, Diagnostics, Fault Diagnosis, Remote Access, Storage Array Configuration, Active Directory, TCP/IP, Backup and Recovery, English, Customer Service, Communication, Problem Solving, Time Management, Quality Assurance, Productivity, Engineering, Technology","Company Name: Not specified
Job Title: IT Infrastructure Support Engineer
Experience: 5-7 years
Skills Needed: 
- Strong knowledge and hands-on experience in deployment and configuration of various IT infrastructure components such as servers, storage devices, network switches, firewalls, etc.
- Proficiency in conducting break-fix technical tasks including power cycling, diagnostics, component replacement, and basic storage array configuration.
- Familiarity with operations tasks like updating activities in IT ticket management systems, coordinating with stakeholders",0.13872832079504832,0.50594604
Data Analyst,Avani Tech Solutions Private Limited,"Minneapolis, MN",https://www.linkedin.com/jobs/view/data-analyst-at-avani-tech-solutions-private-limited-3774016127,2023-12-20,Minneapolis,United States,Associate,Onsite,"Success Factor knowledge
Schedule : Monday through Friday 8:00-5:00 PM: Hybrid schedule as needed but mainly remote.
Pay : 36/hr
Requirements
The Data Management Generalist 2 will assist to implement HR Data Retention Controls across several HR applications to meet requirements from California Privacy Rights Act and Internal Retention Information Management (RIM) policies. The HR Data Retention Consultant will be working as part of the People Data Governance team (HR) and collaborate with application owners as well as RIM COE, IT and Data Governance team to:
identifies Retention Controls gaps for each of the application.
Assess and define best system solution.
understand and analyze RIM data categorization to be applied to the different data sets involved.
Implement system solution.
Show more
Show less","Data Management, HR Data Retention Controls, California Privacy Rights Act, Internal Retention Information Management (RIM) policies, People Data Governance, RIM COE, IT, Data Governance","Company: Not Specified
Job Title: Data Management Generalist 2
Experience: Not specified
Skills: Success Factor knowledge, implementing HR Data Retention Controls, understanding of California Privacy Rights Act and Internal Retention Information Management policies, collaboration with various teams including People Data Governance, RIM COE, IT, and Data Governance, identifying gaps in Retention Controls, defining system solutions, analyzing RIM data categorization, implementing system solutions.",0.33823528950800175,0.73940057
Data Engineer II - NBC Sports Next,NBC Sports Next,"Minneapolis, MN",https://www.linkedin.com/jobs/view/data-engineer-ii-nbc-sports-next-at-nbc-sports-next-3770041073,2023-12-20,Minneapolis,United States,Associate,Remote,"Company Description
NBC Sports Next is where sports and technology intersect. We’re a subdivision of NBC Sports and home to all NBCUniversal digital applications in sports and technology within our three groups: Youth & Recreational Sports; Golf; and Betting, Gaming & Emerging Media.
At NBC Sports Next, we make playing sports better through innovative technology and immersive experiences for athletes, coaches, players and fans. We equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; GolfNow, the leading online tee time marketplace and provider of golf course operations technology; GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, and coaching, tips; TeamUnify, swim team management services; GoMotion, sports and fitness business software solutions; and NBC Sports Edge, a leading platform for fantasy sports information and betting-focused tools.
At NBC Sports Next we’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology that provides the ultimate in immersive experiences.
This role is part of our Youth & Recreational Sports group, comprised of technology platforms such as SportsEngine, GoMotion, TourneyMachine, and TeamUnify. We enable athletes, parents, coaches and team administrators in the youth and recreational space to manage their organizations, collect payments, share schedules, find programs to participate in and connect with other families. Additionally, NCSI enables leagues and organizations to properly screen and train coaches in an effort to keep kids safe.
Job Description
SportsEngine has an exciting opportunity for a Data Engineer II. In this role as part of the Data Engineering Team, you work to manage the full lifecycle of our data warehousing needs. Our data warehouse and data operations are built on top of Amazon Web Services using a modern data warehousing stack which includes the use of Amazon Redshift, Apache Airflow and Sisense for reporting.
In delivering the key priorities of the role, the Data Engineer will;
Work within a small team of passionate data scientists and data engineers.
Contribute to the management of the day to day operations of running our Data Warehouse.
Build data pipelines and ETLs for loading source system data into the data warehouse for further reporting and analysis.
Assist in building scalable data models to support reporting and tracking of key business and product metrics.
Build, analyze and manage reports and dashboards for business stakeholders.
Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.
Qualifications
All candidates must meet the qualifications below:
A minimum of 5 years of Data engineering experience is required.
Bachelor’s Degree in Computer Science or related field/relevant industry experience in data engineering
Experience with AWS, Python is required.
Working experience in building Data Marts and Data Modeling.
Deep Experience and understanding of SQL (MySQL, Postgres, Redshift).
Experience with any ETL (Airflow, Boomi) tools is required.
Experience with BI Tools is a must (such as Periscope, Sisense, Tableau).
Desired Qualifications Are As Follows
Experience with;
ETL (Airflow, Boomi, Stitch) tools.
Python Programming
BI Tools (such as Periscope, Sisense, Tableau).
Database (Redshift)
AWS (S3 bucket, DMS, Lambda)
Interested Candidates Must
Submit a resume/CV through www.nbcunicareers.com to be considered.
Additional Information
NBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations in the US by calling 1-818-777-4107 and in the UK by calling +44 2036185726.
Show more
Show less","Data Engineering, Data Warehousing, SQL, MySQL, PostgreSQL, Redshift, AWS, Python, Apache Airflow, Boomi, Stitch, Sisense, Tableau, ETL, Periscope, Data Marts, Data Modeling, Lambda, S3 bucket, DMS","Company: NBC Sports Next
Job Title: Data Engineer II
Experience: Minimum of 5 years of data engineering experience
Skills Needed: Bachelor’s Degree in Computer Science or related field, experience with AWS, Python, building Data Marts and Data Modeling, deep understanding of SQL (MySQL, Postgres, Redshift), experience with ETL tools (such as Airflow, Boomi), BI Tools (Periscope, Sisense, Tableau), desired experience with Python programming, Red",0.16335540625508627,0.34340957
Data Analyst - Operational Assessment,National Grid Renewables,"Bloomington, MN",https://www.linkedin.com/jobs/view/data-analyst-operational-assessment-at-national-grid-renewables-3748053954,2023-12-20,Minneapolis,United States,Associate,Hybrid,"National Grid Renewables is a leading North American renewable energy company based in Minneapolis, Minnesota, with satellite offices located in the regions where it develops, constructs, and operates renewable energy projects. As a farmer-friendly and community-focused company, National Grid Renewables develops projects for corporations and utilities that seek to repower America’s electricity grid by reigniting local economies and reinvesting in a sustainable future. National Grid Renewables is part of the competitive, unregulated Ventures division of National Grid. It has a portfolio of solar, wind, and energy storage projects throughout the United States in various stages of development, construction, and operation.
National Grid Renewables partners with communities, farmers, and landowners where we develop. This means it’s not just about projects but about the people we work with, both outside and inside our organization. National Grid Renewables Team Members embody our foundational culture of being entrepreneurial, creative, and nimble and take pride in supporting National Grid’s vision to be at the heart of a clean, fair, and affordable energy future for all.
Data Analyst - Operational Assessment will be responsible for analyzing data from operating wind, solar, and battery storage projects, and supporting performance tracking / optimization efforts.
Duties:
Analyze meteorological and equipment performance data collected at operating sites
Identify field data quality issues and work with operations / engineering teams to resolve
Collaborate with plant operations staff to troubleshoot underperformance issues
Maintain and enhance internal performance monitoring processes
Assist in development of baseline production and loss expectations
Assist in performing operational assessments / production re-forecasts
Review contractual performance testing results
· Travel approximately 10% of the time
Qualifications:
3+ years in renewable energy
Experience with relational databases and large data sets
Experience with scientific programming languages
Familiarity with wind and solar energy assessments and industry-standard modeling software
BS in meteorology, engineering or other scientific field; MS preferred
Attributes:
Self-directed with ability to manage multiple complex projects simultaneously
Natural curiosity and desire for continuous improvement
Detail-oriented
Ability to effectively communicate technical information to non-technical collaborators
Ability to work in a collaborative environment with technical and non-technical associates
Show more
Show less","Data Analyst, Operational Assessment, Wind Energy, Solar Energy, Battery Storage, Performance Tracking, Optimization, Meteorological Data, Equipment Performance, Field Data Quality, Troubleshooting, Performance Monitoring, Production Expectations, Production Reforecasts, Contractual Performance Testing, Relational Databases, Large Data Sets, Scientific Programming Languages, Wind and Solar Energy Assessments, IndustryStandard Modeling Software, Meteorology, Engineering, Scientific Field, SelfDirected, Project Management, Continuous Improvement, DetailOriented, Communication, Collaboration","Company: National Grid Renewables

Job Title: Data Analyst - Operational Assessment

Experience: 3+ years in renewable energy

Skills Needed:
- Experience with relational databases and large data sets
- Experience with scientific programming languages
- Familiarity with wind and solar energy assessments and industry-standard modeling software
- BS in meteorology, engineering, or other scientific field; MS preferred

Summary:
National Grid Renewables, a leading North American renewable energy company, is seeking a Data Analyst - Operational",0.3176895275470813,0.7101656
Business Data Analyst,ELITE MENTE LLC,"Bloomington, MN",https://www.linkedin.com/jobs/view/business-data-analyst-at-elite-mente-llc-3727349667,2023-12-20,Minneapolis,United States,Associate,Hybrid,"VCS
is looking for
Business Data Analyst
for
Bloomington, MN location - Hybrid (3 days a week in office).
Title: Business Data Analyst
Duration: 6-month C2H
Location: Bloomington, MN – Hybrid – 3 days a week in office
Job Description
D2D: These analysts will be working on the BI/Data/automation team underneath the Director. They will be expected to create user stories, translate functional requirements. And understand business leads to create potential solutions. They will need to be a self-driven and curious individual when it comes to cutting edge technologies such as RPA, ChatGPT, automation. They will also be expected to work with the business side to create new ideas and initiatives.
Must Haves
Writing user stories
Azure Data Factory
SQL
RPA/automation knowledge and exp
This individual should come from a larger enterprise background where the companies they worked at valued big analytics and insights.
Regards
Jitender Kumar
Vish Consulting Services
Show more
Show less","User Stories, Azure Data Factory, SQL, RPA, Automation, Big Data Analytics, Insights","Vish Consulting Services (VCS) is seeking a Business Data Analyst for a 6-month contract-to-hire position in Bloomington, MN. The role involves working within the BI/Data/automation team, reporting to the Director. Responsibilities include creating user stories, translating functional requirements, and developing potential solutions in collaboration with business stakeholders. The ideal candidate should be self-driven, curious about cutting-edge technologies like RPA and ChatGPT, and able to generate new ideas and initiatives with the business side",0.3999999954246531,0.7505392
Data Science Specialist,ITR Group,"Eden Prairie, MN",https://www.linkedin.com/jobs/view/data-science-specialist-at-itr-group-3783415885,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Contract to hire opportunity.
Client requirements: US Citizen or GC holder
Type: Contract to hire
Onsite (2-4 days per week) - Eden Prairie, MN metro area
As a strategic partner to senior leadership, you will play a crucial role in optimizing the customer experience, pricing strategy, merchandising decisions, and delivery time effectiveness. We are looking for an individual with a strong programmatic approach, excellent communication skills, and a passion for making high-level strategic decisions.
Responsibilities:
Collaborative Optimization: Work closely with cross-functional teams to understand business challenges and identify opportunities for optimization.
Model Development: Develop and implement advanced analytical models and machine learning algorithms to enhance customer experience, inform merchandising decisions, and optimize delivery times.
Data Analysis: Gather and analyze data from various sources, including customer behavior, sales performance, and market trends.
KPI Development: Establish key performance indicators (KPIs) to measure the impact of decisions and recommend adjustments as needed.
Insights and Recommendations: Provide actionable insights and strategic recommendations to the Director of E-Commerce Operations and other key stakeholders.
Communication and Presentation: Prepare and present analytical findings and recommendations to senior leadership in a clear and concise manner.
Documentation: Ensure data accuracy and maintain strong documentation of methodologies, assumptions, and validations.
Adaptability: Undertake miscellaneous projects and various tasks as requested by management.
Qualifications:
Bachelor's degree in Computer Science, Data Science, Mathematics, Statistics, or a related field.
3+ years of relevant experience in data analytics, machine learning, or decision sciences.
Proficiency in SQL, Python, R, or other data manipulation languages.
Experience with data visualization tools such as Tableau, Power BI, or similar.
Strong programmatic approach to working with small data samples.
Excellent communication skills and ability to collaborate with cross-functional teams.
Entrepreneurial spirit with the ability to make complex decisions and provide strategic insights.
4-year degree required; MBA preferred over a PhD for operating outside the academic world.
Skills and Attributes:
Technical proficiency and advanced data analysis skills.
Strong critical thinking and attention to detail.
Initiative and action-oriented with effective time management.
Accountability and ownership of work commitments.
Team collaboration and passion for excellence.
Empathy in problem-solving and client interactions.
Adaptability and willingness to take on new challenges.
Show more
Show less","SQL, Python, R, Tableau, Power BI, Machine learning, Data analysis, Data visualization, Data manipulation languages, Programmatic approach to working with small data samples, Bachelor's degree in Computer Science Data Science Mathematics Statistics or a related field, Entrepreneurial spirit with the ability to make complex decisions and provide strategic insights, Critical thinking, Attention to detail, Initiative, Actionoriented, Effective time management, Accountability, Ownership of work commitments, Team collaboration, Passion for excellence, Empathy in problemsolving and client interactions, Adaptability, Willingness to take on new challenges","Company Name: Not mentioned
Job Title: Data Analyst/Strategic Analyst
Experience: 3+ years
Skills Needed: Bachelor's degree in Computer Science, Data Science, Mathematics, or Statistics; proficiency in SQL, Python, R; experience in data analytics and machine learning; strong programmatic approach; excellent communication skills; ability to collaborate with cross-functional teams; entrepreneurial spirit; proficiency in data visualization tools like Tableau or Power BI; critical thinking; attention to detail; initiative and action-oriented",0.2214765069321202,0.3592933
Senior Data Scientist,Target,"Brooklyn Park, MN",https://www.linkedin.com/jobs/view/senior-data-scientist-at-target-3782166094,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Description
The pay range is: $96,283.00 - $165,600.00 per year
In addition to your salary, Target cares about and invests in you as a team member, so that you can take care of yourself and your family. Target offers eligible team members and their dependents comprehensive health benefits and programs, which may include medical, vision, dental, life insurance and more, to help you and your family take care of your whole selves. Other benefits for eligible team members include 401(k), employee discount, short term disability, long term disability, paid sick leave, paid national holidays, and paid vacation. Find competitive benefits from financial and education to well-being and beyond at https://corporate.target.com/careers/benefits.
EMPLOYER
: Target Enterprise, Inc.
JOB POSITION
: Senior Data Scientist
LOCATION
: 7000 Target Parkway N, Brooklyn Park, MN 55445
DUTIES
: Code for scalable time series forecasting; schedule and monitor workflows; query and analyze relational databases; apply software development principles; influence by interacting within the Data Sciences team and with Product teams, perform within the scale and scope of role by implementing solutions, and contribute to Data Sciences’ and Target’s culture by modeling the culture; through understanding of the foundations and working principles of machine learning algorithms, linear algebra, probability theory, statistics, and optimization theory, perform data exploration and analysis (look at distributions, find anomalies, create simple visualizations, etc.) and implement algorithmic solution given specifications, while adhering to best practices in model development; understand and actively follow foundational programming principles (best practices, know about unit tests, code organization, basics of CI/CD) and create a well-maintainable and tested codebase with relevant documentation; learn and adhere to best practices in data analysis and data understanding; implement prototypes for individual components of software or data science solutions and understand and leverage basic data structures and algorithms in implementing solutions; evaluate multiple specified techniques for a defined problem and determine the most appropriate option from a performance perspective; leverage high-level understanding in business domain to gain knowledge of high-level Target business priorities, strategic goals and their impact, as well as details of the specific business sub-problem focused on; and collaborate with peers on product and provide technical support, and document and present work to peers, and participate in code reviews and gain broader understanding of different components within the application. Tools/technologies used: Scala, Spark, Spark SQL, Shell script, Apache Oozie, Apache Hive, Python, R, and Git. May telecommute from any location in the U.S.
REQUIREMENTS
: This position requires a Master’s degree in Data Science, Mathematics, or a closely related field, and at least two (2) years of experience in mathematics (any title) working on programming concepts using MATLAB, pair programming, and creating interactive visualizations/simulations, and at least six (6) months of experience developing end-to-end algorithms/models for time series forecasting, querying and analyzing data, applying high performance computing techniques such as MPI (Message Passing Interface) and Slurm, creating tools for Big Data analysis, adapting data assimilation techniques, model forecasting, validating performance, setting up data pipelines, and using Git, Python, and command line tools. May telecommute from any location in the U.S.
APPLY ONLINE
at jobs.target.com, Job ID: R0000323300
or
SEND RESUME
to: Target.Recruitment@Target.com and reference R0000323300
Americans With Disabilities Act (ADA)
Target will provide reasonable accommodations with the application process upon your request as required to comply with applicable laws. If you have a disability and require assistance in this application process, please visit your nearest Target store or Supply Chain Facility or reach out to Guest Services at 1-800-440-0680 for additional information.
Show more
Show less","MATLAB, Apache Oozie, Apache Hive, Python, R, SQL, Spark, Spark SQL, Shell script, Git, MPI, Slurm, Linear algebra, Probability theory, Statistics, Optimization theory, Data exploration, Data analysis, Data assimilation techniques, Model forecasting, Data pipeline, High performance computing techniques, Machine learning","Company Name: Target Enterprise, Inc.
Job Title: Senior Data Scientist
Experience: Requires a Master’s degree in Data Science, Mathematics, or a related field, with at least 2 years of experience in mathematics and 6 months of experience developing algorithms/models for time series forecasting, data querying and analysis, and using high-performance computing techniques.
Skills Needed: Proficiency in programming concepts using MATLAB, pair programming, creating interactive visualizations/simulations, experience with tools/technologies like Scala,",0.20861677772759296,0.54305774
Data Scientist,Deluxe,"Minneapolis, MN",https://www.linkedin.com/jobs/view/data-scientist-at-deluxe-3733476714,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"We're utilizing modern technology to fresh concepts to make a difference for our clients. This is your opportunity to create an immediate impact on a growing team where innovation and exploration are encouraged.
Responsible for leading the development of data-driven solutions to Charter’s business problems. Utilizes analytical, statistical, and programming skills to clean, aggregate, and analyze large data sets and interpret results. This position requires a strong command of statistical techniques and machine learning algorithms, as well as a demonstrated practical ability to determine where to invest time, synthesize actionable findings across diverse assignments, and present findings to audiences with diverse agendas and varying levels of technical expertise
Querying, pre-processing, data cleaning, feature engineering and analyzing large amounts of structured and Unstructured data(terabytes/petabytes) across multiple data sources using structured query language(SQL), python, pytorch, pyspark, R, spark and scala. In a cloud native AWS environment.
Deliver custom and commercial scalable solutions for internal and external customers. Combine business requirements and existing processes and data knowledge to create analytical solutions by building and deploying unsupervised and supervised machine learning and deep learning models. Including combining models using ensemble modeling techniques. Required to have knowledge and experience in unsupervised learning, principle component analysis(PCA), GLM, lasso/ridge regression, random forest, gradient boosted machines(GBM’s), XGBoost, baysian optimization, natural language processing(NLP) and deep neural networks/ back propagation.
Use advance statistical concepts for sampling, descriptive statistics, hypothesis testing, data quality, performance testing, attribution analysis, multi variate segmentation and recommender systems.
Collaborate with other data scientisits to solve demanding and complicated business problems by applying machine learning, deep learning to large data sets. Partner with Data Engineering on product development(proof of concept to commercial product), SDLC and CI/CD pipelines to process data, train models, test predictions within a MLOPS framework all at scale and be able to provide requirements for deployment. Must be able to work within an agile framework.
Basic Qualifications:
Education and Experience: Bachelor’s degree in Computer Science, Math, Statistics, Machine Learning, Analytic, Data Science and 0 to 2 years experience.
Preferred Qualifications:
Education: Masters Degree in Computer Science or Statistics
Experience: 1 year in Data Science
_
Target Compensation Range
Annual Salary: $80,000.00 - $90,000.00
_
Deluxe Corporation is an Equal Opportunity / Affirmative Action employer:
All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, disability, sex, age, ethnic or national origin, marital status, sexual orientation, gender identity or presentation, pregnancy, genetics, veteran status or any other status protected by state or federal law.
EOE/Minorities/Females/Vet/Disability
Please view the electronic EEO is the Law Poster which serves to inform you of your equal employment opportunity protections as part of the application process.
Reasonable Accommodation for Job Seekers with a Disability:
If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to deluxecareers@deluxe.com.
Show more
Show less","Datadriven solutions, Data cleaning, Data aggregation, Data analysis, Statistical techniques, Machine learning algorithms, Structured query language (SQL), Python, Pytorch, Pyspark, R, Spark, Scala, Cloud native AWS environment, Unsupervised learning, Principle component analysis (PCA), GLM, Lasso/ridge regression, Random forest, Gradient boosted machines (GBM’s), XGBoost, Bayesian optimization, Natural language processing (NLP), Deep neural networks/ back propagation, Advance statistical concepts for sampling, Descriptive statistics, Hypothesis testing, Data quality, Performance testing, Attribution analysis, Multi variate segmentation, Recommender systems, Agile framework","Company Name: Deluxe Corporation
Job Title: Data Scientist
Experience: 0 to 2 years
Skills Needed: Strong command of statistical techniques and machine learning algorithms, proficiency in SQL, Python, PyTorch, PySpark, R, Spark, and Scala, experience in unsupervised and supervised machine learning and deep learning models, knowledge of ensemble modeling techniques, understanding of advanced statistical concepts, collaboration with other data scientists, ability to work within an agile framework.
Salary Range: $80,",0.18414321994387794,0.40494376
"Sr Data Scientist - Recommendations (Applied ML, Deep Learning, Relevance Systems)",Target,"Minneapolis, MN",https://www.linkedin.com/jobs/view/sr-data-scientist-recommendations-applied-ml-deep-learning-relevance-systems-at-target-3779079953,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Description: The pay range is $92,000.00 - $165,600.00
Pay is based on several factors which vary based on position. These include labor markets and in some instances may include education, work experience and certifications. In addition to your pay, Target cares about and invests in you as a team member, so that you can take care of yourself and your family. Target offers eligible team members and their dependents comprehensive health benefits and programs, which may include medical, vision, dental, life insurance and more, to help you and your family take care of your whole selves. Other benefits for eligible team members include 401(k), employee discount, short term disability, long term disability, paid sick leave, paid national holidays, and paid vacation. Find competitive benefits from financial and education to well-being and beyond at https://corporate.target.com/careers/benefits.
JOIN US AS A SR DATA SCIENTIST – RECOMMENDATIONS
About Us
As a Fortune 50 company with more than 350k team members worldwide, Target is an iconic brand and one of America's leading retailers. Working at Target means the opportunity to help all families discover the joy of everyday life. Caring for our communities is woven into who we are, and we invest in the places we collectively live, work and play. We prioritize relationships, fuel and develop talent by creating growth opportunities, and succeed as one Target team. At our core, our purpose is ingrained in who we are, what we value, and how we work. It’s how we care, grow, and win together.
Every time a guest enters a Target store or browses Target.com, they experience the impact of Target’s investments in technology and innovation. We’re the technologists and data scientist behind one of the most loved retail brands, delivering joy to millions of our guests, team members, and communities.  Join our global in-house technology team of more than 4,000 engineers, data scientists, architects, coaches and product managers striving to make Target the most convenient, safe and joyful place to shop. We use agile practices and leverage open-source software to adapt and build best-in-class technology for our team members and guests—and we do so with a focus on diversity and inclusion, experimentation and continuous learning.
As a Sr Data Scientist, you’ll work on the Target Data Science Recommendations team collaborating with data scientists, machine learning engineers and product managers to build and augment our AI-driven digital Recommendation products. Through your understanding of deep learning, machine learning, linear algebra, probability theory, statistics, and optimization you’ll leverage Python and Scala to perform data exploration and analysis, implement algorithmic solutions given specifications, push solutions to our production environment as well as analyze performance and trade-offs to determine the best solution. We will expect you to understand Agile principles, follow best-practice software design, participate in code reviews, create a maintainable and well-tested codebase with relevant documentation. On the business side, you’ll document and present work to technical and non-technical peers, build knowledge on business priorities/strategic goals and leverage this knowledge while building requirements and solutions for each business need.
Core responsibilities of this job are articulated within this job description. Job duties may change at any time due to business needs.
About You
4-year degree in quantitative disciplines (Science, Technology, Engineering, Mathematics) or equivalent experience
3+ years of professional experience or equivalent industry experience
Experience designing and developing deep learning, machine learning, optimization and statistical models
Strong hands-on programming skills in Python. Knowledge of SQL, Hadoop/Hive, Spark, and/or Scala
Good working knowledge of mathematical and statistical concepts, algorithms and computational complexity
Excellent analytical thinking skills
Strong problem solving skills; develop innovative solution to help solve real-world business problems using data sciences approaches
Able to create documents and narrative suggesting actionable insights
Excellent communication skills; able to clearly tell data driven stories through appropriate visualizations, graphs and narratives
Self-driven and results oriented; able to meet tight timelines
Strong team player with ability to collaborate effectively across geographies/time zones
Preferred
MS or PhD in a quantitative field
Experience with recommender systems
This position will operate as a Hybrid/Flex for Your Day work arrangement based on Target’s needs. A Hybrid/Flex for Your Day work arrangement means the team member’s core role will need to be performed both onsite at the Target HQ MN location the role is assigned to and virtually, depending upon what your role, team and tasks require for that day. Work duties cannot be performed outside of the country of the primary work location, unless otherwise prescribed by Target. Click here if you are curious to learn more about Minnesota.
Americans With Disabilities Act (ADA)
Target will provide reasonable accommodations with the application process upon your request as required to comply with applicable laws. If you have a disability and require assistance in this application process, please visit your nearest Target store or Supply Chain Facility or reach out to Guest Services at 1-800-440-0680 for additional information.
Show more
Show less","Python, Scala, SQL, Hadoop/Hive, Spark, Linear algebra, Probability theory, Statistics, Optimization, Agile, Machine Learning, Deep learning, Recommender systems","Company: Target
Job Title: Sr Data Scientist - Recommendations
Experience: 3+ years
Skills Needed: 4-year degree in quantitative disciplines or equivalent experience, experience in designing deep learning and machine learning models, strong programming skills in Python, knowledge of SQL, Hadoop/Hive, Spark, and/or Scala, proficiency in mathematical and statistical concepts, excellent analytical and problem-solving skills, ability to create actionable insights, strong communication skills, self-driven and results-oriented, ability to collaborate effectively across",0.1527001842637732,0.30712003
Sr Data Scientist - Optimization/Operations Research,General Mills,"Minneapolis, MN",https://www.linkedin.com/jobs/view/sr-data-scientist-optimization-operations-research-at-general-mills-3754655364,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Position Overview
Do you see patterns or opportunities that others don’t see? Do you enjoying asking questions and analyzing data to deepen your knowledge? Do you like to challenge historical assumptions and recommend new ways to drive action based on data driven insights? Do you like to find the best way to tackle a problem and share the approach with others?
To make the food people love, we need to make sure we feed our decision makers the right data and solutions at the right time, every time. As a Senior Data Scientist at General Mills, you will apply your strong expertise in machine learning, data mining and information retrieval to design, prototype and build next generation advanced analytics engine and services. You will collaborate with product owners, business partners and other Data Scientists in the supply chain space to define technical problem statement and hypothesis to test. In addition, you will develop efficient and accurate analytical models that mimic business decisions.
Key Accountabilities
Work closely with data science leadership, machine learning engineering, and business partners / product owners to develop optimization and machine learning models using best in class tools and technology.
Provide data science leadership within a product team through strong partnership, actionable insights, strategic and tactical technical roadmap recommendations.
Construct production ready, reusable, large scale or scalable complex optimization, simulation & machine learning models that provide real time insights aligning with General Mills technology standards.
Design and development of modelling framework and architecture for deterministic / combinatorial optimization and advanced machine learning to solve complex supply chain problems in variety of areas like supply-demand planning, procurement, manufacturing, logistics etc.
Be a storyteller to explain the ‘why and how’ of data driven recommendations to cross-functional teams.
Responsible for monitoring and improvement of model performance metrics in terms of accuracy, optimal / near optimal recommendations with feedback incorporated from business partners.
Design, prototype and build next generation supply chain engines and services delivering productivity improvement and cost reductions using advanced modelling expertise and literature research.
Be a part of the team, collaborate, ask questions, engage, and solicit feedback from other Data Scientists
In addition to project based work, will be expected to participate in activities such as technical standards definition and modelling documentations
Minimum Qualifications
4+ years of relevant data science experience with at least 1 years of experience in linear optimization
Bachelor’s Degree required in any of quantitative field.
High proficiency with Python programming in developing optimization models using different types of solvers suite.
Hands on experience building IP / MIP models with sound knowledge of supporting algorithms.
Comfortable working with large and dynamic Data Frames & writing complex SQL queries.
Highly adaptable, curious, and willing to work independently on complex and challenging problems.
Bias for action with ability to deliver outstanding results through task prioritization and time management.
Preferred Qualifications
Master's degree in any of the quantitative field (Operations research / Statistics / Industrial engineering) or computer science with commensurate work experience in supply chain technology or data science
Relevant experience in Data Science with a preference for supply chain optimization / operations research experience
Experience with Google Cloud Platform or other cloud platforms
Considerations
We are open to 100% remote candidates with occasional travel based on business needs.
International relocation or international remote working arrangements (outside of the US) will not be considered.
Salary Range
The salary range for this position is $104700.00 - $174600.00 / Annually. At General Mills we strive for each employee's pay at any point in their career to reflect their experiences performance and skills for their current role. The salary range for this role represents the numerous factors considered in the hiring decisions including, but not limited to, educations, skills, work experience, certifications, etc. As such, pay for the successful candidate(s) could fall anywhere within the stated range. Beyond base salary, General Mills offers a competitive Total Rewards package focusing on your overall well-being. We are proud to offer a foundation of health benefits, retirement and financial wellbeing, time off programs, wellbeing support and perks. Benefits may vary by role, country, region, union status, and other employment status factors. You may also be eligible to participate in an annual incentive program. An incentive award, if any, depends on various factors, including, individual and organizational performance.
Show more
Show less","Data Science, Machine Learning, Data Mining, Information Retrieval, Optimization, Simulation, Python, SQL, Data Frames, Linear Optimization, Algorithms, Google Cloud Platform, Cloud Platforms, Operations Research, Industrial Engineering, Tableau, Power BI, Hadoop, Spark, Hive, Pig, R, SAS, NoSQL, MongoDB, Cassandra, HBase, AWS, Azure","Company Name: General Mills  
Job Title: Senior Data Scientist  
Experience: Minimum of 4 years of relevant data science experience with at least 1 year in linear optimization  
Skills Needed: Strong expertise in machine learning, data mining, and information retrieval; proficiency in Python programming for developing optimization models; hands-on experience building IP/MIP models; ability to work with large and dynamic Data Frames and write complex SQL queries; high adaptability, curiosity, and ability to work independently on complex problems; bias",0.16877636903416476,0.68969536
Labs - Data Scientist - Senior Associate,PwC,"Minneapolis, MN",https://www.linkedin.com/jobs/view/labs-data-scientist-senior-associate-at-pwc-3782248695,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Specialty/Competency:
Data Science
Industry/Sector:
Not Applicable
Time Type:
Full time
Travel Requirements:
Up to 20%
A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
Responsibilities
As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities, coaching them to deliver results.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Use a broad range of tools and techniques to extract insights from current industry or sector trends.
Review your work and that of others for quality, accuracy and relevance.
Know how and when to use tools available for a given situation and can explain the reasons for this choice.
Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Our mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.
Basic Qualifications
Job Requirements and Preferences
:
Minimum Degree Required
Bachelor Degree
Additional Educational Requirements
Bachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college.
Minimum Years Of Experience
2 year(s)
Preferred Qualifications
Degree Preferred
:
Master Degree
Preferred Fields Of Study
Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research
Additional Educational Preferences
PhD highly preferred
Preferred Knowledge/Skills
Demonstrates thorough abilities and/or a proven record of success:
Exploring new analytical technologies and evaluate their technical and commercial viability;
Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools;
Working across various data mediums: text, audio, imagery, sensory, and structured data;
Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;
Testing and rejecting hypotheses around data processing and ML model building;
Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;
Building ML pipelines that ingest, clean data, and make predictions;
Focusing on AI and ML techniques that are broadly applicable across all industries;
Staying abreast of new AI research from leading labs by reading papers and experimenting with code;
Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients;
Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);
Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;
Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);
Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;
Building ML models and systems, interpreting their output, and communicating the results; and,
Moving models from development to production; conducting lab research and publishing work.
Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:
Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;
Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);
Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;
Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;
Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;
Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,
Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.
Learn more about how we work: https://pwc.to/how-we-work
PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.
All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.
For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.
Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines
For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate
Show more
Show less","Artificial Intelligence, Machine Learning, Natural Language Processing, Computer Vision, Speech Recognition, Reinforcement Learning, Generative Adversarial Networks, Transformers, Deep Learning, Neural Networks, Convolutional Neural Networks, Recurrent Neural Networks, Long ShortTerm Memory Networks, Gated Recurrent Units, Attention Mechanisms, SelfAttention Mechanisms, MultiHead Attention, Residual Connections, Batch Normalization, Dropout, Data Augmentation, Regularization, Transfer Learning, Feature Engineering, Hyperparameter Tuning, Model Selection, Model Evaluation, Model Deployment, Model Monitoring, Model Maintenance, Big Data, Data Science, Data Analytics, Data Mining, Data Visualization, Data Warehousing, Data Engineering, Cloud Computing, Software Engineering, Full Stack Development, Front End Development, Back End Development, DevOps, Agile Development, Scrum, Kanban, User Experience Design, User Interface Design, Information Architecture, Prototyping, User Testing, Usability Testing, A/B Testing","Company: PwC
Job Title: Senior Associate in Data Science
Experience: Minimum of 2 years
Skills Needed: The ideal candidate should have a Bachelor's degree in Computer and Information Science, Mathematics, Computer Engineering, or related fields with a preference for a Master's degree or PhD. They should have experience in exploring new analytical technologies, working across the entire data pipeline, developing ML models, and staying updated on AI research. Additionally, they should be proficient in programming languages such as Python",0.09961685667262013,0.5436506
"Sr Data Scientist - Recommendations (Applied ML, Deep Learning, Relevance Systems)",Jobs for Humanity,"Minneapolis, MN",https://www.linkedin.com/jobs/view/sr-data-scientist-recommendations-applied-ml-deep-learning-relevance-systems-at-jobs-for-humanity-3790309976,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Job Description
Location: 1000 Nicollet Mall, Minneapolis, Minnesota, United States, (phone number removed)
The pay range for this position is $92,000.00 - $(phone number removed), but may vary based on factors such as education, work experience, and certifications. At Target, we care about our team members and offer comprehensive health benefits and programs, including medical, vision, dental, life insurance, and more. Other benefits include a 401(k) plan, employee discount, short-term and long-term disability, paid sick leave, national holidays, and vacation. Learn more about our benefits at (url removed).
JOIN US AS A SR DATA SCIENTIST – RECOMMENDATIONS
About Us
Target is a Fortune 50 company and one of America's leading retailers. We prioritize caring for our communities and investing in the well-being of our team members. Our purpose is to create joy in everyday life. Our technology and data scientists work to make Target the most convenient, safe, and joyful place to shop. Join our global team of engineers, data scientists, and product managers who prioritize diversity, inclusion, experimentation, and continuous learning.
As a Sr Data Scientist, you will collaborate with a team to build and improve our AI-driven digital Recommendation products using deep learning, machine learning, and optimization techniques. You will use Python and Scala to analyze data, implement algorithms, and find the best solutions. Your responsibilities will also include documenting and presenting your work, understanding business priorities, and developing solutions to meet our needs.
About You
You have a 4-year degree or equivalent experience in a quantitative discipline (Science, Technology, Engineering, Mathematics)
You have 3+ years of professional experience or equivalent industry experience
You have experience designing and developing deep learning, machine learning, and statistical models
You have strong programming skills in Python and knowledge of SQL, Hadoop/Hive, Spark, and/or Scala
You have a good understanding of mathematical and statistical concepts, algorithms, and computational complexity
You have excellent analytical thinking and problem-solving skills
You are able to create actionable insights and communicate them effectively
You are self-driven, results oriented, and able to meet tight deadlines
You are a strong team player and able to collaborate effectively across geographies and time zones
Preferred
You have an MS or PhD in a quantitative field
You have experience with recommender systems
This position offers a Hybrid/Flex work arrangement, where you will work both onsite at our Target HQ MN location and virtually, depending on the needs of your role, team, and tasks. Accommodations will be provided as required by the Americans with Disabilities Act (ADA). If you have a disability and need assistance with the application process, please visit your nearest Target store or Supply Chain Facility or contact Guest Services at (phone number removed).
Show more
Show less","Python, Scala, Deep Learning, Machine Learning, Statistical Models, SQL, Hadoop/Hive, Spark, Mathematical Concepts, Statistical Concepts, Algorithms, Computational Complexity, Analytical Thinking, ProblemSolving, Actionable Insights, Communication, SelfDriven, Results Oriented, Meeting Deadlines, Teamwork, Collaboration","Company: Target
Job Title: Sr Data Scientist - Recommendations
Experience: 3+ years of professional experience or equivalent industry experience
Skills Needed: 
- 4-year degree or equivalent experience in a quantitative discipline
- Experience designing and developing deep learning, machine learning, and statistical models
- Strong programming skills in Python and knowledge of SQL, Hadoop/Hive, Spark, and/or Scala
- Good understanding of mathematical and statistical concepts, algorithms, and computational complexity
- Excellent analytical thinking",0.2634730511411309,0.56175363
Sr. Data Scientist (1020250),The Judge Group,"Eagan, MN",https://www.linkedin.com/jobs/view/sr-data-scientist-1020250-at-the-judge-group-3775909387,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Location:
Eagan, MN
Salary:
$55.00 USD Hourly - $60.00 USD Hourly
Description:
Our client is currently seeking a
Sr. Data Scientist
This role is hybrid in Eagan, MN.
This Job Will Have The Following Responsibilities
Designs experiments, formulates hypothesis, conduct multi-variate statistical analyses, and builds models to drive insights and recommendations.
Develops solutions to key strategic problems (such as the accurate identification of members for gap closure) and quality improvement opportunities thorough traditional and new analytics, including data science methods that will drive improved performance on Center of Excellence initiatives.
Analyzes administrative claims data - Medicare and ACA Marketplace - to answer health services research questions on costs, utilization, or outcomes, using advanced statistical and econometric methods.
Ensures enterprise is employing state-of-the-art methods to Star and Enterprise Risk Adjustment problems by staying up to date on trends in analytics and investigates new tools to implement new methodologies and techniques.
Develops innovative and effective approaches to solve analytics problems.
Effectively communicates results and methodologies. Independently manages multiple projects through the entire predictive model life cycle.
Identifies, translates, and applies best practices to assigned projects.
Collaborates to manage, grow, and develop relationships with team members.
Provides guidance to junior-level analysts on data management, data analysis techniques, communication with non-technical stakeholders, project management, and healthcare industry knowledge.
Qualifications & Requirements:
Master’s degree with a quantitative emphasis, including business, actuarial science, quantitative social science, mathematics, statistics, or computer science required, combined with a minimum 5 years of advanced industry experience in utilizing data analysis methods and tools , OR a PhD and minimum of two years of advanced industry experience utilizing data analysis methods and tools
Demonstrated ability to evaluate quantitative data from multiple sources using statistical modeling, analytical methods, and critical thinking skills.
Demonstrated experience with statistical software suites (e.g. Python, R, SAS).
Strong understanding of database structure, relational database concepts, big data platforms, Cloud environment (AWS, Azure or GCP), and data architecture.
Exposure to Unix environments.
Ability to define problems, collect data, establish facts, and infer valid conclusions.
Strong problem-solving skills exhibited by the ability to approach complex, ambiguous business issues with creative ideas and solution.
Demonstrated experience in collaboration, teamwork, and cross-functional communication.
Effective, concise, and professional written, verbal and presentation skills.
Flexible, self-motivated, and continuously seeking ways to improve.
Nice to Have:
PhD degree in health services research or statistics or related area.
Knowledge of healthcare industry including familiarity with health policy, health insurance, benefit plans and product features, provider contracting approaches, reimbursement approaches and health management approaches.
Knowledge of Risk Adjustment and Stat quality programs is strongly preferred.
Experience identifying disparities in outcomes and designing strategies to close quality care gaps and combat racial health inequity.
Interpreting and applying the NCQA Healthcare Effectiveness Data & Information Set™ (HEDIS®).
Contact:
kgregor@judge.com
This job and many more are available through The Judge Group. Find us on the web at www.judge.com
Show more
Show less","Data Science, Advanced Industry Experience, Statistical Modeling, Analytical Methods, Critical Thinking, Statistical Software, Python, R, SAS, Database Structure, Relational Database, Big Data Platforms, Cloud Computing, AWS, Azure, GCP, Data Architecture, Unix, Problem Solving, Collaboration, Teamwork, Communication, Healthcare Industry, Health Policy, Health Insurance, Benefit Plans, Provider Contracting, Reimbursement, Health Management, Risk Adjustment, Stat Quality, Disparities in Outcomes, Closing Quality Care Gaps, Racial Health Inequity, NCQA Healthcare Effectiveness Data & Information Set, HEDIS","Company: The Judge Group

Job Title: Sr. Data Scientist

Experience: Master’s degree with a quantitative emphasis and a minimum of 5 years of industry experience OR a PhD with a minimum of 2 years of industry experience in data analysis methods and tools

Skills Needed: Ability to design experiments, conduct statistical analyses, and build models, experience in analyzing administrative claims data, proficiency in statistical software suites (e.g. Python, R, SAS), strong understanding of database structure and big data platforms",0.23529411495324432,0.38252234
Sr. Data Scientist,Dice,"Eagan, MN",https://www.linkedin.com/jobs/view/sr-data-scientist-at-dice-3781601343,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Judge Group, Inc., is seeking the following. Apply via Dice today!
Location:
Eagan, MN
Salary:
$55.00 USD Hourly - $60.00 USD Hourly
Description:
Our client is currently seeking a
Sr. Data Scientist
This role is hybrid in Eagan, MN.
This job will have the following responsibilities:
Designs experiments, formulates hypothesis, conduct multi-variate statistical analyses, and builds models to drive insights and recommendations.
Develops solutions to key strategic problems (such as the accurate identification of members for gap closure) and quality improvement opportunities thorough traditional and new analytics, including data science methods that will drive improved performance on Center of Excellence initiatives.
Analyzes administrative claims data - Medicare and ACA Marketplace - to answer health services research questions on costs, utilization, or outcomes, using advanced statistical and econometric methods.
Ensures enterprise is employing state-of-the-art methods to Star and Enterprise Risk Adjustment problems by staying up to date on trends in analytics and investigates new tools to implement new methodologies and techniques.
Develops innovative and effective approaches to solve analytics problems.
Effectively communicates results and methodologies. Independently manages multiple projects through the entire predictive model life cycle.
Identifies, translates, and applies best practices to assigned projects.
Collaborates to manage, grow, and develop relationships with team members.
Provides guidance to junior-level analysts on data management, data analysis techniques, communication with non-technical stakeholders, project management, and healthcare industry knowledge.
Qualifications & Requirements:
Master's degree with a quantitative emphasis, including business, actuarial science, quantitative social science, mathematics, statistics, or computer science required, combined with a minimum 5 years of advanced industry experience in utilizing data analysis methods and tools , OR a PhD and minimum of two years of advanced industry experience utilizing data analysis methods and tools
Demonstrated ability to evaluate quantitative data from multiple sources using statistical modeling, analytical methods, and critical thinking skills.
Demonstrated experience with statistical software suites (e.g. Python, R, SAS).
Strong understanding of database structure, relational database concepts, big data platforms, Cloud environment (AWS, Azure or Google Cloud Platform), and data architecture.
Exposure to Unix environments.
Ability to define problems, collect data, establish facts, and infer valid conclusions.
Strong problem-solving skills exhibited by the ability to approach complex, ambiguous business issues with creative ideas and solution.
Demonstrated experience in collaboration, teamwork, and cross-functional communication.
Effective, concise, and professional written, verbal and presentation skills.
Flexible, self-motivated, and continuously seeking ways to improve.
Nice to Have:
PhD degree in health services research or statistics or related area.
Knowledge of healthcare industry including familiarity with health policy, health insurance, benefit plans and product features, provider contracting approaches, reimbursement approaches and health management approaches.
Knowledge of Risk Adjustment and Stat quality programs is strongly preferred.
Experience identifying disparities in outcomes and designing strategies to close quality care gaps and combat racial health inequity.
Interpreting and applying the NCQA Healthcare Effectiveness Data & Information Set™ (HEDIS®).
Contact:
This job and many more are available through The Judge Group. Find us on the web at
Show more
Show less","Data Science, Analytics, Statistical Modeling, Machine Learning, Python, R, SAS, SQL, Cloud Computing, AWS, Azure, Google Cloud Platform, Unix, Problem Solving, Collaboration, Teamwork, Communication, Healthcare Industry, Health Policy, Health Insurance, Benefit Plans, Provider Contracting, Reimbursement, Health Management, Risk Adjustment, Stat Quality Programs, Disparities in Outcomes, Quality Care Gaps, Racial Health Inequity, NCQA Healthcare Effectiveness Data & Information Set, HEDIS","Company Name: Judge Group, Inc.
Job Title: Sr. Data Scientist
Experience: Minimum 5 years of advanced industry experience with a Master's degree or minimum 2 years with a PhD
Skills Needed: 
- Proficiency in statistical software suites such as Python, R, SAS
- Strong understanding of database structure, big data platforms, and data architecture
- Ability to conduct multivariate statistical analyses and build models for insights and recommendations
- Experience in collaborating, teamwork, and cross-functional",0.23772609550040397,0.49659216
Data Engineer Hybrid,Avani Tech Solutions Private Limited,"Wayzata, MN",https://www.linkedin.com/jobs/view/data-engineer-hybrid-at-avani-tech-solutions-private-limited-3758755186,2023-12-20,Minneapolis,United States,Mid senior,Onsite,"Pay: 75-78/hr
Monday through Friday 8:00AM - 5:00PM CST
Hybrid Work
Need SQL
Job Description
The Data Engineer III will design, build and operate high performance data centric solutions utilizing the comprehensive big data capabilities for the company’s data platform environment.
In this role, you will act as an authority for data access pathways and techniques working with analysts within the functional data analytics team. You will design data structures and pipelines to collect data and design and implement data transformations, combinations or aggregations.
Independently handle complex issues with minimal supervision, while escalating only the most complex issues to appropriate staff. *Other duties as assigned*Help drive the adoption of new technologies and methods within the functional data and analytics team and be a role model and mentor for data engineers.
Build prototypes to test new concepts and be a key contributor of ideas and code that improve the core software infrastructure, patterns and standards.
Provide necessary technical support through all phases of solution life cycle.*Perform data modeling and prepare data in databases for use in various analytics tools and configurate and develop data pipelines to move and optimize data assets.
Develop technical solutions utilizing big data and cloud-based technologies and ensuring they are designed and built to be sustainable and robust.
Participate in the decision-making process related to architecting solutions.
Collaborate with businesses, application and process owners, and product team members to define requirements and design solutions for the company’s big data and analytics solutions.
Minimum Qualifications
Bachelor's degree in a related field or equivalent experience
Four years of related work experience.
Preferred Qualifications
Experience developing data or software applications including analysis, design, coding, testing, deploying and supporting of applications.
Experience working with big data platform.
Experience with reporting tools and data sources.
Show more
Show less","SQL, Data structures, Data pipelining, Data transformations, Data combinations, Data aggregations, Data engineering, Software design, Software implementation, Software testing, Software deployment, Software support, Data modeling, Big data technologies, Cloudbased technologies, Data analytics, Business requirements gathering, Solution design, Collaboration","Company: Not specified
Job Title: Data Engineer III
Experience: Four years of related work experience
Skills Needed: SQL, data modeling, data pipelines, big data platform, reporting tools, software development, cloud-based technologies.

The Data Engineer III role involves designing, building, and operating high-performance data-centric solutions utilizing big data capabilities for the company's data platform. Responsibilities include designing data structures, developing data pipelines, handling complex issues, driving adoption of new technologies, and collaborating with various teams to",0.26666666283472223,0.7095057
Senior Data Scientist Operations Consumer/Mortgage Banking -- Remote,Get It Recruit - Real Estate,"Minneapolis, MN",https://www.linkedin.com/jobs/view/senior-data-scientist-operations-consumer-mortgage-banking-remote-at-get-it-recruit-real-estate-3781740758,2023-12-20,Minneapolis,United States,Mid senior,Remote,"**Job Opportunity - Data Analytics Specialist**
At our organization, we're dedicated to making a meaningful impact. We aim to assist our clients and communities in making informed financial decisions, contributing to growth and prosperity. We believe in the collective power of our team, recognizing that each individual brings their unique potential. Joining us opens doors to a wide array of opportunities at every stage of your career. You'll have the chance to explore, learn, and uncover your true potential, starting from day one.
**Position Overview**
As a Data Analytics Specialist, you will play a crucial role in managing big data and analytics projects. You'll work on gathering and integrating extensive data sets and specialize in developing and programming methods, processes, and systems to consolidate and analyze diverse, unstructured big data sources. Your goal will be to extract valuable insights and solutions for client services and product enhancement. You'll be responsible for acquiring data from multiple sources, performing analyses, implementing predictive models, and maintaining statistical models with a primary focus on big data. Your work will involve identifying, analyzing, and interpreting trends and patterns within complex data to provide answers to business inquiries and recommend actionable strategies. You'll be proficient in utilizing advanced statistical techniques and tools to present data and analysis clearly and concisely, enabling stakeholders to make data-driven decisions. Collaboration with various partners to prioritize requests and providing a comprehensive view of the analysis will be a key aspect of your role. Additionally, you will monitor and measure the results of applied recommendations, ensuring compliance with company standards.
**Requirements**
Eight or more years of relevant experience
Bachelor's degree in a quantitative field, such as statistics, computer science, engineering, or applied mathematics, or equivalent work experience
**Preferred Qualifications**
Strong analytical skills with the ability to extract, collect, organize, analyze, and interpret trends or patterns in complex data sets
Experience in analytics, advanced analytics/statistics, predictive modeling, machine learning, and data visualization
Understanding of machine learning techniques and algorithms
Proficiency in Python, R, SAS, or SQL for data extraction, data mining, and predictive analytics
Demonstrated project management skills
Effective interpersonal, verbal, and written communication skills
**Benefits**
Benefits
We understand that well-rounded benefits are essential for a fulfilling life, both inside and outside of work. Our benefits are designed to support your health, financial security, and peace of mind. Some of the benefits we offer include:
Healthcare (medical, dental, vision)
Basic term and optional term life insurance
Short-term and long-term disability
Pregnancy disability and parental leave
401(k) and employer-funded retirement plan
Paid vacation (ranging from two to five weeks based on salary grade and tenure)
Up to 11 paid holiday opportunities
Adoption assistance
Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law
**Equal Opportunity Employer**
We are committed to building a diverse workforce. All qualified applicants are considered without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability, or veteran status, among other factors.
**E-Verify**
We participate in the U.S. Department of Homeland Security E-Verify program. This internet-based system verifies employment eligibility and is operated by the U.S. Citizenship and Immigration Services.
**Compensation Range**
The salary range listed reflects figures based on the primary location, which is listed first. Actual salaries may vary depending on your role's location. In addition to your salary, we offer a comprehensive benefits package, including incentive and recognition programs, equity stock purchase, 401(k) contributions, and pension (eligibility requirements apply).
**Application Note**
If you require accommodations due to a disability during any part of the application or hiring process, please refer to our disability accommodations for applicants.
Employment Type: Full-Time
Show more
Show less","Data Analytics, Big Data, Data Mining, Predictive Modeling, Machine Learning, Data Visualization, Python, R, SAS, SQL, Statistics, SQL, Project Management, Communication","Company Name: Not specified
Job Title: Data Analytics Specialist
Experience: Eight or more years of relevant experience
Skills Needed: Bachelor's degree in a quantitative field, strong analytical skills, experience in analytics and predictive modeling, proficiency in Python, R, SAS, or SQL, project management skills, effective communication skills
Summary: The Data Analytics Specialist position requires a minimum of eight years of experience and a bachelor's degree in a quantitative field. The role involves managing big data projects, developing predictive models",0.14655172195043104,0.7128924
Senior Data Analytics Engineer,When I Work,"Minneapolis, MN",https://www.linkedin.com/jobs/view/senior-data-analytics-engineer-at-when-i-work-3785765740,2023-12-20,Minneapolis,United States,Mid senior,Remote,"When I Work is a remote first company. We are open to hiring candidates in the continental US and Ontario, Canada. If an onsite location is important to you in your search, you are welcome to work from our Minneapolis HQ office.
Who We Are
We help hourly teams get shift done.
At When I Work, everything we do starts with a mission to make shift work awesome. We deliver on that mission by making every piece of hourly workforce management - scheduling, time tracking, shift trading, team messaging, and more - easy and straightforward for managers and employees alike.
The Data and RevOps team at When I Work is a group of inquisitive and driven individuals who love solving problems using data. We have built a best-in-class data environment and fuel insights throughout the organization on our product and customers. We work collaboratively together, invest in our processes and tooling, and move slow to move fast. We focus on projects that will have a big impact to the company and work to enable anyone to be a savvy data user.
What You'll Do
Over the last few years we have been building out a best-in-class data environment that we've used to transform When I Work into a data-driven company. You will be a key contributor extracting value from this environment as well as develop and sustain data projects and analysis that will have significant impact to our company and our users.
Proactively identify opportunities to build out solutions or use internally stored data to provide value to the business
Design and implement scalable ETLs
Own end to end design and implementation of analytical project scope to turn raw data into actionable insight
Work closely with internal teams across the business (Product, GTM, etc.) to understand their analytical needs and help empower them to find success in their initiatives through data
Clearly articulate analytical findings to both technical and non-technical stakeholders
Work with data visualization tools to help end users answer pertinent questions
Make use of statistical modeling / machine learning in order to advance business outcomes
Who You Are
As a Senior Data Analytics Engineer, you are eager to use data to solve business problems and guide data-driven decision making across an entire organization. You enjoy the end to end process of data analytics. You are a maker at heart who enjoys being in the code while also uncovering new product and business opportunities through whatever methods and tools are right for the task. You enjoy collaborating with a team, but you also have the ability to work independently when needed to get things done. Above all, you are broadly curious, driven to learn and a motivated problem solver who wants to help tackle the new and interesting challenges that we encounter as a fast-growing startup.
Experience And Skills Needed
3+ years of experience in data science or data analytics
You have strong programming fundamentals
You are comfortable with agile, collaborative coding processes
You can distinguish signal from noise in complex data sets
You have experience with Python or another, similar programming language
You have solid, hygienic SQL skills
You have experience modeling data to support both consistent and generic usage patterns
You have significant experience with both structured and unstructured data
Experience modeling data within OLAP relational data stores
You have familiarity with cloud computing environments and infrastructure
You have experience taking technical analytics work and presenting in a form that non-technical users are able to glean the significance of your findings
You practice empathy and kindness, and you look to help others
What Would Be Awesome To Have
Advanced Python and data package (Numpy, Pandas, etc.) skills
You are a proponent of DevOps and enthusiastic about DataOps
You are comfortable with different data modeling techniques (Star Schema, Snowflake, DV2, etc.)
Have experience with a data warehouse platform (Redshift, Snowflake, etc.)
Experience with S3 based data lake and parquet file format
What's In It For You
Professional development allowance
Paid parental leave
Medical benefits - employee premiums paid 100% by When I Work
Dental benefits- employee premiums paid 100% by When I Work
Paid vacation and holidays
Flexible work environment
401K Match
Remote first culture including home office set-up stipend and ongoing telecommuter stipend
Casual dress code
Dynamic and dedicated team
We believe actions speak louder than words. Every encounter with our people and products should be memorable and helpful. Challenges are exciting, failure is how we learn, and we all have an entrepreneurial spirit. Building an inclusive and equitable workplace isn't lip service. We invest our time and our money in organizations that are not only working to diversify the current jobscape, but also investing in the future of talent. We're motivated by a strong, innovative, and passionate work culture and we're constantly searching for ways to improve and get shift done.
Whether you're a perfect match or not, if it sounds like a good fit, we encourage you to apply.
The tech industry is notorious for its lack of diverse representation, and we're aware of the research showing that historically underrepresented groups are less likely to apply to a job if they don't believe that they meet all of the criteria. Are you hesitant to submit an application because you're not sure if you check every box? Apply anyway! We would love to hear from you and figure out what you can add to the culture here at When I Work.
We'd love to talk to you! Please submit the following to apply:
Resume (including months/years of employment for each position).
Cover letter including:
an overview of your existing experience
a convincing reason why you'd like to work at When I Work.
Must already be authorized to work in the United States or Canada on a full-time basis for any employer.
Show more
Show less","Data analytics, Data science, Programming, Python, SQL, Data modeling, Cloud computing, DataOps, Data visualization, Agile development, Data warehouse, Data lake, OLAP, Machine learning, Statistical modeling","Company Name: When I Work  
Job Title: Senior Data Analytics Engineer  
Experience: 3+ years in data science or data analytics  
Skills Needed: Strong programming fundamentals, agile coding processes, signal identification in complex data sets, Python or similar language proficiency, hygienic SQL skills, data modeling expertise, experience with structured and unstructured data, OLAP relational data stores, cloud computing familiarity, technical analytics presentation skills, empathy and kindness  

The Senior Data Analytics Engineer at When I Work plays a",0.1347517711483326,0.40578717
Analytics Consultant (Dataiku),phData,"Minneapolis, MN",https://www.linkedin.com/jobs/view/analytics-consultant-dataiku-at-phdata-3775779344,2023-12-20,Minneapolis,United States,Mid senior,Remote,"Join phData, a dynamic and innovative leader in the modern data stack. We partner with major cloud data platforms like Snowflake, AWS, Azure, GCP, Fivetran, and dbt to deliver cutting-edge services and solutions. We're committed to helping global enterprises overcome their toughest data challenges. Even though we're growing extremely fast, we maintain a casual, exciting work environment. We hire top performers and allow you the autonomy to deliver results.
4x Snowflake Partner of the Year (2020, 2021, 2022, 2023)
#1 Partner in Snowflake Advanced Certifications
600+ Expert Cloud Certifications (Fivetran, dbt, Sigma)
7x Best Places to Work
Inc 5000 Fastest Growing US Companies (2020-2023)
Overview:
We’re looking for a talented Senior Analytics Consultant to help our customers gain tangible value from their data. Our consulting services emphasize analytics enablement, data visualization, data preparation, and data science. We specialize in Tableau, PowerBI, Sigma, Alteryx, KNIME, Power Platform and Snowflake.
Responsibilities:
Deliver project-based consulting engagements to help clients develop analytical solutions; activities include requirements gathering, prototyping, analytics engineering, and visualization.
Manage clients expectations by leading weekly status reports to clients; proactively soliciting client feedback by running working sessions
Create reporting and data visualization solutions
Analyze, troubleshoot and / or tune product performance or deployment issues when required
Support or assist with backlog support and development
Identify and recommend functionality and solutions that would meet and enhance user experience
Required Experience:
3+ years of relevant experience and/or demonstrated expertise in data analytics and data visualization platforms
Expertise in Dataiku, plus if paired with other tools such as Alteryx, KNIME, or Matillion
Proven experience to create scalable, durable analytics solutions
Eagerness to learn new data visualization tools
Demonstrated expertise in data fluency and communicating to business users
Knowledge of SQL and experience leveraging data warehouse, data marts, and/or data models
Exceptional customer facing skills, including but not limited to communication and project management
Strong problem solving skills with a passion for learning and mastering new technologies, techniques, and procedures
Preferred Experience:
1+ years of Consulting experience
Experience with data visualization, ideally in one of the following: Tableau, Power BI, Sigma
Experience with Snowflake
Experience with Python and/or R scripting
Why phData? We offer?
Remote-First Work Environment
Casual, award-winning small-business work environment
Collaborative culture that prizes autonomy, creativity, and transparency
Competitive comp, excellent benefits, 4 weeks PTO plus 10 Holidays (and other cool perks)
Accelerated learning and professional development through advanced training and certifications
Show more
Show less","Snowflake, AWS, Azure, GCP, Fivetran, Dbt, Tableau, PowerBI, Sigma, Alteryx, KNIME, Power Platform, Dataiku, Matillion, SQL, Data warehouse, Data marts, Data models, Python, R scripting","Company Name: phData
Job Title: Senior Analytics Consultant
Experience: 3+ years of relevant experience in data analytics and data visualization platforms
Skills Needed: Expertise in Dataiku, Alteryx, KNIME, or Matillion; proficiency in creating scalable analytics solutions; eagerness to learn new data visualization tools; strong data fluency and communication skills; knowledge of SQL and experience with data warehouse and data models
Preferred Skills: Consulting experience, experience with Tableau, Power BI,",0.204819274425352,0.67010784
Senior Data Scientist,Jobs for Humanity,"Brooklyn Park, MN",https://www.linkedin.com/jobs/view/senior-data-scientist-at-jobs-for-humanity-3784531316,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"Company Description
Jobs for Humanity is partnering with Target to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: Target
Job Description
Job Opportunity: Senior Data Scientist at Target
Location: 7000 Target Pkwy N, Brooklyn Park, Minnesota, United States, 55445
Salary Range: $96,283.00 - $165,600.00 per year
About Target:
Target cares about and invests in its team members, providing comprehensive benefits and programs to support their well-being and the well-being of their families. These benefits include medical, vision, dental, life insurance, and more. Other benefits include 401(k), employee discount, short term disability, long term disability, paid sick leave, paid national holidays, and paid vacation. Find more information about the benefits offered by Target at https://corporate.target.com/careers/benefits.
Position:
Senior Data Scientist
Location:
7000 Target Parkway N, Brooklyn Park, MN 55445
Responsibilities:
Code for scalable time series forecasting
Schedule and monitor workflows
Query and analyze relational databases
Apply software development principles
Collaborate within Data Sciences and Product teams
Perform data exploration and analysis
Implement algorithmic solutions
Create well-maintained and tested code with documentation
Follow best practices in data analysis and understanding
Collaborate on product and provide technical support
Document and present work
Participate in code reviews
Tools/Technologies:
Scala, Spark, Spark SQL, Shell script, Apache Oozie, Apache Hive, Python, R, and Git
Requirements:
Master's degree in Data Science, Mathematics, or closely related field
Minimum 2 years of experience in mathematics working with MATLAB, pair programming, and creating interactive visualizations/simulations
Minimum 6 months of experience developing algorithms/models for time series forecasting, querying and analyzing data, and using high performance computing techniques
Experience with Git, Python, and command line tools
How to Apply:
Option 1:
Apply online at jobs.target.com, Job ID: R0000323300
Option 2:
Send your resume to Target.Recruitment@Target.com and reference R0000323300
Americans with Disabilities Act (ADA):
Target is committed to providing reasonable accommodations during the application process to ensure compliance with applicable laws. If you have a disability and require assistance, please visit your nearest Target store or Supply Chain Facility or contact Guest Services at 1-800-440-0680 for more information.
Show more
Show less","Scala, Spark, Spark SQL, Shell script, Apache Oozie, Apache Hive, Python, R, Git, MATLAB, Pair programming, Time series forecasting, Data querying, Data analysis, Highperformance computing, Command line tools","Company Name: Target  
Job Title: Senior Data Scientist  
Experience: Minimum 2 years  
Skills Needed: Scala, Spark, Spark SQL, Shell script, Apache Oozie, Apache Hive, Python, R, Git  
Location: 7000 Target Pkwy N, Brooklyn Park, Minnesota, United States, 55445  

Target is seeking a Senior Data Scientist to join its team at the Brooklyn Park location. The successful candidate will be responsible for coding scalable time series forecasting, scheduling",0.2580645132291604,0.5594194
Data Scientist,Diverse Lynx,"Minneapolis, MN",https://www.linkedin.com/jobs/view/data-scientist-at-diverse-lynx-3764428006,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"Role: Data Scientist
Onsite Location :
Minneapolis, NJ
Duration: 12&plus; Months
Requirement
5&plus; years relevant real-world experience researching, developing, and delivering high impact data driven insights through machine learning.
Deep understanding of supervised, unsupervised, reinforcement machine learning and NLP / NLU / LLM techniques.
High proficiency in exploratory data analysis, data profiling, and feature engineering on large structured and unstructured datasets.
In depth knowledge and hands-on computer programming in SQL, Python, R or similar programming language.
Excellent written and verbal communication and consultancy skills - ability to succinctly communicate results and tell compelling stories with data to any audience.
Deep knowledge of probability, statistics and machine learning algorithms and be able to determine when to apply them.
Familiarity with big data platforms (like Spark, Databricks), machine learning frameworks (like Tensorflow, Keras, MXNet or PyTorch) and libraries (like scikit-learn, numpy, pandas, and scikit-learn) and ability to learn new technologies quickly.
Knowledge of Azure, or similar cloud platforms.
Experience presenting to both technical and non-technical audiences and a history of publications or presentations at conferences is a plus
Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.
Show more
Show less","Data Science, Machine Learning, NLP, NLU, LLM, EDA, Data Profiling, Feature Engineering, SQL, Python, R, Probability, Statistics, Machine Learning Algorithms, Spark, Databricks, Tensorflow, Keras, MXNet, PyTorch, ScikitLearn, Numpy, Pandas, Azure, Cloud Platforms","Company: Diverse Lynx LLC

Job Title: Data Scientist

Experience: 5+ years

Skills Needed:
- Researching, developing, and delivering data-driven insights through machine learning
- Understanding of supervised, unsupervised, reinforcement machine learning, NLP, and LLM techniques
- Proficiency in exploratory data analysis, data profiling, and feature engineering
- Programming in SQL, Python, R, or similar languages
- Strong communication and consultancy skills
- Knowledge of probability",0.3083700404735198,0.6953818
Sr Data Scientist,Aspen Technology,"Medina, MN",https://www.linkedin.com/jobs/view/sr-data-scientist-at-aspen-technology-3764324012,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"The driving force behind our success has always been the people of AspenTech. What drives us, is our aspiration, our desire and ambition to keep pushing the envelope, overcoming any hurdle, challenging the status quo to continually find a better way. You will experience these qualities of passion, pride and aspiration in many ways — from a rich set of career development programs to support of community service projects to social events that foster fun and relationship building across our global community.
The Role
AspenTech is the world's leading supplier of asset optimization software solutions and operates from 30 locations worldwide. We are uniquely positioned to shape a sustainable future for capital-intensive industries. From our roots at MIT over 40 years ago to technology breakthroughs today that extend the reach of optimization, AspenTech has always been at the forefront of innovation. AspenTech Research & Development is a 600–person team of industry-leading experts in the field of process modelling, control, planning, and optimization. On this team, you will have the opportunity to turn creative ideas into reality, affecting products that are utilized by hundreds of thousands of users worldwide.
As a Senior Data Scientist in our rapidly growing AI Team, you'll have the opportunity to work on the next generation of Industrial AI infrastructure and applications. You will develop and investigate hypotheses, structure experiments, and build mathematical models to understand data patterns, relationships and prescribe actions. We are looking for sharp, disciplined, and highly quantitative individuals passionate about playing with data in all its forms and transforming raw data into actionable and prescriptive insights. You will leverage your skills and passion for Machine Learning, AI, and Cognitive Computing to drive AspenTech's Artificial Intelligence vision by developing groundbreaking software solutions.
Your Impact
Design and develop new data-driven solutions for industrial applications combining data science with domain expertise.
Collaborate with customers, product managers, designers, and developers to understand customer needs and translate them into product requirements and specifications.
Investigate new and developing technologies as they appear in industry and academia and determine how to leverage these new technologies into our software applications.
Contribute to Aspen Technology’s intellectual property footprint in the space of AI.
Innovative and build creative solutions by embracing constraints.
A team player that value collaboration.
Hypothesis and data driven.
Action and result oriented in a challenging environment.
User Focus and put yourself in the user's shoes.
Show ownership by identifying and managing the trade-off between risks and opportunities, taking responsibility for the quality of technical deliverables.
What You'll Need
MSc or PhD with a strong quantitative focus, such as Computer Science, Statistics, Data Science, Engineering, Physics, Math or a related field.
3+ years of experience in data science projects and software development.
Track record of experience in Python programming, including data science specific packages, such as Pandas, Numpy, TensorFlow, PyTorch, Scikit-Learn etc.
Experience with machine learning algorithms (regression, deep learning, time series analysis, predictive modelling, data mining, cognitive computing, natural language processing).
Familiarity with rapid prototyping.
Experience with modern data stack, microservices and cloud architecture.
Familiarity with containers and ML CI/CD pipelines.
Experience in building training and inference pipelines.
Understand the full lifecycle of Data Science projects.
Problem-solving ability and attention to details.
Excellent interpersonal, communication, writing, and presentation skills.
Demonstrated ability to convey complex information in a clear and concise manner.
Show more
Show less","Machine Learning, AI, Cognitive Computing, Data Science, Python, Pandas, Numpy, TensorFlow, PyTorch, ScikitLearn, Microservices, Cloud Architecture, Containers, ML CI/CD Pipelines, Data Mining, Natural Language Processing, Regression, Deep Learning, Time Series Analysis, Predictive Modelling, Statistical Modeling, ProblemSolving, DataDriven, Rapid Prototyping","Company Name: AspenTech

Job Title: Senior Data Scientist

Years of Experience: 3+ years

Skills Needed: The ideal candidate should have a MSc or PhD with a strong quantitative focus in fields like Computer Science, Statistics, Data Science, Engineering, Physics, Math, or related area. They should have at least 3 years of experience in data science projects and software development. Proficiency in Python programming and data science specific packages such as Pandas, Numpy, TensorFlow, Py",0.18446601689473563,0.56567293
Staff Data Scientist,RVO Health,"Minneapolis, MN",https://www.linkedin.com/jobs/view/staff-data-scientist-at-rvo-health-3741488869,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"AT A GLANCE
We are looking to hire a staff machine learning engineer to join our RVO Health data science team. We are building an industry leading healthcare platform that will integrate the consumer health journey and help consumers access the right information, care, products, and services at the right time, bringing differentiated value to the lives of millions of people. We are a new joint venture formed via a partnership between Red Ventures, one of the world’s premier digital and consumer analytics companies, and UnitedHealth Group, one of the largest healthcare providers in the world. We're developing applications that will impact how we produce media, personalize our site experience, scale our teammates' reach, and provide our services to every consumer. We're a growing team made up of a mix of data scientists, machine learning engineers, analytics engineers, data engineers, and product managers. We welcome candidates from different backgrounds and believe that diverse, inclusive teams are better teams.
Where You'll Be
To prioritize togetherness, culture, and accountability, RVO Health operates on a hybrid in-office work schedule. We expect employees to work from our Minneapolis office Tuesday, Wednesday and Thursday each week. You are welcome to work remotely Mondays and Fridays if you wish.
11000 Optum Cir Eden Prairie, MN 55344
What You’ll Do
Create and refine ML/AI algorithms, to support the development of digital health solutions
Create innovative data science solutions to create value for consumers and business by advancing technology ideas into proofs of concept.
Initiate and lead the execution of data science research and product development often with cross-functional, multidisciplinary teams. Collaborate with stakeholders to drive decisions.
Collaborate with Technical Product Managers and Software Engineers to integrate AI and machine learning models into our products
Act as an effective technical liaison to the business leaders. Work effectively across business, creative, and engineering groups to build a positive culture.
Mentor and/or manage junior members on the team and internally serve as a subject matter expert. Contribute to the cross-organization technology strategy and roadmap for data science.
Research the state of the art of machine learning, AI, statistical modeling and optimization technologies, and their applications in digital marketing, digital media and e-commerce.
Help create and promote an inclusive environment where team members feel comfortable and empowered.
What We’re Looking For
6+ yrs of professional experience in a data science role with an MS or PhD in STEM with a focus in ML, statistical modeling, or optimization.
Proven experience in data science and machine learning, preferred experience on healthcare applications and AI
Our core problems to solve are:
Website personalization - using contextual multi-armed bandits and other reinforcement learning approaches.
Generative AI Application - leveraging recent advances of large language models and their derivatives to innovate on the current site experiences and create net new user experiences.
Recommender systems - represent a large user and item space in a way to efficiently retrieve and rank personalized recommendations to our users.
Preferred Qualifications
Expert knowledge of deep learning applied to a relevant domain like NLP or representation learning, e.g. RNNs, LSTMs, Transformers and associated libraries - tensorflow, keras, or pytorch.
Experience working with LangChain, vector databases, or other LLM related tools
Ability to own key deliverables and use problem solving to deliver projects on time and iterate when justified by potential, incremental value.
Entrepreneur mindset with strong business acumen and capability of coming up with creative ideas to generate value for consumers and business with a proven track record of advancing research ideas into production.
Proficiency in Python
Experience leveraging technical expertise to identify the feasibility of potential machine learning projects, ensuring the team is delivering value on feasible projects.
Familiarity with healthcare data standards, EHR systems, and medical terminologies (e.g., HL7, ICD-10, SNOMED CT) is a plus
Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.
Starting Salary: $138,700 - $190,000
Note actual salary is based on geographic location, qualifications and experience
Access to a Free Udemy for Business subscription—thousands of hours of learning content on hundreds of different subjects at your fingertips
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
This position may occasionally require travel for training and other work-related duties.
Who We Are
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group’s Optum Health. Together we’re focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy
Show more
Show less","Machine Learning, Deep Learning, AI, NLP, Representation Learning, Recommender Systems, Reinforcement Learning, Generative AI, Healthcare Data Standards, EHR Systems, Medical Terminologies, Python, TensorFlow, Keras, PyTorch, LangChain, Vector Databases","Company: RVO Health
Job Title: Staff Machine Learning Engineer
Experience: 6+ years of professional experience in a data science role with an MS or PhD in STEM with a focus in ML, statistical modeling, or optimization
Skills Needed: Proficiency in Python, expert knowledge of deep learning applied to a relevant domain like NLP or representation learning, experience with LangChain, vector databases, or other LLM related tools, ability to own key deliverables and use problem-solving to deliver projects",0.14814814639274693,0.6127843
PeopleSoft HR Data Analyst,Diverse Lynx,"Minneapolis, MN",https://www.linkedin.com/jobs/view/peoplesoft-hr-data-analyst-at-diverse-lynx-3764424171,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"We are in need of a PeopleSoft HR data analyst to support the daily reconciliation process between PeopleSoft HR and Oracle HCM. Understanding of PeopleSoft HR data and tables, review, and analysis of large data extracts in Excel, identify issues and find data resolution approaches. Loading data to PeopleSoft HR an Oracle HCM Core HR with the focus on PeopleSoft HR.
The Role is predominantly a People Soft HR skill set with Excel analysis skills. Oracle HCM Cloud HR is a secondary skill set as the consultant will gain exposure to the Oracle module but should be content working in PeopleSoft HR for the majority of the role.
5 – 6 years PeopleSoft HR Experience
5- 6 years working in Data analysis using Excel
Less than 1 year Oracle HCM experience
Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.
Show more
Show less","PeopleSoft HR, Data analysis, Excel, Oracle HCM Cloud HR, Data reconciliation, Data extraction, Data resolution, Data loading, SQL, Tableau","Company: Diverse Lynx LLC
Job Title: PeopleSoft HR Data Analyst
Experience: 5-6 years of PeopleSoft HR experience, 5-6 years of data analysis using Excel, less than 1 year of Oracle HCM experience
Skills Needed: Understanding of PeopleSoft HR data and tables, Excel analysis skills, ability to review and analyze large data extracts, identify issues, find data resolution approaches, loading data to PeopleSoft HR and Oracle HCM Core HR. Focus on",0.3658536543961928,0.8731222
"IT Staff Engineer, Data Architect - Legence",Legence,"Minneapolis, MN",https://www.linkedin.com/jobs/view/it-staff-engineer-data-architect-legence-at-legence-3774672925,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"Legence , a Blackstone portfolio company, is an Energy Transition Accelerator™ that provides advisory services and implementation focused on financing, designing, building, and servicing complex systems in mission-critical and high performance facilities. With five decades of expertise in the built environment, Legence has a proven track record of reducing carbon emissions, implementing renewables, lowering utility costs through efficiency consumption, and making systems run better at unmatched speed and scale.
This is an IT staff engineer role that is responsible for enterprise data architecture, design, standards, modeling, and data management.
This role will include collaboration with multiple stakeholders, both business and IT. This role may include 20% of travel.
Responsibilities:
Build data models for database structures, analytics, and AI applications.
Design, document, build, and implement database architectures and applications.
Develop measures that ensure data accuracy, integrity, and accessibility.
Monitor, refine, and report enterprise data management system performance.
Develop and enforce enterprise database development standards.
Develop enterprise data strategy in collaboration with IT and company management.
Create and maintain an inventory of the enterprise data.
Build and maintain enterprise data pipelines.
Maintain data architecture procedures and artifacts in our enterprise repository.
Skills:
Relational database management systems, SQL Server, Oracle, PostgreSQL
Data modeling, migration, and visualization
Proficiency with SQL and modern programming languages
Data management and reporting technologies
Experience with both structured and unstructured data
Information management and data processing
Enterprise resource planning systems experience
Machine learning, predictive modeling, and natural language processing
Power BI experience
Hadoop and MapReduce experience is a plus.
Very good communication skills, including technical writing.
Applied mathematics and statistics skills.
Education:
Bachelor’s degree in computer science, management information systems, mathematics, statistics, or related field.
Experience:
At least 5 years in data architect/analyst/engineer roles in a large enterprise setting.
We are unable to provide immigration sponsorship for this position.
Health And Welfare Benefits
Health and Welfare
Medical
Dental
Vision
Prescription drug
Employee assistance program
Personal Benefits
Paid vacation
Company-paid holidays
Sick leave
Bereavement leave
Jury duty
Financial Benefits
401(k) retirement savings plan
Company-paid long-term disability insurance
AD&D insurance
Life insurance
Contingent Employment Statement
Offers of employment for this role may be contingent upon successfully passing a background check and/or drug screen. Execution of screens will vary based on role requirements and Company policy. All background checks and drug screens will be done in accordance with applicable federal, state, or local law.
Equal Employment Opportunity Employer
Legence and its affiliate companies are proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), parental status, national origin, age, disability, genetic information (including family medical history), political affiliation, military service, other non-merit-based factors, and any other characteristic protected under applicable local, state or federal laws and regulations.
EEO is the Law
Reasonable Accommodations
If you require assistance applying online, email ta@wearelegence.com . Please include a description of the specific accommodations you are requesting as well as the job title and requisition number of the position for which you are applying. If you are selected for an interview, please notify your recruiter of your accommodation needs. All efforts to provide reasonable accommodations will be made.
To all recruitment agencies
Legence and its affiliate companies do not accept unsolicited agency resumes. Do not forward resumes to our career’s alias or employees of Legence and/or its affiliate companies. Legence and/or its affiliate companies are not responsible for any fees related to unsolicited resumes. Any third-party recruiting agreements for Legence and its affiliate companies may only be executed by Legence Holdings LLC’s CHRO or Director of Talent Acquisition, without exception. All others are done without proper authorization and will not be honored. We will not be responsible for any fees under any third-party recruiting agreement not executed by said authority.
Pay Transparency Nondiscrimination Provision
Legence and its affiliate companies will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)
Apply Now
Show more
Show less","Enterprise Data Architecture, Relational Database Management Systems, SQL Server Oracle PostgreSQL, Data Modeling Migration and Visualization, SQL, Modern Programming Languages, Data Management and Reporting Technologies, Information Management and Data Processing, Artificial Intelligence, Machine Learning, Predictive Modeling, Natural Language Processing, Hadoop, MapReduce, Communication Skills, Technical Writing, Applied Mathematics, Statistics","Company Name: Legence
Job Title: IT Staff Engineer - Data Architecture
Experience: At least 5 years in data architect/analyst/engineer roles in a large enterprise setting
Skills Needed: 
- Relational database management systems (SQL Server, Oracle, PostgreSQL)
- Data modeling, migration, and visualization
- Proficiency in SQL and modern programming languages
- Data management and reporting technologies
- Experience with structured and unstructured data
- Information management and data processing
- Enterprise",0.16498993776421103,0.68492633
Senior Cloud Data Engineer,BDO USA,"Minneapolis, MN",https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765472150,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"Job Description
Job Summary:
This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.
Job Duties
Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
Listens to client needs to align solution with business requirements and delivery schedule
Creates written functional and technical designs
Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
Assists with implementation of data governance programs and best practices
Performs the cleaning and transforming of data from source systems into analytics models
Implements models to support data visualizations and integrations
Assists with implementing DevOps, DataOps and MLOps methodologies on projects
Writes custom integration logic in applicable programming languages
Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
Assists clients with licensing, security, and cost estimation of solutions
Performs code reviews to ensure adherence to standards
Works directly with clients and team members to establish secure data analytics platforms and infrastructure
Contributes to successful deployments of developed solutions and integration of DevOps tools
Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
Builds client relationships during project execution, effectively becoming a trusted advisor of the client
Participates in support activities for existing software solutions
Other duties as assigned
Supervisory Responsibilities
Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product
Education
Qualifications, Knowledge, Skills and Abilities:
High School Diploma or GED equivalent, required
Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred
Experience
Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
One (1) or more years of experience technically leading development projects, preferred
One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred
Software
Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
Experience with one (1) or more of the following computer languages, preferred:
C#
Python
Java
Scala
Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
Experience with Git and DevOps deployment technologies, preferred
Experience with Linux, preferred
Experience with one (1) or more of the following, preferred:
Data Lake Medallion Architecture
Batch and/or streaming data ingestion into a data lake
AI Algorithms/Machine Learning
Automation tools such as UiPath, Alteryx, etc.
Computer Vision based AI technologies
Other Knowledge, Skills & Abilities
Ability to work with a high degree of professionalism and autonomy
Excellent verbal and written communication skills
Solid organizational skills, especially the ability to meet project deadlines with a focus on details
Ability to successfully multi-task while working independently or within a group environment
Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
Ability to interact effectively with people at all organizational levels of the Firm
Ability to effectively interact with a team of professionals and delegating work assignments, as needed
Ability to build and maintain strong relationships with internal and client personnel
Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel
Keywords:
Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL
Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.
California Range: $111,000 - $152,000
Colorado Range: $111,000 - $152,000
New York City/ Valhalla Range: $111,000 - $152,000
Washington Range: $111,000 - $152,000
About Us
BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
Unparalleled partner-involvement
Deep industry knowledge and participation
Geographic coverage across the U.S.
Cohesive global network
Focused capabilities across disciplines
BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.
BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.
Some Examples Of Our Total Rewards Offerings Include
Competitive pay and eligibility for an annual performance bonus.
A 401k plan plus an employer match
Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
Paid Parental Leave
Adoption Assistance
Firm paid life insurance
Wellness programs
Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance
Above offerings may be subject to eligibility requirements.
Click here to find out more!
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.
""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""
Show more
Show less","Data Analytics, Business Intelligence, Artificial Intelligence, Application Development, Cloudbased Data Analytics Solutions, SQL, Data Warehousing, Data Modeling, Semantic Model Definition, Star Schema Construction, Azure, AWS, C#, Python, Java, Scala, Microsoft Fabric, Power BI, Azure Analysis Services, DevOps, Linux, Data Lake Medallion Architecture, Batch, Streaming Data Ingestion, AI Algorithms, Machine Learning, Automation Tools, UiPath, Alteryx, Computer Vision based AI Technologies, Professionalism, Autonomy, Verbal Communication, Written Communication, Organizational Skills, Ability to Meet Deadlines, Ability to MultiTask, Ability to Work Independently, Ability to Work in a Team, Ability to Work in a DeadlineDriven Environment, Ability to Handle Multiple Projects, Ability to Interact Effectively, Ability to Build and Maintain Relationships, DataOps","Company Name: BDO USA, P.A.
Job Title: Data Analytics Specialist
Experience: Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
Skills Needed: Strong SQL skills, experience with Data Warehousing, Data Modeling, hands-on delivery experience with cloud analytics platforms (Azure or AWS), proficiency in languages such as C#, Python, Java, Scala, familiarity with DevOps deployment technologies, Git, Linux, and expertise in",0.13024601869862887,0.6158662
Senior Staff AI Data Engineer,Recruiting from Scratch,"Minneapolis, MN",https://www.linkedin.com/jobs/view/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759710402,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/
This is a hybrid role based in our
Palo Alto,
San
Francisco or Chicago
offices and will require you to be in office Tuesdays and Thursdays.
What’s so interesting about this role?
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.
What’s the job?
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.
Responsibilities:
Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure
What We’ll Love About You
Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)
We’ll really swoon if you have
2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects
What You'll Love About Us
Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/
Show more
Show less","Python, Java, SQL, Bash, Git, Pandas, R, Airflow, Kubernetes, Helm, PySpark, NoSQL, Snowflake, Docker, AWS, GCP, Azure, SparkStreaming, Storm, Kafka, Machine Learning","Company Name: Recruiting from Scratch  
Job Title: Data Engineer Lead  
Experience: 5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience  
Skills Needed: 
- Bachelor's in Computer Science, Mathematics, Physics, or related fields  
- Experience in statistical analysis & visualization using Pandas or R  
- Designing and building highly available distributed systems of data extraction, ingestion, normalization,",0.1743970295902878,0.58313906
"Senior Data Engineer, Talent Analytics",RVO Health,"Minneapolis, MN",https://www.linkedin.com/jobs/view/senior-data-engineer-talent-analytics-at-rvo-health-3766410446,2023-12-20,Minneapolis,United States,Mid senior,Hybrid,"AT A GLANCE
RVO Health is looking to grow our Talent Analytics team by adding a Senior Data Engineer. In this role, you’ll be challenged to help shape our Talent Analytics strategy while working on high-priority data efforts – all in line with our broader mission of attracting diverse talent and giving them an experience that will bring out their very best. You will be responsible for scoping, executing, and delivering technical projects to stakeholders across the Human Capital organization, and producing data engineering & analytical solutions that connect them to the data they need.
Where You'll Be
To prioritize togetherness, culture, and accountability, RVO Health operates on a hybrid in-office work schedule. We expect employees to work from our Minneapolis office Tuesday, Wednesday and Thursday each week. You are welcome to work remotely Mondays and Fridays if you wish.
11000 Optum Cir Eden Prairie, MN 55344
What You’ll Do
Develop/maintain data pipelines from various data sources (ADP WFN, Greenhouse Recruiting/Onboarding, CultureAmp, Docebo, etc) to a target data warehouse using batch data load strategies utilizing cutting edge cloud technologies.
Conduct hands-on, advanced data engineering & analytics using multiple data sources originating from different applications and systems.
Collaborate with the data science team to identify new opportunities for deep analytics within the Human Capital organization.
Provide input into strategies as they drive the team forward with delivery of business value and technical acumen.
Execute on proof of concepts, where appropriate, to help improve our technical processes.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
What We’re Looking For
5+ years of Data Engineering experience
3+ years of writing SQL experience against complex databases for data extraction using AWS Athena (Presto), Databricks Delta Lake along with Data Modeling & Data warehousing experience.
3+ years of experience working on Spark (RDDs / Data Frames / Dataset API) using Scala/Python to build and maintain complex ETL pipelines and experience data processing using Parquet and Avro
3+ years of Python coding experience, familiar with utilizing packages such as pandas, boto3, requests, json, csv, os
3+ years of experience working on AWS services including Glue, Athena, Lambda, S3, SNS, SQS, Cloud formation, Step Functions, Serverless architecture.
Experience with GitHub, Code check-in, versioning, Git commands
Introduce and drive adoption of CI/CD framework within the team and build/deploy CI/CD Pipelines using Terraform or AWS Cloud Formation
Experience with visualization tools such as Tableau, Looker or PowerBI to build dynamic/scalable dashboards and reports.
Strong analytical and interpersonal skills
Knowledge or experience within Talent/People analytics is a plus
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.
Starting Salary: $100,000 - $170,000
Note actual salary is based on geographic location, qualifications and experience
Access to a Free Udemy for Business subscription—thousands of hours of learning content on hundreds of different subjects at your fingertips
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
This position may occasionally require travel for training and other work-related duties.
Who We Are
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group’s Optum Health. Together we’re focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy
Show more
Show less","Data Engineering, Data Analytics, Data Warehouse, Data Mining, Data Processing, Data Modeling, Data Integration, Data Visualization, ETL, SQL, Python, Scala, Spark, Parquet, Avro, AWS, Athena, Databricks, Glue, Lambda, S3, SNS, SQS, Cloud Formation, Step Functions, Serverless, Terraform, Tableau, Looker, PowerBI, GitHub, Code Checkin, Versioning, Git, CI/CD, Udemy, Health Insurance, Life Insurance, Disability Insurance, Flexible Spending Accounts, Paid Time Off, Holiday Pay, 401(k), Employee Assistance Program, Paid Parental Bonding Benefit Program","Company Name: RVO Health
Job Title: Senior Data Engineer
Experience: 5+ years of Data Engineering experience

Skills Needed:
- Proficiency in writing SQL against complex databases using AWS Athena, Databricks Delta Lake
- Experience with Spark using Scala/Python for building and maintaining ETL pipelines
- Strong Python coding skills with knowledge of packages like pandas, boto3, requests
- Familiarity with AWS services such as Glue, Athena, Lambda, S3, etc",0.15490533380349034,0.6088224
Part-Time Data Analyst (Entry Level),Staffingandrecruiting,"Belleville, Ontario, Canada",https://ca.linkedin.com/jobs/view/part-time-data-analyst-entry-level-at-staffingandrecruiting-3729288886,2023-12-20,Belleville,Canada,Mid senior,Remote,"Minimum 1 year of work experience - fully remote position. Freshers are also encouraged to apply.
About us: The Future of AI is Patterned We are a stealth-mode technology startup that is revolutionizing the way AI is used. Our platform uses pattern recognition to train AI models that are more accurate, efficient, and robust than ever before.
We are backed by top investors and we are hiring for almost everything! If you are passionate about AI and want to be a part of something big, then we want to hear from you.
Make a positive impact on the world. Be a part of a fast-growing startup. If you are interested in learning more, please visit our website.
We Are Looking For People Who Are
Passionate about AI.
Excellent problem solvers.
Team players.
Driven to succeed.
Requirements
Role Responsibilities:
Work in close collaboration with the Business Intelligence Lead, Federal Data Lead, and other Program teams
Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)
Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels
Communicate with client leadership to assess data needs and emerging requirements
Work with large data sets, workbooks, and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc.
Gather requirements and lead the development of long-term data management tools, processes, and solutions based on organizational needs.
Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office
Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management-related tasks.
Qualifications
Bachelor's Degree in business, business intelligence, data or information management, or similar.
Proficient in Google Scripts
Minimum 1 year of data or information management and/or data analysis experience.
Experience using Microsoft Excel and Google Sheets (macros, imports, query functions).
Experience with developing Google App Script is a plus.
Experience using SQL Developer is a plus.
Excellent written and verbal communication skills.
Willing to work in an administratively manual environment while working towards automation of processes in the future.
Clearable (able to pass both a criminal background check and credit check).
Highly motivated, self-learner, and technically inquisitive
Benefits
Special Benefits you will love:
Flexible vacation paid unlimited holidays and paid sick days
401(k) with up to 2% employer match
Health, vision, and dental insurance
Why Patterned Learning AI?
Patterned Learning AI is made up of incredibly bright, mission-driven coworkers who are passionate about using technology to solve real-world problems---and we're growing quickly. In order to continue building an engaging and dynamic organization, we're committed to giving everyone the support they need to do great work.
We believe diverse perspectives and backgrounds are critical to building great technology, and our goal is to cultivate an environment where people feel equally valued and respected. Patterned Learning AI is proud to be an equal opportunity workplace, and we welcome applicants from all backgrounds regardless of race, color, ancestry, religion, gender identity or expression, sexual orientation, marital status, age, citizenship, socioeconomic status, disability, or veteran status.
Powered by Webbtree
Show more
Show less","Google Suite, Google Sheets, Google App Script, Microsoft Office, Microsoft Excel, SQL Developer, AI, Macros, Queries, Data management, Information management, Data analysis, Business intelligence, Google Scripts, Spreadsheets, Financial management, Risk management, Audits, Project management, Data calls, Analysis","Company Name: Patterned Learning AI

Job Title: Data Analyst

Experience: Minimum 1 year of work experience in data or information management and/or data analysis. Freshers are encouraged to apply.

Skills Needed:
- Proficiency in Google Scripts
- Experience using Microsoft Excel and Google Sheets (macros, imports, query functions)
- Experience with developing Google App Script and SQL Developer is a plus
- Excellent written and verbal communication skills
- Ability to work with large data sets, workbooks,",0.25999999738050006,0.6976578
Senior Staff AI Data Engineer,Recruiting from Scratch,"Oxnard, CA",https://www.linkedin.com/jobs/view/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759707777,2023-12-20,Port Hueneme,United States,Mid senior,Hybrid,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/
This is a hybrid role based in our
Palo Alto,
San
Francisco or Chicago
offices and will require you to be in office Tuesdays and Thursdays.
What’s so interesting about this role?
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.
What’s the job?
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.
Responsibilities:
Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure
What We’ll Love About You
Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)
We’ll really swoon if you have
2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects
What You'll Love About Us
Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/
Show more
Show less","Data Engineering, ML Data Ops, Data Pipelines, Automation Workflows, Data Enrichment, Monitoring Tools, AI Models, Data Pre/Post Processing, ML Models, Data Mining, Data Cleaning, Data Normalization, Data Modeling, Pandas, R, Data Platforms, Frameworks, High Volumes of Data, Real Time, Batch, NLP, Large Language Models, Python, Java, Bash, SQL, Git, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, PySpark, AWS, GCP, Azure, NoSQL, ETL, Kafka, Storm, SparkStreaming, Applied Machine Learning, Data Management Tools, Data Classification, Data Retention","Company: Recruiting from Scratch
Job Title: Data Engineer Lead
Experience: 5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Skills Needed:
- Bachelor's in Computer Science, Mathematics, Physics, or related fields
- Experience in statistical analysis & visualization using Pandas or R
- Proficiency in Python, Java, bash, SQL, and Git version control
- Experience",0.18215613190530813,0.56595236
Senior Staff AI Data Engineer,Recruiting from Scratch,"Oxnard, CA",https://www.linkedin.com/jobs/view/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3773087761,2023-12-20,Port Hueneme,United States,Mid senior,Hybrid,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/
This is a hybrid role based in our
Palo Alto
or
San
Francisco
offices and will require you to be in office Tuesdays and Thursdays.
What’s so interesting about this role?
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.
What’s the job?
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.
Responsibilities:
Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure
What We’ll Love About You
Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)
We’ll really swoon if you have
2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects
What You'll Love About Us
Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/
Show more
Show less","Data Engineering, ML Pipelines, Python, Java, bash, SQL, Git, Pandas, R, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, AWS, GCP, Azure, DynamoDB, ETL, Kafka, Storm, SparkStreaming, ML, Data Management, Data Classification, Data Retention","Company: Recruiting from Scratch
Job Title: Data Engineer Lead
Experience: 5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Skills Needed: Bachelor's degree in Computer Science, Mathematics, Physics, or related fields, experience in statistical analysis & visualization with Pandas or R, expertise in Python, Java, bash, SQL, Git version control, big data technologies (Snowflake",0.17132215819300967,0.5702298
"Engineer Senior, Carbon Emissions Accounting Strategy/Data Analyst","3 Key Consulting, Inc.","Thousand Oaks, CA",https://www.linkedin.com/jobs/view/engineer-senior-carbon-emissions-accounting-strategy-data-analyst-at-3-key-consulting-inc-3624949647,2023-12-20,Port Hueneme,United States,Mid senior,Hybrid,"Job Title:
Engineer Senior, Carbon Emissions Accounting/Data Analyst Strategy/Sustainability - Hybrid (JP11517)
Location:
Thousand Oaks, CA. 91320
Business Unit:
Environment and Sustainability
Employment Type:
Contract to Hire
Duration:
6+ months (with possible extensions and conversion to permanent)
Rate
: Minimum $50/hr W2 with no pay rate cap DOE.
Posting Date:
06/01/2023
Notes:
Only qualified candidates need apply. Can be remote, but requires to be onsite at least two times during the engagement. Preferences to candidates in the greater Los Angeles area.
3 Key Consulting is recruiting an
Engineer Senior, Sustainability
for a consulting engagement with our direct client, a leading global biotechnology company.
Job Description
The successful candidate will reside in the greater LA area, and the expectation is that s/he would be required to be onsite 2x's min at our client’s Thousand Oaks, CA. area over the duration of 6 months. Manager’s education preference is Masters/PHD but would accept Bachelor’s with 4-6 YOE. It is preferred that the candidate has certifications in Sustain Strategy or other certification related to the environmental sustainability field. Ability to perform a sensitivity analysis for various carbon accounting methods and work with databases such as EcoInvent and GaBi.
Data analyst position (6-months) within the Global Operations Environmental Sustainability Team, housed in Engineering and working directly with our Scope 3 carbon strategy lead. In 2022, our client set science-based targets with the Science Based Target Initiative to decarbonize their operations and value chain (Scope 3). The role will support the expansion of Scope 3 carbon accounting methodology from a global to a local level to assess additional opportunities across our business units, functions, and our suppliers.
Candidate must be a critical thinker who can constructively challenge conventional ways of thinking and introduce new ideas in data analysis and carbon accounting.
Roles And Responsibilities Include
Directly working with our Scope 3 carbon strategy manager to expand methodology from a global to local level.
Perform a sensitivity analysis for various carbon accounting methods and work with databases such as EcoInvent and GaBi.
Collaborate with the company’s internal functions to advance a Scope 3 methodology.
The role can be remote but preference over Los Angeles, CA, to work on-site at client’s Thousand Oaks, CA, location.
Top Must Have Skill Sets
Data analysis skills
Knowledge of key sustainability initiatives such as the Greenhouse Gas Protocol, Science Based Targets, as well as greenhouse gas inventories and databases.
Day To Day Responsibilities
Directly working with our Scope 3 carbon strategy manager to expand methodology from a global to local level.
Perform a sensitivity analysis for various carbon accounting methods and work with databases such as EcoInvent and GaBi.
Collaborate with the company’s internal functions to advance a Scope 3 methodology.
Basic Qualifications
Data analysis skills
Strong teamwork and interpersonal skills
Ability to interact in a professional manner with cross-functional managers
Knowledge of key sustainability initiatives such as the Greenhouse Gas Protocol, Science Based Targets, as well as greenhouse gas inventories and databases.
Why is the Position Open?
Planned Project.
Employee Value Proposition
Potential to convert to Full time employment at our client.
Unique and exciting opportunity to decarbonize the scope. Assist in pulling large data sets and analyze by business unit to support launch of strategies around the world.
Interview Process
Manager will phone screen potential candidates 1:1 (30min call)
Select candidates would move to a 2nd interview 1:3 interview.
Candidates should be prepared to discuss and walk through allocate emissions in different scopes and challenges in Carbon Accounting.
We invite qualified candidates to send your resume to resumes@3keyconsulting.com. If you decide that you’re not interested in pursuing this particular position, please feel free to take a look at the other positions on our website www.3keyconsulting.com/careers. You are also welcome to share this opportunity with anyone you think might be interested in applying for this role.
Regards,
3KC Talent Acquisition Team
Show more
Show less","Data analysis, Sustainability initiatives, Greenhouse Gas Protocol, Science Based Targets, Greenhouse gas inventories, Databases, EcoInvent, GaBi, Sensitivity analysis, Carbon accounting","Company Name: 3 Key Consulting
Job Title: Engineer Senior, Carbon Emissions Accounting/Data Analyst Strategy/Sustainability
Years of Experience: 4-6 years
Skills Needed: Data analysis skills, knowledge of key sustainability initiatives such as the Greenhouse Gas Protocol, Science Based Targets, greenhouse gas inventories and databases

The Engineer Senior, Carbon Emissions Accounting/Data Analyst Strategy/Sustainability position at 3 Key Consulting in Thousand Oaks, CA, is a contract-to-hire opportunity lasting 6",0.21515892187755933,0.67465067
Data Visualization / Business Intelligence Analyst (3019),SMX,"Port Hueneme, CA",https://www.linkedin.com/jobs/view/data-visualization-business-intelligence-analyst-3019-at-smx-3760167341,2023-12-20,Port Hueneme,United States,Mid senior,Hybrid,"SMX is seeking a
Data Visualization / Business Intelligence Analyst
to support a government client based out of Port Hueneme, CA. Onsite support is highly preferred but hybrid or remote may be considered.
The Data Visualization / Business Intelligence Analyst will:
Develop reports, dashboards, and advanced visualizations by working closely with stakeholders.
Help define and design reporting data structures and tables. Ensure the integrity of the data and the data structures.
Write SQL queries as needed including for extract and loading, data comparison, validation, and cleaning. This could include creating stored procedures, functions, views, etc.
Help administer the Power BI deployment, workspaces, applications, and permissions.
Participate in the complete software development lifecycle from requirements, prototyping, production, deployment, and support.
Research technologies, standards and services and integrate them into the ecosystem.
Ensure compliance with all security, availability, confidentiality, and privacy policies and controls.
Create and maintain best practices, coding standards, and documentation.
Support presentations to stakeholders, partners, and customers as needed.
Required Skills and Experience:
Clearance Required: Secret or ability to obtain
Bachelor's degree in Computer Science, Information Systems or Computer Engineering or 4 years related experience
3+ years of BI development using Power BI or equivalent tool. Proficient in making DAX queries in Power BI and using advanced calculations.
3+ years of SQL and databases with emphasis on Transact-SQL, OLTP, and OLAP. Understands complex joins and time segment data.
3+ years of Excel experience.
Knowledge of ETL/ELT techniques and methodologies along with best practices.
Exceptional analytical, critical thinking and problem-solving abilities.
Highly self-directed, takes initiative, can work independently while being a strong contributor to a team.
Effective prioritization and time management skills. Can thrive in a dynamic environment in which priorities might change frequently.
Excellent communication and interpersonal skills. Strong documentation and presentation skills.
Work requires CSWF certification in accordance with DoD 8570 and SECNAV 5239.2. (Security+ or CISSP)
#cjpost
At SMX®, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.
We share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what’s possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.
SMX is committed to hiring and retaining a diverse workforce. All qualified candidates will receive consideration for employment without regard to disability status, protected veteran status, race, color, age, religion, national origin, citizenship, marital status, sex, sexual orientation, gender identity or expression, pregnancy or genetic information. SMX is an Equal Opportunity/Affirmative Action employer including disability and veterans.
Selected applicant will be subject to a background investigation.
Show more
Show less","Data Visualization, Business Intelligence, Power BI, DAX, SQL, TransactSQL, OLTP, OLAP, Excel, ETL/ELT, CSWF, Security+, CISSP, DoD 8570, SECNAV 5239.2","Company: SMX

Job Title: Data Visualization / Business Intelligence Analyst

Experience: The candidate should have a Bachelor's degree in Computer Science, Information Systems, or Computer Engineering, or 4 years of related experience. They should have 3+ years of BI development using Power BI or equivalent tools, 3+ years of SQL and databases experience, and 3+ years of Excel experience.

Skills Needed: The candidate must have experience in developing reports, dashboards, and visualizations, defining",0.187667557961029,0.8140561
Data Analyst,Affinity,"Burnaby, British Columbia, Canada",https://ca.linkedin.com/jobs/view/data-analyst-at-affinity-3771774483,2023-12-20,Langley,Canada,Mid senior,Remote,"Job Description:
On behalf of our healthcare client, Affinity is looking for a Data Analyst to develop and publish a performance dashboard, to analyze referral patterns between healthcare provider senders and receivers to inform implementation strategy and roadmaps and to support the development of reports and briefing notes by providing data analysis and visuals to support findings.
Responsibilities:
• Develop and publish the performance dashboard to measure performance and quality indicator by combining data extracted from the Analytics platform with other process and quality measures.
• Document standard operating procedures for data collection and analysis processes.
• Maintain a data dictionary.
• Work with implementation team members to identify data analytics needs and document requests.
• Develops complex data extraction and transformation scripts, including data linkages, to prepare data for analysis. Performs analysis and prepares reports and other analytical products (e.g. dashboards, scorecards). Implements indicators for monitoring and regular reporting.
• Skilled with and uses tools such as Excel, Power BI, SAS, SPSS, Python
• Translates complex data analysis into charts, tables, infographics and other easily consumed visuals to educate and inform team members, health care providers and the public.
• Assists the team in the development of dashboards, tables, charts and trending graphs to inform presentations and reports.
• Takes measures to protect all data and information sources to comply with protection of confidentiality and privacy policies.
• Produces regular and ad hoc reports as requested.
• Identify and implement prospective and methods to avoid, reduce and rectify data quality issues.
• Collaborates with appropriate personnel to obtain data and understand its meaning in order to properly analyze it.
• Collaborates with the team to support the development of key performance indicators and reporting requirements to monitor benefits of the program.
• Identifies learning needs that contribute to skill enhancement fosters a working environment that stimulates learning and inquiry for the team.
• Collaborates with all team members and communicates information in a timely manner.
• Performing other related duties as assigned.
Qualifications:
• 5+ years of recent related experience or an equivalent combination of education, training, and experience.
• Advanced or Expert skills in one or more of the following: SAS, R, SQL, Python
• Experience working with health administrative data and data warehouses
• Manipulating and compiling large databases
• Significant experience writing programs and queries to manipulate and compile large health datasets and analyze the date accordingly
• Master’s degree in Statistics, Computer Science, or related discipline
• Experience within healthcare is a plus
Hourly Rate: $90-$100 per hour.
Affinity Earn:
Know someone who’s great for this, or any of our open roles? Earn up to $4,000/year for each successful referral through Affinity Earn.   You can also earn up to $50,000 for helping us find new clients.   Learn about our referral program at   https://affinity-group.ca/earn/   or browse our jobs & follow us at   https://www.linkedin.com/company/affinity-staffing/jobs/
About Affinity:
Affinity Group is a full-service Information Technology services and staffing company. We believe recruiting is about creating long term relationships that foster a mutually beneficial partnership - an affinity. Bringing a new style of recruiting founded on five core principles: Transparency – Flexibility – Efficiency – Agility – Inclusivity.
We teamed up with ClimatePartner on 2022 to offset our emissions and move toward being a more environmentally friendly company and we are proud to now be officially Carbon Neutral Certified.
For more information on Affinity, please visit   www.affinity-group.ca
Job Number: 9452
Show more
Show less","Data Analysis, Data Visualization, SAS, R, SQL, Python, Data Extraction, Data Transformation, Data Analytics, Data Warehousing, Data Quality, Data Management, Data Dictionary, Performance Dashboard, Power BI, Excel, SPSS, Tableau, Healthcare Data, Statistics, Machine Learning, Artificial Intelligence","Company Name: Affinity Group
Job Title: Data Analyst
Experience: 5+ years of recent related experience or equivalent combination of education, training, and experience
Skills Needed: Advanced or Expert skills in SAS, R, SQL, Python, experience working with health administrative data and data warehouses, manipulating and compiling large databases, writing programs and queries to manipulate and compile large health datasets, Master’s degree in Statistics, Computer Science, or related discipline, experience within healthcare is a plus.",0.2404092045986094,0.58324355
Medical Data Analyst,Montefiore St. Luke's Cornwall,"Newburgh, NY",https://www.linkedin.com/jobs/view/medical-data-analyst-at-montefiore-st-luke-s-cornwall-3748499751,2023-12-20,Beacon,United States,Mid senior,Onsite,"Pay Rate
: $20-$24 per hour
Position Summary
: Develop and analyze medical data related to patient flow functions included but not limited to: Length of Stay, re-admission data, Volume indicators, and compliance with both internal and external benchmarks. Assists with automating regular reports. Identifies trends in the data that will be useful in making organizational changes.
Education/Training
: Associates degree required; Bachelors preferred. Ability to read, write and communicate in English.
Experience
: Minimum of one (1) year experience in an acute care hospital with basic understanding of medical terminology. Strong experience with Excel, Word, Access, and PowerPoint applications required. Experience with EPIC, Allscripts, MIDAS preferred. Ability to think critically, analyze data, and develop comprehensive reports
Montefiore St. Luke's Cornwall
(MSLC) is a not-for-profit hospital dedicated to serving the health care needs of those in the Hudson Valley. In January 2018, St. Luke's Cornwall Hospital officially partnered with the Montefiore Health System, making MSLC part of the leading organization in the country for population health management. With dedicated staff, modern facilities and state-of-the-art treatment, Montefiore St. Luke's Cornwall is committed to meeting the needs of the community and continuing to aspire to excellence.
We are proud to be on Becker's Hospital Review as one of the 150 Great Places to Work in Healthcare, as well as being a Certified Great Place to Work.
Visit https://www.greatplacetowork.com/certified-company/1379468 to learn what makes MSLC an exceptional place to work.
Show more
Show less","Data Analysis, Medical Terminology, Excel, Word, Access, PowerPoint, EPIC, Allscripts, MIDAS, Critical Thinking, Data Analysis, Report Writing","Company Name: Montefiore St. Luke's Cornwall (MSLC)
Job Title: Data Analyst
Experience: Minimum of one (1) year
Skills Needed: Strong experience with Excel, Word, Access, and PowerPoint applications required. Experience with EPIC, Allscripts, MIDAS preferred. Ability to think critically, analyze data, and develop comprehensive reports. Basic understanding of medical terminology.

Montefiore St. Luke's Cornwall is seeking a Data Analyst to develop and analyze medical data related to",0.3849765221309705,0.7166991
Senior Data Engineer,Jobs for Humanity,"Poughkeepsie, NY",https://www.linkedin.com/jobs/view/senior-data-engineer-at-jobs-for-humanity-3788481507,2023-12-20,Beacon,United States,Mid senior,Onsite,"Company Description
Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: Capital One
Job Description
Job Opportunity: Senior Data Engineer - Capital One
Are you passionate about technology and problem-solving? Do you enjoy working in a diverse and collaborative environment? Capital One is looking for Senior Data Engineers who are enthusiastic about using data and emerging technologies to drive innovation. Join our team and be part of a transformational journey at Capital One. We welcome applicants from all backgrounds and walks of life.
What You'll Do:
Collaborate with Agile teams to design, develop, test, implement, and support technical solutions using cutting-edge tools and technologies
Work with highly skilled developers specialized in machine learning, microservices, and full-stack systems
Utilize programming languages like Java, Scala, Python, and various databases and cloud-based data warehousing services
Stay up-to-date with tech trends, experiment with new technologies, participate in tech communities, and mentor other engineers
Collaborate with product managers to deliver powerful cloud-based solutions that empower millions of Americans financially
Perform unit tests and code reviews to ensure high-quality performance
Basic Qualifications:
Bachelor's Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development using Python, SQL, Scala, or Java
2+ years of experience with a public cloud platform (AWS, Microsoft Azure, Google Cloud)
3+ years of experience with distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL)
2+ years of experience with real-time data and streaming applications
2+ years of experience with NoSQL databases such as MongoDB or Cassandra
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux and shell scripting
2+ years of experience with Agile engineering practices
Salary Information:
New York City (Hybrid On-Site): $161,900 - $184,800
San Francisco, California (Hybrid On-Site): $171,500 - $195,800
Benefits:
Capital One offers a comprehensive and competitive benefits package that supports your overall well-being. Learn more at the Capital One Careers website. Eligibility may vary based on employment status and level.
How to Apply:
If you require any accommodations during the application process, please contact Capital One Recruiting at 1-800-304-9102 or RecruitingAccommodation@capitalone.com. All information provided will be treated confidentially. For technical support or questions about the recruiting process, contact Careers@capitalone.com.
Note:
Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate based on race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited by law.
Capital One promotes a drug-free workplace and complies with applicable laws regarding criminal background inquiries.
Disclaimer: This job posting is for the United States. Salary ranges for other locations may vary. Performance-based incentive compensation may also be offered.
Capital One Financial Corporation consists of multiple entities. Positions posted in Canada are with Capital One Canada, positions posted in the United Kingdom are with Capital One Europe, and positions posted in the Philippines are with Capital One Philippines Service Corp. (COPSSC).
Show more
Show less","Agile, Java, Scala, Python, Machine learning, Microservices, Databases, Cloudbased data warehousing, AWS, Azure, Google Cloud, MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, MongoDB, Cassandra, Redshift, Snowflake, UNIX/Linux, Shell scripting","Company Name: Capital One  
Job Title: Senior Data Engineer  
Experience: At least 4 years of application development experience, and at least 1 year of big data technologies experience  
Skills Needed: Proficiency in Python, SQL, Scala, or Java; experience with public cloud platforms (AWS, Microsoft Azure, Google Cloud); familiarity with distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL); expertise in real-time",0.21904761666712022,0.75663704
"Manager, Data Loss Prevention (DLP) Engineer (Symantec)",Jobs for Humanity,"Poughkeepsie, NY",https://www.linkedin.com/jobs/view/manager-data-loss-prevention-dlp-engineer-symantec-at-jobs-for-humanity-3788483129,2023-12-20,Beacon,United States,Mid senior,Onsite,"Company Description
Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: Capital One
Job Description
Job Opportunity: Data Loss Prevention (DLP) Engineer Location: McLean, Virginia, United States of America About Us: At Capital One, we are committed to delivering excellent cybersecurity solutions based on data, threat, and design thinking. We believe in doing the right thing and aim to provide financial products using modern technology and constant innovation. As part of this, we are seeking a data protection subject matter expert to join our team. What You'll Do: - Use your expertise in data loss prevention tools to design and implement solutions that protect data in use, in motion, and at rest. - Analyze the problem space, document the approach, and work with architecture to create a target state architecture. - Collaborate with cross-functional teams to execute technical resolution programs. - Maintain relationships with stakeholders, developers, and engineers to ensure that our services meet their evolving needs. - Communicate extensively with Data Protection Product and engineering teams. - Collaborate with partners in different teams to resolve dependencies with data loss prevention products. - Design, build, and maintain cloud-based infrastructure to meet organizational requirements and ensure high availability. About You: - You are an expert in data loss prevention tools. - You have a strong understanding of web proxy, email, and endpoint solutions. - You pay attention to detail and can clearly articulate key details in both conversation and technical writing. - You have the ability to drive complex technical initiatives leveraging cybersecurity practices and software engineering principles. - You can foster collaborative, working relationships with technology groups and stakeholders. - You have excellent communication skills and can interact effectively at all levels of the organization. - You have experience managing enterprise cybersecurity projects with cross-functional teams. - You have a passion and expertise in technical delivery, product security, software development practices, or platform engineering. - You have hands-on knowledge and expertise in securing technology, including operating systems, databases, virtualization, cloud computing environments, and networks. - You have the ability to troubleshoot, investigate, configure, and support data loss prevention products. Basic Qualifications: - High School Diploma, GED, or equivalent certification. - At least 6 years of experience in cybersecurity or information technology. - At least 5 years of experience in the data protection field. - At least 3 years of experience with Symantec Data Loss Prevention (DLP) infrastructure engineering. - At least 3 years of experience with URL filtering, proxy, or Network DLP. Preferred Qualifications: - Bachelor's Degree in Cybersecurity, Systems Engineering, or Computer Science. - 4+ years of experience in scripting and solving cyber technical challenges. - 4+ years of experience in the Agile delivery model. - 4+ years of experience in public cloud security and multi-cloud environments. - 3+ years of experience in IT Delivery projects and technical writing. - 3+ years of hands-on JIRA experience. - 2 or more professional cybersecurity certifications: CISSP, GIAC, CISM, CCSP, CISA, or Security+. - 1 or more professional cloud certifications: AWS Cloud Practitioner, AWS Solution Architect - Associate, AWS Developer - Associate, AWS Security - Specialty, or AWS Solution Architect - Professional. Salary Range: $197,400 - $225,300 per year for Manager, Cyber Technical (based on location) Additional Information: - This role is also eligible for performance-based incentive compensation. - We offer a comprehensive set of health, financial, and other benefits to support your total well-being. - Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate based on various factors. - We promote a drug-free workplace and comply with applicable laws regarding criminal background inquiries. - If you require an accommodation during the application process, please reach out to Capital One Recruiting. - For technical support or questions about the application process, please contact Careers@capitalone.com. To apply for this role, please visit our website. Applications will be accepted for a minimum of 5 business days. Note: This information is subject to change and candidates will be provided with the actual offer details in their offer letter.
Show more
Show less","Data Loss Prevention (DLP), Symantec Data Loss Prevention (DLP), URL filtering, Proxy, Network DLP, Cloud security, Multicloud environments, Agile delivery model, Public cloud security, AWS, JIRA, CISSP, GIAC, CISM, CCSP, CISA, AWS Cloud Practitioner, AWS Solution Architect  Associate, AWS Developer  Associate, AWS Security  Specialty, AWS Solution Architect  Professional","Company Name: Capital One  
Job Title: Data Loss Prevention (DLP) Engineer  
Experience: At least 6 years of cybersecurity or information technology experience, with at least 5 years in data protection field, and 3 years with Symantec Data Loss Prevention (DLP) infrastructure engineering  
Skills Needed:  
- Expertise in data loss prevention tools  
- Strong understanding of web proxy, email, and endpoint solutions  
- Attention to detail and ability to articulate key details  
- Ability",0.20264316964350174,0.64366746
Senior Data Scientist,CVS Health,"Wellesley, MA",https://www.linkedin.com/jobs/view/senior-data-scientist-at-cvs-health-3763338443,2023-12-20,Attleboro,United States,Mid senior,Onsite,"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.
Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand - with heart at its center - our purpose sends a personal message that how we deliver our services is just as important as what we deliver.
Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
Build machine learning, deep learning and statistical predictive models and develop analytical approaches which form the foundation for driving patient engagement tactics aimed at improving medication adherence and patient experience.
Deploy large scale machine learning and deep learning models in a production environment.
Design and execute A/B testing and Multi-Armed Bandits based experimentation.
Effectively collaborate with Data Engineering, IT and other technical teams to onboard new data sources, create feature stores and optimize/ automate model development and deployment processes (Github, MLOps etc.)
Write complex and efficient SQL code and leverage Exploratory Data Analysis techniques to develop insights from billions of transactional records at the Retail Pharmacy.
Collaborate effectively with business, marketing, trade and other stakeholders across the organization.
Mentor peers and lead intern projects.
Required Qualifications
3+ years of hands-on experience in machine learning and deep learning frameworks
Strong experience with deployment of machine learning and deep learning models in production
Strong experience with cloud based ML frameworks (either AWS, Azure or GCP)
Strong proficiency with Python and SQL
Strong proficiency with Github and MLOps
Education
Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline.
Master's degree or PhD preferred
Pay Range
The typical pay range for this role is:
$103,500.00 - $200,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.
In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Companypolicies.
For more detailed information on available benefits, please visitjobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services throughColleagueRelations@CVSHealth.comIf you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
Show more
Show less","Machine Learning Frameworks, Deep Learning Frameworks, Python, SQL, Github, MLOps, Cloudbased ML Frameworks (AWS/Azure/GCP), Exploratory Data Analysis, A/B Testing, MultiArmed Bandits, Feature Stores, Model Development Automation, Model Deployment Automation, Data Engineering, IT Collaboration, Statistical Predictive Modeling, Patient Engagement Tactics, Medication Adherence, Patient Experience, Business Collaboration, Marketing Collaboration, Trade Collaboration, Intern Project Leadership, Peer Mentoring","Company: CVS Health
Job Title: Machine Learning Engineer
Experience: The ideal candidate should have at least 3+ years of hands-on experience in machine learning and deep learning frameworks, as well as experience with deployment of machine learning and deep learning models in production.
Skills Needed: Proficiency in building machine learning, deep learning, and statistical predictive models, deploying large-scale models in a production environment, conducting A/B testing and Multi-Armed Bandits based experimentation, collaborating with technical teams, writing",0.12673267129544166,0.36855036
Sr Data Scientist - Product&Pricing Analytics,CVS Health,"Wellesley, MA",https://www.linkedin.com/jobs/view/sr-data-scientist-product-pricing-analytics-at-cvs-health-3744994250,2023-12-20,Attleboro,United States,Mid senior,Onsite,"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.
Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
The Pricing and Product team’s mission is to build innovative solutions that bring tangible impact to our CVS Health members, clients, and plan sponsors.
We accomplish this while offering a diverse work experience that empowers colleagues for career success, collaboration, innovation, caring, integrity, inclusiveness, and accountability.
The position will focus on our Caremark Pharmacy Benefit Management business unit where you work directly with Actuarial, Underwriting, Finance and Sales leaders to ideate and build analytical solutions and implement to show direct impact.
Position Summary:
Uses strong knowledge in algorithms and predictive models to investigate problems, detect patterns and recommend solution
Performs analyses of structured and unstructured data to solve multiple complex business problems utilizing advanced statistical techniques, mathematical analyses, and organization / industry knowledge
Collaborates with business partners to understand their problems and goals, develops predictive modeling, statistical analysis, data reports and performance metrics
Develops and participates in written presentations and consultations to various stakeholders on analytics results and solutions
Interacts with peers and managers to exchange complex information related to areas of specialization
Independently leads workstreams with minimal guidance from leaders
Required Qualifications
3+ years of progressively complex experience as an applied data scientist
3+ years of hands-ondata manipulation andmodeling experience using statistical, machine learning or deep learning methods; Experience on recommendation system is a plus
3+ years programming experience with SQL, R/Python
2+ years of experience of business stakeholder engagement or analytical project management
Preferred Qualifications
Prior experience in Insurance is highly preferred but will consider other verticals like Tech and Retail where pricing and solving for unique business problems are a big part of your day
Ability to anticipate potential challenges and proactively address them in modeling and non-modeling settings
Experience in building deep learning models, and Object-Oriented Programming skills, preferably in Python
Prior exposure to healthcare or insurance businesses
Strong proficiency in working with large data sets from multiple sources, building machine learning models, and applying statistical analyses in business settings
Strong consultative problem-solving skills, business acumen, and ability to think on your feet; experience working with mid-level stakeholders to define problem, develop and implement a solution to realize impact
Effective communication of technical concepts and business implications to non-technical stakeholders
Education
Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline.
Master's degree preferred
Pay Range
The typical pay range for this role is:
$103,500.00 - $200,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.
In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Companypolicies.
For more detailed information on available benefits, please visitjobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services throughColleagueRelations@CVSHealth.comIf you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
Show more
Show less","Predictive modeling, Statistical analysis, Machine learning, Deep learning, Objectoriented programming, SQL, R, Python, Data manipulation, Data analysis, Business intelligence, Data visualization, Stakeholder engagement, Project management, Problemsolving, Communication, Business acumen","Company Name: CVS Health
Job Title: Data Scientist
Experience: The ideal candidate should have at least 3+ years of progressively complex experience as an applied data scientist with hands-on data manipulation and modeling experience using statistical, machine learning, or deep learning methods.

Skills Needed:
- Strong knowledge in algorithms and predictive models
- Proficiency in programming with SQL, R/Python
- Experience in business stakeholder engagement or analytical project management
- Ability to collaborate with business partners, develop predictive modeling",0.1599999980680556,0.42463598
"Sr. Data Scientist, Patient Engagement and Personalization",CVS Health,"Woonsocket, RI",https://www.linkedin.com/jobs/view/sr-data-scientist-patient-engagement-and-personalization-at-cvs-health-3759735735,2023-12-20,Attleboro,United States,Mid senior,Onsite,"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.
Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
The Sr. Data Scientist (Manager) ofPatient Engagement and Experimentationis directly responsible for designing and developingpatient engagement use cases (including experiments, mini-tests, campaigns and patient engagement tactics)to enhance patient experiences andbusiness outcomes. The Manager leads the deployment ofpatient engagement use casesandanalytical models (including descriptive/inferential statistics, machine learning, etc.)by effectively managing and guiding data scientists and data engineers through end-to-end product development. The Manager also performs hands-on analyses in product diagnostics, opportunity assessment, pre-deploayment validation and post-deployment evaluation by querying, mining and analyzing big data in CVS’ cloud computing environment using programming tools including Python (Pyspark) and SQL.
Required Qualifications
Academic background or prior experiences in data science, statistics, computer science, product analytics, marketing analytics, or business analytics
Proficiency in programming languages including SQL, Python and PySpark
Experience with cloud computing and programming in a cloud platform (e.g. Azure, GCP, AWS)
Strong understanding of descriptive and inferential statistics (e.g. sample size calculation, statistical significance determination)
Solid understanding of the design of both experimental studies (e.g. A/B testing) and observational studies
Working knowledge of supervised and unsupervised machine learning and data engineering
Ability to structure problems and influence stakeholders in a data-driven way
Experienced in leading complex projects with multiple stakeholders in a cross-matrixed environment
Effective communication and presentation skills
Preferred Qualifications
Hands-on experiences with building machine learning models including deep-learning models
Hands-on experiences with data engineering pipeline, analysis of algorithm, optimization of complex codes and code automation
Experiences with data visualization and business intelligence
Education
Academic background or prior experiences in data science, statistics, computer science, product analytics, marketing analytics, or business analytics
Pay Range
The typical pay range for this role is:
$94,500.00 - $196,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.
In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Companypolicies.
For more detailed information on available benefits, please visitjobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services throughColleagueRelations@CVSHealth.comIf you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
Show more
Show less","Data Science, Statistics, Computer Science, Product Analytics, Marketing Analytics, Business Analytics, SQL, Python, PySpark, Azure, GCP, AWS, Descriptive Statistics, Inferential Statistics, A/B Testing, Machine Learning, Data Engineering, Problem Structuring, Stakeholder Influence, Data Visualization, Business Intelligence","Company: CVS Health
Job Title: Sr. Data Scientist (Manager) of Patient Engagement and Experimentation
Experience: Requires experience in data science, statistics, computer science, product analytics, marketing analytics, or business analytics. Experience in cloud computing and programming in a cloud platform is essential. Must have a strong understanding of descriptive and inferential statistics, experimental and observational study designs, as well as supervised and unsupervised machine learning.
Skills Needed: Proficiency in SQL, Python, and PySpark",0.16074766161823742,0.5766014
Software Engineer - UniData,PrismHR,"Hopkinton, MA",https://www.linkedin.com/jobs/view/software-engineer-unidata-at-prismhr-3790500209,2023-12-20,Attleboro,United States,Mid senior,Remote,"Developer with skills in one of the multivalue BASIC languages needed to assist with maintenance and enhancement of Payroll/HR Software product. This position will be a key member of the Engineering Rapid Response Team and will work on PrismHR’s flagship software products in SaaS, mobile, and on premise environments.
Experience with SB+ or 4GL languages will be helpful. Any other development languages such as Java, Scala, Javascript will be definite plus.
Responsibilities:
Writing, debugging software using UniData BASIC and editing/debugging tools
Supporting QA Engineers to ensure system quality, functionality, and performance
Troubleshooting issues across all application tiers
Self-starting, with the ability to recognize when assistance is required without waiting for a check-in or for the project to fall behind schedule
Ability to manage to deadlines
Actively participating within Agile software project development teams, as well as contributing to or leading priority R&D initiatives
Continually improving reliability and scalability of the existing application. Becoming an expert in multiple areas the product, the technology used in the product and the design patterns used to implement the product
Consistently demonstrating PrismHR’s values: empathy, integrity, results orientation, enthusiasm, and hard work
Qualifications:
UniData (or related MultiValue)
BASIC or demonstrated skills that would allow quick adoption of the language
Background in HR, payroll and/or accounting skills useful
Strong problem solving and communication skills
Great interpersonal skills as this job will require interaction with Customer Support, Product Management, QA, other Engineers and, in some cases, with Customers
Proficiency in Javascript, Java, HTML5/CSS
Building and consuming REST web services
Scrum, Agile Process, Unit Testing & Test Driven Development
Please note: This position can be remote/telecommute. Notice for candidates located in the following states: CA, CO, NJ, NY, WA: The base salary range for this position is between $100,000 - $135,000 (salary is dependent on experience, knowledge, and skills based on the responsibilities outlined in the job description).
PrismHR is a fast-paced SaaS company which provides customers with a cloud-based payroll process software application. PrismHR also provides professional services including system implementation consulting, custom configurations, and training. Lastly, via the Company’s Marketplace platform customers and end users access other human resources and employee benefits applications from PrismHR’s Marketplace Partners.
Diversity, Equity and Inclusion Program/Affirmative Action Plan:
We have transformed our company into an inclusive environment where individuals are valued for their talents and empowered to reach their fullest potential. At PrismHR, we strive to continually lead with our values and beliefs that enable our employees to develop their potential, bring their full self to work, and engage in a world of inclusion.
Ensuring an inclusive environment for our employees is an integral part of the PrismHR culture. We aren't just checking a box, we are truly committed to creating a workplace that celebrates the diversity of our employees and fosters a sense of belonging for everyone. This is essential to our success. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about our roles but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for these open roles or other open roles. We particularly encourage applicants from traditionally under-represented groups as we seek to increase the diversity of our workforce and provide fair opportunities for all.
As a proud Equal Opportunity and Affirmative Action Employer, PrismHR encourages talent from all backgrounds to join our team. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations.
The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers.
Privacy Policy: For information about how we collect and use your personal information, please see our privacy statement available at https://www.prismhr.com/about/privacy-policy.
PrismHR provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at PrismHR: taglobal@prismhr.com. Please indicate in the subject line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response.
Powered by JazzHR
aDM7kWhcPQ
Show more
Show less","UniData, BASIC, SB+, 4GL, Java, Scala, JavaScript, HTML5, CSS, REST, Agile, Scrum, Unit Testing, Test Driven Development","Company: PrismHR
Job Title: Developer
Experience: Not specified
Skills Needed: 
- Proficiency in one of the multivalue BASIC languages (UniData, SB+, 4GL)
- Experience with development languages such as Java, Scala, Javascript is a plus
- Strong problem-solving and communication skills
- Knowledge of HR, payroll, and/or accounting is useful
- Ability to work on PrismHR’s flagship software products in SaaS, mobile, and on-premise environments",0.15018314834225605,0.78999436
"Power Apps/Dataverse / Dynamics CRM Developer (USD $70,000/year), Sparkrock",Sparkrock,"Massachusetts, United States",https://www.linkedin.com/jobs/view/power-apps-dataverse-dynamics-crm-developer-usd-%2470-000-year-sparkrock-at-sparkrock-3777893506,2023-12-20,Attleboro,United States,Mid senior,Remote,"Are you a high performing software engineer who's looking to take your technical skills to the next level?
If you are a top performer, you understand that the more time you spend on writing code and less time in meetings and status reporting, the more successful you will be. That’s why at Sparkrock we believe that Software engineers should be focused on what they do best - producing great solutions. We believe that the quality of design and code is the most important part of any quality business solution.
We also understand that top performers want to develop and grow. That’s why we provide continuous training and coaching focused on unlocking people’s potential. We want our consultants and engineers to be the best they can be!
Imagine working for an organization where you have unlimited opportunities to grow and develop. Where you don’t have to worry about factors outside of your control. Where there’s no ambiguity about what’s expected or what it takes to be successful. If you are passionate about learning and growing and want to develop into the best consultant engineer you can be, then this role is for you!
What will you be doing?
Most of your day is spent doing actual software development; not other meaningless activities. We have tried to cut out nonessential work so the majority of your day is on design solutions, writing code, testing and deploying, Everyday you'll be refining your skills to next level.
The only exception is training and development. In addition to being a great software engineer, we expect our people to be product, industry, and market experts. Maintaining and building upon that expertise requires continuous coaching, training, and self development. On average, you will spend 20% of your week on such activities.
What you will NOT be doing
In this job, you will not be responsible for these activities:
Shepherding other team members on your team (we have others to do it)
Endless meetings and Presentations.
Candidate Responsibilities
You will be expected to be an expert on the products you work on, understand problems, create solutions Job Ad/Landing Page Section Content Search Profile The purpose of this table is to provide recruiters with search criteria for their outbound campaigns, posting, and inbound qualification and effectively communicate its benefits as well as value to customers. This means that you will continuously stay up-to-date on product releases and know your technical landscape.
You will participate in Deep dives that uncover quality issues and pain points, and propose solutions to fix them.
You will participate in regular coaching and training to improve your skills
Candidate Requirements
Previous software development and consulting experience (minimum 5 years) in Power Apps/Dataverse, Dynamics CRM (minimum 2 years) as well as have good exposure to Azure and Cloud technologies
At least 2 years in professional services. Excellent verbal and written English communication skills.
Excellent at Customer facing softskills (Requirements gathering, Solution consulting, Presentation)
Candidate ""Nice to have""
Previous experience in Remote jobs
Quality mindset
Detail orientated
What candidates will learn
How to consistently deliver high quality software solutions like Custom Modules, Custom Integrations, Extensions, PowerApps that solve business problems.
How to conduct effective requirements gathering, scoping that uncover customer needs and pain points to produce effective solutions.
Work Examples
Designing and Building an Import/Export tool to migrate data from one product/application to another.
Customizing look & feel, branding for Customer's product instance.
Coding customer specific business logics and rules on top of OOTB product capabilities.
Benefits - We don’t call them perks, they’re just part of what makes working at Sparkrock great.
We are 100% remote and global. Live your best life, wherever that may be, and never lose out on career opportunities because of it.
Flexible work hours. We work asynchronously and don’t care when you’re online, just that you deliver great results.
Dedication to development. We focus on career pathing for each and every one of our employees and help provide training to advance at every stage in your career.
Focus on culture. Coffee chats, happy hours, cooking classes, book clubs, and more!
Swag! Because who doesn’t love swag?
Stipend to help set up your ideal home office
Introductions to thought leaders in the space and webinars on cutting-edge tech hot topics
Sparkrock is an Ionic Partners company.
https://www.ionicpartners.com/
We strive to build a team that reflects the diversity of the community we work in and encourage applications from traditionally underrepresented groups such as women, visible minorities, Indigenous peoples, people identifying as LGBTQ2SI, veterans, and people with disabilities.
Show more
Show less","Software Development, Consulting, Power Apps, Dataverse, Dynamics CRM, Azure, Cloud Technologies, Professional Services, English Communication, Customer Facing Skills, Requirements Gathering, Solution Consulting, Presentation, Remote Work, Quality Mindset, Detail Orientation, Custom Modules, Custom Integrations, Extensions, PowerApps, Business Problem Solving, Effective Scoping, Business Logic Coding, OOTB Product Capabilities, Remote Work, Flexible Work Hours, Asynchronous Work, Career Pathing, Training, Culture Building, Thought Leadership Introductions, CuttingEdge Tech Webinars","Company: Sparkrock
Job Title: Software Engineer
Experience: Minimum 5 years of software development and consulting experience, with at least 2 years in Power Apps/Dataverse, Dynamics CRM, and exposure to Azure and Cloud technologies. At least 2 years in professional services.
Skills: Excellent verbal and written English communication skills, customer-facing soft skills, expertise in product knowledge, problem-solving, solution consulting, and presentation skills. Nice to have experience in remote jobs, quality mindset, and detail",0.16701461165022818,0.45675474
Lead Big Data Engineer (Remote),Syrinx Consulting,"Massachusetts, United States",https://www.linkedin.com/jobs/view/lead-big-data-engineer-remote-at-syrinx-consulting-3648836284,2023-12-20,Attleboro,United States,Mid senior,Remote,"As a Lead Software Engineer, you will be directly responsible for many of the innovative features we’ll be working on, whether collaborating with our outstanding design and product team or helping our data science group work on the bleeding-edge technology to personalize technology for our ever expanding population of members.
In This Role You Will
Align and drive team members towards an inspiring vision, yet an internship to deliver value incrementally
Build highly scalable software to ensure data quality and reliability of our microservices architecture, leveraging Scala and technologies like HBase, Spark, etc.
As a hands-on lead, you will work closely with our team of software engineers and product managers to deliver rapid value
Mentor and coach technical team members
A PERFECT CANDIDATE HAS:
Experience with designing and building large scale data pipelines and data warehouses
Thrived in complex microservices ecosystem and written robust and well-performing services
The ability to bring technology to the table
Excelled in cross-functional teams, working fluidly with Product Managers, Data Scientists, Mobile Engineers, Backend Engineers, and other highly skilled specialists
Experience leading an Agile Development Team
Experience mentoring and leading people at different stages in their career
Show more
Show less","Software Engineering, Scala, HBase, Spark, Microservices, Data Pipelines, Data Warehouses, Agile Development, Product Management, Data Science, Mobile Engineering, Backend Engineering","Company: Not specified
Job Title: Lead Software Engineer
Experience: Not specified

Skills Needed:
- Experience in designing and building large scale data pipelines and data warehouses
- Proficiency in working with complex microservices ecosystem and developing robust services
- Ability to bring innovative technology solutions to the team
- Strong collaboration skills with cross-functional teams including Product Managers, Data Scientists, Mobile Engineers, and Backend Engineers
- Experience in leading Agile Development Teams and mentoring team members at various career stages",0.4141414098025712,0.7585622
Senior Data Science Advisor - Clinical Pharmacy Analytics - Hybrid,The Cigna Group,"Massachusetts, United States",https://www.linkedin.com/jobs/view/senior-data-science-advisor-clinical-pharmacy-analytics-hybrid-at-the-cigna-group-3787351294,2023-12-20,Attleboro,United States,Mid senior,Hybrid,"Overview
A career within Forsyth Health’s Data & Analytics team will provide you with the opportunity to help Pharma/Life Science organizations uncover patient and market insights. At Forsyth Health, we focus on a collection of data management, business intelligence and advanced analytics capabilities to support various functions within these organizations to meet their business needs around market access and patient support programs.
How You'll Make a Difference
The Sr. Data Scientist role is a key role to the enterprise and will be supporting a highly complex and growing area within the health care data and analytics services space. As a strong individual contributor, the role will lead client engagements to define, develop and communicate insights critical to Commercial, Market Access, HEOR and Evidence Generation functions at Pharma/Life Science. Responsibilities include leading Outcomes Research studies, Advanced Analytics, ML model development and general analytic support for all stakeholders. This role will work closely with the internal Sales and Technology teams. This person will need to be able to understand the needs within the Commercial Pharma Analytics space and translate those into actionable insights.
Role Summary
The Data Science Advisor- Pharmacy Analytics position is an opportunity for an analytics professional to provide leadership on complex analytics projects and initiatives. This role will work with an innovative team on setting and executing the vision for how advanced embedded analytics can lead Cigna to achieving our growth goals. This role will work collaboratively with our business stakeholders to provide partnership in analytics, developing analytics solutions, leveraging data science and technologic capabilities and embedding analytics driven processes.
The job responsibilities include, but are not limited to the following:
Lead analyses related to Healthcare Resource Utilization, Total Healthcare Cost and Clinical Outcomes with a focus on Specialty Medications/Rare diseases, Channel Management, Utilization Management, and specific Therapeutic area research (root cause analyses, Health Outcome Studies, Opportunity analysis including descriptive and multivariate statistics to identify patterns in the data.)
Develop new reports, models and analytic solutions with innovative ways to present data internally and externally in order to support Forsyth Health’s Sales & Business stakeholders. This requires combining business knowledge and data acumen along with technical (SAS, SQL) skills to efficiently complete these ad-hoc requests. Query data warehouse(s) using variety of tools available. Extract data and manipulate into reports for client both internal and external. Maintain turn-around times per agreements.
Consultation with Data & Analytics matrix partners to develop best practices and help understand complex issues and requests. Cross-Functional collaboration as needed to create alignment with stakeholders.
Project management and prioritization – Advisor role will support multiple projects and will need to be able to work with Forysth Health Sales’ and Analytics team to manage multiple initiatives at the same time and negotiate timelines/priority with stakeholders.
Manage the analytic solution development efforts in the role of a Product Owner, requiring effective project management, technical and functional documentation, communication and stakeholder alignment.
Explore and visualize the data using advanced tools such as including Tableau, PowerBI, Thoughtspot and/or Looker. (Largely Tool agnostic environment)
Extraction and analysis of large healthcare claims data using state of the art big-data infrastructure leveraging cloud and on premise tools i.e. SAS, Analytic platform (Python), R, Teradata, Hadoop, etc.
Qualifications
BS/MS/PhD in Econometrics, Actuarial Science, Data Science, Health Outcomes, Epidemiology, Statistics, or in any technical field that provides a solid basis for analytics highly desired.
Minimum 6 years of industry experience in solving Health Plan, PBM business or Commercial Pharma Analytic problems through the application of analytic approaches.
Prior experience in Healthcare analytics, Specialty Medication or Specialty Condition analytics or Health Outcomes required
A demonstrated ability to understand and effectively communicate (both verbally and written) analytic and clinical data to a varied audience.
Deep healthcare data (e.g., PBM experience, Provider Networks, Billing, Medical and Pharmacy claims), statistical analysis experience, and an understanding of all the associated clinical, utilization and financial levers.
Experience with statistical software/programming languages such as SQL programming, SAS, R, Python and other tools preferred (Python knowledge not requisite but preferred).
Experience with data visualization tools such as Tableau, Thoughtspot or PowerBI.
A data-driven personality w/ Intellectual curiosity and internal motivation.
If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.
About The Cigna Group
Doing something meaningful starts with a simple decision, a commitment to changing lives. At The Cigna Group, we’re dedicated to improving the health and vitality of those we serve. Through our divisions Cigna Healthcare and Evernorth Health Services, we are committed to enhancing the lives of our clients, customers and patients. Join us in driving growth and improving lives.
Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.
If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.
The Cigna Group has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.
Show more
Show less","SAS, SQL, Python, R, Teradata, Hadoop, Tableau, PowerBI, Thoughtspot, Looker, PBM, Health, Finance, Statistics, Clinical, Analytics, Insights, Machine Learning, Epidemiology, Outcomes Research, Data Management, Data Visualization","Company Name: The Cigna Group

Job Title: Data Science Advisor - Pharmacy Analytics

Experience: Minimum 6 years of industry experience in solving Health Plan, PBM business, or Commercial Pharma Analytic problems

Skills Needed: BS/MS/PhD in technical fields like Econometrics, Actuarial Science, Data Science, Health Outcomes, or Statistics, experience in Healthcare analytics and Specialty Medication, proficiency in statistical software (SQL programming, SAS, R, Python), familiarity with",0.1331114791482859,0.6463306
Senior Data Scientist,Northeastern University,"Portland, ME",https://www.linkedin.com/jobs/view/senior-data-scientist-at-northeastern-university-3633341452,2023-12-20,Brunswick,United States,Mid senior,Onsite,"About The Opportunity
About the Institute:
Do you want to be part of an exciting new Institute focused on the fusion of human and machine intelligence into working AI solutions? We are launching a pioneering research and innovation hub in AI—one that will shape the way humans and machines collaborate. Led by Dr. Usama Fayyad, the Institute for Experiential AI (EAI) is built around the challenges and opportunities made possible by human-machine collaboration. The institute provides a framework to design, implement, and scale AI-driven technologies in ways that make a true difference to society. Our ability to respond to the opportunities afforded to society will depend on training and building a workforce that is AI-capable. EAI has locations in the Northeastern campus in Boston, MA and the Roux Institute in Portland, ME. TAs part of the Roux Institute, EAI is closely involved in the goal of growing the Maine tech economy. Founded in 1898, Northeastern is a global research university and the recognized leader in experience-driven lifelong learning. Our world-renowned experiential approach empowers our students, faculty, alumni, and partners to create impact far beyond the confines of discipline, degree, and campus. This role collaborates with researchers and data scientists from various fields including Applied Analytics, Bioinformatics, Biotechnology, Computer Science, Cybersecurity, Genomics, Health Data Analytics, Law & ethics, Neuroscience and Therapeutics discovery. General research and interpersonal skills are especially valued. We are building a new team together to deliver the true promise of AI, which lies at the intersection of humans and intelligent machines
The Culture
Here at the EAI we are committed to the highest of standards in all that we do. Working at EAI offers opportunities, an environment, a culture that aren’t found together anywhere else. This is the right place for you if you’re curious, motivated by the future of technology and want to be part of a unique community that works on high-impact business and societal problems
Summary
This position supports the Institute in delivering data science and AI projects and expertise to its industry partners and researchers. Assist in delivering data science and AI courses and professional development programs to learners from across the University and industry. Help build AI products that will solve the most-pressing issues for organizations including Responsible AI. Be part of a fast-growing team that will develop and maintain a cutting-edge data platform, acquire data sets for research and education purposes and use data science strategically to support the Institute’s mission. Part of your role as Senior Data Scientist will be working with a major Maine research institute focusing on projects related to the “blue economy” of Maine (i.e. the sustainable use of ocean resources for economic growth).
Minimum
Qualifications:
Bachelor’s degree in Computer Science, Engineering, Mathematics, Statistics or similar disciplines and 5 or more years of professional experience, or can convincingly demonstrate this level of skill.
Knowledge, Skills And Abilities
Proficiency with statistical computer languages (Python is preferred).
Proficiency with relational database systems (SQL) and object-based data stores.
Advanced applied statistics skills, such as distributions, statistical testing, regression, etc.
Professional experience with developing machine learning solutions and applying them in real-world scenarios.
Experience scoping a project and collaborating with a team of technical and non-technical contributors on execution.
Proficient in Git and version control.
Ability to define and solve logical problems for technical applications.
Knowledge of and ability to select, adapt, and effectively use a variety of programming methods.
Knowledge of and ability to select, adapt, and effectively use a variety of programming methods.
Preferred Experience
Experience as a technical lead on projects, distributing tasks to other team members
Experience with forecasting methodologies
Experience with ecosystem and/or oceanographic data
Master’s degree in Computer Science, Mathematics, or Artificial Intelligence.
Experience with distributed data systems such as Apache Hadoop.
Expertise in analyzing large, complex, multi-dimensional datasets with a variety of tools.
Proficiency in Linux and version control software (git).
Familiarity with Agile / Scrum development practices.
Values & Abilities
Aptitude to independently learn new technologies, prototype and propose software design and solutions.
Excellent verbal and written communication skills.
Drive to learn new technologies, statistical methods and data manipulation techniques.
Ability to communicate effectively across academia and industry.
Team-player who can collaborate effectively across many teams within the University.
Open-minded and assertive when collaborating and working within our team and with other groups within Northeastern University.
Entrepreneurial mind-set with an ability to navigate complex structures and processes
Position Type
Research
Additional Information
Northeastern University considers factors such as candidate work experience, education and skills when extending an offer.
Northeastern has a comprehensive benefits package for benefit eligible employees. This includes medical, vision, dental, paid time off, tuition assistance, wellness & life, retirement- as well as commuting & transportation. Visit https://hr.northeastern.edu/benefits/ for more information.
Northeastern University is an equal opportunity employer, seeking to recruit and support a broadly diverse community of faculty and staff. Northeastern values and celebrates diversity in all its forms and strives to foster an inclusive culture built on respect that affirms inter-group relations and builds cohesion.
All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, religion, color, national origin, age, sex, sexual orientation, disability status, or any other characteristic protected by applicable law.
To learn more about Northeastern University’s commitment and support of diversity and inclusion, please see
www.northeastern.edu/diversity
.
Show more
Show less","Python, SQL, Machine learning, Git, Version control, Statistical testing, Regression, Forecasting, Ecosystem data, Oceanographic data, Hadoop, Linux, Agile, Scrum, Databases","Company Name: Institute for Experiential AI (EAI) at Northeastern University
Job Title: Senior Data Scientist
Experience: Bachelor's degree in Computer Science, Engineering, Mathematics, Statistics, or similar disciplines with at least 5 years of professional experience
Skills Needed: Proficiency in statistical computer languages, relational database systems, object-based data stores, applied statistics, machine learning solutions, Git version control, logical problem-solving, programming methods, scoping projects, forecasting methodologies, ecosystem and",0.16457960441242828,0.7203114
Lead Data Scientist,Northeastern University,"Portland, ME",https://www.linkedin.com/jobs/view/lead-data-scientist-at-northeastern-university-3733807583,2023-12-20,Brunswick,United States,Mid senior,Onsite,"About The Opportunity
About the Institute
Do you want to be part of an exciting new Institute focused on the fusion of human and machine intelligence into working AI solutions?
We are launching a pioneering research and innovation hub in AI—one that will shape the way humans and machines collaborate. Led by Dr. Usama Fayyad, the Institute for Experiential AI (IEAI) is built around the challenges and opportunities made possible by human-machine collaboration. The institute provides a framework to design, implement, and scale AI-driven technologies in ways that make a true difference to society. Our ability to respond to the opportunities afforded to society will depend on training and building a workforce that is AI-capable. Located in Portland, Maine, with the goal of growing the Maine tech economy, the Roux Institute will be a center of activity for the Institute’s efforts.
Founded in 1898, Northeastern is a global research university and the recognized leader in experience-driven lifelong learning. Our world-renowned experiential approach empowers our students, faculty, alumni, and partners to create impact far beyond the confines of discipline, degree, and campus.
This role collaborates with researchers and data scientists from various fields including Applied Analytics, Bioinformatics, Biotechnology, Computer Science, Cybersecurity, Genomics, Health Data Analytics, Law & ethics, Neuroscience and Therapeutics discovery. General research and interpersonal skills are especially valued. We are building a new team together to deliver the true promise of AI, which lies at the intersection of humans and intelligent machines
The Culture
Here at the Institute of Experiential AI (IEAI) we are committed to the highest of standards in all that we do. Working at the Institute of Experiential AI offers opportunities, an environment, a culture that just aren’t found together anywhere else. This is the right place for you if you’re curious, motivated by the future of technology and want to be part of a unique community that works on high-impact business and societal problems
Summary
This position supports the Institute in delivering data science and AI projects and expertise to its industry partners and researchers. Assist in delivering data science and AI courses and professional development programs to learners from across the University and industry. Help build AI products that will solve the most-pressing issues for organizations including Responsible AI. Be part of a fast-growing team that will develop and maintain a cutting-edge data platform, acquire data sets for research and education purposes and use data science strategically to support the Institute’s mission.
Qualifications
Education & Experience
:
Master’s degree in Computer Science, Engineering, Mathematics, Statistics or similar disciplines and 8 or more years of professional experience, or can convincingly demonstrate this level of skill.
Experience managing technical staff in the completion of projects
Experience communicating to technical and non-technical stakeholders and translating business problems into technical specifications
Knowledge, Skills And Abilities
Proficiency with statistical computer languages such as Python or R.
Proficiency with relational database systems (SQL) and object-based data stores.
Advanced applied statistics skills, such as distributions, statistical testing, regression, etc.
Professional experience with developing machine learning solutions and applying them in real-world scenarios.
Proficiency with deep learning frameworks such as PyTorch or TensorFlow.
Proficient in Git and version control.
Ability to define and solve logical problems for technical applications.
Knowledge of and ability to select, adapt, and effectively use a variety of programming methods.
Preferred Experience
Master’s degree in Computer Science, Mathematics, or Artificial Intelligence with 10 or more years professional experience
Experience with distributed data systems such as Apache Spark.
Expertise in analyzing large, complex, multi-dimensional datasets with a variety of tools.
Expertise in hypothesis testing, AB testing.
Proficiency in Linux and version control software (git).
Familiarity with Object Oriented programming languages such as Python, Java, C# or C++.
Familiarity with Agile / Scrum development practices.
Management of a team of 3 or more technical staff
Values & Abilities
Aptitude to independently learn new technologies, prototype and propose software design and solutions.
Excellent verbal and written communication skills.
Drive to learn new technologies, statistical methods and data manipulation techniques.
Ability to communicate effectively across academia and industry.
Team-player who can collaborative effectively across many teams within the University.
Open-minded and assertive when collaborating and working within our team and with other groups within Northeastern University.
Entrepreneurial mind-set with an ability to navigate complex structures and processes
Key Responsibilities & Accountabilities
30%
Management of AI and data science staff in the Solutions Hub team
Overseeing co-op recruitment, hiring and development
Support recruitment and development of technical talent
40%
Interface with research and business stakeholders to develop partnerships and statements of work
Lead delivery of projects by defining technical tasks, providing technical contributions and synthesizing results
Serve as technical representative in internal and external meetings
Support in developing technical stack (e.g. datasets, infrastructure) for execution on projects
20%
Supporting management of vendor involvement in projects
Track project health/performance
Support development and pricing of Solutions Hub projects
Position Type
Data Planning and Analysis
Additional Information
Northeastern University considers factors such as candidate work experience, education and skills when extending an offer.
Northeastern has a comprehensive benefits package for benefit eligible employees. This includes medical, vision, dental, paid time off, tuition assistance, wellness & life, retirement- as well as commuting & transportation. Visit https://hr.northeastern.edu/benefits/ for more information.
Northeastern University is an equal opportunity employer, seeking to recruit and support a broadly diverse community of faculty and staff. Northeastern values and celebrates diversity in all its forms and strives to foster an inclusive culture built on respect that affirms inter-group relations and builds cohesion.
All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, religion, color, national origin, age, sex, sexual orientation, disability status, or any other characteristic protected by applicable law.
To learn more about Northeastern University’s commitment and support of diversity and inclusion, please see
www.northeastern.edu/diversity
.
Show more
Show less","Python, R, SQL, Statistics, Machine learning, Deep learning, PyTorch, TensorFlow, Git, Linux, Apache Spark, Objectoriented programming, Agile, Scrum, Data science, AI, Data analysis, Data management, Data visualization, Communication, Teamwork, Problemsolving, Critical thinking, Analytical skills","Company Name: Institute for Experiential AI (IEAI) at Northeastern University

Job Title: Data Planning and Analysis

Experience: Master's degree in Computer Science, Engineering, Mathematics, Statistics, or related fields with at least 8 years of professional experience or equivalent skills

Skills Needed:
- Proficiency in statistical computer languages like Python or R
- Familiarity with relational database systems and object-based data stores
- Advanced applied statistics skills
- Experience in developing machine learning solutions",0.16554053866531226,0.5974865
Research Professor & Roux Institute Member in Computational Medicine & Biomedical Data Science (Open Rank),Northeastern University,"Portland, ME",https://www.linkedin.com/jobs/view/research-professor-roux-institute-member-in-computational-medicine-biomedical-data-science-open-rank-at-northeastern-university-3620792592,2023-12-20,Brunswick,United States,Mid senior,Onsite,"About The Opportunity
Northeastern University’s The Roux Institute invites applications for multiple
Research Professor and Roux Institute Member
positions in the fields of
Computational Medicine and Biomedical Data Science
. Sucessful applicants will be based at The Roux Institute in Portland, Maine. The faculty title is open rank. These are unique positions that offer a period of guaranteed salary support and startup funds commensurate with level of appointment. The
Research Professor (open rank)
at the Roux Institute at Northeastern University will be responsible for the growth of an independent research program positioned in the fields of Computational Medicine and Biomedical Data Science, coordinated under the umbrella of the Life Science and Medicine Research vertical directed by Dr. Raimond Winslow. Besides the faculty title of “Research Professor (open rank)”, the successful candidate will be named as an “Institute Member” at the Roux Institute. Besides driving their own research program as a Northeastern University faculty member, the Research Professor will contribute to a portfolio of highly matrixed collaborations with contributors on the Institute campus in Portland ME and beyond. Collaborators will include faculty and professional research staff at The Roux Institute, faculty across the Northeastern network, and industry researchers who may be co-located at the Institute or located at their own company.
The Successful Applicant Will Have Experience In
Developing computational models of disease at the level of molecular networks and physiological function, constraining these models using patient data, and applying these personalized models to predict outcomes and guide therapies. Modeling approaches can include dynamical systems modeling, control theoretic analyses, and machine learning
Developing data-driven, machine learning based methods for clinical decision support in broad areas of medicine and healthcare
A particular interest is the emerging field of machine-learning of dynamical systems, machine learning for simplifying complex dynamical systems models, and applications of these approaches in the life sciences and clinical research. Another area of interest is modeling-based quantitative systems pharmacology.
Academic appointments will be as a faculty member in one or more of Northeastern’s Colleges and Departments. Appointees will report to their disciplinary department chair in their role as a faculty member, and will report to the Director of Life Science and Medicine in Portland, who is responsible for the construction and execution of the relevant overarching research theme in Portland.
Candidates should have a PhD or other terminal degree in engineering or a related field, with experience level appropriate for appointment at the rank of Research Assistant Professor, Research Associate Professor, or Research Professor. Candidates should have: collaborative leadership skills; strong communication skills across diverse audiences and settings; an ability to work in a fast-paced and innovative setting; experience in working independently and as a member of a team. More senior candidates should have a demonstrated track record of scholarly achievement in relevant areas of engineering, with a research funding history commensurate with level of appointment.
Northeastern University is an equal opportunity employer, seeking to recruit and support a broadly diverse community of faculty and staff. Northeastern values and celebrates diversity in all its forms and strives to foster an inclusive culture built on respect that affirms inter-group relations and builds cohesion. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, religion, color, national origin, age, sex, sexual orientation, disability status, or any other characteristic protected by applicable law. To learn more about Northeastern University’s commitment and support of diversity and inclusion, please see
www.northeastern.edu/diversity
.
Founded in 1898, Northeastern University is a global research university and the recognized leader in experience-driven lifelong learning. Its world-renowned experiential approach empowers students, faculty, alumni, and partners to create impact far beyond the confines of discipline, degree, and campus.
The recently established Roux Institute at Northeastern University located in Portland ME is designed as an engine of innovation, talent-building, and economic growth for Portland, Maine, and northern New England. Partnerships set its model of graduate education and research apart. With leading companies and organizations at the table from day one, the Roux Institute creates programs that are preparing the workforce to stay agile and thrive in a competitive landscape powered by artificial intelligence (AI). It is creating an environment supporting high-impact research and innovation in AI, computational medicine, biomedical data science, digital engineering, data visualization and human-AI interactions. It assists entrepreneurs in launching businesses focused on and powered by technology. The Roux seeks to create an innovation corridor that will stretch from Boston to Portland and beyond. The Roux is a place where discovery science and engineering, entrepreneurship, and corporate partnerships co-exist in a positive feedback loop.
Position Type
Academic
Additional Information
Northeastern University is an equal opportunity employer, seeking to recruit and support a broadly diverse community of faculty and staff. Northeastern values and celebrates diversity in all its forms and strives to foster an inclusive culture built on respect that affirms inter-group relations and builds cohesion.
All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, religion, color, national origin, age, sex, sexual orientation, disability status, or any other characteristic protected by applicable law.
To learn more about Northeastern University’s commitment and support of diversity and inclusion, please see
www.northeastern.edu/diversity
.
Show more
Show less","Computational Medicine, Biomedical Data Science, Machine Learning, DataDriven Methods, Clinical Decision Support, ModelingBased Pharmacology, Dynamical Systems Modeling, Control Theoretic Analyses, Machine Learning for Simplifying Systems Models, Collaborative Leadership, Communication Skills, Innovation, Teamwork, Research Funding History","Company Name: Northeastern University, The Roux Institute
Job Title: Research Professor and Roux Institute Member
Experience: Candidates should have a PhD or other terminal degree in engineering or a related field, with experience level appropriate for appointment at the rank of Research Assistant Professor, Research Associate Professor, or Research Professor.
Skills Needed: The successful applicant will have experience in developing computational models of disease at the level of molecular networks and physiological function, constraining these models using patient data, and applying these personalized",0.21645021419013888,0.7565247
Business Data Analyst,Arkatechture,"Portland, ME",https://www.linkedin.com/jobs/view/business-data-analyst-at-arkatechture-3774854571,2023-12-20,Brunswick,United States,Mid senior,Remote,"Department:
Professional Services
Employment Type:
Full Time
Location:
Portland, ME, USA
Description
Why Work Here?
At Arkatechture, we have a simple shared mission: to build a sustainable organization built upon three pillars: Do something meaningful, With a great team, Earning what you deserve.
We started in 2012 with a passion for data, business, and getting things done. We are a team of data lovers and technical experts who use our skills to help businesses big and small harness, utilize, and optimize their data. As New England's Data Resource, we are a small company constantly evolving to keep up with changing landscapes in the data world.
We are proud of the community and culture that we've created at Arkatechture, and we have no intention of slowing down. We offer a competitive benefits package that includes:
A flexible work-from-home policy
Open-concept office in Portland, ME with an easy-going dress code, and fresh pots and pops all day (that's coffee and popcorn!)
Training & certificate reimbursement
A competitive benefits package that includes medical, disability, life insurance and optional dental/vision
401K Retirement planning with company matching
Generous paid time off and eleven paid holidays
Employee recognition through milestone awards including annual PTO increases, as well as a 4 day work-week at 3 years of service!
All employees share our core values: put the team first, practice humility, take pride in everything we do, stay curious, care for our community & environment, take work seriously; ourselves not so much.
The Position
Arkatechture is seeking candidates for a Business Data Analyst position to support Business Intelligence and Data warehousing initiatives focused on our Financial Services clients.
As a Business Data Analyst, responsibilities include data analysis, data profiling, data mapping, and developing SQL views. This role requires proficiency in interpreting data, trends, patterns in complex data sets, technical expertise with data models, databases and reporting tools like Tableau or PowerBI. The ability to interpret and use artifacts like business requirement documents, system requirements documents, requirement traceability matrix, workflows, data mapping, etc. is required. The ideal candidate will be able to work efficiently with the business and the technology teams collaborating with the project/program managers. This position has the opportunity to be 100% remote if desired.
How To Apply
Please send a cover letter and resume with your application.
You must submit both documents to be considered for the position
. Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Arkatechture we are dedicated to building a diverse, inclusive and authentic workplace, so if you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.
Key Responsibilities
Requirement gathering for Data pipeline development
Managing client interactions and growing client relationship during projects
Develop Source to Target Mappings
Data Profiling, analyzing source system data and metadata and collect requirements for data ingestion into a data warehouse
Developing and deconstructing complex SQL, Common Table Expressions, Stored Procedures, and Views for Business Conformance layers
Data Cleansing, Data Quality assessments and developing data quality rules
Building reference data for hierarchies, lookups and grouping purposes
Acquiring data from primary or secondary data sources and developing and maintaining Data Dictionaries
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and ""clean"" data by reviewing reports and key performance indicators to locate and correct code problems
Testing using SQL and providing development sign off
Locate and define new process improvement opportunities
Documentation of processes and workflows
Additional responsibilities as assigned
Minimum Qualifications
Skills, Knowledge and Expertise
Bachelor's Degree in a relevant field or 2-5 years of experience in a similar role
SQL Experience
Domain expertise in Financial Services working with Banks and/or Credit Unions, preferably focused on full credit lifecycle for Commercial and/or Consumer lending
Enthusiastic, learner and driven with a positive attitude
Strong critical and analytical thinking and problem solving skills
Experience working on multiple databases such as Snowflake, SQL Server, Databricks, Oracle, PostgreSQL, MySQL, etc
A strong understanding of Agile software development life cycle and methodology
Experience working on Data Management projects for Data Lakes/Data Warehousing
Preferred Experience
2+ years as a Subject Matter Expert in Financial Services, especially Commercial and/or Consumer lending
Understanding of cloud platforms such as AWS
Experience developing and implementing dbt models
Show more
Show less","Business Data Analyst, Data analysis, Data profiling, Data mapping, SQL views, Data models, Databases, Reporting tools, Tableau, PowerBI, Business requirement documents, System requirements documents, Requirement traceability matrix, Workflows, Data mapping, Project managers, Data pipeline development, Client interactions, Client relationship, Source to Target Mappings, Data Profiling, Data ingestion, SQL, Common Table Expressions, Stored Procedures, Views, Business Conformance layers, Data Cleansing, Data Quality assessments, Data quality rules, Reference data, Hierarchies, Lookups, Grouping, Data Dictionaries, Trends, Patterns, Data sets, Reports, Key performance indicators, Development sign off, Process improvement opportunities, Documentation, Workflows, Agile software development life cycle, Data Management projects, Data Lakes, Data Warehousing, Subject Matter Expert, Financial Services, Commercial lending, Consumer lending, Cloud platforms, AWS, dbt models","Company: Arkatechture  
Job Title: Business Data Analyst  
Experience: Bachelor's Degree in a relevant field or 2-5 years of experience in a similar role  
Skills Needed: SQL Experience, Domain expertise in Financial Services, Enthusiastic and driven with a positive attitude, Strong critical thinking and problem-solving skills, Experience with multiple databases, Understanding of Agile methodology, Experience with Data Management projects, Preferred experience in Financial Services and cloud platforms.",0.14615384435384618,0.36950395
Data Center Operations Engineer,"Liberty Personnel Services, Inc.","Secaucus, NJ",https://www.linkedin.com/jobs/view/data-center-operations-engineer-at-liberty-personnel-services-inc-3698219138,2023-12-20,Nyack,United States,Associate,Onsite,"Job Details:
Data Center Operations Engineer
My client is looking to hire a Data Center Operations Engineer for its Secaucus NJ location. In this role you will support linux and windows, telecom and security. Shift work is required. This is a permanent position.
If you are interested please forward your resume in word format to kevin@libertyjobs.com
Kevin McCarthy
#associate
#mid-senior
Show more
Show less","Linux, Windows, Telecom, Security","Company Name: N/A
Job Title: Data Center Operations Engineer
Experience: Mid to Senior Level
Skills Needed: Linux and Windows support, telecom and security knowledge, ability to work in shifts.",0.27160493382716056,0.73730683
Data Analyst,Motion Recruitment,"Woodcliff Lake, NJ",https://www.linkedin.com/jobs/view/data-analyst-at-motion-recruitment-3762684541,2023-12-20,Nyack,United States,Associate,Onsite,"Our client is looking to hire for an
Ecommerce
Data Analyst
to join their team
onsite
, in
Woodcliff Lake, NJ!
Responsibilities:
Provide support in managing and maintaining digital analytics, opportunity identification and prioritization, hypothesis generation, test setup and reporting
Responsible for reporting and analysis of digital platforms and marketing campaigns against a holistic set of KPIs and benchmarks
Collecting and analyzing data from multiple sources such as customer databases, web analytics, market research, and surveys.
Creating reports and dashboards to track key performance indicators.
Identifying trends and recommending strategies to improve ecommerce performance.
Building and monitoring predictive models to optimize pricing and promotional decisions.
Enhancing customer segmentation and targeted marketing campaigns.
Understanding user behavior and leveraging insights to drive product design, development, and optimization.
Collaborating with teams across departments to ensure data accuracy and integrity.
Qualifications:
2+ years of direct and hands-on experience providing solutions.
Excellent analytical skills, be detail-oriented, and work well within a small, dynamic and data-driven team.
Solid understanding of database technologies, data analytics, and reporting tools.
Analytical skills to interpret data and draw meaningful insights.
Good communication and presentation skills.
Knowledge of machine learning and predictive modeling techniques is plus but not required.
Understanding of web analytics and customer segmentation techniques.
Hands-on experience with statistical platform such as Google Analytics, Ads
Benefits:
A competitive starting salary based on experience, with achievement based opportunities for annual bonuses and increases.
Opportunities for professional advancement. We value big thinking tied to practical, collaborative execution in a structured and growth oriented company.
Ongoing mentoring from senior staff and periodic opportunities to attend industry seminars and workshops.
Starting on the first day of hire, all employees can begin participating in our excellent Major Medical, Dental, Vision and Life Insurance plans.
Paid holiday and vacation time, which starts in the first year of employment and increases with tenure.
A modern, professional, suburban office space, concentrated work day (8:30-5:30) and business-attire environment.
We enjoy a professional, collegial and positive work atmosphere, sharing camaraderie and rooting for individual and collective success.
Show more
Show less","Digital Analytics, Opportunity Identification, Hypothesis Generation, Test Setup, Reporting, Data Analysis, Data Collection, Customer Databases, Web Analytics, Market Research, Surveys, Predictive Modeling, Customer Segmentation, User Behavior Analysis, Product Design, Product Development, Product Optimization, Machine Learning, Statistical Platforms, Google Analytics, Google Ads, Databases, Data Analytics Software, Reporting Tools, Communication Skills, Presentation Skills","Company Name: Not specified
Job Title: Ecommerce Data Analyst
Experience: 2+ years
Skills Needed: The ideal candidate should have excellent analytical skills, attention to detail, and the ability to work effectively in a dynamic, data-driven team. They should possess a solid understanding of database technologies, data analytics, and reporting tools. Additionally, proficiency in interpreting data, strong communication and presentation skills, knowledge of web analytics and customer segmentation techniques, and hands-on experience with statistical platforms such as Google",0.24836600965162975,0.7406224
Data Analyst,Steneral Consulting,"Ramsey, NJ",https://www.linkedin.com/jobs/view/data-analyst-at-steneral-consulting-3758496996,2023-12-20,Nyack,United States,Associate,Onsite,"100% onsite role, must be local to NJ and under 60 mins commute
need LinkedIn
Need 10/10 comms
Sage 100 ERP migrating to FactoryMaster (do not need experience w/ this)
They need a person to come in a clean up the data
Advanced Excel
Any ERP Experience
Data Cleanse
After cleanse they will do migration to FactoryMaster
Show more
Show less","Sage 100 ERP, FactoryMaster, Advanced Excel, Data Cleanse, ERP Experience","The job is with a company located in New Jersey and requires the candidate to be within a 60-minute commute. The position involves migrating from Sage 100 ERP to FactoryMaster, although prior experience with FactoryMaster is not required. Key skills needed include strong communication, proficiency in Advanced Excel, any ERP experience, and expertise in data cleansing. The main responsibility will be cleaning up data before proceeding with the migration process to FactoryMaster.",0.3518518468587106,0.7049266
Data Analyst,Steneral Consulting,"Ramsey, NJ",https://www.linkedin.com/jobs/view/data-analyst-at-steneral-consulting-3757540480,2023-12-20,Nyack,United States,Associate,Onsite,"100% onsite role, must be local to NJ and under 60 mins commute
need LinkedIn
Need 10/10 comms
Sage 100 ERP migrating to FactoryMaster (do not need experience w/ this)
They need a person to come in a clean up the data
Advanced Excel
Sage 100 background
Data Cleanse
After cleanse they will do migration to FactoryMaster
Show more
Show less","Sage 100 ERP, FactoryMaster, Advanced Excel, Data Cleanse","This job is for a 100% onsite role in New Jersey, requiring the candidate to be local and within a 60-minute commute. The company is seeking an individual with expert communication skills (rated 10/10 on LinkedIn) who has experience with Sage 100 ERP. Experience with FactoryMaster is not required as the role involves migrating data from Sage 100 ERP to FactoryMaster. The main responsibility is to clean up data using advanced Excel skills, particularly focusing on data cleanse. The successful candidate",0.41071428075414546,0.8086952
DATA ANALYST,Steneral Consulting,"Ramsey, NJ",https://www.linkedin.com/jobs/view/data-analyst-at-steneral-consulting-3755501845,2023-12-20,Nyack,United States,Associate,Onsite,"100% onsite role, must be local to NJ and under 60 mins commute
need LinkedIn
Need 10/10 comms
Sage 100 ERP migrating to FactoryMaster (do not need experience w/ this)
They need a person to come in a clean up the data
Advanced Excel
Sage 100 background
Data Cleanse
After cleanse they will do migration to FactoryMaster
Show more
Show less","Sage 100 ERP, FactoryMaster, Advanced Excel, Data Cleanse","The job is with a company based in New Jersey and requires the candidate to be local with a commute of under 60 minutes. The role involves working onsite and requires excellent communication skills, as well as proficiency in LinkedIn. The candidate should have experience with Sage 100 ERP and advanced Excel skills. Experience with data cleansing and migration, particularly from Sage 100 to FactoryMaster, is required. The main responsibility will be cleaning up data before migrating it to FactoryMaster.",0.39999999502644634,0.79735905
Data Analyst - Hoboken NJ - 12+ Months Contract,TMS,"Hoboken, NJ",https://www.linkedin.com/jobs/view/data-analyst-hoboken-nj-12%2B-months-contract-at-tms-3782773358,2023-12-20,Nyack,United States,Associate,Onsite,"Role: Data Analyst
Location: Hoboken NJ
Duration: 12+ Months
Job Description
The Labeling / Data analyst within the Pricing team will play a key role in maintaining precise pricing strategies by analyzing tickets, collaborating with stakeholders, providing 24x7 on-call support (rotation), and ensuring superior customer service.
Primary Responsibilities
Ticket Analysis and Labeling: Review generated tickets, focusing on pricing parameters. Label tickets for precision and recall analysis to ensure comprehensive tracking and resolution of pricing-related issues and model improvements for Walmart Owned & Marketplace products.
Stakeholder Collaboration: Engage with merchants, SAMs, and other stakeholders to understand pricing requirements. Escalate issues promptly to the appropriate personnel for resolution, ensuring timely fixes.
Cross-Functional Collaboration: Collaborate with cross-functional stakeholders such as engineering, product, legal, customer trust, and internal teams. Identify root causes, resolve issues independently or escalate to relevant teams for resolution.
Customer Interaction and Issue Resolution: Respond to customer queries, process orders, and troubleshoot issues across multiple communication channels. Maintain a high level of customer service while addressing customer comments and resolving issues promptly
Bug Replication and Ticket Escalation: Replicate, troubleshoot, and document simple bugs. Maintain thorough records in the ticketing system and escalate unresolved tickets to the L2 Support team
Documentation and Process Improvement: Create documentation of support processes when assigned. Continuously seek to improve support workflows and procedures by providing recommendations based on RCA done during ticket review.
Performance Metrics and SLA: Strive to exceed SLA expectations, drive key support metrics, and improve the seller and customer experience through superior support.
24x7 On-Call Support: Participate in a rotational on-call schedule, being available round-the-clock to address urgent pricing issues, ensuring minimal disruption to pricing strategies across all channels
Skillset Requirements
Knowledge of SDLC, JIRA, Tableau, etc.
Excellent written and verbal communication skills
Strong troubleshooting, analytical, and problem-solving abilities.
Proficiency in Excel, Word, and email software
Ability to work in a team, prioritize tasks, and multitask efficiently
Qualifications
High School diploma or Bachelor’s
Strong troubleshooting and analytical skills.
Ability to work autonomously in a fast-paced, agile environment.
Adaptability to change and proactive problem-solving skills.
Show more
Show less","Data Analysis, Tableau, SDLC, JIRA, Microsotf Excel, Microsoft Word, Documentation, Troubleshooting, Communication, Teamwork","Company: Walmart
Job Title: Labeling / Data Analyst
Experience: High School diploma or Bachelor's degree required
Skills Needed: Knowledge of SDLC, JIRA, Tableau, excellent written and verbal communication skills, strong troubleshooting and analytical abilities, proficiency in Excel, Word, and email software, ability to work in a team, prioritize tasks, and multitask efficiently
Summary: The Labeling / Data Analyst at Walmart in Hoboken, NJ, will be responsible for maintaining precise pricing strategies",0.26845637258299176,0.6182334
Senior Data Analyst,Amtex Systems Inc.,"Queens, NY",https://www.linkedin.com/jobs/view/senior-data-analyst-at-amtex-systems-inc-3783113035,2023-12-20,Nyack,United States,Associate,Onsite,"Amtex Systems Inc is an information technology and talent solutions company offering talent and BI consulting to the companies in US for over 20 years.
Our solutions are designed to fill resource gaps, by providing the right candidates who deliver value to the organization. Our propensity to nurture and build strong relationships with our clients helps us better understand their business demands and gives us the ability to provide services that are on time and rise above the rest.
Position Overview:
Develop analysis and reporting.
Responsibilities
Compile data from various resources and perform data analysis;
Run ad hoc reports at request;
Produce and update pre-formatted report;
Ability to write scripts in Excel or Access for reports, data cleanup and advanced query
Build Access relational database and set up queries and reports
Understand the business context of report and be able to prepare presentations for internal and external audience;
Support team with other assignments.
Qualifications And Skills (Required)
Data analysis; familiar with MS Office, esp. Excel, Access and PowerPoint; ability to write scripts to update files, run reports and simplify manual work.
Bachelor's Degree.
Show more
Show less","Data analysis, Microsoft Office Suite, Excel, Access, PowerPoint, Scripting, Report generation, Presentation skills, Relational database, Querying, Data cleanup","Company: Amtex Systems Inc
Job Title: Data Analyst
Experience: Not specified
Skills Needed: Data analysis, proficiency in MS Office (Excel, Access, PowerPoint), ability to write scripts for reports and data cleanup, familiarity with creating Access relational databases, strong presentation skills, Bachelor's Degree.",0.23595505263413716,0.8497249
Financial Analyst - Data Analytics,"REV Group, Inc","Woodcliff Lake, NJ",https://www.linkedin.com/jobs/view/financial-analyst-data-analytics-at-rev-group-inc-3789168654,2023-12-20,Nyack,United States,Associate,Hybrid,"As an independent group of companies, the BMW Group has a commitment to creativity and breakthrough ideas that goes well beyond the racetrack. In order to continuously create ultimate driving machines, we drive our growth and design excellence by staffing our teams with individuals who are innovative and always looking for the next great idea. If you share our vision and view yourself as an independent, creative thinker, we invite you to join our team in this exceptional role located in Woodcliff Lake, NJ.
The Financial Analyst – Data Analytics is responsible for the planning, reporting and steering of sales allowances for BMW/MINI/Motorrad effectively utilizing data and analytics.
Key Responsibilities:
Identifying and solving problems for Cost of Retail planning & reporting and processes
Collecting information and automating the data feed from a variety of sources
Use data analysis techniques to get practical information from raw data and communicate findings to executives, managers, and employees to impact decision making
Plan, report on and steer smaller size CoR programs (up to approx. $100m) with the respective Business Departments
Support the Controlling department on special data automation tasks as needed
Planning and Reporting (BMW / MINI / Motorrad) with the emphasis on supporting the following with BI tools:
Build in-depth understanding of topics and processes within the sales allowances team with emphasis on observing how controlling, sales and financial services interact to steer the KPI
Gather, analyze and interpret data relevant to the sales allowance programs
Support in reviewing the GL and monthly close for Sales Allowances, particularly in regards to the analysis of deviations vs. plan. Take initiative and investigate and resolve any identified errors.
Support the team in planning submissions (Actuals / Forecasts / Budgets / ad hoc requests) in adherence with BMW Group reporting guidelines for BMW, MINI and Motorrad Sales Allowances.
Completion of these processes for the assigned smaller size CoR programs
Support the team in compiling data for the monthly variance reports comparing Actuals / Forecast and Budget figures
Support the team to make data/information available for ad-hoc analysis and reporting as requested by executive management
Join the BMW North America team and enjoy a high-performance Total Rewards package that may include:
Medical, Dental, and Vision insurance
All with options for $0 Employee contribution
401(k) with Company match
Retirement Income Account (RIA)
Employee vehicle program
Bonus eligibility
Paid Parental Leave of up to 6 weeks
Paid Time Off in addition to Company paid holidays where eligible
Hybrid work environment
Voluntary Benefits to fit your needs
The pay range for this role is: $74,831.00 - $87,642.00.
The selected candidate’s education, skills, experience, and location will be used to determine the final salary offer. All pay ranges are based on a full-time work schedule. This statement is in accordance with state and local pay disclosure requirements.
Even more so than the generous compensation and benefits, the culture and values of BMW of North America makes it the ultimate working environment. These values are Responsibility, Appreciation, Transparency, Trust, and Openness. We allow these values to guide the way we conduct ourselves and our business.
At BMW, we are driven by diversity, equity, and inclusion. We are proud to be an Equal Opportunity Employer and are welcoming of all individuals, regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.
Qualification:
Requirements:
Bachelor’s degree in Business Administration, Business Analytics, Finance or Accounting/Controlling or Economics
3+ years of professional or academic experience working with Data and Analytics tools including BI Tools, Data Analysis tools and Data preparation Tools
Experience using SQL
Preferences:
2+ years Financial Services or Automotive Industry experience
2+ years data exploration and mining using tools like R, Python, or equivalent 2+ years Data Governance / Management process application experience; i.e. Informatica EDC, Axon, IDQ, or equivalent training
Educational background in Data Analytics, Computer Science, MIS, Economics, Mathematics, or Statistics
Experience assessing and providing insights using Tableau or Qlik
Experience creating reports/dashboard development using Tableau or Qlik
Experience using MS SQL or PostgreSQL
Exposure to data analysis tools like R, SAS orRapidMiner
Data Preparation skills using Tableau Prep or Alteryx
Show more
Show less","Business Analytics, Finance, Accounting, Controlling, Economics, Data Analysis, SQL, BI Tools, Data Preparation Tools, R, Python, SQL, PostgreSQL, Tableau Prep, Alteryx, Tableau, Qlik","Company: BMW Group

Job Title: Financial Analyst – Data Analytics

Experience: 3+ years of professional or academic experience working with Data and Analytics tools including BI Tools, Data Analysis tools, and Data preparation Tools

Skills Needed: Bachelor’s degree in Business Administration, Business Analytics, Finance or Accounting/Controlling or Economics, experience using SQL, 2+ years Financial Services or Automotive Industry experience preferred, experience with data exploration and mining tools like R, Python, or equivalent, background in Data",0.18789143846827727,0.6785285
VDC Data & Reporting Analyst,"REV Group, Inc","Woodcliff Lake, NJ",https://www.linkedin.com/jobs/view/vdc-data-reporting-analyst-at-rev-group-inc-3789171179,2023-12-20,Nyack,United States,Associate,Hybrid,"As an independent group of companies, the BMW Group has a commitment to creativity and breakthrough ideas that goes well beyond the racetrack. In order to continuously create ultimate driving machines, we drive our growth and design excellence by staffing our teams with individuals who are innovative and always looking for the next great idea. If you share our vision and view yourself as an independent, creative thinker, we invite you to join our team in this exceptional role located in Woodcliff Lake, NJ.
VDC Data and Reporting Analyst primary responsibilities is to develop, maintain, and distribute daily, monthly, and annual reporting to internal departments and external partners. The selected candidate will identify opportunities to automate existing reporting and condense large data sets into actionable insights and recommend potential reporting optimization opportunities.
In support of BMW Group’s business objectives, this position requires regular attendance at a BMW office/facility with remote work capability (hybrid).
Analysis & Insights:
Analyze Wholesale and Transportation trends and identify opportunities.
Assist with the development of ad/hoc analysis.
Develop and maintain regional transportation performance analysis.
Partner with internal business units to provide reporting and analysis support and to gain insights.
Reporting:
Update and distribute wholesale reporting to internal departments.
Update, maintain and distribute regular reporting to external partners.
Develop and update Business Steering reporting.
Update and distribute all standard monthly reporting.
Identify opportunities to automate reporting and implement.
Identify opportunities to leverage latest data visualization tools and create new reports. Continuously innovate and advance reporting in order to develop actionable insights.
Join the BMW North America team and enjoy a high-performance Total Rewards package that may include:
Medical, Dental, and Vision insurance
All with options for $0 Employee contribution
401(k) with Company match
Retirement Income Account (RIA)
Employee vehicle program
Bonus eligibility
Paid Parental Leave of up to 6 weeks
Paid Time Off in addition to Company paid holidays where eligible
Hybrid work environment
Voluntary Benefits to fit your needs
The pay range for this role is: $74,831.00 - $87,642.00.
The selected candidate’s education, skills, experience, and location will be used to determine the final salary offer. All pay ranges are based on a full-time work schedule. This statement is in accordance with state and local pay disclosure requirements.
Even more so than the generous compensation and benefits, the culture and values of BMW of North America makes it the ultimate working environment. These values are Responsibility, Appreciation, Transparency, Trust, and Openness. We allow these values to guide the way we conduct ourselves and our business.
At BMW, we are driven by diversity, equity, and inclusion. We are proud to be an Equal Opportunity Employer and are welcoming of all individuals, regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.
Qualification:
Requirements:
Bachelor’s degree in business administration, engineering, programming or equivalent work experience
3-5 years in reporting and analysis
Preference:
OEM
Advanced Knowledge of MS Office
Advanced skills in Excel, BI, and Tableau
Experience with SAP
Strong analytical and problem solving skills
Experience in working with large data sets
Show more
Show less","Reporting, Data Analysis, Analysis & Insights, Ad Hoc Analysis, Business Steering, Visualization Tools, BI, Tableau, MS Office, Excel, SAP, Analytical Skills, Problem Solving Skills, Working with Large Data Sets","Company Name: BMW Group
Job Title: VDC Data and Reporting Analyst
Experience: 3-5 years in reporting and analysis
Skills Needed: Bachelor’s degree in business administration, engineering, programming or equivalent work experience, Advanced Knowledge of MS Office, Advanced skills in Excel, BI, and Tableau, Experience with SAP, Strong analytical and problem-solving skills, Experience in working with large data sets.",0.20911527921914194,0.5819623
Data Software Engineer,C2R Ventures,New York City Metropolitan Area,https://www.linkedin.com/jobs/view/data-software-engineer-at-c2r-ventures-3775618610,2023-12-20,Nyack,United States,Associate,Hybrid,"Hedge Fund managing 8 Billion in AUM is seeking an Software Developer who will sit on the Data team and will work closely with the front office to improve data ingestion / analysis.
Responsibilities
Deliver data quickly including thoughtful design, unit testing, integration testing, and development
Maintain and enhance the data platform
Partner with front office analysts and quants, on variety of financial, macroeconomic, and alternative data
Qualifications
Bachelor's degree or equivalent experience in Computer Science or related field
Development experience with programming languages (Python
Strong SQL experience (Microsoft SQL Server a plus)
Experience with data sets that are specific to an industry (financial data preferred)
2+ Years of Experience
Show more
Show less","Python, SQL, Data Analysis, Data Ingestion, Unit Testing, Integration Testing, Development, Platform Maintenance, Financial Data, Macroeconomic Data, Alternative Data","Company: Hedge Fund managing 8 Billion in AUM
Job Title: Software Developer on the Data Team
Experience: 2+ years
Skills Needed: Bachelor's degree in Computer Science or related field, programming languages (Python), strong SQL experience (Microsoft SQL Server a plus), experience with industry-specific data sets (financial data preferred). Responsibilities include delivering data with thoughtful design, unit testing, and integration testing, maintaining and enhancing the data platform, and collaborating with front office analysts and quants on",0.5616438307515482,0.8644546
IQVIA Data Analyst,SUN PHARMA,"Hawthorne, NY",https://www.linkedin.com/jobs/view/iqvia-data-analyst-at-sun-pharma-3778536401,2023-12-20,Nyack,United States,Associate,Hybrid,"Job description:
Summary:
This position will support and collaborate with the department and other cross functional departments (sales, art department, regulatory, supply chain, portfolio, etc.) in the development, review, and maintenance of marketing tools, competitor market intelligence, hub services, competitive product intelligence, product launch materials, executive and customer presentations and databases. In addition will be responsible for helping with the coordination of major trade shows each year.
Further, the candidate will utilize these tools for market analysis and to formulate go forward recommendations to support the organizations sales and marketing functions related to the continuous growth of Taro’s product portfolio.
Additionally, the Senior Analyst will assist with the development and management of product strategies to maximize revenue growth and ensure launch target goals are achieved, including revenue and desired market share.
The ideal candidate will have a background consistent with managing multiple projects and be able to work closely with cross functional teams to develop and maintain valuable marketing and reporting information.
Duties and Responsibilities:
Work with marketing team and other cross functional departments to provide sales with the necessary marketing tools, materials, and support to more efficiently and effectively sell Taro generic products.
Data review, organization, and presentation
Analyze historical sales trends, IQVIA prescription trends, market intelligence, and other pertinent information to formulate launch strategies
Provide pro-active and in-depth financial analysis of the products
Database / website maintenance
Supply chain / product launch coordination
Work with cross functional departments to collect data and monitor market opportunities
Market research and reporting
Provide proactive and in-depth financial analysis of product or market-specific business activity
Responsible for managing, analyzing and tracking commercial portfolio’s performance to budget. Identify challenges and underperforming molecules and make strategic adjustment recommendations to increase sales performance.
Review monthly performance of Generic business. Work cross-functionally with finance, supply chain and sales to identify areas for improvement and present results from implemented strategies.
Responsible for generating and forecasting the Generics Sales Budget plan while working cross-functionally with finance, sales, supply chain, and pricing & contracts.
Assist Pricing team with maximizing margin retention while dealing with constant pricing pressure from accounts.
Quarterly Analysis of market trends, and Taro’s portfolio. Identify price and unit growth trends, identify key drivers, and make strategic recommendations to adjust to market dynamics.
Account based strategic analytics.
Product based strategic analytics.
Work with cross functional departments to implement new strategies that will resolve current limitations, improve processes and increase sales.
Quarterly tracking and reporting of Taro’s market share KPOs.
Responsible for supporting cross functional departments with strategic ad hoc analytics to drive sales.
Responsible for generating and forecasting the expense budget plan for department of Sales & Marketing.
Responsible for generating Monthly Performance Review deck. Reporting on Taro’s financial monthly performance. Reporting on top positive and negative molecule drivers, identifying key wins and losses, and any impactful market share changes.
Work closely with supply chain to understand supply limitations and make recommendations on strategies to limit backorders and maximize potential sales.
Qualifications/Education:
BS in business, marketing or related discipline.
Strong orientation to detail and ability to grasp new concepts
Ability to analyze and interpret IQVIA data
Strong organization, communication and presentation skills
Ability to meet tight deadlines in an environment of competing priorities
Ability to build strong internal and external relationships, foster an environment of teamwork and collaboration.
Previous experience within the generic pharmaceutical industry strongly preferred.
Subject matter expert on Microsoft Office applications
The presently-anticipated base compensation pay range for this position is $95,500 to $119,000. Actual base compensation may vary based on a number of factors, including but not limited to geographical location and experience. In addition, this position is part of the Annual Performance Bonus Plan.  Employees are eligible to participate in Company employee benefit programs which include medical, dental and vision coverage; life insurance; disability insurance; 401(k) savings plan; flexible spending accounts; and the employee assistance program. Employees also receive various paid time off benefits, including vacation time and sick time.
The compensation and benefits described above are subject to the terms and conditions of any governing plans, policies, practices, agreements, or other materials or documents as in effect from time to time, including but not limited to terms and conditions regarding eligibility. If hired, employee will be in an “at-will position” and the Company reserves the right to modify base salary (as well as any other discretionary payment or compensation program) at any time, including for reasons related to individual performance, Company, or individual department/team performance, and market factors.
The preceding job description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees as assigned to this job. Nothing herein shall preclude the employer from changing these duties from time to time and assigning comparable duties or other duties commensurate with the experience and background of the incumbent(s).
EEO Notice:
We provide equal employment opportunities for all current employees and applicants for employment. This policy means that no one will be discriminated against because of race, religion, creed, color, national origin, nationality, citizenship, ancestry, sex, age, marital status, physical or mental disability, affectional or sexual orientation, military or veteran status, generic predisposing characteristics or any other basis prohibited by law.
Notice to Agency and Search Firm Representatives:
Sun Pharmaceuticals (Sun) is not accepting unsolicited resumes from agencies and/or search firms for this job posting. Resumes submitted to any Sun employee by a third party agency and/or search firm without a valid written & signed search agreement, will become the sole property of Taro. No fee will be paid if a candidate is hired for this position as a result of an unsolicited agency or search firm referral.
Show more
Show less","Microsoft Office, IQVIA, Data Analysis, Market Research, Financial Analysis, Sales Reporting, Strategic Analytics, Project Management, Team Collaboration, Communication, Presentation Skills, Time Management, Data Review and Organization, Databases and Website Maintenance, Supply Chain Coordination, Product Launch Management, Revenue Growth Strategies, Market Share Analysis, Pricing and Contracts, AccountBased Analytics, ProductBased Analytics, Ad Hoc Analytics, Performance Review and Reporting, Backorder Mitigation, Pharmaceutical Industry Experience","Company Name: Taro Pharmaceuticals
Job Title: Senior Analyst - Marketing and Sales
Experience: Previous experience within the generic pharmaceutical industry strongly preferred.
Skills Needed: Strong orientation to detail, ability to analyze and interpret IQVIA data, strong organization, communication, and presentation skills, ability to build strong relationships, subject matter expert on Microsoft Office applications, BS in business, marketing, or related discipline.",0.15162454697702307,0.7151996
Sales Data Analyst,Eliassen Group,New York City Metropolitan Area,https://www.linkedin.com/jobs/view/sales-data-analyst-at-eliassen-group-3757643109,2023-12-20,Nyack,United States,Associate,Hybrid,"Hybrid (1-2 days a week) in NYC office
W2 Contract
$28 to $32 per hour
Our Fortune 500 Media Client is seeking a Sales Data Analyst for a contract opportunity. The Analyst will help organizations make data-driven decisions by gathering, analyzing, and presenting data and insights. This position involves collecting and transforming data from various sources, creating meaningful reports, dashboards, and visualizations. This person needs to be process oriented and collaborate with different departments to enhance data quality, monitor key performance indicators, create process workflows and dynamic analyses of various datasets.
Required Skills:
• 2-3+ years' experience as an Analyst in Media, Sales Operations, or related field
• Advanced proficiency with Microsoft Excel and PowerPoint are must haves
• Familiarity with sales CRM and reporting tools, such as Salesforce, Google Data Studio, and Tableau or similar visualization tools is a HUGE plus
• Experience with large data sets, synthesizing insights, financial / operational modeling and recommending actions from data
• Great written and verbal communication skills
• Ability to thrive in fast-paced environment
• Multitasking and excellent organizational skills
Additional Qualifications
• Strong knowledge and interest in the media, entertainment, and advertising industry
• Ability to apply knowledge and resourcefulness in acquiring needed data, both from internal systems as well as external data and sources, understanding the proper internal groups on point to provide key types of data (e.g., financials, ratings, etc.).
Show more
Show less","Data Analytics, Microsoft Excel, Microsoft PowerPoint, Sales CRM, Salesforce, Google Data Studio, Tableau, Data Visualization, Financial Modeling, Communication, Multitasking, Data Acquisition, Media, Entertainment, Advertising","Company: Fortune 500 Media Client
Job Title: Sales Data Analyst
Experience: 2-3+ years
Skills Needed: Advanced proficiency in Microsoft Excel and PowerPoint, familiarity with sales CRM and reporting tools (e.g. Salesforce, Google Data Studio, Tableau), experience with large data sets, strong communication skills, ability to thrive in a fast-paced environment, multitasking and organizational skills. Additional qualifications include knowledge and interest in media, entertainment, and advertising industry, resourcefulness in acquiring data",0.3690987085811122,0.6181633
Clinical Flow Cytometry Data Analyst TEMP,Magnit,"Tarrytown, NY",https://www.linkedin.com/jobs/view/clinical-flow-cytometry-data-analyst-temp-at-magnit-3703018754,2023-12-20,Nyack,United States,Mid senior,Onsite,"Clinical Flow Cytometry Data Analyst TEMP
Pay Range: 36.39 - 59.38
We are seeking a Clinical Flow Cytometry Data Analyst to join our Precision Medicine team. Precision Medicine, a part of Early Clinical Development & Experimental Sciences leads biomarker strategy and execution from early concept studies through late development and is supported by Precision Medicine Strategy Leads, Precision Medicine Operations specialists, as well as quantitative analytical and companion diagnostics scientists.
Flow cytometry continues to gain importance with regulators as an essential method in the development of personalized medicine. In this newly created role that resides within Precision Medicine, the individual would be primarily responsible for supporting analysis and review of clinical flow cytometry data acquired across various clinical studies and therapeutic areas. The role requires a solid, hands-on understanding of flow cytometry and will support data characterization from conventional and spectral cytometry platforms often from large multi-color panels. In this role, the individual would develop a pipeline to ensure high data quality, working closely with key internal stakeholders and vendors. The selected individual would be an important contributor to the Biomarker Assays and Quality team. This is an onsite role with participation in meetings and activities in Tarrytown, NY.
As a Clinical Flow Cytometry Data Analyst, a typical day may include the following:
Review and analyze raw data (using various gating strategies) to identify irregularities and negative trends
Contribute independently and in matrix teams to improve data quality from flow cytometry experiments
Meet with key stakeholders and develop KPIs for assay quality, and periodically review assay quality data from various sources on relevant clinical trials
Support clinical biomarker strategy leads through data upload, workflow sharing, and other activities performed especially through cloud platforms
Support initiatives to reduce instrument and technical variation across assays and vendors
Support the development of business process documents related to these activities
Manage limited number of critical internal reagents especially supporting cytometry assays with monitoring of consumption and forecasting future needs
Participate in cross functional meetings to support flow cytometry and other biomarker assay development, validation and assay quality initiatives
This role may be for you if:
Candidate must be detail-oriented, self-starter and possess both strong organizational and communication skills
Able to multi-task and critically analyze and troubleshoot technical/scientific problems of various complexity levels
Ability to collaborate cross-functionally with members of the Flow Cytometry Core and research therapeutic areas
To be considered for this role, you must have a B.S. with at least 2-3 years’ experience performing and analyzing flow cytometry assays or M.S. with at least 1 year experience. Experience and coursework in Immunology and/or Oncology setting preferred. Experience independently using at least 1 or more flow cytometry software programs (FlowJo, FCS Express, etc) is required. Knowledge of OMIQ analysis platform a plus. Experience in coding (R, Python, etc), Data Science or willingness to learn in support of role and tool building. Proficiency with Microsoft Word, Excel, PowerPoint; experience with MS Project is helpful. Role may involve infrequent travel to meet with key vendors.
This is a contract position at Regeneron with Magnit Global being the Employer.
To do our best work we need different viewpoints. Therefore, we celebrate diversity and embrace inclusion. As an equal opportunity employer, we are dedicated to building a team that represents a variety of backgrounds, perspectives, and skills. We strive to ensure that we maintain a positive and enriching work environment for all.
​
Show more
Show less","Clinical Flow Cytometry, Flow Cytometry, Immunology, Oncology, FlowJo, FCS Express, OMIQ, R, Python, Data Science, Microsoft Word, Excel, PowerPoint, MS Project, Gating, Spectral Cytometry, Multicolor panels, Assay, Biomarker, KPI, Business process documents, Forecasting, Troubleshooting, Collaboration","Company Name: Regeneron
Job Title: Clinical Flow Cytometry Data Analyst TEMP
Experience: B.S. with at least 2-3 years’ experience or M.S. with at least 1 year experience
Skills Needed: Strong organizational and communication skills, ability to analyze and troubleshoot technical/scientific problems, collaboration skills, experience in flow cytometry assays, knowledge of flow cytometry software programs, proficiency in Microsoft Office, coding experience (R, Python), willingness to learn",0.19199999753472002,0.6083574
Senior Data Scientist AI & Machine Learning - Manufacturing Systems,PepsiCo,"Valhalla, NY",https://www.linkedin.com/jobs/view/senior-data-scientist-ai-machine-learning-manufacturing-systems-at-pepsico-3770726215,2023-12-20,Nyack,United States,Mid senior,Onsite,"Overview
PepsiCo’s strategy is to build capabilities that can enable us to become Faster, Stronger, and Better. Packaging can be a critical lever to enable this, by driving better consumer experiences and product liking, bringing cost opportunities to our bottom line, and integrating purpose into our business strategy through sustainable packaging. And more and more we have the need to deliver this right first time, and in the most timely and agile way. To do this effectively, we therefore need to transform the way we work, looking holistically at our end-to-end development processes, from design to market implementation. This will require us to move from more physical development and testing to a virtual development process, using the latest virtual design tools, data analytics, digital models, and prototyping capabilities.
The PepsiCo Global Beverages Packaging R&D Advanced Engineering & Design Team is leading the PepsiCo R&D digital transformation for Beverage Packaging. With the vision of delivering winning products through digital innovation, this team develops breakthrough technologies centered around Modeling and Simulation (M&S), Machine Learning and Artificial Intelligence to deliver faster and better consumer centric innovated packaging and sustainable solutions.
Digital Analysis, AI/ML and Digital Twins, combined with smart, instrumented physical testing can accelerate packaging design, structures, and processes. Working as a team of R&D professionals, you will partner with the R&D Packaging Teams, Data Analytics Teams and Industrial Design Teams to apply advanced tools and capabilities for new package design and development.
Responsibilities
Lead development of advanced analysis capabilities, leveraging data science and analytics principles.
Combine physics-based simulation, sensor technology, data analytics (AI/ML) to deliver digitized innovation projects (digital twin) in support of key packaging processes.
Build and train virtual models based on physical data; design and develop innovative experiments to validate and improve models.
Validate virtual and physical sensors, in lab-scale and pilot plant scale process packaging applications.
Work with external partners, OEMs, engineering firms, etc., to develop technologies needed to fulfill PepsiCo’s need, while protecting PepsiCo’s information and intellectual property.
Travel mainly in North America however some international travel may be required to meet project and business objectives, 10% total travel target.
Qualifications
M.S. degree or PhD in Data Science and Data Analytics OR Chemical Engineering, Mechanical Engineering, Material Science & Materials Engineering or similar field
Masters candidates require 1+ years of experience in Simulation, Data Science and Analytics, preferably in consumer goods field (preferably in rigid and flexible packaging)
PhD candidates require strong research experience in data analytics
Application of reduced order surrogate models in industrial applications (AI/ML)
Demonstrated expertise on application of data science and analytics principles in industrial applications, to verify performance and manufacturability, and drive form/fit/function optimization
Experience with CAD software: SolidWorks, Catia, Creo/ProE, Fusion360
Experience with data science and analytics software such as NumPy, SciPy, Matplotlib, TensorFlow, ML, DL, NLP, GCP.
Experience with analysis software: Abaqus, LS-Dyna, ANSYS, Fluent, MSC –Nastran, SW Simulation.
Fundamental knowledge of numerical methods and physics-based simulation (FEA, DEM, CFD)
Solid experience with data science and analytics software and tools, advanced engineering, and simulation preferred.
Preferred Skills:
Knowledge and experience in packaging processes – injection molding, stretch blow molding.
Understanding of Structural Mechanics, Polymer Material Modeling, Material Characterization, Stress/Strain analysis, Additive Manufacturing.
Hands-on experience with commercial software - FEA (ABAQUS, ANSYS Mechanical), DEM (ROCKY, EDEM), CFD (ANSYS FLUENT, STAR-CCM+), COMSOL.
Experience with Python, MATLAB, R, JMP (or other statistical software) a plus.
Strong project management and communication skills.
Ability to collaborate with internal and external partners in a global setup.
Compensation and Benefits:
The expected compensation range for this position is between $74,800 - $125,250 based on a full-time schedule.
Location, confirmed job-related skills and experience will be considered in setting actual starting salary.
Bonus based on performance and eligibility; target payout is 8% of annual salary paid out annually.
Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.
EEO Statement
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity
If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.
Please view our Pay Transparency Statement
Show more
Show less","SolidWorks, Catia, Creo/ProE, Fusion360, NumPy, SciPy, Matplotlib, TensorFlow, Abaqus, LSDyna, ANSYS, Fluent, MSC –Nastran, SW Simulation, FEA, DEM, CFD, Machine Learning, Artificial Intelligence, Data Science, Data Analytics, Digital Twins, Simulation, Virtual Design Tools, Digital Models, Prototyping, Packaging, Injection Molding, Stretch Blow Molding, Structural Mechanics, Polymer Material Modeling, Material Characterization, Stress/Strain Analysis, Additive Manufacturing, Python, MATLAB, R, JMP, SAP","The job is at PepsiCo for the position of Advanced Engineering & Design Team Leader in Global Beverages Packaging R&D. Candidates should have an M.S. degree or PhD in Data Science, Data Analytics, Chemical Engineering, Mechanical Engineering, or a similar field, with 1+ years of experience for Master's candidates and strong research experience for PhD candidates. Skills required include proficiency in CAD software, data science & analytics tools, analysis software, numerical methods, physics-based simulations, and packaging processes knowledge.",0.1863799262570496,0.5028658
Big Data Developer,ASK Consulting,"Ridgefield Park, NJ",https://www.linkedin.com/jobs/view/big-data-developer-at-ask-consulting-3776138343,2023-12-20,Nyack,United States,Mid senior,Onsite,"""All candidates must be directly contracted by ASK Consulting on their payroll and cannot be subcontracted. We are unable to provide sponsorship at this moment"".
Job Title: Big Data Developer
Location: Ridgefield Park, NJ
Duration: Contract Position
Pay Range : 65-71 per hour
Job Description:
Job Opportunity: Big Data Engineer (Contract)
Are you ready to take on a pivotal role in shaping the data landscape of a cutting-edge analytics organization? We are seeking a skilled and passionate Big Data Engineer to join our dynamic team. As a Big Data Engineer, you will play a crucial role in ensuring the reliability and applicability of our data products across our organization. This is a contract position where you will have the opportunity to showcase your expertise in SQL (Hive), Python, and Spark.
Responsibilities:
Translate intricate functional and technical requirements into comprehensive designs.
Engineer highly scalable end-to-end pipelines using open source tools and innovative techniques.
Design, develop, and implement Hadoop solutions, leveraging the power of Kafka for data loading from diverse sources.
Utilize Hive, Impala, Spark, and Pig to preprocess data efficiently.
Create and execute effective data modeling strategies to drive actionable insights.
Maintain top-notch security and data privacy standards in a secured environment.
Harness in-memory technologies like Spark for high-speed querying.
Contribute to best practices in source control, release management, and deployment.
Provide production support, monitor job scheduling, and ensure ETL data quality and freshness reporting.
Qualifications:
5-8 years of hands-on experience crafting complex SQL queries.
4+ years of Python development expertise, demonstrating your programming prowess.
5+ years of proven technical proficiency in Hadoop and big data projects.
3+ years of success in data modeling, transforming concepts into structured solutions.
Ability to streamline processes through automated ETL implementations.
Proficiency in writing shell scripts (bash, korn) for efficient workflows.
Knowledge and aptitude in implementing Oozie workflows and schedulers.
Familiarity with AWS components to harness cloud capabilities.
Strong analytical and problem-solving skills, tailored for the Big Data domain.
Proven understanding and hands-on experience with Hadoop, Hive, Presto, and Spark.
Adept at multi-threading and concurrency concepts.
B.S. or M.S. in Computer Science or Engineering.
Why Join Us:
This is your chance to be at the forefront of innovation, shaping the data-driven future of our organization. As a contracted Big Data Engineer, you will have the unique opportunity to work closely with cutting-edge technologies and contribute to impactful projects from day one.
About ASK:
ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With 5 nationwide offices, two global delivery centers, and employees in 42 states-ASK Consulting connects people with amazing opportunities
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.
Show more
Show less","SQL, Hive, Python, Spark, Hadoop, Kafka, Impala, Pig, ETL, Oozie, Bash, Korn, AWS, Presto, Multithreading, Concurrency","Company Name: ASK Consulting
Job Title: Big Data Developer
Experience: 5-8 years
Location: Ridgefield Park, NJ
Skills Needed: SQL (Hive), Python, Spark, Hadoop, Kafka, Hive, Impala, Pig, data modeling, ETL implementations, shell scripting, Oozie workflows, AWS, problem-solving skills, multi-threading, concurrency concepts.

Summary:
ASK Consulting is seeking a Big Data Developer for a contract position in Ridgefield Park",0.20512820268504317,0.84273267
senior data software engineer,"The Randy Neuringer Co., LLC.",New York City Metropolitan Area,https://www.linkedin.com/jobs/view/senior-data-software-engineer-at-the-randy-neuringer-co-llc-3784399173,2023-12-20,Nyack,United States,Mid senior,Hybrid,"Role
The Senior Software Engineer position in the Data Strategy teampresents a chance to create and execute data products for the world's biggest and most reputable reinsurance brokerage. Data Strategy has a “start-up style” mandate (within a $2 billion company) to enhance the acquisition, storage, analysis, fidelity, and monetization of client, internal, and third-party data across the organization.
This innovation spans our petabyte-scale insured assets, including property, business, marine, and aviation entities, and their associated risks, such as hurricanes, wildfires, cyber-attacks, and wars, in a financial and economic context.
As a member of the Data Strategy group, the Senior Software Engineer will work with fellow data and web engineers, data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across and (2) driving the monetization of data via newly designed and existing products for reinsurance clients. The Senior Software Engineer will be the head facilitator on multiple innovative initiatives and will have ownership over the design, development, and delivery of projects requiring direct reporting to senior-level management in both business and technical groups.
Leadership Responsibilities
Work with a product manager as technical lead of a team of ~5 engineers, data scientists, and analysts to design, scope, and oversee work in an Agile environment.
Manage junior data and web engineers, focusing on productivity, quality, and professional development.
Partner with the head of Data Strategy and other senior engineers to create and evangelize best-in-class engineering competency and tooling within the organization.
Enforce strong development standards across the team through code reviews, automated testing, and monitoring.
Establish strong relationships with internal clients as an engineering representative for data strategy.
Contribute to the overall Data Strategy vision and execution via quarterly planning and executive committee reporting.
Partner regularly improving engineering recruiting process for the required skillsets and resourcing demands.
Learn the complex business of reinsurance to coach data technologists and execute the team's initiatives more effectively.
Software Engineer Responsibilities
Develop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting, and new data products.
Innovate new ways to leverage large and small datasets to drive revenue via the development of new products with the Data Strategy team, as well as the enhancement of existing products.
Architect engineering solutions using the latest cloud technologies in a process that spans hypothesis-validating prototypes to large-scale production data products, ensuring internal security and regulatory compliance.
Design solutions that account for unstructured data and document management system(s), including ingesting, tracking, parsing, analyzing, and summarizing documents at scale.
Perform exploratory and goal-oriented data analyses to understand and validate the requirements of data products and help create product roadmaps.
Develop, implement, and deploy front-ends and APIs, which may involve business intelligence dashboards, data pipelines, machine learning algorithms, and file ingestion mechanisms.
Work closely with data scientists, data engineers, web engineers, PMs, and other stakeholders to design & develop products.
Keep current on the latest trends and innovations in data technology and how these trends apply to GC's business and data strategy.
Required Qualifications
5-8+ years of relevant experience in data-focused software engineering
Master’s Degree, Ph.D., or equivalent experience in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research
Experience in Python and familiarity with OOP and functional programming principles
Strong knowledge of SQL and familiarity with the high-level properties of modern data stores.
Strong understanding of the contemporary SDLC, including dev/QC/prod environments, unit/integration/UA testing, CI/CD, etc.
Experience building and maintaining CI/CD pipelines with tools such as Azure DevOps, GitLab, Travis, Jenkins, etc.
At least two and ideallyall of the following sets of experience:
Data Engineering
2+ years’ experience with data engineering
Extensive experience with (py)Spark, Python, JSON, and SQL
Experience integrating data from semi-structured and unstructured sources
Knowledge of various industry-leading SQL and NoSQL database systems
Backend Web
2+ years of backend/full-stack web engineering
Experience working with Python-based server-side web frameworks like FastAPI or Django
Experience with complex backends involving multiple data stores, asynchronous worker queues, pub-sub messaging, and the like
Knowledge of cloud-based web deployments (AWS/Azure/GCP, Kubernetes, auto-scaling, etc.)
Experience with one or more major frontend frameworks (React strongly preferred)
Data Science/Analytics
2+ years of data analysis, AI, or data science work
Experience with data cleaning, enrichment, and reporting to business users
Experience selecting, training, validating, and deploying machine-learning models
Experience with or strong interest in learning about LLMs in a productized context
Experience working in an Agile environment to facilitate the quick and effective fulfillment of group goals
Good interpersonal and communication skills for establishing and maintaining sound internal relationships, working well as part of a team, and for presentations and discussions
Strong analytical skills and intellectual curiosity (interest in the meaning and usefulness of the data), as demonstrated through academic experience or work assignments
Excellent English verbal and writing skills for complex communications with GC colleagues in all departments and levels of the organization, including communicating technical concepts to a non-technical audience
Good ability to prioritize workload according to volume, urgency, etc., and to deliver on required projects in a timely fashion
Preferred Qualifications
Strong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks
Experience with web scraping and crowdsourcing technologies
Experience with Databricks and optimizing Spark clusters
Experience architecting web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.
Experience working with data visualization dashboarding tools (PowerBI, Tableau)
Insurance domain knowledge or strong interest in developing it
Experience with the MS Azure cloud environment
Show more
Show less","Python, OOP, Functional programming, SQL, Data stores, SDLC, CI/CD, Azure DevOps, GitLab, Travis, Jenkins, Data engineering, (py)Spark, JSON, NoSQL, Backend web engineering, FastAPI, Django, Asynchronous worker queues, Pubsub messaging, Kubernetes, Autoscaling, React, Data science, AI, Machine learning, Agile, Entity resolution, Streaming technologies, ELT/ETL, Web scraping, Crowdsourcing, Databricks, Spark clusters, Monolith, Microservice, Caching, Security integrations, Data visualization, Dashboarding, PowerBI, Tableau, Insurance","Company Name: Not specified
Job Title: Senior Software Engineer - Data Strategy Team
Experience: 5-8+ years of relevant experience in data-focused software engineering
Skills Needed: The ideal candidate should have a Master’s Degree, Ph.D., or equivalent experience in data science, computer science, or related quantitative field. They should also have experience in Python, SQL, contemporary SDLC, and building CI/CD pipelines. Additionally, the candidate should have expertise in at least two of the following",0.15272727075510745,0.57812685
Senior Software Engineer - Data Strategy (NYC-Hybrid),Rad Hires,"West Nyack, NY",https://www.linkedin.com/jobs/view/senior-software-engineer-data-strategy-nyc-hybrid-at-rad-hires-3747283789,2023-12-20,Nyack,United States,Mid senior,Hybrid,"Role
The Senior Software Engineer position in the Data Strategy team presents a chance to create and execute data products for the world's biggest and most reputable reinsurance brokerage. Data Strategy has a “start-up style” mandate (within a $2 billion company) to enhance the acquisition, storage, analysis, fidelity, and monetization of client, internal, and third-party data across the organization. This innovation spans our petabyte-scale insured assets, including property, business, marine, and aviation entities, and their associated risks, such as hurricanes, wildfires, cyber-attacks, and wars, in a financial and economic context.
As a member of the Data Strategy group, the Senior Software Engineer will work with fellow data and web engineers, data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across the company and (2) driving the monetization of data via newly designed and existing products for the company’s reinsurance clients. The Senior Software Engineer will be the head facilitator on multiple innovative initiatives and will have ownership over the design, development, and delivery of projects requiring direct reporting to senior-level management in both business and technical groups.
Leadership Responsibilities
Work with a product manager as technical lead of a team of ~5 engineers, data scientists, and analysts to design, scope, and oversee work in an Agile environment.
Manage junior data and web engineers, focusing on productivity, quality, and professional development.
Partner with the head of Data Strategy and other senior engineers to create and evangelize best-in-class engineering competency and tooling within the organization.
Enforce strong development standards across the team through code reviews, automated testing, and monitoring.
Establish strong relationships with internal clients as an engineering representative for data strategy.
Contribute to the overall Data Strategy vision and execution via quarterly planning and executive committee reporting.
Partner regularly improving engineering recruiting process for the required skillsets and resourcing demands.
Learn the complex business of reinsurance to coach data technologists and execute the team's initiatives more effectively.
Software Engineer Responsibilities
Develop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting, and new data products.
Innovate new ways to leverage large and small datasets to drive revenue via the development of new products with the Data Strategy team, as well as the enhancement of existing products.
Architect engineering solutions using the latest cloud technologies in a process that spans hypothesis-validating prototypes to large-scale production data products, ensuring internal security and regulatory compliance.
Design solutions that account for unstructured data and document management system(s), including ingesting, tracking, parsing, analyzing, and summarizing documents at scale.
Perform exploratory and goal-oriented data analyses to understand and validate the requirements of data products and help create product roadmaps.
Develop, implement, and deploy front-ends and APIs, which may involve business intelligence dashboards, data pipelines, machine learning algorithms, and file ingestion mechanisms.
Work closely with data scientists, data engineers, web engineers, PMs, and other stakeholders to design & develop products.
Keep current on the latest trends and innovations in data technology and how these trends apply to the company's business and data strategy.
Required Qualifications
5-8+ years of relevant experience in data-focused software engineering
Master’s Degree or Ph.D. in data science, computer science, or related quantitative field such as applied mathematics, statistics, engineering or operations research, or equivalent experience
Experience in Python and familiarity with OOP and functional programming principles
Strong knowledge of SQL and familiarity with the high-level properties of modern data stores.
Strong understanding of the contemporary SDLC, including dev/QC/prod environments, unit/integration/UA testing, CI/CD, etc.
Experience building and maintaining CI/CD pipelines with tools such as Azure DevOps, GitLab, Travis, Jenkins, etc.
At least two and ideally all of the following sets of experience:
Data Engineering
2+ years’ experience with data engineering
Extensive experience with (py)Spark, Python, JSON, and SQL
Experience integrating data from semi-structured and unstructured sources
Knowledge of various industry-leading SQL and NoSQL database systems
Backend Web
2+ years of backend/full-stack web engineering
Experience working with Python-based server-side web frameworks like FastAPI or Django
Experience with complex backends involving multiple data stores, asynchronous worker queues, pub-sub messaging, and the like
Knowledge of cloud-based web deployments (AWS/Azure/GCP, Kubernetes, auto-scaling, etc.)
Experience with one or more major frontend frameworks (React strongly preferred)
Data Science/Analytics
2+ years of data analysis, AI, or data science work
Experience with data cleaning, enrichment, and reporting to business users
Experience selecting, training, validating, and deploying machine-learning models
Experience with or strong interest in learning about LLMs in a productized context
Experience working in an Agile environment to facilitate the quick and effective fulfillment of group goals
Good interpersonal and communication skills for establishing and maintaining sound internal relationships, working well as part of a team, and for presentations and discussions
Strong analytical skills and intellectual curiosity (interest in the meaning and usefulness of the data), as demonstrated through academic experience or work assignments
Excellent English verbal and writing skills for complex communications with company colleagues in all departments and levels of the organization, including communicating technical concepts to a non-technical audience
Good ability to prioritize workload according to volume, urgency, etc., and to deliver on required projects in a timely fashion
Preferred Qualifications
Strong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks
Experience with web scraping and crowdsourcing technologies
Experience with Databricks and optimizing Spark clusters
Experience architecting web ecosystems from the ground up, including monolith vs. microservice decisions, caching technologies, security integrations, etc.
Experience working with data visualization dashboarding tools (PowerBI, Tableau)
Insurance domain knowledge or strong interest in developing it
Experience with the MS Azure cloud environment
Show more
Show less","Azure DevOps, AWS, Agile, GCP, SQL, Python, FastAPI, React, Apache Spark, GitLab, Django, Kubernetes, Jenkins, Travis CI, NoSQL, CSS, Data Engineering, LLM, Machine Learning, Data Science, Natural Language Processing, DevOps, JSON, Azure, Spark, CI/CD, SDLC, OOP, Jenkins, Kafka, PySpark, Kafka, PowerBI, Tableau","Company: Not specified
Job Title: Senior Software Engineer in Data Strategy

Experience: The ideal candidate should have 5-8+ years of relevant experience in data-focused software engineering

Skills Needed:
- Master’s Degree or Ph.D. in data science, computer science, or related quantitative field
- Proficiency in Python and familiarity with OOP and functional programming principles
- Strong knowledge of SQL and modern data stores
- Experience building and maintaining CI/CD pipelines
- Expertise in at",0.16727272532892565,0.56074727
Data Engineer (Databricks),Lawrence Harvey,New York City Metropolitan Area,https://www.linkedin.com/jobs/view/data-engineer-databricks-at-lawrence-harvey-3757675923,2023-12-20,Nyack,United States,Mid senior,Hybrid,"**UNFORTUNATELY, AT THIS TIME APPLICANTS MUST BE ELIGIBLE TO WORK IN THE UNITED STATES WITHOUT SPOSNORSHIP. WE CANNOT PROVIDE ANY TYPE OF VISA SPONSORSHIP OR TRANSFER AT THIS TIME**
**THIS IS A FULL TIME OPPORTUNITY AND
NOT AVAILABLE ON C2C
**
Location
: NYC (Tuesday-Thursday in office)
This opportunity is with one of the world's leading entertainment/media companies worldwide across production, news, development, and marketing. They have a dynamic portfolio of DTC products which include streaming TV and more.
The DTC group is looking to expand the decision sciences team and is looking to add a Sr Data Engineer to join the team. This person will be responsible for creating a connected data ecosystem that unleashes the power of streaming data
Qualifications:
2-5 years experience
At least 1 year experience with
Databricks is required
Ability to design and build data pipelines to ingest data, integrate data from multiple data sources and create aggregated data sets for reporting needs
Hands-on experience working with Spark, Python, Pyspark, Scala
Experience in GCP, AWS or Azure
**UNFORTUNATELY, AT THIS TIME APPLICANTS MUST BE ELIGIBLE TO WORK IN THE UNITED STATES WITHOUT SPOSNORSHIP. WE CANNOT PROVIDE ANY TYPE OF VISA SPONSORSHIP OR TRANSFER AT THIS TIME**
**THIS IS A FULL TIME OPPORTUNITY AND
NOT AVAILABLE ON C2C
**
Show more
Show less","Data Engineering, Data Pipelines, Databricks, Spark, Python, Pyspark, Scala, GCP, AWS, Azure","Company: Not specified
Job title: Senior Data Engineer
Experience: 2-5 years
Location: NYC (Tuesday-Thursday in office)
Skills needed: At least 1 year experience with Databricks, ability to design and build data pipelines, hands-on experience with Spark, Python, Pyspark, Scala, experience in GCP, AWS or Azure.",0.292134827915036,0.57622933
Data Engineer - Scala / Java,Eliassen Group,New York City Metropolitan Area,https://www.linkedin.com/jobs/view/data-engineer-scala-java-at-eliassen-group-3784023005,2023-12-20,Nyack,United States,Mid senior,Hybrid,"*Hybrid in NYC: 4 days ON-SITE*
Our client's Ad Intelligence team is transforming advertising and their Ad platform with data and AI across TV and streaming video. They build solutions to measure and optimize every aspect of the advertising life cycle. Their tenant is a strong cross-domain team to deliver E2E solutions covering tech areas ranging from machine learning, big data, microservices to data visualization. They are seeking 2 senior software engineers for their advertising data platform engineering group. This engineering group focuses on big data infrastructure, operational data, audience solution, inventory forecasting and full funnel measurements as a foundation layer for their addressable Ad Platforms.
Due to client requirement, applicants must be willing and able to work on a w2 basis. For our w2 consultants, we offer a great benefits package that includes Medical, Dental, and Vision benefits, 401k with company matching, and life insurance.
Rate: $90 - $95 / hr. w2
Responsibilities:
Hands on Data Engineering work using primarily Scala - Batchside- will be writing using spark , data extractions and data cleansing; ALL pipelines developed in Scala -
Build components of large-scale data platform for real-time and batch processing, and own features of big data applications to fit evolving business needs
Build next-gen cloud based big data infrastructure for batch and streaming data applications, and continuously improve performance, scalability and availability
Contribute to the best engineering practices, including the use of design patterns, CI/CD, code review and automated test
Chip in ground-breaking innovation and apply the state-of-the-art technologies
Contribute to all aspects of the software lifecycle: design, experimentation, implementation and testing.
Collaborate with program managers, product managers, SDET, and researchers in an open and innovative environment
Requirements:
Bachelor or above in computer science or EE
4+ years of professional programming in Java, Scala, Python, and etc.
3+ years of big data development experience with technical stacks like Spark, Flink, Singlestore, Kafka, Nifi and AWS big data technologies
Knowledge of system, application design and architecture
Experience of build industry level high available and scalable service
Passion about technologies, and openness to interdisciplinary work
TECH SKILL SETS MUST HAVE:
Scala / Java – Scala is critical and the most important, Java is second
Big Data- Spark is most preferred as team uses spark and flink
Must have programming experience-object oriented experience from a software dev perspective
Preferred Qualifications:
Experience with processing large amount of data at petabyte level
Demonstrated ability with cloud infrastructure technologies, including Terraform, K8S, Spinnaker, IAM, ALB, and etc.
Experience with ClickHouse, Druid, Snowflake, Impala, Presto, Kinesis, etc.
Experience in widely used Web framework (React.js, Vue.js, Angular, etc.) and good knowledge of Web stack HTML, CSS, Webpack
Skills, experience, and other compensable factors will be considered when determining pay rate. The pay range provided in this posting reflects a W2 hourly rate; other employment options may be available that may result in pay outside of the provided range.
W2 employees of Eliassen Group who are regularly scheduled to work 30 or more hours per week are eligible for the following benefits: medical (choice of 3 plans), dental, vision, pre-tax accounts, other voluntary benefits including life and disability insurance, 401(k) with match, and sick time if required by law in the worked-in state/locality.
Please be advised- If anyone reaches out to you about an open position connected with Eliassen Group, please confirm that they have an Eliassen.com email address and never provide personal or financial information to anyone who is not clearly associated with Eliassen Group. If you have any indication of fraudulent activity, please contact InfoSec@eliassen.com.
Job ID: 381295
Show more
Show less","Scala, Java, Python, Spark, Flink, Singlestore, Kafka, Nifi, AWS, Cloud infrastructure technologies, Terraform, K8S, Spinnaker, IAM, ALB, ClickHouse, Druid, Snowflake, Impala, Presto, Kinesis, HTML, CSS, Webpack, React.js, Vue.js, Angular","Company Name: Eliassen Group
Job Title: Senior Software Engineer - Advertising Data Platform Engineering
Experience: 4+ years of professional programming
Skills Needed: Scala, Java, Big Data (Spark, Flink), Batch and Streaming Data Processing, Cloud Infrastructure (AWS), System and Application Design, Web Frameworks (React.js, Vue.js, Angular), Data Visualization, Machine Learning, Microservices, Data Cleansing, CI/CD, Design Patterns",0.09174311720025675,0.4689655
Data engineer,Zortech Solutions,"Tarrytown, NY",https://www.linkedin.com/jobs/view/data-engineer-at-zortech-solutions-3667478321,2023-12-20,Nyack,United States,Mid senior,Hybrid,"Role: Data Engineer
Location: Tarrytown, NY 10591 (Hybrid role 3 days onsite 2 days WFH)
Duration: 6-12+ Months
Job Description
Must have AWS , Apache Airflow , Pyspark , Redshift
Candidate should have 8+ years of experience in Data Engineering
Designing, creating, testing and maintaining the complete data management & processing systems.
Working closely with the stakeholders & solution architect.
Ensuring architecture meets the business requirements.
Building highly scalable, robust & fault-tolerant systems.
Taking care of the complete ETL process.
Knowledge of Hadoop ecosystem and different frameworks inside it HDFS, YARN, MapReduce, Apache Pig, Hive, Flume, Sqoop, ZooKeeper, Oozie, Impala and Kafka
Must have knowledge and working experience in Real-time processing Framework (Apache Spark), PySpark and in AWS Redshift
Must have experience on SQL-based technologies (e.g. MySQL/ Oracle DB) and NoSQL technologies (e.g. Cassandra and MongoDB)
Should have Python/Scala/Java Programming skills
Discovering data acquisitions opportunities
Finding ways & methods to find value out of existing data.
Improving data quality, reliability & efficiency of the individual components & the complete system.
Creating a complete solution by integrating a variety of programming languages & tools together.
Creating data models to reduce system complexities and hence increase efficiency & reduce cost.
Introducing new data management tools & technologies into the existing system to make it more efficient.
Setting & achieving individual as well as the team goal.
Problem solving mindset working in agile environment
Show more
Show less","Apache Airflow, AWS, Cassandra, ETL, Hadoop, Hive, HDFS, Impala, Java, Kafka, MapReduce, MongoDB, MySQL, NoSQL, Oracle DB, Oozie, Pig, Pyspark, Python, Redshift, Scala, Spark, Sqoop, YARN, ZooKeeper","Company: Not specified
Job Title: Data Engineer
Experience: 8+ years

Skills Needed:
- AWS, Apache Airflow, Pyspark, Redshift
- Designing, creating, testing, and maintaining data management & processing systems
- Collaboration with stakeholders & solution architect
- Ensuring architecture meets business requirements
- Building highly scalable, robust & fault-tolerant systems
- ETL process management
- Knowledge of Hadoop ecosystem and its frameworks
- Real-time processing",0.36018956974551336,0.8567436
"Senior Data Analyst (Product Team) (Bangkok Based, relocation provided)",Agoda,"San Francisco, CA",https://www.linkedin.com/jobs/view/senior-data-analyst-product-team-bangkok-based-relocation-provided-at-agoda-3750109651,2023-12-20,Daly City,United States,Associate,Onsite,"About Agoda
Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.
Get to Know our Team:
In Product, ideas come alive. The world is moving fast so our culture empowers ownership and minimal bureaucracy. That’s the environment that enables you to do what you think is right – and quickly. Product Operations is a large, multicultural team of diversely talented individuals that serve as the curators of Agoda’s content. We manage all the content our customers and partners see on each of our products. As a part of our team, you will take ownership of processes that are critical to multiple other teams across the business. We are driving property-level content to map inventories from 3 rd  party supplies which will enable our reach to span the globe. Content Operations is also keen on self-improvement and innovation. We run our own structured data and analyze it to make impactful decisions. With the support of state-of-the-art technology and an enriching work environment, we strengthen the bottom line and drive new business for Agoda.
The Opportunity:
As an Analyst/Senior Analyst, you will report directly to either the Senior Manager or Associate Director within the Product Department and this will be an individual contributor role. You will be responsible and fully empowered to work with the partners on the ground. You will be supported by a team within the Product department and work closely with other Team members within Agoda. You will be instrumental in ensuring there is consistency in data being used for reporting, identifying value-added data to help the business grow as well as using data to make strategic business decisions. You will be expected to dig into data to provide business insights, guide decision-making and offer valuable inputs to further grow our business model.
In this Role, you’ll get to
:
Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output)
Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders
Conducted an analysis of customer behavior and their path through the platform, guaranteeing that the conversion rates for each front-end page met the established benchmarks and continually pinpointed opportunities for enhancement
Partnered with the Product Design and User Research team to generate fresh data-driven projects, one of which involved the development of a Dashboard designed for more efficient monitoring of user behavior and the measurement of novel business metrics
Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply
Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence
Automate manual operational processes and present back on time savings gained through modernization of business operations
What you’ll Need to Succeed:
Bachelor’s degree or higher in Mathematics, Business, Economics, Data Science, Information Technology or similar field
Bachelor’s Degree or higher in computer sciences, engineering, mathematics, statistics, data science or a related degree program. Masters degree preferred
Advanced domain of data analysis and data visualization tools and software such as Excel, SQL, Tableau, Python or similar
Analytical mindset, with proven track record in using data to measure performance and make decisions
Excellent problem-solving skills including the ability to analyze and resolve complex problems using data
Ability to work under pressure in a fast-paced and rapidly changing environment
Excellent communication skills (both verbal and written), with proven ability to convey complex messages clearly and with conviction
Team player with strong interpersonal, relationship-building, and stakeholder management skills
#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server #productanalyst #product
Equal Opportunity Employer
At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.
We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .
To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.
Show more
Show less","Data Analysis, SQL, Data Analytics, Python, Data Mining, Data Science, R, Tableau, Analytical Skills, Data Visualization, Databases, Business Analysis, Business Intelligence, Product Analyst","Company: Agoda
Job Title: Analyst/Senior Analyst
Experience: Bachelor’s degree or higher in Mathematics, Business, Economics, Data Science, Information Technology or related field, with advanced data analysis skills and proven track record using data for decision-making.
Skills Needed: Data analysis, data visualization tools (Excel, SQL, Tableau, Python), analytical mindset, problem-solving skills, ability to work under pressure, strong communication skills, teamwork, and stakeholder management.",0.1121751011844053,0.44888717
"Data Analyst (Bangkok Based, relocation provided)",Agoda,"Oakland, CA",https://www.linkedin.com/jobs/view/data-analyst-bangkok-based-relocation-provided-at-agoda-3750111586,2023-12-20,Daly City,United States,Associate,Onsite,"About Agoda
Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.
Get to Know our
Team:
The Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.
In this Role, you’ll get
to:
Search: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests
Display: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others
Modeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers
What you’ll Need to
Succeed:
Bachelor’s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)
Ability to communicate fluently in English
Exposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau
Good numerical reasoning skills
Proficiency in Excel
Intellectual curiosity and analytical skills
It’s Great if you
Have:
Experience in digital marketing
Academic research experience
#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner
Equal Opportunity Employer
At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.
We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .
To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.
Show more
Show less","Google, Bing, Baidu, Naver, Facebook, Twitter, Instagram, SAS, R, SPSS, Python, VBA, SQL, Tableau, Excel, Data analysis, Data analytics, Analytics, Data mining, Data science, Data visualization, Databases, Business analysis, Business intelligence (BI), Microsoft SQL Server, Machine learning, Statistics, Microsoft Power BI, Java, Finance, Shopee, Traveloka, Google, Facebook, Ctrip, Trip.com, MakeMyTrip, Grab, Amazon, Pandas (software), Artificial intelligence (AI), Information technology, Capital One, Accenture, Upwork, Deloitte, McKinsey, Bain, Microsoft, Uber, Lyft, Gojek, Lazada, Alibaba, Shopify, Expedia, Skyscanner","Company: Agoda
Job Title: Performance Marketing Team Member
Experience: Bachelor’s Degree or higher in a quantitative subject (computer science, mathematics, engineering, statistics, or science) required
Skills Needed: Ability to communicate fluently in English, exposure to data analysis packages or databases (SAS, R, SPSS, Python, VBA, SQL, Tableau), good numerical reasoning skills, proficiency in Excel, intellectual curiosity, analytical skills
Additional Skills (preferred): Experience in digital marketing",0.11821086093846013,0.65049356
Safety Security Data Analyst,San Mateo County Transit District,"San Mateo, CA",https://www.linkedin.com/jobs/view/safety-security-data-analyst-at-san-mateo-county-transit-district-3763561857,2023-12-20,Daly City,United States,Associate,Onsite,"The San Mateo County Transit District serves nearly 100,000 customers each weekday on its SamTrans buses, Redi-Wheel paratransit vehicles, Caltrain commuter rail cars and shuttles, as well as a robust capital program. The Transit District, which is in the heart of the San Francisco Bay Area, also is the managing agency for the San Mateo County Transportation Authority. Staff enjoys a dynamic organization that fosters personal development and professional advancement of its staff. The Transit District’s core values include integrity, customer focus, respect, quality, teamwork, leadership and accountability. Excellent benefits are provided.
DIVISION
Rail
EMPLOYMENT TYPE
Non-exempt/non-safety sensitive
APPLICATION DEADLINE
Continuous Recruitiment Until Filled
Job Summary
The Safety & Security Data Analyst reports to the Deputy Director Safety and Security and will work closely with the Chief Safety Officer, Rail. The Safety & Security Data Analyst will work 50% with District Safety and Security and 50% with Rail Safety and will be responsible for collecting data, assessing, reporting, and providing insights on the programs operated by the San Mateo County Transit District (SamTrans) and Peninsula Corridor Joint Powers Board (Caltrain).
Minimum Qualifications
Sufficient experience, tr aining and/or education to demonstrate the knowledge and ability to successfully perform the essential functions of the position. In lieu of a degree, work-related experience that demonstrates the skills and experience necessary to perform this role will be accepted. Development of the required knowledge and abilities is typically obtained through but not limited to:
Bachelor’s degree in mathematics, Computer Science, Information Management, Statistics, or closely related field.
Two years of full-time working experience in a data analysis role using MS, Excel, R, Python, etc.
Must possess advanced-level MS Excel skills.
Must be able to communicate effectively orally and in writing.
Preferred Qualifications
Experience with project management
Essential Functions And Duties
Process and analyze safety related data collected from vendors and the Metropolitan Transportation Commission (MTC).
Analyze safety related information to discover trends and patterns. Develop and create a repository of safety information.
Create data models to monitor the performance and quality of the safety program to address business compliance.
Recommend solutions to business challenges.
Lead and/or participate in safety related working groups for SamTrans and Caltrain.
Example Of Duties
Participate and/or develop the requirements for databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Interpret data, analyze results using statistical techniques to provide ongoing reports.
Present the data models and trend/patterns analysis to internal and external stakeholders.
Analyze data and make operational recommendations from key safety and performance data (accidents, incidents, near misses, lag & lead indicators).
Perform all job duties and responsibilities in a safe manner to protect oneself, fellow employees, and the public from injury or harm. Promote safety awareness and follow safety procedures in an effort to reduce or eliminate accidents.
Perform other duties as assigned.
How To Apply
To apply, please visit the https://www.caltrain.com/about-caltrain/jobs . Complete an online employment application and supplemental questionnaire. Open until filled. A resume will not be accepted in lieu of the application and supplemental questionnaire (If required). Incomplete application will not be considered.
The Human Resources Department will make reasonable efforts in the recruitment/examination process to accommodate applicants with disabilities upon request. If you have a need for accommodation, please contact the Human Resources Department at (650) 508-6308.
SamTrans celebrates diversity and is committed to creating an inclusive, and welcoming workplace environment. We are an Affirmative Action/Equal Opportunity Employer. Minorities, Women, Persons with Disabilities and Veterans are encouraged to apply.
Selection Process May Include
The process may include written and skills test assessments or supplemental questions and will require a panel interview. Only those candidates who are the most qualified will continue in the selection process. Meeting the minimum qualifications does not guarantee an invitation to continue in the process.
PAY RANGE
$1,414 - $2,120 weekly ($73,494 - $110,241 estimated annually)
Current Employment Benefits
For further Benefits details please go to: https://www.caltrain.com/about-caltrain/jobs/employee-benefits
Holidays: Seven (7) paid holidays, plus up to four (4) floating holidays per year
Paid Time Off: Up to 26 days per year
Cafeteria Plan: Medical, dental, vision care, group life insurance, and more
Transportation: Free bus transportation for employees and qualified dependents
Retirement: Social Security and California Public Employees Retirement Systems (CalPERS)
Classic Members - 2% @ 60 benefit formula, 3-year average of highest compensation
New Members - 2% @ 62 benefit formula, 3-year average of highest compensation
Show more
Show less","Data analysis, Data mining, Statistical analysis, Data modeling, Trend analysis, Reporting, Communication, Project management, MS Excel, R, Python, SQL, Databases, Data collection systems, Data analytics, Safety, Security, Risk management, Accident investigation, Incident investigation, Near miss reporting, Performance monitoring, Compliance, Business intelligence, Data visualization, Stakeholder engagement, Problem solving, Decision making, Critical thinking, Analytical skills, Research skills, Presentation skills, Teamwork, Attention to detail, Problemsolving skills, Data interpretation, Statistical techniques, Operational recommendations, Safety awareness, Safety procedures, Diversity, Inclusion, Equal opportunity","Company Name: San Mateo County Transit District
Job Title: Safety & Security Data Analyst
Experience: Two years of full-time working experience in a data analysis role
Skills Needed: Bachelor’s degree in mathematics, Computer Science, Information Management, Statistics, or related field, proficiency in MS Excel, experience with R, Python, etc., ability to communicate effectively orally and in writing, experience with project management

The San Mateo County Transit District is seeking a Safety & Security Data Analyst with at least",0.18955512364399585,0.7476009
"Data Scientist, Algorithms - Rider",Lyft,"San Francisco, CA",https://www.linkedin.com/jobs/view/data-scientist-algorithms-rider-at-lyft-3751170717,2023-12-20,Daly City,United States,Mid senior,Onsite,"At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.
Lyft’s Data Science Team builds mathematical models underpinning the platform’s core services. Compared to other technology companies of a similar size, the set of problems that we tackle is incredibly diverse. They cut across optimization, prediction, modeling, inference, transportation, and mapping. We are hiring motivated experts in each of these fields. We're looking for someone who is passionate about solving mathematical problems with data, and are excited about working in a fast-paced, innovative and collegial environment.
You will report into a Science Manager.
Responsibilities:
Partner with Engineers, Product Managers, and Business Partners to frame problems, both mathematically and within the business context.
Perform exploratory data analysis to gain a deeper understanding of the problem
Construct and fit statistical, machine learning, or optimization models
Write production modeling code; collaborate with Software Engineers to implement algorithms in production
Design and run both simulated and live traffic experiments
Analyze experimental and observational data; communicate findings; facilitate launch decisions
Experience
:
M.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative fields
4+ years professional experience
Passion for solving unstructured and non-standard mathematical problems
End-to-end experience with data, including querying, aggregation, analysis, and visualization
Proficiency with Python, or another interpreted programming language like R or Matlab
Willingness to collaborate and communicate with others to solve a problem
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.
This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.
The expected range of pay for this position in the San Francisco area is $139,000 - $180,000
.
Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.
Show more
Show less","Python, R, Matlab, Data analysis, Data visualization, Querying, Aggregation, Optimization, Prediction, Modeling, Inference, Transportation, Mapping, Machine learning, Statistics, Mathematical modeling, Production modeling, Software engineering, Experimental design, Observational data analysis, Communication, Collaboration","Company: Lyft
Job Title: Data Scientist
Experience: 4+ years
Skills Needed: M.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, proficiency in Python or similar language, experience in data analysis, visualization, and modeling. Passion for solving complex mathematical problems and ability to collaborate effectively with cross-functional teams.
Salary: $139,000 - $180,000 (dependent on qualifications and experience)
Benefits: Medical, dental, vision insurance, mental health",0.18627450726078915,0.6207864
"Senior, Data Scientist",Walmart,"San Bruno, CA",https://www.linkedin.com/jobs/view/senior-data-scientist-at-walmart-3723653705,2023-12-20,Daly City,United States,Mid senior,Onsite,"Position Summary...
What you'll do...
Senior Data Scientist - Market Intelligence
As part of the Customer Insights & Strategy team in the Marketing org at Walmart, the Senior Data Scientist of Market Intelligence helps drive organization's understanding of competitive landscape to fuel market share growth. Our ideal candidate is a sharp, thoughtful, and collaborative problem solver, who enjoys uncovering key business drivers and challenges, and then building data science and analytics solutions to enable strategic decision making. You will have direct visibility with executives and drive our strategic initiatives to support the rapid growth of our omni-channel businesses.
About Walmart Marketing
Named Ad Age's Marketer of the Year in 2022, you'll join an internationally recognized team of thinkers, creators, and problem solvers passionate about helping people save money and live better.
Walmart Marketing is a dynamic, multidimensional organization dedicated to redefining how the world shops through impactful creative and fast-paced innovation - all grounded in customer insights and brand strategy. We live out our company values each day while striving to exceed customer expectations and drive growth for the company.
We orchestrate marketing campaigns and experiences that reach millions of daily shoppers. Our work spans the digital and physical spaces and combines the work of numerous internal teams and external advertising and media agencies. Our teams work together to show our customers how they can save money and live better. If you are motivated by complex challenges and want to build the future of commerce and consumer services, a Marketing role at Walmart could be what you've been looking for.
Our Marketing team has flexibility on location, for most of our openings, you can live within driving distance to one of our hubs: Bentonville, AR, Hoboken, NJ, San Bruno, CA, Sunnyvale, CA or Los Angeles, CA, with preference given to our San Bruno, CA office. We're moving toward 3 days in the office per week, with flexibility.
You Will Make An Impact By
Analyze large and complex datasets to identify trends, patterns, and insights to measure performance against competition and inform business growth opportunities
Research, create and implement advanced statistical models and cutting-edge machine learning algorithms on fast-moving structured and unstructured data to support decision making
Have a very strong product mindset and proactively ideate, design, improve and automate relevant data products
Lead projects and take ownership of whole lifecycle of projects. Including prototype model and data process code, communicate with cross-functional teams (e.g., Engineers, Finance, Merch, Ops, Marketing, etc.) to align progress and collaborate on integrations
Communicate findings and insights to both technical and non-technical stakeholders through clear and concise reports, visualizations and presentations to gain alignment and drive business actions
Guide and mentor junior data scientists on modeling process and algorithm and foster a collaborative and innovative work environment
Minimum Qualification
BA/BS in Marketing, Mathematics, Computer Science, Statistics, Economics or related field with 3+ years of experience in data science, data analytics and/or decision science; or Master's degree in relevant fields with 2+ years of experience
Proven advanced modeling experience in leading data-driven projects from definition to execution, driving and influencing project roadmaps
Deep expertise in writing and debugging complex SQL code and Python code
Strong written, oral communication and presentation skills
You'll Sweep Us Off Our Feet If
You are able to analyze complex problems with critical thinking and innovative solutions; and also have exceptional analytic mindset with strong attention to details
You have strong production level modeling experience with one programming language from end-to-end
You have experience with full lifecycle of a real-world modeling project in a lead role from inception, problem definition, solution design to implementation, production deployment, maintenance and refactor
You have more than 2 years of experience and in-depth knowledge in retail industry and macro-economic related functions
You are able to prioritize tasks while managing multiple projects to meet fast evolving business requirements with strong desire to drive for continuous improvement and excellence
You have proven experience in building compelling stories by integrating multiple data sources and complex analytics into cohesive insights to drive executive decisions
How You'll Thrive At Walmart
Performance-based incentive awards
401k with company match
Discounted employee stock purchase plan
Paid parental leave,
New surrogacy & adoption benefits
Unlimited Flex Time Off
Working alongside a diverse group of collaborative and innovative team members
Opportunity for growth and development across several areas of the Fortune 1 organization
And much more
Equal Opportunity Employer
Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.
Who We Are
Join Walmart and your work could help over 275 million global customers live better every week. Yes, we are the Fortune #1 company. But you'll quickly find we're a company who wants you to feel comfortable bringing your whole self to work. A career at Walmart is where the world's most complex challenges meet a kinder way of life. Our mission spreads far beyond the walls of our stores. Join us and you'll discover why we are a world leader in diversity and inclusion, sustainability, and community involvement. From day one, you'll be empowered and equipped to do the best work of your life. careers.walmart.com
At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .
The annual salary range for this position is $117,000.00-$234,000.00
Additional Compensation Includes Annual Or Quarterly Performance Incentives.
Additional compensation for certain positions may also include:
Regional Pay Zone (RPZ) (based on location)
Stock equity incentives
Minimum Qualifications...
Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.
Option 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.
Preferred Qualifications...
Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.
Data science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)
Primary Location...
850 Cherry Avenue, San Bruno, CA 94066-3031, United States of America
Show more
Show less","Data Science, Machine Learning, Statistics, SQL, Python, Data Modeling, Coding, Big Data Analysis, Data Visualization, Business Intelligence, Data Mining, Decision Making, Data Warehousing, Predictive Analytics, DataDriven Decision Making","Company: Walmart
Job Title: Senior Data Scientist - Market Intelligence
Experience: 3+ years of experience in data science, data analytics, and/or decision science with a Bachelor's degree or 2+ years with a Master's degree.
Skills Needed: Advanced modeling experience, proficiency in SQL and Python, strong communication and presentation skills, ability to analyze complex problems, experience in the retail industry, and strong project management skills.
Summary: The Senior Data Scientist of Market Intelligence at Walmart will be responsible",0.10796915026926204,0.80748487
"Software Data Engineer, Java",Jobs for Humanity,"Springfield, MA",https://www.linkedin.com/jobs/view/software-data-engineer-java-at-jobs-for-humanity-3786353531,2023-12-20,Holyoke,United States,Mid senior,Onsite,"Company Description
Jobs for Humanity is partnering with MassMutual to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: MassMutual
Job Description
Job Description
At MassMutual, we are committed to helping people protect their families, support their communities, and assist one another. We believe in inspiring people to come together and live in mutual support. We welcome a diverse range of individuals from all backgrounds and perspectives, including the elderly, refugees, people with disabilities, LGBTQIA+ individuals, and veterans. Our goal is to create an inclusive environment where everyone can thrive.
What we are looking for in this role
We are seeking a candidate who enjoys designing, building, and delivering complex systems. You should have a passion for coding and solving challenging problems with innovative solutions. You should also have experience working with large-scale data and an eagerness to explore open-source tools. Collaboration and effective communication skills are essential as well.
Objectives of the role
Design, develop, and deliver scalable and robust components using technologies such as Python, Java, AWS serverless (Lambda, Glue), Apache Spark, Apache Kafka, and REST
Participate in all aspects of development from design to delivery, taking on roles as a developer and component lead
Interact closely with data users, such as data engineers and data scientists, to understand and refine requirements
Develop, test, and review code
Troubleshoot and debug issues in code and data pipelines
Evaluate and recommend tools, technologies, and processes to improve efficiency and enhance existing systems
Collaborate with other developers and provide mentorship when needed
Work closely with other teams to prevent and resolve technical issues
Contribute to an Agile development environment, attending daily stand-up meetings and delivering incremental improvements
Basic Qualifications
4+ years of Java development experience
Strong knowledge of algorithms, design patterns, and writing performant code
Good understanding of data processing tools like Spark, Kafka, and SQL, as well as relational and analytics databases
Experience with source control and CI/CD tools
Proficiency in writing unit, integration, and load tests
Excellent communication, problem-solving, organizational, and analytical skills
Ability to work independently and provide leadership to small development teams
Bachelor's degree or equivalent work experience
Preferred Qualifications
Experience building and deploying on cloud platforms like AWS and working with serverless architectures (Lambda, Glue)
2+ years of experience working with big data and/or streaming technologies like Spark, Kafka, and Flink
MassMutual is an equal opportunity employer. We welcome applicants regardless of race, gender identity, sexual orientation, disability, or veteran status. We value diversity and strive to create a workplace where everyone feels included and supported. Veterans are encouraged to apply, regardless of their discharge status. If you require any accommodations during the application process, please let us know so we can assist you accordingly.
Show more
Show less","Java, Python, AWS serverless, Apache Spark, Apache Kafka, REST, Data engineering, Data science, Algorithms, Design patterns, Performant code, Spark, Kafka, SQL, Relational databases, Analytics databases, Source control, CI/CD, Unit tests, Integration tests, Load tests, AWS, Serverless architectures, Big data, Streaming technologies, Cloud platforms","Company Name: MassMutual
Job Title: Software Engineer
Experience: 4+ years
Skills Needed: Java development, algorithms, design patterns, data processing tools (Spark, Kafka, SQL), source control, CI/CD tools, cloud platforms (AWS, Lambda, Glue), big data/streaming technologies (Spark, Kafka, Flink), unit testing, collaboration, communication, problem-solving, leadership, Bachelor's degree or equivalent work experience.",0.16620498384389318,0.4882198
Data Engineer,Jobs for Humanity,"Springfield, MA",https://www.linkedin.com/jobs/view/data-engineer-at-jobs-for-humanity-3786356207,2023-12-20,Holyoke,United States,Mid senior,Onsite,"Company Description
Jobs for Humanity is partnering with MassMutual to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: MassMutual
Job Description
At MassMutual, we believe in helping everyone achieve financial freedom. We are looking to hire data engineers to join our Data Management and Engineering team. We welcome people from all backgrounds, including the elderly, refugees, people with disabilities (visible and invisible), LGBTQIA+ individuals, and veterans.
What we are looking for
We are seeking passionate individuals who love working with data. As a Data Engineer, you will be involved in building data projects from scratch. You will collaborate with business partners to understand their requirements and develop robust solutions that meet high standards. We value individuals who are eager to learn new technologies and enjoy working in the cloud. Additionally, being a team player and a strong communicator is essential.
Key responsibilities
Design, build, and maintain complex data jobs that provide business value.
Translate high-level business requirements into technical specifications.
Ingest data from multiple sources into the data lake and data warehouse.
Cleanse, enrich, and ensure good data quality.
Provide insights and guide future development.
Support existing data warehouse applications and consumers, serving as a technical leader for the offshore team.
MassMutual's data platform
Develop reusable tools to streamline project delivery.
Collaborate closely with other developers and provide mentorship.
Evaluate and recommend tools, technologies, processes, and architectures.
Work in an Agile development environment, attending daily stand-up meetings and delivering incremental improvements.
Basic Qualifications
Bachelor’s degree in computer science, engineering, or a related field.
5+ years of experience with data warehousing and analytics.
Strong knowledge of SQL programming and query optimization.
Good understanding of ETL/ELT methodologies and tools.
Experience with troubleshooting and root cause analysis.
Excellent communication, problem-solving, organizational, and analytical skills.
Ability to work independently and lead small teams of developers.
Preferred Qualifications
Master’s degree in computer science, engineering, or a related field.
Experience working in a cloud environment (e.g., AWS).
Hands-on experience with Python.
Experience with data processing technologies like Apache Spark or Kafka.
Good knowledge of orchestration and scheduling tools (e.g., Apache Airflow).
Experience with data reporting tools (e.g., Microstrategy, Tableau, Looker) and data cataloging tools (e.g., Alation).
MassMutual is an equal opportunity employer. We welcome all individuals to apply, including those from minority groups, females, individuals with disabilities, LGBTQIA+ individuals, and veterans, regardless of discharge status. If you need assistance or accommodation during the application process, please contact us.
Show more
Show less","SQL, Python, Apache Spark, Apache Kafka, Apache Airflow, Data warehousing, Data analytics, ETL/ELT, Data processing, Data quality, Cloud computing, AWS, Data reporting, Data cataloging, Agile development, Software development, Communication, Problem solving, Leadership","Company Name: MassMutual

Job Title: Data Engineer

Experience: 5+ years

Skills Needed: SQL programming, ETL/ELT methodologies, Python, Apache Spark or Kafka, AWS, Apache Airflow, data reporting tools, data cataloging tools

Summary: MassMutual is seeking a Data Engineer to join their Data Management and Engineering team. The ideal candidate will have a Bachelor’s degree in computer science or related field, with at least 5 years of experience in data",0.21142856870187757,0.6917642
Quantitative Data Engineer,Jobs for Humanity,"Springfield, MA",https://www.linkedin.com/jobs/view/quantitative-data-engineer-at-jobs-for-humanity-3786353512,2023-12-20,Holyoke,United States,Mid senior,Onsite,"Company Description
Jobs for Humanity is partnering with MassMutual to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: MassMutual
Job Description
Job Title: Quantitative Data Engineer
Team: Quantitative Investment Platforms and Developer Operations
Location: Boston, MA, Springfield, MA, or New York, NY
About The Role
Join our team as a Data Engineer and work in a fast-paced, innovative, and collaborative environment. In this role, you will use your technical and people skills to solve complex problems and communicate effectively. We are looking for someone with a strong background in Data Engineering, workflow orchestration, CI/CD pipelines, cloud platforms, and system architectures.
About The Team
As a Quantitative Operations Engineer, you will be part of MassMutual's Investment Management organization. Our team of skilled professionals provides collaborative and portfolio risk solutions to our portfolio managers. We value resilience, accountability, agility, and continuous improvement. Our team culture is collaborative and promotes work-life balance.
Your Impact
We are looking for a passionate Quant Data Engineer who enjoys working with data and deploying solutions. You will have the opportunity to build data projects from scratch and collaborate with business partners to understand requirements. Your responsibilities will include designing and maintaining complex ETL jobs, ingesting data from various sources, ensuring data quality, and providing insight to guide the development of our data platform. You will also collaborate with other developers, provide mentorship, and evaluate tools and technologies.
Minimum Qualifications
Bachelor's degree in Computer Science, Finance, Business, or related field
2+ years of experience in IT and/or finance industry
Understanding of ETL methodologies and proficiency in Python
Experience with Python, AWS services, and cloud environments
Experience with relational and NoSQL databases
Experience with GIT and code review/deployment
Experience in Agile/SCRUM development
Ideal Qualifications
Master's degree in computer science, engineering, or related field
4+ years of experience in IT and/or quantitative, investment, or finance industry
Experience with troubleshooting and root cause analysis
Knowledge of orchestration and scheduling tools
Experience with data reporting tools or Python libraries
Entrepreneurial mindset and rapid development experience
Excellent communication, problem-solving, and organizational skills
Data-driven mindset and ability to use quantitative tools for analysis
Ability to adapt to changing priorities and strong work ethic
Curiosity about emerging digital and technology trends
Proven ability to collaborate cross-functionally
What To Expect
Regular meetings with project teams
One-on-one meetings with your manager
Mentorship opportunities
Networking opportunities with diverse Business Resource Groups
Access to learning content on Degreed and other platforms
Strong ethical business practices, industry-leading pay, and benefits
Equal Employment Opportunity
MassMutual is an equal opportunity employer that welcomes all applicants, including minorities, females, individuals with disabilities, veterans, and LGBTQIA+ individuals. Veterans are encouraged to apply, regardless of discharge status.
Accommodation
If you require an accommodation to complete the application process, please contact us and provide details of the assistance you need.
Show more
Show less","Data Engineering, Python, AWS, Cloud Computing, Relational Databases, NoSQL Databases, Agile, Scrum, Troubleshooting, Root Cause Analysis, Data Reporting, Quantitative Tools, Curiosity, Collaboration, Ethical Business Practices","Company Name: MassMutual
Job Title: Quantitative Data Engineer
Experience: 2+ years
Skills Needed: Bachelor's degree in Computer Science, Finance, Business, or related field, proficiency in Python, experience with ETL methodologies, Python, AWS services, cloud environments, relational and NoSQL databases, GIT, Agile/SCRUM development. Ideal qualifications include a Master's degree, 4+ years of experience, troubleshooting skills, knowledge of orchestration tools, data reporting tools,",0.21932114632835456,0.63763225
MDM Data Engineer,Jobs for Humanity,"Springfield, MA",https://www.linkedin.com/jobs/view/mdm-data-engineer-at-jobs-for-humanity-3786351877,2023-12-20,Holyoke,United States,Mid senior,Onsite,"Company Description
Jobs for Humanity is partnering with MassMutual to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.
Company Name: MassMutual
Job Description
Job Title: Data Integration Specialist
About The Company
We are a diverse and inclusive company that values all individuals. At MassMutual, we are committed to equal employment opportunity and welcome applicants from all backgrounds and walks of life. We also provide accommodations for applicants who require assistance during the application process.
Job Description
We are looking for a Data Integration Specialist to join our team. In this role, you will be responsible for designing and building complex Informatica Power Center and MDM processes to master data in various domains. You will be working on projects that involve data collection, processing, modeling, and master data solutions to meet specific business needs.
Responsibilities
Design, build, and evaluate complex ELT/ETL tasks to integrate data from different sources into a reliable data repository.
Develop Master Data Management (MDM) solutions for various domains.
Provide comprehensive support for MDM solutions, including data ingestion, master record creation, data extracts, and API integration.
Implement data modeling standards and processes.
Assist in documenting technical data and system information.
Establish data quality benchmarks and develop tools/processes for data accuracy.
Perform data profiling and analysis.
Collaborate with different departments to understand data patterns.
Translate business needs into technical specifications.
Contribute to the development and implementation of MDM Solutions and other Information Management initiatives.
Requirements
Basic Qualifications:
Bachelor’s degree in computer science or engineering.
5+ years of experience with Informatica Power Center.
5+ years of experience with data analytics, data modeling, and database design.
3+ years of coding and scripting experience (Python, Java, Scala).
3+ years of experience with Informatica MDM platform in customer/party subject area.
Experience with ELT methodologies and tools.
Expertise in tuning and troubleshooting SQL.
Strong data integrity, analytical, and multitasking skills.
Experience with Oracle database.
Experience with AWS.
Knowledge of basic UNIX commands and shell scripts.
Experience with 3rd party job schedulers like Maestro.
Experience with RESTful APIs.
Experience with near real-time mastering via SIF.
Experience with data profiling tools.
Willingness to provide support for batch processing cycles outside business hours.
Excellent communication, problem-solving, organizational, and analytical skills.
Able to work independently.
Authorized to work in the USA with or without sponsorship.
Preferred Qualifications:
Master’s degree in computer science or engineering.
Experience with agile project delivery process.
Knowledge of SQL for data access and analysis.
Ability to manage diverse projects impacting multiple roles and processes.
Able to identify and troubleshoot data gaps and issues.
Ability to adapt to a fast-changing environment.
Experience with Python.
Experience with Kafka.
Basic knowledge of database technologies (Vertica, Redshift, etc.).
Experience designing and implementing automated ETL processes.
How To Apply
If you are interested in this position, please submit your application through our online application portal. If you require any accommodations during the application process, please contact us and let us know how we can assist you.
Show more
Show less","Informatica Power Center, MDM, ELT/ETL, Data Analytics, SQL, Python, Java, Scala, Data Modeling, AWS, RESTful APIs, SIF, Data Profiling, Agile, Vertica, Redshift, Kafka","Company Name: MassMutual

Job Title: Data Integration Specialist

Experience: 5+ years

Skills Needed:
- Bachelor’s degree in computer science or engineering.
- 5+ years of experience with Informatica Power Center.
- 5+ years of experience with data analytics, data modeling, and database design.
- 3+ years of coding and scripting experience (Python, Java, Scala).
- 3+ years of experience with Informatica MDM platform in customer/party subject",0.21727019287746063,0.652614
Informatics RN (Quality Data Analyst),Artius Solutions,"Grand Junction, CO",https://www.linkedin.com/jobs/view/informatics-rn-quality-data-analyst-at-artius-solutions-3788167436,2023-12-20,Colorado,United States,Associate,Onsite,"Job Description
Facility Address:
Grand Junction, CO 81505
Number of Weeks:
16
Shift Information:
Full-Time
Rate Type:
All Inclusive
Rate:
$79-$84/Hr.
Guaranteed Hours:
40
Overtime Type:
By the Week
Overtime Starts After:
40
On Call Rate:
No Call
Call Back Minimum (Hrs.):
0 Hour Minimum
Call Back Rate:
All Inclusive Rate
Holiday Rate:
All Inclusive Rate
Specialty Type:
Nursing
Sub Specialties:
Informatics Nurse
Certifications/Requirements:
ACLS, BLS/BCLS, NRP, STABLE
Duties
Interim to Perm Opportunity
**Must be an Informatics RN**
***ONSITE POSITION*****
Provide nursing informatics support to Clinical Improvement Department and Quality Management Program. Priorities are activities that promote continuous compliance and improvement activities to meet Medicare and Medicaid Conditions of Participation, Joint Commission Accreditation Standards, Healthcare Facilities Accreditation Program/American Osteopathic Accreditation (HFAP/AOA) standards, Bariatric Center of Excellence standards, and others as needed to obtain or maintain hospital accreditation or certifications.
Colorado West HealthCare System participates in Centers for Medicare and Medicaid (CMS), and is deemed in compliance with those Conditions of Participation through its successful accredited status from the Joint Commission and the HFAP/AOA. CWHS is committed to the provision of quality health care to the community it serves, and is accountable to collect and submit data from which the organization is measured. Further, CWHS is committed to a continuous monitoring of the quality of care provided, and collects, analyzes, and presents data to the board and medical staff, providing actionable information from which to assess clinical competence and quality outcomes.
Education
Bachelor's Degree in Nursing and/or eight (8) years of healthcare organization experience. Proficient in Meditech and Meditech Reports, Microsoft Office. Current working knowledge of Rules/Regulations CMS (CoPs), ORYX Core Measures, and accreditation bodies (TJC & HFAP) preferred. Case Management experience including utilization review and discharge planning preferred.is required.
Show more
Show less","Nursing Informatics, ACLS, BLS/BCLS, NRP, STABLE, Meditech, Meditech Reports, Microsoft Office, CMS (CoPs), ORYX Core Measures, TJC, HFAP, Utilization Review, Discharge Planning","Company Name: Colorado West HealthCare System
Job Title: Informatics Nurse
Experience: Bachelor's Degree in Nursing and/or eight (8) years of healthcare organization experience
Skills Needed: ACLS, BLS/BCLS, NRP, STABLE certifications, proficiency in Meditech and Meditech Reports, Microsoft Office, knowledge of Rules/Regulations CMS (CoPs), ORYX Core Measures, and accreditation bodies (TJC & HFAP)

This full-time position in Grand Junction,",0.32411066862472465,0.6985558
Data Scientist (IV) – Generative AI,HP,"Colorado, United States",https://www.linkedin.com/jobs/view/data-scientist-iv-%E2%80%93-generative-ai-at-hp-3713203043,2023-12-20,Colorado,United States,Mid senior,Remote,"Locations include Spring, Texas (preferred location), and US remote.
Typically need at least Master's degree and minimum 0-2 years full-time relevant work experience.
The Team
We are a growing centralized team helping HP take advantage of new AI/ML technology, especially around Generative AI and large language models. We engage with business units to advise and prototype solutions, and we develop and run software applications for internal use.
The Role
As a Data Scientist with a focus on Generative AI you will work on multiple engagements across HP involving large language models and other new Generative AI capabilities. Beyond our team, you will work with business stakeholders and developers from other business units. Your primary focus and mindset is to help deliver business solutions to our (mostly internal) customers. You are expected to stay up to date on important new Gen AI papers and releases, but note that this is not an AI research role.
Skills And Profile
Knowledge of data science and machine learning core skills.
Experience with NLP, Large Language Models, LLM prompt engineering, vector databases, Retrieval Augmented Generation (RAG), and search engines.
Good computer science skills. Experience in a software development team is a big plus, especially with business applications in a cloud environment.
Tools you may use include Azure services such as Azure Machine Learning and Azure prompt flow, as well as python, langchain, streamlit, docker, git, and elastic search.
Some experience from a large complex organization is a plus.
Ability to participate in meetings with a multitude of stakeholders and communicate in a crisp manner. Mastery in English is required.
You enjoy explaining technical concepts (such as LLM's) to a non-technical audience.
You propose pragmatic solutions that are as simple as possible, which sometimes mean that no Gen AI component is necessary.
Interest in working in a distributed team with diverse backgrounds.
The recent AI progress is disruptive, and our team is in the midst of it. As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value ""business as usual"".
Education And Length Of Experience
For this position, we prefer at least a relevant Master's degree (e.g. Computer Science) or demonstrated competence, and a minimum of 6-10 years experience.
About HP
You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you.
So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.
HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.
Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are.
From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!
Show more
Show less","Data Science, Machine Learning, NLP, Large Language Models, LLM, Prompt Engineering, Vector Databases, Retrieval Augmented Generation, RAG, Search Engines, Computer Science, Software Development, Cloud Computing, Azure Machine Learning, Azure Prompt Flow, Python, Langchain, Streamlit, Docker, Git, Elastic Search, Complex Organization, Stakeholder Communication, English, Technical Concepts Explanation, Pragmatic Solutions, Distributed Team, AI Progress, Rapid Change, Master's Degree, Computer Science, 610 Years Experience","Company: HP
Job Title: Data Scientist - Generative AI
Experience: Preferably a Master's degree with a minimum of 6-10 years of experience
Skills Needed: Data science and machine learning core skills, NLP, Large Language Models, LLM prompt engineering, Azure services, python, langchain, streamlit, docker, git, elastic search, experience in a software development team, ability to communicate technical concepts to non-technical audiences, interest in working in a distributed team",0.23896103636579524,0.76191604
"Senior Data Scientist, Acquisition",Grammarly,"Colorado, United States",https://www.linkedin.com/jobs/view/senior-data-scientist-acquisition-at-grammarly-3774289392,2023-12-20,Colorado,United States,Mid senior,Hybrid,"Grammarly is excited to offer a
remote-first hybrid working model
. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.
All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków.
This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.
Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.
The opportunity
Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the
Fortune
500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of
Inc.
’s best workplaces, a Glassdoor Best Place to Work, one of
TIME
’s 100 Most Influential Companies, and one of
Fast Company
’s Most Innovative Companies in AI.
To achieve our ambitious goals, we’re looking for a Senior Data Scientist to join our incredible team and work on core marketing measurement and optimization projects. The ideal candidate will have strong technical expertise and marketing domain knowledge and collaborate with cross-functional teams to develop solutions and drive data-driven actions. The person in this role will advance our statistical rigor, testing, and measurement methodologies, define a framework to measure the impact of our marketing channels, leverage Grammarly’s internal data and Google Ads platform data to solve ambiguous marketing problems and provide data-driven solutions.
The Grammarly data teams are trusted subject matter experts who uncover new insights to inform marketing, product, and growth strategies. We have large datasets and are looking for folks with deep technical and analytical skills who can break down complex business problems and provide solutions with high impact and visibility for marketing and the company. Our teams have the freedom to innovate and uncover breakthroughs—and, in turn, influence the marketing roadmap.
Your impact
As a Senior Data Scientist, You Will
Lead testing and measurement efforts for our key online marketing channels, especially paid searches, such as Google and Bing.
Develop cross-channel measurement models such as MediaMixModeling to optimize budget allocation.
Collaborate with Engineering and Marketing teams to drive LTV bidding optimizations and their impact measurement for our digital marketing channels.
Measure the effectiveness of Individual Marketing channels and Cross-Channels by building/leveraging different attribution models and experimentation methods.
Devise a solution to inform marketing strategy and drive measurement in a cookieless world.
Analyze the impact of our overall marketing budget to understand its full-funnel impact and how it influences Grammarly for Business conversions.
Run elasticity analysis to drive discussions and identify opportunities for spending re-allocation across countries.
Conduct deep-dive analyses into marketing channel performance and user behavior.
We’re Looking For Someone Who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
Is able to collaborate in person 2 weeks per quarter, traveling when necessary to the hub where the team is based.
Has 8+ years of relevant work experience.
Has experience as an influential and effective thought partner to marketing teams.
Demonstrates strong communication, proactiveness, creativity, and prioritization skills.
Has strong analytical and critical thinking skills and a strong bias toward actionable insights.
Has the ability to work in a fast-paced, dynamic environment.
Has practical experience in data analysis, statistics, and marketing measurement.
Is proficient in SQL, Python, R, Scala, or an equivalent language.
Support for you, professionally and personally
Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.
Compensation And Benefits
Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
Disability and life insurance options
401(k) and RRSP matching
Paid parental leave
Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
Home office stipends
Caregiver and pet care stipends
Wellness stipends
Admission discounts
Learning and development opportunities
Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.
Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.
United States
Zone 1: $197,000 - $253,000year (USD)
Zone 2: $177,000 - $228,000/year (USD)
Zone 3: $168,000 - $215,000/year (USD)
Zone 4: $157,000 - $202,000/year (USD)
We encourage you to apply
At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).
Please note that EEOC is optional and specific to US-based candidates.
#NA
All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.
Show more
Show less","SQL, Python, R, Scala, Data analysis, Statistics, Marketing measurement, Crosschannel measurement models, MediaMixModeling, LTV bidding optimizations, Attribution models, Experimentation methods, Deepdive analysis, User behavior analysis, Communication, Proactiveness, Creativity, Prioritization, Analytical thinking, Critical thinking, Actionable insights, Fastpaced environment, Agile development, Customer focus","Company: Grammarly
Job Title: Senior Data Scientist
Experience: 8+ years
Skills Needed: Strong technical expertise, marketing domain knowledge, collaboration skills, statistical rigor, testing methodologies, data-driven actions, analytical skills, communication skills, proactiveness, creativity, prioritization skills, SQL, Python, R, Scala, or equivalent language proficiency.

Grammarly is offering a remote-first hybrid working model with team members primarily working remotely in the United States, Canada, Ukraine, Germany, or",0.13031161322280094,0.7098256
"Senior Data Scientist, SEO",Grammarly,"Colorado, United States",https://www.linkedin.com/jobs/view/senior-data-scientist-seo-at-grammarly-3776412363,2023-12-20,Colorado,United States,Mid senior,Hybrid,"Grammarly is excited to offer a
remote-first hybrid working model
. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.
All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków.
This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.
Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.
The opportunity
Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.
To achieve our ambitious goals, we’re looking for a Senior Data Scientist to join our Data Engineering and Intelligence team. This candidate will partner with our SEO Marketing team to accelerate SEO growth at Grammarly. The ideal candidate will have a strong track record of delivering impactful analytical projects within the SEO domain and partner with cross-functional peers to guide and influence decision-making.
The Grammarly data teams are trusted subject matter experts who uncover new insights to inform marketing, product, and growth strategies that drive outcomes at the highest levels of the company. We have large datasets and are looking for folks with deep technical and analytical skills who can break down complex business problems and provide solutions with high visibility and impact for the company.
Grammarly’s Data teams have the freedom to innovate and uncover breakthroughs—and, in turn, influence our marketing, product, and growth roadmap. The complexity of the technical questions we face is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.
Your impact
In This Role, You Will
Become a part of the core team focused on SEO growth for the company – a company-level objective.
Own the metric development for the SEO space, partnering with cross-functional members to ensure clear and actionable insights.
Design and run SEO experiments leveraging advanced statistical methodologies, including causal inference.
Be the Data science thought leader for the cross-functional working group and provide evidenced-based guidance.
Provide actionable insights and recommendations to improve our SEO performance by leveraging your deep expertise in the SEO and Data Science fields.
Co-own the strategy, prioritization, and roadmap for SEO growth at the company.
Collaborate directly with Marketing, Growth, and Engineering teams.
Apply machine learning to identify the most critical web architecture components that drive beneficial SEO growth.
Recruit, guide, and mentor junior and mid-level Data Scientists to create a best-in-class Data Science organization.
Collaborate with other Data Scientists to continue to enhance the methodologies and practices used across the team that leverage the newest technological developments in the industry.
We’re Looking For Someone Who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
Is able to collaborate in person 2 weeks per quarter, traveling when necessary to the hub where the team is based.
Holds a PhD or master’s degree in a quantitative field.
Has 8+ years of relevant work experience with a proven track record of applying data science methods within the SEO domain.
Is fluent in SQL with strong data exploration and manipulation skills.
Is proficient in Python, R, or similar programming language.
Has an understanding of causal inference methods and their application and ability to apply machine learning techniques when necessary.
Has firm knowledge of experiment design and A/B and MVT testing.
Is comfortable working with clickstream and web event-related data.
Has a self-starting growth mindset and strong communication skills, translating technical insights into impactful business recommendations.
Is a creative problem-solver who simplifies problems to their core elements.
Support for you, professionally and personally
Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.
Compensation And Benefits
Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
Disability and life insurance options
401(k) and RRSP matching
Paid parental leave
Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
Home office stipends
Caregiver and pet care stipends
Wellness stipends
Admission discounts
Learning and development opportunities
Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.
Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.
United States
Zone 1: $226,000 - $262,000/year (USD)
Zone 2: $203,000 - $236,000/year (USD)
Zone 3: $192,000 - $223,000/year (USD)
Zone 4: $181,000 - $210,000/year (USD)
We encourage you to apply
At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).
Please note that EEOC is optional and specific to US-based candidates.
#NA
All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.
Show more
Show less","Causal inference, Python, R, Data science, SQL, Experiment design, A/B testing, MVT testing, Clickstream analytics, Machine learning, Natural language processing, Data analysis, Data exploration, Data manipulation, Data mining, Data visualization, Programming languages, SQL, NoSQL, Hadoop, Spark, Data warehouses, Big data platforms, Cloud computing, Machine learning, Artificial intelligence, Deep learning, Natural language processing, Computer vision, Speech recognition, Robotics, Automation, Agile development, Scrum, Kanban, DevOps, Continuous integration, Continuous delivery, Continuous deployment, Infrastructure as code, Microservices, Containers, Kubernetes","Company: Grammarly
Job Title: Senior Data Scientist
Experience: 8+ years of relevant work experience
Skills Needed: The ideal candidate should hold a PhD or master’s degree in a quantitative field. They should have a proven track record of applying data science methods within the SEO domain, be fluent in SQL, proficient in Python, R, or similar programming language, have an understanding of causal inference methods, experiment design, and A/B and MVT testing. Additionally, they should be comfortable",0.13477088788932806,0.24179672
Data Analyst,Accroid Inc,"Des Moines, IA",https://www.linkedin.com/jobs/view/data-analyst-at-accroid-inc-3763534389,2023-12-20,West Des Moines,United States,Associate,Onsite,"Able to understand and assess the quality of source data; Gain knowledge of the system to validate the data being reported by providers and prepared for use by stakeholders. Collect metrics for trends in data reported into IBHRS. Review data reported for outliers.
Provide technical assistance and guidance to providers to clean data and prepare it for analysis.
Able to use a relational database, reporting software, and data analytic software to create simple to complex ad hoc queries, write reports and create dashboards against the data reported from IBHRS.
Uses data visualization tools such as Microsoft Excel and Power BI or Tableau. Set up and maintain executive dashboards so all stakeholders (internal and external) view the same data in the same way.
Show more
Show less","Data Analysis, Data Validation, Data Visualization, Data Mining, Database Management, Data Quality Assessment, Reporting Software, Relational Databases, Data Analytic Software, Microsoft Excel, Power BI, Tableau, Data Dashboards, Ad Hoc Queries, Data Cleaning, Data Reporting","Company Name: Not specified
Job Title: Data Quality Analyst
Experience: Not specified

Skills needed: 
- Ability to understand and assess the quality of source data
- Knowledge of systems to validate data reported by providers and prepare it for use by stakeholders
- Proficiency in collecting metrics for data trends
- Experience in reviewing data for outliers
- Providing technical assistance and guidance to providers to clean and prepare data for analysis
- Proficiency in using relational databases, reporting software, and data analytic",0.4558823481531142,0.6267086
Technical Data Analyst,System One,"Des Moines, IA",https://www.linkedin.com/jobs/view/technical-data-analyst-at-system-one-3781198905,2023-12-20,West Des Moines,United States,Associate,Onsite,"What To Expect
Technical Data analyst responsibilities include conducting full lifecycle data analysis to include requirements, activities, and design.
Complete data profiling and define data transformations for use by the ETL Developers
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Locate and define new process improvement opportunities
Qualifications:
Qualifications:
Strong knowledge of Advanced SQL
Strong knowledge of and experience with databases, programming (XML, Python, Json, Javascript, or ETL frameworks)
Previous experience in working with Informatica/other ETL environments preferred
Previous experience or knowledge of mulesoft preferred
Previous experience working with Cloud Data Warehouse/Data Lake preferred(Eg: Snowflake)
Understanding of Data projects and Data Design Documents
Previous experience with creating data mapping document, data requirements, translating business requirements to transformation rules
Previous experience with Data Modeling and exposure to at least Dimensional and 3NF modeling preferred(Exposure to Data Vault 2.0 an additional advantage).
Previous experience in an agile analytics environment preferred. Previous experience working in FAST application preferred
Proactive, problem solver and self-motivated.
Strong analytical abilities
Bachelor's Degree business or information technology related major preferred
Minimum 6 years' quality assurance experience relative to the development and execution of test cases and analysis of testing results preferred
Proven experience with test automation tools preferred
Proven experience working in Agile teams preferred
Demonstrated leadership experience
Strong mathematical aptitude and analytical skills
Strong Microsoft Excel skills and familiarity with other Microsoft tools such as Word and Access. Ability to understand and create complex SQL queries
Understanding of complex life or annuity products and processes
Strong communication skills including verbal, written, and presentation skills
Strong interpersonal skills and proven ability to work and communicate with a variety of personalities, across locations and varying organizational levels
Proven ability to research, analyze, and resolve problem situations using strong judgment and high level decision making skills
Strong initiative, self-motivation, and ability to work independently and oversee work of others
College Degree in the field of computer science, information science, management information systems preferred
Strong knowledge in Insurance industry preferably Life insurance
Problem solving skills sufficient to perform research and recommend a proposed solution to problems
Able to work on multiple tasks and meet established deadlines
Able to effectively direct and coordinate the work of other team members on a project without having HR management responsibility for them
Knowledge of computer programming languages as required for the system
Criminal background check required.
Show more
Show less","Data analysis, SQL, Databases, Programming, XML, Python, JSON, JavaScript, ETL frameworks, Informatica, Mulesoft, Cloud Data Warehouse, Data Lake, Snowflake, Data mapping, Data requirements, Data Modeling, Dimensional modeling, 3NF modeling, Data Vault 2.0, Agile analytics, FAST application, Microsoft Excel, Microsoft Word, Microsoft Access, Complex SQL queries, Life insurance, Problem solving, Research, Decision making, Initiative, Selfmotivation, Teamwork, Computer programming languages, Criminal background check","Company: Not specified
Job Title: Technical Data Analyst
Experience: Minimum 6 years' quality assurance experience

Skills Needed:
- Strong knowledge of Advanced SQL
- Experience with databases, programming languages (XML, Python, Json, Javascript, ETL frameworks)
- Previous experience with Informatica or other ETL environments
- Familiarity with Mulesoft
- Experience with Cloud Data Warehouse/Data Lake (e.g. Snowflake)
- Understanding of Data projects and Data Design Documents
-",0.24913494514577175,0.7905042
"Engineer Product II ( Data acquisition tools, CAN bus )",Cube Hub Inc.,"Ankeny, IA",https://www.linkedin.com/jobs/view/engineer-product-ii-data-acquisition-tools-can-bus-at-cube-hub-inc-3666771823,2023-12-20,West Des Moines,United States,Mid senior,Onsite,"Position Title
Performance Engineer
Onsite and must be willing to travel - there will be a lot of travel toward the last half of the year supporting field test sites.
Contingent Performance Engineer for the Cotton Harvesting Product Verification and Validation (PV&V) Group
Job Description
This position is for a Performance engineer to support the verification of the function of parts and systems used on cotton harvesting equipment. Some but not all of the key tasks will include:
Plan, coordinate, conduct, and oversee full vehicle evaluations and field test activities of cotton harvesters.
Provide field test site support throughout the harvest season in southern US.
Become proficient in the safe operation and maintenance of cotton harvesters to aid in design reviews, tests, evaluations, and trouble shooting.
Responsible for completing test Activities through all phases of planning, execution, and reporting to closure.
Participate in, contribute to, and document design reviews and Event disposition.
Assist in the shipping and tracking of test equipment, including machines, and office related tasks as required.
Report test results in a timely and clear manner; help in the definition and execution of any follow up testing.
May provide lab test support.
Required Skills And Experience
Strong personal skills and the ability to work with farmers, technicians, and engineers, to get work done.
Ability to work with others in a professional manner while unsupervised.
Strong technical report writing skills.
A working knowledge of mechanical, hydraulic, and electrical systems.
A knowledge of engineering theory and principles.
4-year degree in engineering, technology, or equivalent experience.
Experience working in a team environment and soliciting cooperation when needed.
SOME TRAVEL IS REQUIRED. Up to 30% travel required. Most travel will be in the last half of the year. Flexibility and ability to adapt regarding hours/travel/priorities
Desired Skills And Experience
Farming experience
Experience with design, development and/or test of mobile equipment, preferably agricultural harvesting equipment.
Experience with data acquisition tools.
Knowledge of the safe operation and maintenance of agricultural equipment.
A working knowledge of the CAN bus and how to extract information from it.
A working knowledge of advanced electronic systems used in agriculture for monitoring and tracking the harvest and post-harvest processing of product.
Show more
Show less","Mechanical systems, Hydraulic systems, Electrical systems, Engineering theory, Engineering principles, Data acquisition tools, CAN bus, Advanced electronic systems, Agriculture, Farming experience, Mobile equipment, Test of mobile equipment, Agricultural harvesting equipment","Company: Cotton Harvesting Product Verification and Validation (PV&V) Group
Job Title: Performance Engineer
Experience: 4-year degree in engineering, technology, or equivalent experience
Skills Needed: Strong personal skills, technical report writing, mechanical, hydraulic, and electrical systems knowledge, engineering theory, team collaboration, flexibility, farming experience, data acquisition tools, CAN bus understanding, electronic systems knowledge.",0.27169811014595946,0.73878366
Data Science Supervisor,EMC Insurance Companies,"Des Moines, IA",https://www.linkedin.com/jobs/view/data-science-supervisor-at-emc-insurance-companies-3775739493,2023-12-20,West Des Moines,United States,Mid senior,Onsite,"At EMC, you'll put your skills to good use as an important member of our team. You can count on gaining valuable experience while contributing to the company's success. EMC strives to hire and retain the best people by engaging, developing and rewarding employees.
This position can be performed remotely for candidates who reside in the state of Iowa
Essential Functions
Leads machine learning operations (MLOps) driven full-cycle data science projects, including problem definition, data exploration, model creation, evaluation, and deployment
Reviews artificial intelligence (AI), machine learning (ML), and statistical models developed by the team for accuracy. Supports team in generating insights and recommendations
Collaborates with stakeholders to understand business requirements and translate them into actionable initiatives to embed analytics and streamline operations
Ensures the team understands the scope and requirements for each project assigned, and escalates resource allocation and performance issues when necessary
Creates processes to measure the value of initiatives based on established criteria and ensures the team is meeting goals
Oversees and monitors the workload and performance of the team
Guides team through complex work issues and answers questions
Conducts performance reviews and provides coaching
Develops team expertise and assists with succession planning, including identifying talent and implementing development plans for critical positions
Stays updated with the latest advancement and trends in data science and analytics and evaluates their applicability to the team’s projects
Collaborates with business partners, Strategic Analytics team members, and project owners to identify top data science opportunities
Communicates data science vision, capabilities, and goals to team and business partners
Education & Experience
Bachelor’s degree in mathematics, statistics, computer science, data science or related field and Certified Specialist in Predictive Analytics (CSPA) OR Master’s degree in mathematics, statistics, computer science, data science, or related field
Seven years of experience in data science, including experience with artificial intelligence or machine learning, or related experience
Prior experience in property and casualty insurance preferred
Prior leadership or supervisory experience preferred
Knowledge, Skills & Abilities
Excellent knowledge of data analysis tools and techniques, such as generalized linear models, decision trees, gradient boosting machines, random forests, boosting, bagging, neural networks, further statistical analysis, machine learning, or deep learning techniques
Advanced knowledge of programming within R, Python, SQL, Hadoop, and other data visualization tools
Strong property and casualty insurance knowledge
Excellent verbal and written communication skills
Excellent ability to translate technical ideas into more general terms for business customers
Excellent analytical, investigation, and problem-solving skills
Our employment practices are in accordance with the laws that prohibit discrimination due to race, color, creed, sex, sexual orientation, gender identity, genetic information, religion, age, national origin or ancestry, physical or mental disability, medical condition, veteran status, active military status, citizenship status, marital status or any other consideration made unlawful by federal, state, or local laws.
All of our locations are tobacco free including in company vehicles.
To learn more about why you’re gonna love it here, watch the video below.
Show more
Show less","Machine learning, Data science, Data analysis, Artificial intelligence, Problem solving, Data visualization, Statistics, R programming, Python programming, SQL programming, Hadoop, Neural networks, Deep learning, Decision trees, Random forests, Gradient boosting machines, Bagging, Boosing, Generalized linear models, Property and casualty insurance, Communication, Analytical thinking","Company: EMC
Job Title: Machine Learning Operations (MLOps) Lead
Experience: Seven years of experience in data science with AI or machine learning experience
Skills Needed: Proficiency in data analysis tools, programming languages like R, Python, SQL, and Hadoop, strong property and casualty insurance knowledge, excellent communication skills, ability to translate technical concepts into business terms, analytical and problem-solving skills.",0.18032786633700623,0.693086
Labs - Data Scientist - Senior Associate,PwC,"Des Moines, IA",https://www.linkedin.com/jobs/view/labs-data-scientist-senior-associate-at-pwc-3782253043,2023-12-20,West Des Moines,United States,Mid senior,Onsite,"Specialty/Competency:
Data Science
Industry/Sector:
Not Applicable
Time Type:
Full time
Travel Requirements:
Up to 20%
A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
Responsibilities
As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities, coaching them to deliver results.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Use a broad range of tools and techniques to extract insights from current industry or sector trends.
Review your work and that of others for quality, accuracy and relevance.
Know how and when to use tools available for a given situation and can explain the reasons for this choice.
Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Our mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.
Basic Qualifications
Job Requirements and Preferences
:
Minimum Degree Required
Bachelor Degree
Additional Educational Requirements
Bachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college.
Minimum Years Of Experience
2 year(s)
Preferred Qualifications
Degree Preferred
:
Master Degree
Preferred Fields Of Study
Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research
Additional Educational Preferences
PhD highly preferred
Preferred Knowledge/Skills
Demonstrates thorough abilities and/or a proven record of success:
Exploring new analytical technologies and evaluate their technical and commercial viability;
Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools;
Working across various data mediums: text, audio, imagery, sensory, and structured data;
Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;
Testing and rejecting hypotheses around data processing and ML model building;
Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;
Building ML pipelines that ingest, clean data, and make predictions;
Focusing on AI and ML techniques that are broadly applicable across all industries;
Staying abreast of new AI research from leading labs by reading papers and experimenting with code;
Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients;
Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);
Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;
Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);
Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;
Building ML models and systems, interpreting their output, and communicating the results; and,
Moving models from development to production; conducting lab research and publishing work.
Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:
Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;
Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);
Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;
Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;
Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;
Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,
Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.
Learn more about how we work: https://pwc.to/how-we-work
PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.
All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.
For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.
Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines
For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate
Show more
Show less","Artificial Intelligence, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Augmented Reality, Virtual Reality, Blockchain, Drones, Internet of Things, 3D Printing, Data Science, Data Analytics, Business Intelligence, Data Mining, Data Visualization, Data Warehousing, Data Lakes, Data Pipelines, Data Engineering, Software Development, Web Development, Mobile Development, Cloud Computing, DevOps, Agile, Scrum, Kanban, Git, GitHub, Docker, Kubernetes, AWS, Azure, GCP, Python, R, Java, JavaScript, C++, Unix, SQL, NoSQL, Postgres, Neo4j, Hadoop, GCP BigQuery, Parquet, Python (Numpy Pandas etc.), Spark, GCP DataFlow, Python (scikitlearn genism etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy, Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS, Python (Matplotlib Seaborn bokeh etc.), JavaScript (d3), Power BI, Tableau, Data Studio, GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS","Company: PwC
Job Title: Senior Associate in Data Science
Experience: 2 years
Skills Needed: The ideal candidate should have a Bachelor's degree in Computer and Information Science, Mathematics, or related fields, with a preference for a Master's or PhD. They should demonstrate expertise in exploring new analytical technologies, working across data mediums, developing ML models, staying updated on AI research, and applying ML techniques to various problems. Additionally, proficiency in programming languages like Python, knowledge of data",0.08939974300723061,0.5742378
Data Engineer,Accroid Inc,"Ankeny, IA",https://www.linkedin.com/jobs/view/data-engineer-at-accroid-inc-3788129009,2023-12-20,West Des Moines,United States,Mid senior,Onsite,"Onsite
Data Engineer
Build and maintain data pipelines utilizing Databricks and ADLS.
Collaborate with cross-functional teams to understand and fulfill data requirements.
Deliver outputs that align with defined specifications and meet business objectives.
Provide expertise in data engineering and contribute to the overall success of data-related projects.
Show more
Show less","Data Engineering, Data Pipelines, Databricks, ADLS, Data Requirements, Business Objectives","Company: Not specified
Job Title: Onsite Data Engineer
Experience: Not specified

Skills needed:
- Experience in building and maintaining data pipelines using Databricks and ADLS
- Ability to collaborate with cross-functional teams to gather and fulfill data requirements
- Deliver outputs that meet defined specifications and business objectives
- Expertise in data engineering and contributing to the success of data-related projects",0.6516853882742079,0.8405922
Data Engineer,Accroid Inc,"Des Moines, IA",https://www.linkedin.com/jobs/view/data-engineer-at-accroid-inc-3782787357,2023-12-20,West Des Moines,United States,Mid senior,Onsite,"IA
ETL Development:
Design, develop, and maintain robust ETL processes, ensuring efficient extraction, transformation, and loading of data into Snowflake from diverse sources.
Uphold data quality, integrity, and reliability standards throughout the ETL lifecycle.
Snowflake Optimization:
Leverage in-depth knowledge of Snowflake architecture, features, and best practices to optimize performance, scalability, and efficiency of data pipelines and warehouse operations.
Data Modeling:
Collaborate with data architects to design and implement data models in Snowflake, aligning with business requirements and ensuring scalability for future growth.
Show more
Show less","ETL, Snowflake, Data modeling, Data quality, Data integrity, Data reliability, Data pipelines, Data warehouse operations","Company: IA

Job Title: ETL Developer

Experience: Not specified

Skills needed: 
- Proficiency in designing, developing, and maintaining ETL processes
- Strong understanding of Snowflake architecture and features
- Ability to optimize performance and scalability of data pipelines in Snowflake
- Experience in collaborating with data architects for designing and implementing data models
- Ensure data quality, integrity, and reliability standards throughout the ETL lifecycle",0.38938052608661605,0.8439636
Data Center Engineer,Park Place Technologies,"Des Moines, IA",https://www.linkedin.com/jobs/view/data-center-engineer-at-park-place-technologies-3765295148,2023-12-20,West Des Moines,United States,Mid senior,Remote,"Field Service Engineer
The Field Service Engineer is responsible for providing onsite system diagnostic and analytical support to customers within a geographic territory, or assigned to a specific account, supporting the customer per the terms of the SLA (Service Level Agreement) with Park Place Technologies. Specifically, the FSE responds to customers’ systems failures by way of computer hardware service, testing, diagnostic analysis, and systems analysis of hardware, storage area networks, and system configurations. An FSE must be available to respond to customer issues 24/7 and service all equipment regardless of product training within the designated service area. They also must have a thorough and broad knowledge of system configuration.
Who We Are:
As the global leader in third party maintenance, our 2500 Park Place Associates provide support to 21,000+ customers in more than 154+ countries. We are proud to service 90% of Fortune 500 companies and 40% of Forbes 100 clients.
Our company’s strength and success are a credit to our Associates, and Park Place Life is how we communicate and deliver our culture internally. We have been awarded as a NorthCoast 99 “Best Workplace” winner for 13 consecutive years in recognition of our employee commitment. Park Place Life is about collaboration, responsiveness, diversity, and integrity, and represents everything that makes our company great and our culture unique.
Top Rated Benefits We Offer:
We cover 100% of your Healthcare benefits!
Profit Sharing!
401K matching contributions and earnings are always 100% vested.
Flexible Vacation.
Overtime Pay.
Mileage Reimbursement.
Plus much more!!!
What you’ll be doing:
Provides onsite technical customer support:
Ensures timely, professional, and effective response to customer service needs to maintain a high level of customer satisfaction.
Must be able to be scheduled for work on shifts occurring at any time of day.
Provides effective problem analysis and identification remotely before arrival at customer site; determines needed parts and documentation to minimize down time and multiple trips
Performs service in a cost effective manner.
Displays professional attitude and courtesy while on site.
Maintains effective communication with customer and our customer support center during repair process and any projected delay.
Analyzes software and hardware error logs, utilizes diagnostic and troubleshooting techniques and operating system analysis to ensure timely and effective repair.
Analyzes, diagnoses, troubleshoots and repairs hardware, storage area network and systems configuration and compatibility problems.
Utilizes multiple tools for remote system connection to perform remote diagnosis, repair or configuration changes.
Follows customer specific repair procedures.
Assesses current and future customer needs based on usage of the system.
Inventory / Parts Management:
Determines needed parts and quantities based on contracts in service area.
Returns bad or excess parts in a timely manner.
Manages accurate inventory count, daily and as required and performs bi-yearly physical count inventory.
Administrative:
Accurately completes and timely returns audit forms, email replies, timesheets and expense reports.
Attends and participates in regularly scheduled team meetings.
Accounts for all activities correctly using Field Point time reporting utility.
What we’re looking for:
Minimum seven (7) years specific experience working with OEM data center hardware
Successful Prior Field experience
Solid technical aptitude
Understanding of different OEM equipment with the ability to grasp new products/concepts
Ability to work long and/or unusual hours while maintaining effectiveness (manage being on call 24/7)
Demonstrated experience providing Customer Service (may be internal to organization) and ability to put the Customer Needs first
Proven ability to work independently, while exhibiting leadership and collaboration, when working with others
CompTIA A+ and Server + preferred
Must possess a valid driver’s license and an appropriate driving record based on the position travel requirements.
Must be able to assume an on-call status position and respond based on service level agreements within assigned territory.
Must be able to maintain regular working hours assigned, if site specific assignment.
Must be able to lift 50 pounds, stand and walk for extended periods of time, pull, lift, squat, reach, bend, and stoop to equipment, parts, and supplies. Again, this is an extremely active position that requires walking, standing, squatting, bending, and driving for over 50% of the workday.
Must be able to pass customer background screenings in addition to Park Place Technologies pre-employment screenings.
Bonus Points:
Certification and other OEM computer hardware certifications from major vendors such as Dell, IBM, HP, etc. are helpful
Bachelor's degree in related field (i.e. Computer Science, Engineering) or equivalent experience preferred
Education:
High School Degree required
Travel:
Must be able to travel to client sites up to 75% of the time within a predetermined territory radius (up to 4+ hours/one way by car).
Show more
Show less","Field Service, System Diagnostic, Analytical Support, Hardware Service, Hardware Analysis, Network Analysis, System Configuration, Customer Service, CompTIA A+, CompTIA Server +, OEM Computer Hardware, Dell, IBM, HP","Company Name: Park Place Technologies
Job Title: Field Service Engineer
Experience: Minimum seven (7) years specific experience working with OEM data center hardware
Skills Needed: Solid technical aptitude, ability to work long hours, CompTIA A+ and Server+ preferred, strong customer service skills, ability to work independently and collaboratively, valid driver's license, ability to lift 50 pounds, travel up to 75% of the time, high school degree required. Bonus points for OEM computer",0.17543859430738423,0.6581521
Data Scientist-Supply Chain,Casey's,"Ankeny, IA",https://www.linkedin.com/jobs/view/data-scientist-supply-chain-at-casey-s-3751160160,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"Data Science & Analytics at Casey’s is a centralized group that partners with various business units including merchandising, store operations, fuel (supply, transportation, and pricing), and supply chain, to deliver insightful, practical, and effective solutions to help business make crucial data-driven decisions to maximize ROI and company’s brand equity. This role will have the opportunity to be part of a highly skilled and cross-functional team to deliver strategic solutions using AI/ML, technology, and analytical methods.
As a Data Analyst at Casey's you will lead and own all data science initiatives in various areas in the supply chain including network optimization, pricing, procurement planning etc. that influence strategic decision making. You will have the opportunity to work on some of the challenging problems, unique to the C-Store retail space, and build ML models using cutting-edge technologies to deliver high-impact solutions. You will work closely with a team of talented data scientists, product owners, data engineers, and other technology leaders. This position is based in Ankeny, Iowa, and you will be reporting to the Director of Data Science & Analytics.
*Open to hiring at multiple levels based on skills & experience
*Open to H1B Visa Transfers, sorry no student visa's at this time
*Prefer candidates who are willing to relocate to Iowa, if outside of Iowa qualified candidate must reside within Casey's 17 state foot print.
What You Will Do:
Work closely with supply chain business unit leaders to understand, translate and formulate complex business problems into appropriate data science models using a range of statistical and AI/ML methodologies, experiment with various approaches, implement models into production using cloud technologies, and communicate the insights to business. Comfortable working in a fast-paced agile environment.
Act as the subject matter expert to design, build, productionize, and maintain ML solutions in supply chain.
You will lead the development and delivery of data science solutions that help us improve and make our supply chain processes more efficient.
Identify new KPIs and track current metrics that measure the health of various supply chain processes.
Follow established state-of-the-art MLOps practices in a Cloud setting (preferably Azure) to scale the models in production.
Work on data science and AI/ML projects in other areas like customer & marketing, if needed.
Work with data analysts to design insightful visualizations and reports as needed and communicate the findings to business partners.
Mentor junior data scientists.
What You Bring:
Master’s or PhD degree in statistics, econometrics, operations research, engineering, or related field; Bachelor’s degree in a quantitative field with extensive relevant industry experience.
5 years of industry experience in data science / ML preferably at a retail company in the supply chain data science space including pricing optimization, demand forecasting, network planning, logistics optimization, replenishment etc.
Strong programming experience with Python and/or R.
Demonstrable experience in writing advanced SQL.
Experience with data science and ML packages/technologies like scikit-learn, AutoML; Bonus: TensorFlow, PySpark, ML tools on Azure/Databricks.
Proficiency in statistics and ML – hypothesis testing, regression including causal inference, time series analysis/forecasting, classification, tree-based models, deep learning, reinforcement learning, unsupervised learning etc.
Knowledge in operation research and optimization methods including experience with linear and integer programming using open-source solvers.
Knowledge in simulation techniques.
Experience in end-to-end model building and deployment to production on cloud environments using MLOps practices.
Experience in data story-telling using compelling visualizations and ability of explain complex data concepts in simple language.
Passion to experiment with out-of-the-box approaches and have courage to fail fast.
Experience with agile mode of working.
Show more
Show less","Statistics, Econometrics, Operations Research, Engineering, Python, R, SQL, ScikitLearn, AutoML, TensorFlow, PySpark, ML tools, Azure/Databricks, Hypothesis Testing, Regression, Causal Inference, Time Series Analysis, Forecasting, Classification, Treebased Models, Deep Learning, Reinforcement Learning, Unsupervised Learning, Operation Research, Optimization Methods, Linear Programming, Integer Programming, Opensource Solvers, Simulation Techniques, Data Storytelling, Agile","Company Name: Casey's
Job Title: Data Analyst - Data Science & Analytics

This position requires a Master's or PhD degree in statistics, econometrics, operations research, engineering, or a related field, or a Bachelor's degree with extensive industry experience. The ideal candidate should have at least 5 years of experience in data science and machine learning within the retail industry, specifically in supply chain areas such as pricing optimization, demand forecasting, network planning, and logistics optimization. Proficiency in Python and",0.2564102535646286,0.7475253
Data Scientist-Marketing & Customer Insights,Casey's,"Ankeny, IA",https://www.linkedin.com/jobs/view/data-scientist-marketing-customer-insights-at-casey-s-3744387341,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"Data Science & Analytics at Casey’s is a centralized group that partners with various business units including merchandising, store operations, fuel (supply, transportation, and pricing), and supply chain, to deliver insightful, practical, and effective solutions to help business make crucial data-driven decisions to maximize ROI and company’s brand equity. The selected candidate will have the opportunity to be part of a highly skilled and cross-functional team to deliver strategic solutions using AI/ML, technology, and analytical methods.
In this role you will lead and own all data science initiatives in the marketing and customer insights space. You will have the opportunity to work on some of the challenging problems, unique to the C-Store retail space, and build ML models using cutting-edge technologies to deliver high-impact solutions. You will work closely with a team of talented data scientists, product owners, data engineers, and other technology leaders. This position is based in Ankeny, Iowa, and you will be reporting to the Director of Data Science & Analytics.
*Open to hiring at multiple levels based on skills & experience
*Open to H1B Visa Transfers, sorry no student visa's at this time
*Prefer candidates who are willing to relocate to Iowa, if outside of Iowa qualified candidate must reside within Casey's 17 state foot print.
What You Will Do:
Partner with stakeholders in marketing and customer insights business units to translate and formulate complex business problems into appropriate data models using a range of statistical and AI/ML methodologies, experiment with various approaches, implement models into production using cloud technologies, and communicate the insights to business. Comfortable working in a fast-paced agile environment.
Develop & build accurate marketing measurement and attribution capabilities, customer behavioral patterns and personalization. You will lead the development and delivery of data science solutions that help us understand our customers better, design and measure incremental value in marketing campaigns to maximize customer satisfaction and strengthen the company’s brand.
Follow established state-of-the-art MLOps practices in a Cloud setting (preferably Azure) to scale the models in production.
Work on data science and AI/ML projects in other areas in supply chain as well, if needed.
Work with data analysts to design insightful dashboard and reports as needed.
Mentor junior data scientists
What You Bring:
Master’s or PhD degree in statistics, econometrics, operations research, engineering, or related field; Bachelor’s degree in a quantitative field with extensive relevant industry experience.
5 years of industry experience in data science / ML preferably at a retail company in marketing or customer analytics including market mix modeling, attribution, customer lifetime modeling, propensity and churn modeling, segmentation etc.
Strong programming experience with Python and/or R.
Demonstrable experience in writing advanced SQL.
Experience with data science and ML packages/technologies like scikit-learn, AutoML; Bonus: TensorFlow, PySpark, ML tools on Azure/Databricks.
Proficiency in statistics and ML – hypothesis testing, regression incl causal inference, classification, tree-based models, neural networks, unsupervised learning, text analysis, recommender systems etc.
Experience in end-to-end model building and deployment to production on cloud environments using MLOps practices.
Experience in data story-telling using compelling visualizations and ability of explain complex data concepts in simple language.
Passion to experiment with out-of-the-box approaches and have courage to fail fast
Preferred Skills/Abilities:
Prior experience with digital and retail media advertising tools.
In-depth knowledge and practice of software engineering principles, best coding practices etc., in a agile setup.
In-depth knowledge of data analytic cloud platforms, databases, and surrounding ecosystems (Azure or Databricks Preferred), and Source Control & Documentation Tools. Examples include GitHub, Teams, and Confluence.
Proven ability to thrive in and work with noisy and ambiguous data in a fast-paced environment with tight deadlines.
Proven ability to write high-quality code that is scalable, efficient, readable, and bug-free.
Excellent interpersonal, verbal and written communication skills.
Excellent interpersonal, verbal and written communication skills with the ability to convey complex data-driven insights to non-technical stakeholders.
Must be detail oriented with strong attention to accuracy.
Excellent analytical and hardworking problem-solving mindset.
Excellent problem-solving skills with the ability to influence team members at different levels.
Show more
Show less","Data Science, Applied Machine Learning, Data Analytics, Statistics, Econometrics, Operations Research, R Programming, Python Programming, SQL, TensorFlow, PySpark, ML tools on Azure/Databricks, Scikitlearn, AutoML, Hypothesis testing, Regression, Causal inference, Classification, Treebased models, Neural networks, Unsupervised learning, Text analysis, Recommender systems, MLOps, Cloud computing, Agile development, Data visualization, Data storytelling, Digital and retail media advertising tools, Software engineering principles, GitHub, Teams, Confluence, Azure, Databricks","Company Name: Casey's
Job Title: Data Science & Analytics Lead in Marketing and Customer Insights
Experience: 5 years of industry experience in data science / ML, preferably at a retail company in marketing or customer analytics

Skills Needed:
- Master’s or PhD degree in statistics, econometrics, operations research, engineering, or related field; Bachelor’s degree in a quantitative field with extensive relevant industry experience
- Strong programming experience with Python and/or R
- Demonstrable experience in writing advanced SQL",0.22477063976222542,0.6346574
Data Engineer,"Professional Project Partners, Inc. (P3)","Des Moines, IA",https://www.linkedin.com/jobs/view/data-engineer-at-professional-project-partners-inc-p3-3783766847,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"** This is a Full-Time position and our client is not offering sponsorship at this time**
**This is a Hybrid position in Des Moines, Iowa, so if a candidate is not located in Des Moines they will need to relocate in order to be considered**
Passionate about crafting innovative data solutions that seamlessly integrate and transform information? Proficient with relational databases like Azure SQL and adept at wielding data integration tools such as Talend and Azure Data Factory? Are you someone who thrives on providing top-notch service while maintaining a keen eye for detail?
We invite you to join one of our esteemed clients as a Data Engineer! In this role, you'll collaborate closely with analysts, developers, and business users, contributing to the construction of data pipelines and marts essential for robust reporting and analytics support.
Key Responsibilities:
Develop Azure-based solutions to harmonize on-premise and cloud data sources, ensuring alignment with data warehouse reporting needs.
Design and implement data integration and automation processes, emphasizing best practices for performance, security, data integrity, and code reusability.
Provide adept maintenance support for existing ETL processes, swiftly addressing issues through root cause analysis and resolution.
Collaborate across functions to comprehend intricate business challenges, proposing and executing technical solutions effectively.
Translate business requirements into functional technical necessities, offering precise estimates regarding effort and timelines.
Continuously enhance understanding of our client’s audiences, systems, processes, and tools, identifying gaps, quality concerns, and performance improvements.
Knowledge:
Proficiency in Azure cloud services including Azure SQL database, Data Lake Gen 2, and Data Factory.
Demonstrated understanding of data modeling, data warehousing, and ETL strategies.
Strong grasp of relational databases (preferably Azure SQL) and Data Governance principles.
Working knowledge of agile methodology and project management tools.
Skills:
Strong experience in developing data flows and relational data stores in Azure cloud services.
Proficiency in Azure Data Factory, Talend, or similar ETL tools (preferably Azure Data Factory and Talend).
Proven background in data design, workflow, integrations, standards, and complex business rules.
Sharp problem-solving and analytical skills to decipher trends and create solutions for complex challenges.
Excellent interpersonal, written, and verbal communication skills with the ability to translate technical aspects to business stakeholders.
Exceptional organizational abilities to manage multiple projects effectively.
Aptitude for troubleshooting and issue resolution in dynamic environments.
Forward-thinking attitude and a proclivity for purposeful change and continual improvement.
Ability to simplify complex data and concepts into easily understandable language and visualizations for business stakeholders.
Education:
Bachelor's degree in computer science, information technology, data science, business, or related field from an accredited college or equivalent experience.
Experience:
3+ years of experience in ETL/ELT development, including expertise with Azure SQL, Talend, Azure Data Factory, and Data Lake Gen 2, or equivalent technologies.
Show more
Show less","Azure SQL, Data Lake Gen 2, Data Factory, Azure, Talend, ETL, Data Integration, Data Warehousing, Data Modeling, Agile Methodology, Project Management, Data Design, Workflow, Integrations, ProblemSolving, Analytical Skills, Communication Skills, Organizational Abilities, Troubleshooting, Issue Resolution, Change Management, Data Visualization","Company Name: Not specified
Job Title: Data Engineer
Years of Experience: 3+ years of experience in ETL/ELT development
Skills Needed: Proficiency in Azure cloud services including Azure SQL database, Data Lake Gen 2, and Data Factory. Strong experience in developing data flows and relational data stores in Azure cloud services. Strong grasp of relational databases and Data Governance principles. Proficiency in ETL tools such as Talend and Azure Data Factory. Excellent problem-solving and analytical skills",0.23423423168213262,0.7002401
Hybrid Work - Need Senior Data Platform Engineer-Azure in Des Moines IA,Steneral Consulting,"Des Moines, IA",https://www.linkedin.com/jobs/view/hybrid-work-need-senior-data-platform-engineer-azure-in-des-moines-ia-at-steneral-consulting-3750853112,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"Senior Data Platform Engineer-Azure
Des Moines, IA - Hybrid 3 days a week - locals are highly preferred but will consider someone from Midwest who will relocate from day one to work onsite.
Communication and collaboration are key. They must be easily understood and able to speak well to their projects and technical experience.
Must have valid LinkedIn and Photo ID required with submission
Must Have’s: Must have everything or please do not send them to me.
Azure Microsoft Fabric -- end to end lifecycle.
Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security.
Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models.
Azure Data Factory: Data integration and ETL processes.
Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle.
Azure Stream Analytics: Real-time data streaming and analytics.
Azure Databricks & HDInsight: Big data analytics solutions. (lower priority)
Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
SQL: Writing, optimizing, and debugging SQL queries.
Data modeling: Normalization, star schema, snowflake schema
Familiarity with SDKs and APIs associated with Azure data services.
Integration with other Azure services or third-party applications.
Experience in one or more programming languages like C#, Python, or Java can be beneficial.
Azure Monitor, Azure Log Analytics, and Application Insights.
DP-203 certification
Financial/Investment industry experience.
Job Description
Here are the skills sets for building out the Microsoft Azure Data Platform.
Azure Fundamentals:
Understanding of Azure subscriptions, resources, and resource groups.
Familiarity with Azure regions, availability zones, and the Azure portal.
Azure Data Services Knowledge of tool set:
Azure Microsoft Fabric -- end to end lifecycle.
Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security.
Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models.
Azure Data Factory: Data integration and ETL processes.
Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle.
Azure Stream Analytics: Real-time data streaming and analytics.
Azure Databricks & HDInsight: Big data analytics solutions. (lower priority)
Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
Skills:
SQL: Writing, optimizing, and debugging SQL queries.
Data modeling: Normalization, star schema, snowflake schema
Familiarity with SDKs and APIs associated with Azure data services.
Integration with other Azure services or third-party applications.
Experience in one or more programming languages like C#, Python, or Java can be beneficial.
Azure Monitor, Azure Log Analytics, and Application Insights.
DP-203 certification
Optional but helpful:
Azure Active Directory and role-based access control (RBAC)
Tools like Azure Data Migration Service, SSIS (SQL Server Integration Services).
Strategies for migrating data from on-premises or other clouds to Azure.
Show more
Show less","Azure, Azure SQL Database, Azure Cosmos DB, Azure Data Factory, Azure Blob Storage, Azure Data Lake Storage, Azure Stream Analytics, Azure Databricks, Azure HDInsight, Azure Synapse Analytics, SQL, Data modeling, Azure Monitor, Azure Log Analytics, Application Insights, DP203 certification, Microsoft Fabric, Azure Subscriptions, Azure Resources, Azure Resource Groups, Azure Regions, Azure Availability Zones, Azure Portal, Azure Data Services, Azure Fundamentals, SDKs, APIs, C#, Python, Java, Azure Data Migration Service, SSIS, SQL Server Integration Services, Azure Active Directory, RBAC, ETL processes","Company: Not specified
Job Title: Senior Data Platform Engineer - Azure
Experience: Not specified, but likely requires several years of experience in Azure data platform engineering
Skills Needed: Must have strong expertise in Azure data services such as Azure SQL Database, Cosmos DB, Data Factory, Blob Storage, Stream Analytics, Databricks, HDInsight, and Synapse Analytics. Proficiency in SQL, data modeling, SDKs, APIs, and integration with other services is required. Knowledge of programming languages",0.21789882910566405,0.71013594
Hybrid Work - Need Senior Data Platform Engineer-Azure in Des Moines IA,Steneral Consulting,"Des Moines, IA",https://www.linkedin.com/jobs/view/hybrid-work-need-senior-data-platform-engineer-azure-in-des-moines-ia-at-steneral-consulting-3758725468,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"Senior Data Platform Engineer-Azure
Des Moines, IA - Hybrid 3 days a week - locals are highly preferred but will consider someone from Midwest who will relocate from day one to work onsite.
Communication and collaboration are key. They must be easily understood and able to speak well to their projects and technical experience.
Must have valid LinkedIn and Photo ID required with submission
Must Have’s: Must have everything or please do not send them to me.
Azure Microsoft Fabric -- end to end lifecycle.
Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security.
Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models.
Azure Data Factory: Data integration and ETL processes.
Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle.
Azure Stream Analytics: Real-time data streaming and analytics.
Azure Databricks & HDInsight: Big data analytics solutions. (lower priority)
Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
SQL: Writing, optimizing, and debugging SQL queries.
Data modeling: Normalization, star schema, snowflake schema
Familiarity with SDKs and APIs associated with Azure data services.
Integration with other Azure services or third-party applications.
Experience in one or more programming languages like C#, Python, or Java can be beneficial.
Azure Monitor, Azure Log Analytics, and Application Insights.
DP-203 certification
Financial/Investment industry experience.
Job Description
Here are the skills sets for building out the Microsoft Azure Data Platform.
Azure Fundamentals:
Understanding of Azure subscriptions, resources, and resource groups.
Familiarity with Azure regions, availability zones, and the Azure portal.
Azure Data Services Knowledge of tool set:
Azure Microsoft Fabric -- end to end lifecycle.
Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security.
Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models.
Azure Data Factory: Data integration and ETL processes.
Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle.
Azure Stream Analytics: Real-time data streaming and analytics.
Azure Databricks & HDInsight: Big data analytics solutions. (lower priority)
Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
Skills:
SQL: Writing, optimizing, and debugging SQL queries.
Data modeling: Normalization, star schema, snowflake schema
Familiarity with SDKs and APIs associated with Azure data services.
Integration with other Azure services or third-party applications.
Experience in one or more programming languages like C#, Python, or Java can be beneficial.
Azure Monitor, Azure Log Analytics, and Application Insights.
DP-203 certification
Optional but helpful:
Azure Active Directory and role-based access control (RBAC)
Tools like Azure Data Migration Service, SSIS (SQL Server Integration Services).
Strategies for migrating data from on-premises or other clouds to Azure.
Show more
Show less","Azure, Microsoft Fabric, Azure SQL Database, Azure Cosmos DB, Azure Data Factory, Azure Blob Storage, Data Lake Storage, Azure Stream Analytics, Azure Databricks, HDInsight, Azure Synapse Analytics, SQL, Data modeling, SDKs, APIs, C#, Python, Java, Azure Monitor, Azure Log Analytics, Application Insights, DP203 certification, Azure Active Directory, RBAC, Azure Data Migration Service, SSIS, Azure Fundamentals, Azure subscriptions, Azure resources, Resource groups, Azure regions, Availability zones, Azure portal","Company: Not specified
Job Title: Senior Data Platform Engineer - Azure
Experience: Not specified, but likely requires several years of experience in Azure data platform engineering
Skills Needed: The ideal candidate must have expertise in various aspects of Microsoft Azure data platform, including Azure SQL Database, Cosmos DB, Data Factory, Blob Storage, Data Lake Storage, Stream Analytics, Databricks, HDInsight, Synapse Analytics, SQL, data modeling, SDKs and APIs associated with Azure data services, integration",0.21093749645294194,0.7316469
Hybrid Work - Need Senior Data Platform Engineer-Azure in Des Moines IA,Steneral Consulting,"Des Moines, IA",https://www.linkedin.com/jobs/view/hybrid-work-need-senior-data-platform-engineer-azure-in-des-moines-ia-at-steneral-consulting-3751750122,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"Senior Data Platform Engineer-Azure
Des Moines, IA - Hybrid 3 days a week - locals are highly preferred but will consider someone from Midwest who will relocate from day one to work onsite.
Communication and collaboration are key. They must be easily understood and able to speak well to their projects and technical experience.
Must have valid LinkedIn and Photo ID required with submission
Must Have’s: Must have everything or please do not send them to me.
Azure Microsoft Fabric -- end to end lifecycle.
Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security.
Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models.
Azure Data Factory: Data integration and ETL processes.
Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle.
Azure Stream Analytics: Real-time data streaming and analytics.
Azure Databricks & HDInsight: Big data analytics solutions. (lower priority)
Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
SQL: Writing, optimizing, and debugging SQL queries.
Data modeling: Normalization, star schema, snowflake schema
Familiarity with SDKs and APIs associated with Azure data services.
Integration with other Azure services or third-party applications.
Experience in one or more programming languages like C#, Python, or Java can be beneficial.
Azure Monitor, Azure Log Analytics, and Application Insights.
DP-203 certification
Financial/Investment industry experience.
Job Description
Here are the skills sets for building out the Microsoft Azure Data Platform.
Azure Fundamentals:
Understanding of Azure subscriptions, resources, and resource groups.
Familiarity with Azure regions, availability zones, and the Azure portal.
Azure Data Services Knowledge of tool set:
Azure Microsoft Fabric -- end to end lifecycle.
Azure Azure SQL Database: Provisioning, performance tuning, scaling, and security.
Azure Cosmos DB: Understanding of NoSQL databases, partitioning, consistency models.
Azure Data Factory: Data integration and ETL processes.
Azure Blob Storage and Data Lake Storage: Management, performance, security, and data lifecycle.
Azure Stream Analytics: Real-time data streaming and analytics.
Azure Databricks & HDInsight: Big data analytics solutions. (lower priority)
Azure Synapse Analytics: Knowledge of data warehousing, data integration, and analytics.
Skills:
SQL: Writing, optimizing, and debugging SQL queries.
Data modeling: Normalization, star schema, snowflake schema
Familiarity with SDKs and APIs associated with Azure data services.
Integration with other Azure services or third-party applications.
Experience in one or more programming languages like C#, Python, or Java can be beneficial.
Azure Monitor, Azure Log Analytics, and Application Insights.
DP-203 certification
Optional but helpful:
Azure Active Directory and role-based access control (RBAC)
Tools like Azure Data Migration Service, SSIS (SQL Server Integration Services).
Strategies for migrating data from on-premises or other clouds to Azure.
Show more
Show less","Azure, Microsoft Fabric, Azure SQL Database, Azure Cosmos DB, Azure Data Factory, Azure Blob Storage, Data Lake Storage, Azure Stream Analytics, Azure Databricks, HDInsight, Azure Synapse Analytics, SQL, Data modeling, SDKs, APIs, C#, Python, Java, Azure Monitor, Azure Log Analytics, Application Insights, DP203 certification, Financial/Investment industry experience, Data platform, Azure Active Directory, Azure Data Migration Service, SSIS (SQL Server Integration Services), Azure subscriptions, Azure resources, Azure resource groups, Azure regions, Azure availability zones, Azure portal","Company: Not Specified
Job Title: Senior Data Platform Engineer - Azure
Experience: Not specified, but likely requires several years of experience in data engineering and Azure platform
Skills Needed: 
- Strong understanding and experience with Azure Microsoft Fabric, Azure SQL Database, Cosmos DB, Data Factory, Blob Storage, Data Lake Storage, Stream Analytics, Databricks, HDInsight, Synapse Analytics.
- Proficiency in SQL, data modeling, SDKs, APIs, and integration with other Azure",0.18399999665888003,0.7746408
Report Developer/Data Engineer,Steneral Consulting,"Des Moines, IA",https://www.linkedin.com/jobs/view/report-developer-data-engineer-at-steneral-consulting-3755298271,2023-12-20,West Des Moines,United States,Mid senior,Hybrid,"Des Moines, IA - Hybrid -
This position requires onsite/hybrid work 3 days a week in Des Moines, IA.
The client would prefer someone local to Iowa, but will consider relocation as long as they are from the Midwest and can be onsite to work from day one.
Banking Industry Experience Required.
Must have LinkedIn
Must Have’s
Report Creation
SSRS
Power BI
Banking industry experience
ETL
Data Warehouse concepts
Review documented report specifications, clarify requirement ambiguity, develop report output, and unit test the reports to confirm data accuracy. Report Developer may also participate in QA or UAT testing as requested.
Excellent communication and collaboration and easily understood.
Job Description
Position Purpose:
Responsible for development of SSRS and PowerBI reports in accordance with business requirements. This position will also support development, deployment and implementation of the Bank’s Data Warehouse (HUB). Data Developer role will review documented report specifications, clarify requirement ambiguity, develop report output, and unit test the reports to confirm data accuracy. Report Developer may also participate in QA or UAT testing as requested.
Responsibilities/Duties/Function/Tasks
Works with Business Intelligence Analysts, internal customers, and external consulting teams to understand reporting requirements.
Provides recommendations to the internal customers with reporting choices based on future-state reporting needs.
Develop SSRS and/or PowerBI reports as assigned.
Unit test reports to confirm data accuracy.
Work with development teams, architects, management, and business stakeholders to ensure the Hub infrastructure is aligned with business requirements and IT standards.
Implement data solutions and designs with high quality to ensure alignment with the data architecture and applicable standards.
Support QA and UAT testing as assigned.
Quickly troubleshoot and resolve incidents and problems and follow with root cause analysis and solution.
Actively seek opportunities to improve processes.
Manage administrative tasks related to this position.
Ensures reporting solution development is documented in accordance with Data and Reporting Team standards.
Qualifications
Knowledge/experience with SQL Server Reporting Services (SSRS).
Hands on experience with PowerBI strongly preferred.
Strong analytic skills.
Strong attention to detail.
Knowledge/experience with SQL queries and Business Intelligence concepts.
Able to build and maintain relationships and facilitate collaboration and communication.
Able to influence without authority.
Knowledge/experience with ETL, data models and Business Intelligence concepts.
Excellent oral and written communication and planning skills.
Able to work independently and collaborate with people at all levels.
Ability to positively engage, self-motivate and possess a strong desire to learn.
Show more
Show less","SQL Server Reporting Services (SSRS), PowerBI, ETL, Data Warehouse, Data Models, SQL, Business Intelligence, Communication, Collaboration, Problemsolving, Documentation","The job position is for a Report Developer at a company in Des Moines, IA, requiring 3 days of onsite/hybrid work per week. The client prefers candidates local to Iowa or the Midwest with Banking Industry Experience. The essential skills needed for this role include Report Creation, SSRS, Power BI, ETL, and Data Warehouse concepts. The responsibilities include developing SSRS and PowerBI reports, collaborating with internal customers and consulting teams, unit testing reports, supporting QA and UAT testing, troubleshooting",0.3183390967842818,0.8657268
Senior Data Engineer,Ingram Content Group,"La Vergne, TN",https://www.linkedin.com/jobs/view/senior-data-engineer-at-ingram-content-group-3729295016,2023-12-20,Murfreesboro,United States,Mid senior,Onsite,"Job Description
Ingram Content Group (ICG)
is currently recruiting for a
Senior Data Engineer
join our team in
LaVergne, TN
(Greater Nashville area). This individual will work to deliver enterprise grade software solutions with high customer impact. They’ll lead architecture and development activities with a specialization in at least one major enterprise IT application, one major database platform (e.g, MySQL, Oracle, SQL Server), and one major operating system (e.g. Linux). The Senior Data Engineer also performs all aspects of the development life cycle. They will act as the senior technical programmer for the assigned enterprise system and/or application of responsibility. Finally, they will deliver results through independent contributions and through mentoring of junior engineers.
Want to help explore and build new ways to deliver content to the world?
At Ingram, our Technology team is blazing a trail by providing content distribution services to thousands of publishers with key initiatives around business intelligence, machine learning, continuous integration and omnichannel.  We support diverse people and technology that highlights innovation through SaaS platforms, metadata, cloud, and containerization.   Our teams are agile, and emphasize authenticity, creativity, and transparency upon a fact-based foundation.
The world is reading, and it is our goal to connect as many people as possible to the content they want in the simplest ways.  If you are an IT professional who strives to deliver results through collaborative partnerships, understanding what drives business, and enjoys working in a connected culture, we can’t wait to meet you!
The ideal candidate will have the following minimum qualifications:
Bachelor’s Degree in Computer Science or related field or directly related year for year experience
6 years’ experience in designing, developing, implementing, and supporting enterprise level IT solutions
We have a preference for:
6+ years of experience with writing and optimizing existing complex SQL queries
6+ years of database application development experience
Advanced knowledge of SQL relational databases, query authoring (SQL)
Experience with Vertica (projections, segmentation, columnar data)
Experience with columnar databases or non-relational databases
Knowledge of common tools for CentoOS Linux (logs, piping, redirections, grep, sed, yum)
Knowledge of Linux scripting (Python, Perl, shell scripts) and/or advanced stored procedures
Experience with architecting data modeling and meeting requirements for data visualization or reporting tools
Experience with collaborating in a cross-functional capacity across teams, building consensus and executing the necessary vision for application and other analytical needs.
Knowledge of developing in Visual Studio, SSMS and DB Visualizer
Knowledge of JIRA and Confluence
Ability to take business requirements and transpose them into technical details
The Sr Data Developer key responsibilities are:
Serves as Designer/Architect/Engineer for a major enterprise IT application.
Creates, develops, modifies, and maintains data models for internal and external facing application as part of an Agile/SCRUM engineering team
Assembles large and complex data sets that meet business requirements.
Coordinates and communicates with users, developers, and product owners to gather and understanding requirements.
Develops new design patterns, standards, documentation, etc. and works with other developers for implementation.
This list is not exhaustive
Additional Information
Perks/Benefits:
A highly competitive compensation package with generous benefits beginning first day of employment for Medical/Prescription Drug plans, HSA, Vision, Dental and Health Care FSA.
15 vacation days & 12 sick days accrued annually and 3 personal days
401K match, Life and AD&D, Employee Assistant programs, Group Legal, & more
Wellness program with access to onsite gym and basketball court for associates
Avid reader? Numerous opportunities to engage with books and authors
Free card registration at the Nashville Public Library
Discounted offers to self-publish with IngramSpark®!
Encouraged continued education with our tuition reimbursement program
Financial and in-kind opportunities to engage with non-profits in your community
Company match program for United Way donations
Volunteer opportunities and in-kind drives for non-profits throughout the year
Take breaks or brainstorm in our game room with ping pong & foosball
Casual Dress Code & Flexible Schedules (per team)
The world is reading, and Ingram Content Group (“Ingram”) connects people with content in all forms. Providing comprehensive services for publishers, retailers, libraries and educators, Ingram makes these services seamless and accessible through technology, innovation and creativity. With an expansive global network of offices and facilities, Ingram’s services include digital and physical book distribution, print-on-demand, and digital learning. Ingram Content Group is a part of Ingram Industries Inc. and includes Ingram Book Group LLC, Ingram Publisher Services LLC, Lightning Source LLC, Ingram Library Services LLC, Tennessee Book Company LLC, Ingram Content Group UK Ltd. and Ingram Content Group Australia Pty Ltd.
Ingram Content Group LLC is an affirmative action/equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, work related mental or physical disability, veteran status, sexual orientation, gender identity, or genetic information.
EEO/AA Employer/Vet/Disabled
We participate in EVerify.
EEO Poster in English
EEO Poster in Spanish
Show more
Show less","SQL, MySQL, Oracle, SQL Server, Linux, CentoOS, Python, Perl, Visual Studio, SSMS, DB Visualizer, JIRA, Confluence, Agile, Scrum, Hadoop, Hive, Pig, Spark, NoSQL, MongoDB, Cassandra, HBase, Cloud computing, AWS, Azure, GCP, Docker, Kubernetes, DevOps, Continuous integration, Continuous delivery, Machine learning, Artificial intelligence, Natural language processing, Data visualization, Tableau, Power BI, QlikView","Company Name: Ingram Content Group (ICG)

Job Title: Senior Data Engineer

Experience: The ideal candidate will have a Bachelor’s Degree in Computer Science or related field or directly related year for year experience, along with 6 years of experience in designing, developing, implementing, and supporting enterprise-level IT solutions.

Skills Needed:
- Specialization in at least one major enterprise IT application, one major database platform (e.g., MySQL, Oracle, SQL Server), and one major operating system (e",0.1938958686745163,0.72707134
Senior Data Engineer,"Resolution Technologies, Inc.","La Vergne, TN",https://www.linkedin.com/jobs/view/senior-data-engineer-at-resolution-technologies-inc-3777073358,2023-12-20,Murfreesboro,United States,Mid senior,Hybrid,"Senior Data Engineer Job Description:
This individual will work to deliver enterprise grade software solutions with high customer impact. They will lead architecture and development activities with a specialization in at least one major enterprise IT application, one major database platform (e.g, MySQL, Oracle, SQL Server), and one major operating system (e.g. Linux). The Senior Data Engineer also performs all aspects of the development life cycle. They will act as the senior technical programmer for the assigned enterprise system and/or application of responsibility. Finally, they will deliver results through independent contributions and through mentoring of junior engineers.
Senior Data Engineer Minimum Qualifications:
Bachelor’s Degree in Computer Science or related field or directly related year for year experience
6 years’ experience in designing, developing, implementing, and supporting enterprise level IT solutions
Senior Data Engineer Preferred Skills:
6+ years of experience with writing and optimizing existing complex SQL queries
6+ years of database application development experience
Advanced knowledge of SQL relational databases, query authoring (SQL)
Experience with Vertica (projections, segmentation, columnar data)
Experience with columnar databases or non-relational databases
Knowledge of common tools for CentoOS Linux (logs, piping, redirections, grep, sed, yum)
Knowledge of Linux scripting (Python, Perl, shell scripts) and/or advanced stored procedures
Experience with architecting data modeling and meeting requirements for data visualization or reporting tools
Experience with collaborating in a cross-functional capacity across teams, building consensus and executing the necessary vision for application and other analytical needs.
Knowledge of developing in Visual Studio, SSMS and DB Visualizer
Knowledge of JIRA and Confluence
Ability to take business requirements and transpose them into technical details
Senior Data Engineer Key Responsibilities:
Serves as Designer/Architect/Engineer for a major enterprise IT application.
Creates, develops, modifies, and maintains data models for internal and external facing application as part of an Agile/SCRUM engineering team
Assembles large and complex data sets that meet business requirements.
Coordinates and communicates with users, developers, and product owners to gather and understanding requirements.
Develops new design patterns, standards, documentation, etc. and works with other developers for implementation
#RT
Show more
Show less","SQL, Linux, Vertica, Python, Perl, Shell scripting, Visual Studio, SSMS, DB Visualizer, JIRA, Confluence, Agile/SCRUM, Data modeling, Data visualization, Reporting tools, Business requirements, Data sets","Company Name: Not specified
Job Title: Senior Data Engineer
Experience: 6 years

The Senior Data Engineer will be responsible for delivering enterprise-grade software solutions with high customer impact and leading architecture and development activities in at least one major enterprise IT application, major database platform, and major operating system. They will be involved in all aspects of the development life cycle and act as the senior technical programmer for assigned systems. Additionally, they will mentor junior engineers and deliver results through independent contributions.

Minimum Qualifications",0.366197179420006,0.83218986
Property Data Analyst,Bromford,"West Midlands, England, United Kingdom",https://uk.linkedin.com/jobs/view/property-data-analyst-at-bromford-3771943221,2023-12-20,Coventry,United Kingdom,Associate,Onsite,"We are Bromford, where property data transforms into community connections. If you are motivated leveraging technology and intelligence to elevate service and enrich people’s lives and, you would you like to join a leading Housing Association who has been certified as a
Great Place to Work
, read on!
We seek a passionate Property Data Analyst to provide safe, secure housing for our customers. This is a perfect role for detail-driven professionals who enjoy optimising systems and processes. You’ll be working within our Homes, Investment and Compliance team who are responsible for the management and ongoing maintenance of our social and affordable housing. This role will help keep our business on track, making the difference in our ability to deliver our essential services and support to customers, technical knowledge of housing and data systems and ensure the most effective use of data to drive and monitor performance.
The role will also support the effective delivery of the stock condition survey and data collation programme. This is a data-driven opportunity where you will be responsible for assisting in the implementation of systems and effectively upkeeping our records and performance. Your work will support our future investment decisions and provide property asset information to customers and colleagues.
This role is available as a 12-month fixed term contract and subject to a basic DBS check.
To succeed in this position, you will need:
Extensive experience of performance monitoring and reporting
Demonstrable knowledge of data management systems
Experience of delivering an asset-based business support service
Experience of working with and implementing integrated application and data systems
Flexible working attitude
Customer focused with the ability to communicate effectively
We offer location flexibility with offices in Wolverhampton (WV10) and Tewkesbury (GL20) plus remote work options. If you have extensive monitoring/reporting experience, housing data skills, and a flexible approach, here is a chance to directly impact 100,000 plus lives for the better.
Apply before 7 December 2023 for a chance to join our rapidly growing team of property experts.
About Us
We are a housing association- one that owns and provides 46,000 homes for people who can't access market housing; has individual relationships with more than 110,000 customers; has a strong balance sheet and plans to build 11,000 homes by 2030. all of this is only possible because of our 1,800 dedicated colleagues.
We take a simple view that nothing is more important to any individual or a family than their home. It's a matter of social justice that everyone should have a home that is safe, secure, and affordable. We exist to provide such homes. With the right home, people can achieve great things, not only for themselves but for wider society too.
We provide quality, affordable homes. But we care about the people who live in them too. We want each of them to be able to achieve their goals. This will be different for each customer. Put simply, we want people to thrive.
Diversity Statement
We are committed to providing a culture where our customers, our colleagues and our partners feel valued for being unique. We empower individuals to reach their full potential within an open, fair and supportive environment. In return we expect everyone to be respectful, collaborate effectively and embrace diversity. By listening, learning and acting we aim to constantly evolve our ambitions for equality, diversity and inclusion to ensure we can always achieve our purpose.
Great Place To Work Certified
Bromford have been certified as a Great Place To Work (Nov 22 – Nov 23). The 2022 Great Place to Work Trust Index Survey highlighted that our employees believe we have an amazing company culture and that 89% of our employees where made to feel welcome when they joined us. We are also proud to have been named on ‘UK’s Best Workplaces for Wellbeing’ list, proving that colleague health and wellbeing remains a top priority and that our people are truly at the heart of everything we do.
Benefits
Flexible benefits
Learning and development
Private medical cover
Work-life balance
Pay and financial wellbeing
Health and wellbeing
Documents
Show more
Show less","Data management systems, Performance monitoring, Reporting, Data analysis, Assetbased business support, Integrated application systems, Customer focus, Effective communication, Datadriven decisionmaking, Stock condition surveys, Data collation","Company: Bromford
Job Title: Property Data Analyst
Experience: Extensive experience of performance monitoring and reporting, demonstrable knowledge of data management systems, experience of delivering an asset-based business support service, experience of working with and implementing integrated application and data systems
Skills: Technical knowledge of housing and data systems, detail-oriented, flexible working attitude, customer-focused with effective communication skills
Summary: Bromford is looking for a passionate Property Data Analyst to join their Homes, Investment, and Compliance team for",0.1757719692249536,0.8118601
Data Analyst,Aldi UK,"Atherstone, England, United Kingdom",https://uk.linkedin.com/jobs/view/data-analyst-at-aldi-uk-3504168071,2023-12-20,Coventry,United Kingdom,Associate,Hybrid,"A role in the National Supply Chain function is a great opportunity to play a key part in shaping the future department and its ways of working. You will gain valuable experience working on a global transformation project and have a significant role in being a source of analytical expertise within your function. You will form relationships with across all domains and across the Aldi global network of countries.
You will support the Supply Chain Team and will work with representatives from across all business and IT domains. As the department and the transformation project evolves, so will the role. As such you will require a proactive approach and an ability to be resilient, whilst managing multiple responsibilities. This is an excellent opportunity for someone with a passion for data, reporting and analytics, whilst working within the National Supply Chain Function, at the heart of the business.
The role would suit a data scientist with knowledge of R Studio, Python and analytics software, confidently working with Big Data and using analytical skills to make recommendations. Having the ability to effectively present this information, through visualization tools will be key. The individual will also be able to communicate effectively and share their reports and data sets both clearly and meaningfully to different stakeholders.
If you’re looking for a career with a business that means more to it’s colleagues, join #TeamAldi today!
Your New Role:
Managing a workload of data analyses sprints and report creation tasks
Collaborating with multiple departments to ensure that our Supply Chain teams have the tools they need to operate effectively
Solving complex problems with data insights
Working with IT and Supply Chain counterparts to successfully implement a key area of the global transformation project
To identify and communicate project information necessary for senior management decision making
Supports creation and maintenance of deployment project plans
About You:
Data analysis and maintenance, using a range of skills
Scripting and/or automation capabilities
Ability to create sophisticated business reports
A clear passion for and capability to solve problems
Create and deliver presentations to illustrate processes and share insights
What you'll get in Return:
Salary starting from £50,945 rising to £58,680
Monday to Friday, 8am to 4:30pm, with the opportunity of 2 days a week remote working
5 weeks’ annual leave plus Bank Holidays
In office flexi-time
Full training provided
Pension scheme
Private employee medical insurance after 4 years
Company sick pay scheme
Company maternity, paternity and adoption leave pay after 2 years
Long service rewards
Access to MyBenefits, where you can find a wide range of benefits, including our bike to work scheme, shopping and cinema discounts, health cash plan, a FREE will, travel and discounted gym memberships, as well as a host of benefits to support your financial and wellbeing needs.
Access to a free,24/7, confidential virtual GP service for all Aldi Colleagues and their children (under the age of 16)
Aldi is an equal opportunities employer. We’re committed to maintaining a diverse and inclusive workforce and are dedicated to promoting a culture of inclusion, providing an environment in which collaboration, respect and fairness are essential. We value diversity and are dedicated to treating all of our colleagues and prospective colleagues fairly and with respect.
If you’re looking for a career that gives you more, apply today!
Show more
Show less","Data analysis, Data reporting, Data visualization, Python, R Studio, Analytics software, Big data, Visualization tools, Business reporting, Problem solving, Project management, Communication, Collaboration","Company: Aldi
Job Title: Data Scientist in National Supply Chain Function
Experience: Not specified
Skills Needed: Data analysis and maintenance, scripting and/or automation capabilities, ability to create sophisticated business reports, problem-solving skills, presentation skills
Salary: £50,945 to £58,680
Work Schedule: Monday to Friday, 8am to 4:30pm with 2 days remote working
Benefits: 5 weeks annual leave, pension scheme, private medical insurance, company",0.16711590032708282,0.52891165
Data Analyst Assistant,Aldi UK,"Atherstone, England, United Kingdom",https://uk.linkedin.com/jobs/view/data-analyst-assistant-at-aldi-uk-3504163676,2023-12-20,Coventry,United Kingdom,Associate,Hybrid,"We are on the lookout for an individual with an understanding of supply chain and data analytics or a graduate with a passion for working within supply chain.
In conjunction with key stakeholders, you will be responsible for delivering a high quality and cost efficient inbound supply chain both through operational and project management. You will be working as part of a growing and developing supply chain team, looking for continuous improvement within your role to simplify processes and maximise efficiencies.
This is a fantastic opportunity for you to develop within the business and play a key part in shaping the future of Aldi globally. Ready for more? Apply to join #TeamAldi today!
Your New Role
Maintain overall control and responsibility for all demand forecasts for all Key Business Stakeholders
Analyse sales trends and product behaviours to build future forecast profiles
Supervise large data sets for accuracy and consistency, whilst drawing meaningful conclusions from data trends
Management and control of multiple supply chain projects and tasks, working with Buying, RDCs, Stores and suppliers to deliver to agreed timeframes.
Internal and external stakeholder engagement and management of all levels of business.
Management and control of supply chain forecasting processes, KPI’s, development and continual improvements, to maximise availability of product into the RDC’s from suppliers, and DCs to stores.
Continuous improvement within role, simplifying processes and operations to maximise efficiencies.
Deliver successful Christmas and key events.
Support the delivery of the department strategy as required.
About You
GCSE or equivalent
Supply Chain work experience OR a recent graduate with a degree in any of the following - Supply Chain, Forecasting, Data Analytics, Business, Logistics, Maths, Economics or any other Supply Chain or Logistics degree.
Demonstrate understanding of supply chain processes
Experience in data analytics
Strong written and verbal communication skills with the ability to build effective relationships with stakeholders
Highly proficient with Microsoft Office Suite; especially Microsoft Excel.
Ability to manage a varied workload, conflicting deadlines and multiple projects simultaneously.
A strong desire to improve and simplify processes and ensure consistency wherever possible.
Strong attention to detail
What you'll get in Return
Starting salary from £34,690 rising to £40,510
Monday- Friday, 8am to 4:30pm with the opportunity of 2 days a week remote working.
5 weeks’ annual leave plus Bank Holidays
In-Office flexi time
Full training provided
Pension Scheme
Private employee medical insurance after 4 years
Company sick pay scheme
Company maternity, paternity and adoption leave pay after 2 years.
Long service rewards.
Access to MyBenefits, where you can find a wide range of benefits, including our bike to work scheme, shopping and cinema discounts, health cash plan, a FREE will, travel and discounted gym memberships, as well as a host of benefits to support your financial and wellbeing needs.
Access to a free, 24/7, confidential virtual GP service for all Aldi Colleagues and their children (under the age of 16)
Aldi is an equal opportunities employer. We’re committed to maintaining a diverse and inclusive workforce and are dedicated to promoting a culture of inclusion, providing an environment in which collaboration, respect and fairness are essential. We value diversity and are dedicated to treating all of our colleagues and prospective colleagues fairly and with respect.
If you’re looking for a career that gives you more, apply today!
Show more
Show less","Supply Chain Management, Data Analytics, Forecasting, Microsoft Excel, Data Visualization, Business Intelligence, Stakeholder Management, Project Management, KPI Monitoring, Continuous Improvement, Communication, Collaboration, Teamwork","Company: Aldi  
Job Title: Supply Chain Analyst  
Experience: Supply Chain work experience OR a recent graduate with a degree in Supply Chain, Forecasting, Data Analytics, Business, Logistics, Maths, Economics or related field.  
Skills: Understanding of supply chain processes, experience in data analytics, strong communication skills, proficiency in Microsoft Office Suite (especially Excel), ability to manage multiple projects, attention to detail.  
Benefits: Starting salary from £34,690 rising to £40,510,",0.2097186675142104,0.58398163
Senior Data Engineer - Future Opportunities,Avanade,"Birmingham, England, United Kingdom",https://uk.linkedin.com/jobs/view/senior-data-engineer-future-opportunities-at-avanade-3784432462,2023-12-20,Coventry,United Kingdom,Mid senior,Onsite,"Job Description
RECRUITING FOR THE FUTURE
This posting is for a future job opportunity.
To support the needs of our clients, Avanade is actively recruiting and interviewing for the role outlined below, as we continue to build on another year of growth in our business. Now, with more than 60,000 employees around the globe, we are positioning our organization to effectively prepare for the future. What does this mean for you? We encourage you to apply and interview for this role without the need to decide now. This allows you to connect with leaders and hiring managers at a pace that works for you and when roles become available, you will be the first to know.
Our talented Data Engineering team is made up of globally recognised experts—and there’s room for more analytical, innovative, client-driven data professionals. If you’re passionate about helping clients make better data-driven decisions to tackle their most complex business issues, let’s talk. Take your skills to a new level and launch a career where you can truly do what matters.
Come join us
As a member of the Data Engineering team, you’ll have access to the research, knowledge and tools to create leading-edge solutions across Avanade’s Data & AI practice. The role of Senior Data Engineer is perfect for ambitious technologists passionate about working with the latest Microsoft cloud technology and Microsoft experts. Our clients look to us for innovation, which means you’ll have early access to the newest Microsoft technologies so you can master them and stay ahead of the curve.
As you bring your skills and abilities to Avanade, you’ll get distinctive experiences, limitless learning and ambitious growth in return. As we continue to build our diverse and inclusive culture, we become even more innovative and creative, helping us better serve our clients and our communities. You’ll join a community of smart, supportive collaborators to lift, mentor and guide you, but to also lean on your expertise. You get a company purpose-built for business-critical, leading-edge technology solutions, committed to improving the way humans work, interact and live. It’s all here, so take a closer look!
Together we do what matters.
What You’ll Do
Architecture, design, development, and delivery of enterprise-grade analytics solutions based on Fabric, Azure and Databricks technologies
Mentoring of more junior team members and supporting their personal development
Constantly developing technical skills in the latest Fabric, Azure and Databricks technologies - achieving & maintaining relevant certifications
Working directly with high profile clients across a variety of sectors to understand their requirements and present solutions to customer sponsors
Skills And Experiences
Demonstrable end-to-end experience in Data Engineering, including large-scale projects
Experience in working with the latest Azure technologies, such as; Databricks, Synapse, Data Factory, Azure Data Lake Storage (Gen 2), Cosmos DB, Fabric
Understanding of software engineering tools and concepts including experience in Python, Scala or PySpark
Confident communicator who is able to explain technical terms to non-technical audiences and mentor junior colleagues
Leads small development teams: track work, manage assignments, manage capacity, etc.
About You
Characteristics that can spell success for this role
Analytical, curious, agile
Team player and good communicator
Problem-solver, patient, quality-driven
Self-motivating
Innovative mindset
Enjoy your career
Some of the best things about working at Avanade
Opportunity to work for Microsoft’s 2023 Global Alliance Partner of the Year (winner 18 times), 2023 UK partner of year, Databricks Global partner of the year for the last 5 consecutive years.
Exceptional development and training (minimum 80 hours per year for training and paid certifications)
Real-time access to technical and skilled resources globally
Collaborate with some of the brightest “Microsoft minds”
Build your expertise, solve problems, learn, and develop
Find out more about some of our benefits here .
A great place to work
We work hard to provide an inclusive, diverse culture with a deep sense of belonging for all our employees. Visit our Inclusion & Diversity page.
Create a future for our people that focuses on
Expanding your thinking
Experimenting courageously
Learning and pivoting
Inspire greatness in our people by
Empowering every voice
Encouraging boldness
Celebrating progress
Accelerate the impact of our people by
Amazing the client
Prioritizing what matters
Acting as one
Learn more
To learn more about the types of projects our Analytics team works on check out these case studies:
What matters to PageGroup is using AI to grow businesses and career opportunities
What matters to SSE Renewables is innovating for a sustainable future
Interested in knowing what’s going on inside Avanade? Check out our blogs:
Avanade Insights – exchange ideas that drive tomorrow’s innovation
Inside Avanade – explore what life is like working at Avanade
About Avanade
Avanade is the leading provider of innovative digital, cloud and advisory services, industry solutions and design-led experiences across the Microsoft ecosystem. Every day, our 59,000 professionals in 26 countries make a genuine human impact for our clients, their employees and their customers.
We have been recognized as Microsoft’s Global SI Partner of the Year more than any other company. With the most Microsoft certifications (60,000+) and 18 (out of 18) Gold-level Microsoft competencies, we are uniquely positioned to help businesses grow and solve their toughest challenges.
We are a people first company, committed to providing an inclusive workplace where employees feel comfortable being their authentic selves. As a responsible business, we are building a sustainable world and helping people from underrepresented communities fulfil their potential.
Majority owned by Accenture, Avanade was founded in 2000 by Accenture LLP and Microsoft Corporation. Learn more at www.avanade.com .
Show more
Show less","Data Engineering, Azure, Databricks, Fabric, Synapse, Data Factory, Azure Data Lake Storage, Cosmos DB, Python, Scala, PySpark","Company Name: Avanade
Job Title: Senior Data Engineer
Experience: Demonstrable end-to-end experience in Data Engineering, including large-scale projects
Skills Needed: Experience in working with the latest Azure technologies such as Databricks, Synapse, Data Factory, Azure Data Lake Storage (Gen 2), Cosmos DB, Fabric; Understanding of software engineering tools and concepts including experience in Python, Scala or PySpark; Confident communicator who can explain technical terms to non-technical audiences and mentor",0.18466898767497483,0.66362786
Senior Datacentre Engineer,Energy Jobline,"Abbots Salford, England, United Kingdom",https://uk.linkedin.com/jobs/view/senior-datacentre-engineer-at-energy-jobline-3773345159,2023-12-20,Coventry,United Kingdom,Mid senior,Onsite,"Title: Senior Datacentre Engineer
Salary: £40,000 DOE
Location: Salford
We are looking for an experienced Data Centre Engineer who wants to join a medium sized company with a great community culture and lots of progression opportunities onto management roles. They have been providing their clients with fully-managed dedicated server hosting, colocation, cloud hosting and data backup services to the benefit of their business and their client relations.
With paid certification and training, a generous holiday and benefits package, and free parking next to the office our client offers a comfortable space for you to grow your team lead skills and develop your existing knowledge with new technologies and exciting projects.
You will assisting a small team of dedicated technical support engineers responsible for providing top-notch Windows/Linux and cloud infrastructure support. You will be instrumental in ensuring our clients' success by delivering timely and effective solutions to their technical challenges. If you are a dynamic and motivated engineer with a passion for Linux and cloud technologies, this is an exciting opportunity to lead a team that makes a real impact on our clients' businesses. Ideally, you will already have experience of being in a similar role at a data centre or hosting company within the UK.
The Ideal Candidate Will Have The Following Experience
Client Support: Manage provision of technical support to clients, helping to resolve complex Linux and cloud infrastructure issues promptly and effectively.
Incident Management: Manage and prioritise client incidents and service requests, ensuring timely resolution and adherence to service level agreements (SLAs).
Managing client escalations and conflicts to resolve issues, rebuild client trust and identify root cause to prevent reoccurrence.
Technical Guidance: Offer guidance and expertise to team members, assisting them in troubleshooting and resolving technical challenges.
Pre-sales: Provide technical pre-sales assistance to Sales staff by capturing customer requirements and proposing appropriate solutions.
Process Improvement: Continuously improve support processes and procedures to enhance service quality and efficiency.
Client Communication: Maintain clear and effective communication with clients, keeping them informed about incident status and resolution progress.
Monitoring progress, tracking team KPIs, managing budgets, developing and delivering new client technologies.
Manage occasionally challenging scenarios and elevate the team performance.
Documentation: Contribute to the development and maintenance of knowledge base articles and documentation to empower clients and team members.Benefits:
Casual dress
Company events
On-site parking
Bonuses for achieving key metrics
Reward programme
Shift allowance
8 hour shift
Monday to Friday
Contributory pension scheme
Over-time allowance
Bonuses for achieving key metrics
Holidays: 26 days, plus all bank holidays. As well as one day extra for every year of serviceIf you believe you are suitable for this role and like the sound of the opportunity, please reply with a copy of your up to date CV. If you know of anyone who you believe would be suitable for this position then please get in contact with us with their details.
In Technology Group Ltd is acting as an Employment Agency in relation to this vacancy
Show more
Show less","Windows, Linux, Cloud Infrastructure, Client Support, Incident Management, Technical Guidance, PreSales, Process Improvement, Client Communication, KPI Tracking, Budget Management, Knowledge Base Development, Documentation, Casual Dress, Company Events, OnSite Parking, Bonuses, Reward Program, Shift Allowance, 8Hour Shift, Contributory Pension Scheme, Overtime Allowance","Company Name: In Technology Group Ltd
Job Title: Senior Datacentre Engineer
Experience: Ideal candidate will have experience in a similar role at a data centre or hosting company within the UK
Skills Needed: Client support, incident management, technical guidance, pre-sales, process improvement, client communication, monitoring progress, documentation
Salary: £40,000 DOE
Location: Salford
Description: The company is seeking an experienced Data Centre Engineer to join their team, offering opportunities for career progression and",0.26525198639939773,0.8132026
Software Engineer / Data Analyst,Capgemini Engineering,"Ashby-de-la-Zouch, England, United Kingdom",https://uk.linkedin.com/jobs/view/software-engineer-data-analyst-at-capgemini-engineering-3782214223,2023-12-20,Derby,United Kingdom,Associate,Onsite,"NOTE
You must be eligible for Security Clearance
Overview
Capgemini Engineering's client develops and delivers complex power and propulsion solutions for in the air, at sea and on land. They have designed the world’s most efficient large aero-engine, powered nuclear submarines and enabled land-speed records. They have created game-changing engineering solutions for supersonic jets and even supported NASA missions on the edge of space. Capgemini Engineering's client goal is to make power safer, cleaner and more sustainable. They have a market-leading position in submarine propulsion systems which encompasses everything from design and procurement to manufacture and in-service support. For the last 60 years Capgemini Engineering's client have designed, supplied and supported the nuclear propulsion plant that provides power for all of the UK Royal Navy's nuclear powered submarines.
The Role
The Hybrid Intelligence Team have worked with this client for several years:
Our work enables our client to derive new insights about their operations by opening up previously unused datasets.
We add extra value by applying rigorous data engineering principles to critically assess data quality enabling conversations to improve data collection mechanisms in future.
We have leveraged our scientific backgrounds to work effectively with RR engineering experts and produce analytics which are of real value and trusted by the consumers.
We bring best practice software engineering and reproducible data science methodology to ensure data science is done with the traceability required in this highly regulated environment.
Requirements
We are frequently looking for staff interested in joining the team. This requires:
Full-time on-site working at Derby on a secure site. Access to HI systems is therefore limited and so the team maintain connection to the business by booking in days to work at the Ashby office, attending branch meetings, etc. Benefits and relocation support will be discussed with interested candidates.
UK Security Clearance. You do not need to be cleared currently; we will initiate the process for getting clearance as necessary.
Good communication and technical leadership skills.
Being able to mentor other team members, particularly in best practices for software development. Working in Scrum teams, there are lots of opportunity to influence the development methodology.
An ability to lead technical decision making.
Designing and documenting system-level, distributed architectures (microservices, workflow orchestration, relatively straightforward but with an unusual set of constraints).
Proactively maintaining communications with the Enterprise Architect and Client IT team to ensure the team get IT support, tools and infrastructure as and when required.
Supporting the client product owner/team lead engaging with stakeholders for prospective new projects.
Knowledge of one of more of the following technologies: Python (sqlalchemy, pandas, fastapi); Javascript/Typescript (React, Vue); SQL (MSSQL).
Show more
Show less","Python, SQL, MSSQL, Javascript, Typescript, React, Vue, SQLAlchemy, Pandas, FastAPI, Software development, Technical leadership, Communication, Mentoring, Scrum, Microservices, Workflow orchestration, Distributed architectures, Enterprise architecture, IT support, Stakeholder engagement","Company: Capgemini Engineering

Job Title: Hybrid Intelligence Team Member

Experience: Several years of experience working with rigorous data engineering principles and data science methodology in a highly regulated environment.

Skills Needed: 
1. UK Security Clearance
2. Good communication and technical leadership skills
3. Ability to mentor team members in best practices for software development
4. Experience in designing system-level, distributed architectures
5. Proactive communication with Enterprise Architect and Client IT team
6. Knowledge of technologies such",0.25507246063835326,0.5958264
Senior Data Engineer,Attractions.io,"Uttoxeter, England, United Kingdom",https://uk.linkedin.com/jobs/view/senior-data-engineer-at-attractions-io-3746567683,2023-12-20,Derby,United Kingdom,Mid senior,Remote,"As a Senior Data Engineer, you will be responsible for designing, maintaining, and optimising our data systems to drive business value and play a key role in helping build the connected guest experience of the future at theme parks, zoos, resorts and other out-of-home venues.
Your expertise in data engineering will be critical to our growth and success, so we are excited to have you onboard as we expand and innovate in our industry. Your skills will help us build modern data architectures that will enable us to provide robust products that cater to our evolving client base.
Responsibilities
Create solutions to provide data in various forms to our wider platform, whether via databases, APIs, or streaming
Design and architect data solutions, ensuring we use the best approach to benefit from the data we hold
Supporting and facilitating data modelling and exploration
Collaborate with data scientists and software developers to ensure seamless integration of ML processes
Ensure data quality, security, and privacy are preserved in all data processing and storage processes
Be proactive in identifying and solving data processing issues
Continuously optimise our systems to enhance data processing and storage speed and accuracy
Requirements
5+ years experience in data engineering and related roles
Experience in building and maintaining data platforms with cloud-based architectures
Experience in AWS technologies such as Aurora, S3, Athena, Redshift, Kinesis
Experience in Data Warehouse and Data Lake design and implementation
Strong programming skills in Python and SQL
Strong analytical and problem-solving skills, with the ability to work with large and complex datasets
Familiarity with agile working practices
Understanding of software versioning and CI/CD pipelines
Excellent communication and collaboration skills
Knowledge of MLOps desirable
Benefits
Competitive salary and share option scheme
100% remote working with a remote work allowance
Flexible working hours
33 days paid holiday
High-end equipment
Quarterly company off-sites at fantastic attractions (our customers)
Show more
Show less","Data Engineering, Data Platforms, AWS, Aurora, S3, Athena, Redshift, Kinesis, Data Warehouse Design, Data Lake Design, Python, SQL, Agile, CI/CD Pipelines, MLOps","Company: Unspecified

Job Title: Senior Data Engineer

Experience: 5+ years

Skills Needed:
- Experience in data engineering and related roles
- Building and maintaining data platforms with cloud-based architectures
- Familiarity with AWS technologies like Aurora, S3, Athena, Redshift, Kinesis
- Data Warehouse and Data Lake design and implementation experience
- Proficiency in Python and SQL programming
- Strong analytical and problem-solving skills for large datasets
- Knowledge of agile working practices",0.34241244795348913,0.77014315
Senior Data Scientist,Blue Light Card,"Cossington, England, United Kingdom",https://uk.linkedin.com/jobs/view/senior-data-scientist-at-blue-light-card-3782184667,2023-12-20,Derby,United Kingdom,Mid senior,Hybrid,"Blue Light Card. Individually great, together unstoppable
The Role and the Team
There’s never been a better time to join the team at Blue Light Card. We continue to grow rapidly in the UK and as a result, we have an exciting opportunity for Senior Data Scientist to join our Data & Insights team, in a newly created role where you can really make your mark setting up foundations.
We do the right thing, challenge the status quo, deliver on our promises, bring out the best in each other and treat others how we wish to be treated. If this resonates with you then we encourage you to apply to join our team at Blue Light Card and contribute to our mission.
What You’ll Do
Set foundations for our data science capabilities
Work collaboratively with Product, Engineering and Data Analytics to build, test, deploy and optimise new models, to help us improve our personalisation capabilities across our product and marketing channels
Understand our business obstacles and translate into machine learning solutions that deliver impact to our members and partners
Stay on top of trends, emerging technologies and players in the AI market and promote internally
Partner with internal stakeholders and third parties as needed
What You’ll Bring
A degree in a quantitative subject e.g. Mathematics, Statistics, Computer Science or considerable experience in the data science field
Proven hands on experience as a Data Scientist in a technical organisation, developing and productionising machine learning solutions
Experience of setting up foundations and infrastructure or scaling a function
Excellent programming skills e.g. Python, Pyspark, R
Great communication skills and the ability to work effectively with technical and non-technical stakeholders across different levels
Previous experience with ranking and recommendations models would be desirable
Our Culture
Our members, partners and colleagues are at the heart of everything we do.
Our colleagues are integral to helping create the unique experience we deliver, so we’re genuinely committed to creating a place where our team love to work, and people want to join. We work as a team and try to have a bit of fun while we do it, and we recognise the importance of culture and the positive impact it can have on performance for you, the team, our organisation and our members. We believe in attracting the best talent no matter where you are, and have a hybrid working model, with colleagues based in London, the East Midlands and around the country.
We're also officially recognised as a Top 100 Great Place To Work UK, one of the UK's Best Workplaces for Wellbeing, Top 100 Best Workplaces for Women and recognised as investors in wellbeing by Investors in People.
What We Offer
Hybrid working and flexible hours
Free onsite parking
25 days plus public holidays, buy and sell and an additional day off for your birthday
A company bonus scheme
Great social events e.g., Christmas party, family fun day, summer party, sports matches
Relaxed dress code and modern office space (games area, chill-out areas, book club, free coffee/tea/soft drinks/snacks)
Onsite gym (including access to free HIIT & stretch classes)
Learning and development opportunities
Group auto-enrolment pension plan
Enhanced maternity, paternity, sick pay
Company funded private medical insurance
Healthcare cashback plan
Employee assistance programme (including mental health support)
Show more
Show less","Data Science, Machine Learning, Python, Pyspark, R, Data Analytics, SQL, Statistics, Mathematics, Computer Science, Engineering, Product Management, Communication Skills, Ranking and Recommendations Models, Software Development, Agile, NoSQL, Git, Cloud Computing, Big Data, AI, Algorithms","Company Name: Blue Light Card
Job Title: Senior Data Scientist
Years of Experience: Considerable experience in the data science field
Skills Needed: Degree in a quantitative subject, hands-on experience in developing and productionising machine learning solutions, programming skills in Python, Pyspark, R, excellent communication skills, experience with ranking and recommendations models preferred.

The job at Blue Light Card for a Senior Data Scientist involves setting up foundations for data science capabilities, collaborating with various teams to build and optimize new",0.19095477123911012,0.75252616
Senior Data Engineer,Boots UK,"Nottingham, England, United Kingdom",https://uk.linkedin.com/jobs/view/senior-data-engineer-at-boots-uk-3747628070,2023-12-20,Derby,United Kingdom,Mid senior,Hybrid,"This is an exciting opportunity for experienced Data Engineer to join our team as Senior Data Engineer. Based out of Nottingham in our International Data Office, you will be responsible for the analytics engineering of data products within a specified data domain.
Who we are
International Technology & Advanced Analytics (IT2A) is a multi-national function of Walgreens Boots Alliance based in the UK, Europe, Asia, South America and the USA. We leverage emerging technology and robust data to transform our pharmacy and retail offerings, improve experiences for customers and patients and enhance operational effectiveness for team members. Partnering with some of the finest tech providers and utilising a cutting-edge tech stack, we support two of the UK’s most trusted and established brands - Boots and No7 – in personalising their customer interactions. We’re an innovative team of specialists spanning security, hosting, architecture, software engineering, networks, project delivery and more. A proud equal opportunity employer, we passionately embrace team member diversity and provide a positive and inclusive working environment for all.
About the role
Within our recently formed Data Office, the Data Platform team builds and maintains our self-serve data platform for our international divisions. Seeking to better align ourselves with our organisation needs, we take a business domain-oriented approach to organising our data engineering and data products. Data domains are very broad across our business across Retail, Pharmacy, Healthcare, Marketing, Product, Merchandising, Opticians etc
As a Senior Data Engineer you will lead a domain-focused, multi-disciplinary squad focused on building products that drive value from our data. Working with our business you’ll design and implement products that allow us to maximise the value of our data to our customers and patients.
Using your data engineering expertise, you’ll coach and support your team building them into a highly performing squad.
Hybrid Working – 3 days office & 2 days home
We offer our Support Office team members a flexible, hybrid working approach based upon empowerment, accountability, care and trust which includes a balanced mix of remote and office-based working - this will be discussed with you as part of the application process
.
What you’ll need to have
Hands-on’ experience of data engineering within analytics and/or data science environment.
Expert knowledge of one or more data languages including SQL, Python and Spark.
Experience of coaching and developing your peer’s knowledge and understanding of modern data engineering principles and practices.
Experience of data warehousing techniques such as Kimball dimensional modelling.
It would be great if you also have
Experience of developing large scale data engineering solutions in Microsoft Azure cloud technologies (preferably Databricks too)
Experience of developing data warehouses, Business Intelligence/Management Information, ML and AI solutions
Experience of line management of engineers
Knowledge of agile processes such as Scrum
Knowledge of Supply Chain or Pharmacy data domains
Our benefits
Boots Retirement Savings Plan
Generous employee discount plus enhanced discounts for Boots brands, Boots Opticians and Boots Hearingcare
Excellent onsite facilities including staff shop, opticians (including free eye tests for team members), gym, cafeteria, and outdoor seating spaces.
What’s next?
If your application is successful, our recruitment team will be in touch to arrange an interview and to answer any initial questions you have. If you have not been successful on this occasion, you will be notified by email.
We are always open to discussing possible flexible working options and what this may look like for you, including job share and reduced hours. If you require additional support as part of the application and interview process, we are happy to provide reasonable adjustments to enable you to be at your best.
Show more
Show less","SQL, Python, Spark, Kimball dimensional modelling, Data engineering, Coaching, Mentoring, Azure, Databricks, Data warehousing, Business Intelligence, Management Information, ML, AI, Line management, Agile, Scrum","Company Name: Walgreens Boots Alliance  
Job Title: Senior Data Engineer  
Years of Experience: Experienced  
Skills Needed: Hands-on experience in data engineering within analytics and/or data science environment, expert knowledge of SQL, Python, and Spark, experience in coaching and developing peers, familiarity with data warehousing techniques, experience in Microsoft Azure cloud technologies and Databricks, familiarity with agile processes, knowledge of Supply Chain or Pharmacy data domains.",0.16080401786608925,0.54422104
"Senior Data Scientist, Clinical Analytics (On-Site, Illinois Based)",AbbVie,"Lake County, IL",https://www.linkedin.com/jobs/view/senior-data-scientist-clinical-analytics-on-site-illinois-based-at-abbvie-3756652055,2023-12-20,Barrington,United States,Mid senior,Onsite,"Purpose:
A team of data scientists with a unique blend of Business, Scientific, and Machine Learning expertise who seek to:
Unleash the full potential of AbbVie’s data assets by bringing technology and/or data and insights to the forefront of decision making via fit-for-purpose data analytics solutions
Broaden the scope and impact of Analytics and Data Science by constantly exploring new opportunities to transform clinical development and R&D
Collaborate with stakeholders to outline the problem, explore solutions, refine opportunities and deliver a product with a continuous innovation mindset
Responsibilities:
Connects with cross-functional teams to design work product and as an analytics consultant. Anticipates and identifies issues that could affect timelines or quality and develops options and solutions
Leads and helps establish the design principles and standards to ensure analytical work product is consistent across projects where appropriate and that user experience is optimized
In addition to standard statistical methods, develops prototypes, test methods and algorithms. Leverages emerging statistical methodologies, ML and AI to drive innovative analytical solutions to create insights
Enables data-driven insights to support of clinical development continuum, including precision medicine
Ensures adherence to federal regulations and applicable local regulations, Good Clinical Practices (GCPs), ICH Guidelines, AbbVie Standard Operating Procedures (SOPs), and to functional quality standards. Stays abreast of new and/or evolving local regulations, guidelines and policies related to clinical development
Identify business needs and support the creation of standard KPIs, reports, and statistical analyses;
Responsible for coaching and mentoring junior team members.
Work side by side with cross-functional teams as an analytics consultant to strategize on how analytics can help evaluate the progress of clinical trials, as well as facilitate discussions around emerging risks; Applies machine learning techniques to validate assumptions and predict future behavior
Qualifications:
Bachelor’s degree statistics, analytics, bioinformatics, data science or equivalent field. Master’s degree preferred
Must have 3-5 years of analytics-related experience in clinical research including demonstrated high-level analytics and leadership competencies.
Advanced career level proficiency in R, Python or other statistical packages. Intermediate-level knowledge of statistical and data mining techniques
Expert proficiency with visualization tools like Spotfire, Tableau or equivalent
Proven expertise with Machine Learning and other advanced analytics techniques
Demonstrated effective communication skills. Demonstrated ability to communicate analytical and technical concepts in layman’s terms
Demonstrated problem-solving and analytical skills
Demonstrated history of successful execution in a fast-paced environment and in managing multiple priorities effectively
Experience working in Cloud Computing environments (e.g., AWS, Azure, etc) is preferred
AbbVie is committed to operating with integrity, driving innovation, transforming lives, serving our community, and embracing diversity and inclusion. It is AbbVie’s policy to employ qualified persons of the greatest ability without discrimination against any employee or applicant for employment because of race, color, religion, national origin, age, sex (including pregnancy), physical or mental disability, medical condition, genetic information, gender identity or expression, sexual orientation, marital status, status as a protected veteran, or any other legally protected group status.
Show more
Show less","Data Science, Machine Learning, Python, R, Statistical Analysis, Data Mining, Spotfire, Tableau, AWS, Azure","Company: AbbVie
Job Title: Data Scientist
Experience: 3-5 years of analytics-related experience in clinical research
Skills Needed: Bachelor’s degree in statistics, analytics, bioinformatics, data science or equivalent field (Master’s degree preferred), proficiency in R, Python or other statistical packages, intermediate-level knowledge of statistical and data mining techniques, expertise in visualization tools like Spotfire, Tableau or equivalent, proficiency in Machine Learning and other advanced analytics techniques, experience working in Cloud Computing",0.2216216191287071,0.53700423
Marketing Data Analyst,FLEETCOR,"Swindon, England, United Kingdom",https://uk.linkedin.com/jobs/view/marketing-data-analyst-at-fleetcor-3784532867,2023-12-20,Oxford,United Kingdom,Associate,Hybrid,"About the role:
We have an exciting new opportunity for a Marketing Data Analyst to join our team. Due to expansion and new projects the role will see you being a key part of our CRM data Team. The CRM Data Team supports several business functions through multiple stages of the customer lifecycle. Through data generated this will help the growth ambitions of our organisation and continue our path of becoming more data-driven and expand our data capabilities.
The digital and marketing teams produce and consume a lot of data in our CRM and it is the role of the marketing data analyst to support this activity in line with our data governance procedures. From analysing the quality of the data acquired though digital platforms, segmenting and selecting data for marketing campaigns as well as reviewing marketing activity performance within our CRM and other data sources. If you are passionate about data, love the challenge of taking something complex and making it useable, want to be a part of an organisation undergoing a data transformation and have the opportunity to explore different data career paths, this could be the job for you.
Key Accountabilities:
Analysing marketing campaign performance and helping improve conversion rates
Analysing the quality of data created through marketing activities, understand the impact it has on performance and determine the root cause
Segmenting our CRM data to improve customer experience
Creating and maintaining reports for marketing and sales teams
Documenting processes for the CRM team to ensure repeatability
Producing training materials for CRM users to support its continued use and growth
Pro-active investigation and analysis into data issues and making recommendations for their remediation
Pro-active analysis to identify areas for consideration for business growth
Skills and experience we’d like you to have:
Data enthusiast
Salesforce (or other CRM)
Strong Excel skills
SQL Curiosity and able to think outside the box
Enthusiasm to learn and develop a career in data
Demand Tools
Tableau
Knowledge of Marketo
Experience in data quality analysis and audits
Experience with data governance
Experience working in B2B marketing and sales environments
Experience working for a commercial payments organisation
Degree/equivalent education
The rewards we give you:
Excellent progression
4 X Life insurance
Pension scheme 5% employer contribution
Private Healthcare
25 days Holiday (plus Holiday Buy/Sell)
Access to benefits portal/discounted goods and services
Employee Fuel Card
Access to LinkedIn learning
About us:
FLEETCOR is a global technology organisation that is leading the future of commercial payments with a culture of innovation that drives us to constantly create new and better ways to pay. Our specialized payment solutions help businesses control, simplify, and secure payment for fuel, general payables, toll and lodging expenses. Millions of people in over 80 countries around the world use our solutions for their payments.
Fleetcor is committed to equality of opportunity and welcome applications from people, regardless of age, gender, ethnicity, disability, sexuality, social background, religion and/or belief. And we promote flexible working opportunities where operational needs allow.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to
receive other benefits and privileges of employment. Please contact us to request accommodation.
Show more
Show less","Data Analytics, Salesforce, Excel, SQL, Tableau, Marketo, Data Quality Analysis, Data Governance, B2B Marketing, B2B Sales, Datadriven, Demand Tools","Company: FLEETCOR

Job Title: Marketing Data Analyst

Experience: Experience working in B2B marketing and sales environments with knowledge of Marketo and data governance, as well as strong Excel skills, SQL Curiosity, and Salesforce or other CRM experience.

Skills: The ideal candidate should be a data enthusiast with experience in data quality analysis, audits, and demand tools. Proficiency in Tableau, along with the ability to segment CRM data, analyze marketing campaign performance, and create reports for",0.20163487461247764,0.6186441
Senior Data Scientist,Harnham,"Oxford, England, United Kingdom",https://uk.linkedin.com/jobs/view/senior-data-scientist-at-harnham-3781946029,2023-12-20,Oxford,United Kingdom,Mid senior,Onsite,"To Apply for this Job Click Here
SENIOR DATA SCIENTIST
REMOTE
£70,000 - £90,000
Company
We are collaborating with a dynamic healthcare startup committed to revolutionizing the industry through data-driven insights. Leveraging clinical trial and survey data, they aim to drive innovation, enhance patient outcomes, and optimize healthcare solutions. We are currently seeking an experienced Senior Data Scientist to join their team and contribute to shaping the future of healthcare analytics.
Role
Lead the development and implementation of advanced data science models and algorithms, leveraging clinical trial and survey data.
Design and execute complex data analyses to extract meaningful patterns, trends, and insights.
Collaborate with cross-functional teams to integrate data-driven solutions into existing products and services.
Stay at the forefront of emerging technologies and industry trends to continually enhance data science capabilities.
Mentor and provide technical leadership to junior members of the data science team.
Collaborate with other departments to ensure alignment of data science initiatives with overall business objectives.
Requirements
Ph.D. or Master's degree in Data Science, Computer Science, Statistics, or a related field.
Proven experience in technical data science roles, with a specific focus on healthcare and pharma.
Expertise in developing and implementing machine learning models, statistical analyses, and data mining techniques.
Proficiency in programming languages such as Python or R, along with experience with relevant data science tools and frameworks.
Strong understanding of clinical trial and survey data, and its application in healthcare analytics.
Excellent communication skills, with the ability to effectively convey technical concepts to both technical and non-technical stakeholders.
To Apply for this Job Click Here
Show more
Show less","Data Science, Machine Learning, Statistical Analysis, Data Mining, Python, R, Data science frameworks and tools, Clinical Trial Data, Survey Data, Healthcare Analytics","Company: Healthcare startup
Job Title: Senior Data Scientist
Experience: Proven experience in technical data science roles, with a specific focus on healthcare and pharma
Skills Needed: Ph.D. or Master's degree in Data Science, Computer Science, Statistics, or related field; expertise in developing and implementing machine learning models, statistical analyses, and data mining techniques; proficiency in Python or R programming languages; strong understanding of clinical trial and survey data; excellent communication skills.",0.3964757669948962,0.7708194
DataOps Engineer (ELK),Rebellion,"Oxford, England, United Kingdom",https://uk.linkedin.com/jobs/view/dataops-engineer-elk-at-rebellion-3702467759,2023-12-20,Oxford,United Kingdom,Mid senior,Onsite,"We want you to
#JOINTHEREBELLION!
For 30 years we've been creating incredible video games at our multiple studios, but Rebellion is more than just games. We have our own film and mo-cap studio, we create board games, publish books, and through 2000AD, publish comics and graphic novels such as the amazing Judge Dredd.
We operate across multiple UK locations, with studios based in Oxford, Warwick, Liverpool, and Wakefield. Work-life balance is important to us, and we want everyone at Rebellion to work in the way that works best for them. So, if you are based in the UK, we are always open to discussing how we can support
flexible/hybrid
working options.
We are looking for someone like you to become our all-new DataOps Engineer (ELK) and join our passionate and talented Code team, where we are building on t
he years of success that Rebellion has enjoyed.
As our games grow and we gather increasing amounts of analytics data via our Recon Analytics pipeline, we require a dedicated resource to service the maintenance and development of our data cluster, and to service the increasing number of requests arising and the level of usage that Recon receives.
Key Outcomes:
Improving reliability, performance and response times of existing ELK stack
Increasing capacity and enabling more teams to access and utilise our analytics platform
Maintaining high availability and zero-data loss of pipeline
Responsibilities:
Create, maintain and iterate on our existing ELK infrastructure
Investigate and propose solutions for performance and reliability challenges
Work with developers and stakeholders to establish and provide SLOs
Setting up and assisting internal users with access, usage and configuring of Kibana
Troubleshooting errors and performance issues
Assisting other developers with ELK related matters
We are actively recruiting for a diverse team and continue to develop a culture of growth and inclusion. Rebellion encourages innovation in all areas and we look forward to hearing how you can help us to be better. We would like to invite all demographics of culture, gender, ethnicity, neuro-diversity and beyond because we believe a representative team makes better games and provides a better working life.
Requirements
Professional real world and hands-on experience in the design, maintenance and management of ELK stacks (Elasticsearch, Logstash, and Kibana)
Understanding and knowledge of open-source data pipeline frameworks and automation tools
Solid understanding of ELK stack internals and optimisations for different use cases, good practices and design patterns
Ability to learn on the fly, diagnose problems and actively communicate
A team player, self-motivated and initiative taking
Ability to manage your own time and tasks well
Any experience developing Kibana extensions is desirable
Elastic certified training and/or qualifications is an advantage
Experience working with large scale analytics collection is a bonus
Benefits
We offer an extensive benefits package to our team including:
26 days holiday + Bank holidays (increasing with service at 5 years - one day each year until you reach 31 days)
Private Medical Insurance, healthcare cash plan, including dental and Vision
Life Assurance, Income Protection & Critical Illness Cover
Enhanced Family Leave
Interest Free, Tax-Free loans
Enhanced Pension Scheme
EAP a range of Mental Health and Wellbeing Support
Plus loads more... including a wide range of discounts, freebies, and social events!
About Us
Whichever team you join at Rebellion we are proud of our open, friendly, and creative atmosphere. We love what we do, and we have fun doing it! As a big indie developer, we have complete creative freedom over our titles which allows us to work on a massive variety of projects across all the major platforms.
Find out more about us
here
Our size, stability, and the variety of in-house expertise across multiple industries, makes Rebellion completely unique! We work in our own way, and we celebrate that as the key to our success. We foster an inclusive culture where you are encouraged to be yourself, to express your creativity and your talent. We are people focused and will support you in every way to can be the best at what you do. We recognise the importance of enjoying what you do and having a healthy work-life balance. We offer a friendly, creative, and relaxed working atmosphere, with sensibly managed projects and a wide variety of benefits and development opportunities for all our teams to ensure you are fully supported with your physical and Mental Well-being.
We are actively recruiting for a diverse team and continue to add to our culture of growth and inclusion. Rebellion encourages innovation in all areas, and we look forward to hearing how you can help us to be better. We encourage all demographics of culture, gender, ethnicity, neurodiversity and beyond, because a representative team makes better products.
If you are interested in working at Rebellion, but this role doesn't sound quite like you, we're recruiting for a range of positions across the studio and we're always happy to receive speculative applications via our website. Visit our Careers website to view all our live vacancies: Rebellion: Careers
Show more
Show less","ELK stack, Elasticsearch, Logstash, Kibana, DataOps, Opensource data pipeline frameworks, Automation tools, Data visualization, Analytics, Troubleshooting, SLOs, Kubernetes, Kibana extensions","Company Name: Rebellion
Job Title: DataOps Engineer (ELK)
Years of Experience: Professional real-world experience in the design, maintenance, and management of ELK stacks required

Skills Needed:
- Hands-on experience with Elasticsearch, Logstash, and Kibana
- Knowledge of open-source data pipeline frameworks and automation tools
- Understanding of ELK stack internals and optimization for different use cases
- Ability to troubleshoot, propose solutions, and communicate effectively
- Team player with self-m",0.1357285409285222,0.5830765
Data Engineer Senior Consultant,Viable Data,"Oxford, England, United Kingdom",https://uk.linkedin.com/jobs/view/data-engineer-senior-consultant-at-viable-data-3772735215,2023-12-20,Oxford,United Kingdom,Mid senior,Remote,"Viable Data is an innovative technology, data and UX consultancy, delivering excellence through our projects and providing our people with a supportive culture and opportunities for growth and continuous learning.
We thrive on the challenge of working across different projects, user needs and technologies and our teams and people live this every day. Our people-first approach and culture is central to our growing success as a consultancy.
We are an all-inclusive equal opportunities employer and proudly celebrate diversity. If you thrive on challenge, have a passion to learn and make a difference, and enjoy being part of a growing multidisciplinary team, look no further and start your Viable career, now.
About The Role
As a Senior Data Engineer at Viable Data, you will ensure that data is in the right state and format, ready to implement data schemas and models. You will make sure that the data is ready and available for data mining purposes.
You will be someone who can adapt quickly and easily to the flexible needs of our Central Government customers. You will work across our high-performing consulting teams where you will play a pivotal role in designing & delivering exceptional digital products and services that directly contribute to the delivery of UK policy, economic growth and security.
This role is largely remote with occasional business essential travel.
Due to the nature of work, you must be willing to undergo and be capable of achieving SC security clearance
Requirements
Key responsibilities:
Develop analysis and design solutions using SQL and NoSQL technologies, data streaming, logging and monitoring tools, BI and Data Warehousing solutions and ETL and migration technologies.
Lead conversations with stakeholders to understand client data and processes to identify solutions.
Create advanced analytics and statistics techniques to business problems.
Effectively communicate insights from a dataset using narratives and visualizations.
Skills and experience needed:
Proven experience of working with large volumes of data, applying tools such as SAS, R, Python, SQL, PowerBI, Tableau, Looker
Ability to work across different data, cloud and messaging technology stacks.
Excellent written and verbal communication abilities - presenting findings and related design/business recommendations and insights clearly that stakeholders can understand and use.
Experience of pragmatic, hands-on analysis of enterprise-scale data projects across the full SDLC from design to migration, integration and live service in an Agile environment
A thorough understanding of Master Data Management, Data Lineage analysis, Metadata Management, Data Quality assessment and management, Data Transformation and migration
Able to communicate with stakeholders at all levels.
Proven analysis skills - experience of various data analysis methods at enterprise scale
People skills – empathetic, great listener and have a natural curiosity to understand people, their motivations and thought processes.
Experience and understanding of a range of User Centred Design practices.
Excellent organisation, time management and collaboration skills.
Benefits
As well as providing a great place to work that has an amazing culture and the opportunity to work on excellent projects where you will really make a difference, we have a whole host of additional employee benefits.
Our benefits package includes:
Employee Assistance Programme (EAP)
Flexible hours and supportive of remote working
A Green Energy incentive
Buy or sell annual leave
Volunteering day
A discount portal through Perkbox
Compensation package:
£55 - 65k + Company pension contributions
Annual bonus based on company performance
25 days leave + Bank holidays
5 days dedicated training allowance, with individual budget
Personal Development programme, with 6-month review cycles
Choice of company laptop (MacBook or Windows)
Show more
Show less","SQL, NoSQL, Data streaming, Logging, Monitoring tools, SAS, R, Python, PowerBI, Tableau, Looker, Master Data Management, Data Lineage analysis, Metadata Management, Data Quality assessment, Data Transformation, Agile, User Centred Design, Employee Assistance Programme (EAP)","Company Name: Viable Data
Job Title: Senior Data Engineer
Experience: Not specified
Skills Needed: Proven experience with SAS, R, Python, SQL, PowerBI, Tableau, Looker; Ability to work across different data, cloud and messaging technology stacks; Excellent communication skills; Experience in enterprise-scale data projects in Agile environment; Understanding of Master Data Management, Data Lineage analysis, Metadata Management, Data Quality assessment, Data Transformation and migration; People skills; Experience in User Cent",0.21234567655832953,0.726727
Data Center Engineer - Detroit,DeRisk Technologies,"Detroit, MI",https://www.linkedin.com/jobs/view/data-center-engineer-detroit-at-derisk-technologies-3766683122,2023-12-20,Oak Park,United States,Associate,Onsite,"Job Responsibilities:
Deployment / In-Scope Configuration Items
Servers (Virtual & Physical)
Storage & Backup Devices
Server Appliances
Hyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)
Tape Storage Units
Power Distribution Units rated 3KVA and below
SAN Fabric Switches
Network Switches
KVM Units
WAN Optimization Devices
Firewalls
Access Points
Routers
Physical Cabling
Cable Management
Cables which connect the device to itself, a peripheral, or a power/network port Break-fix / Technical Tasks List
Power Cycling
Running Diagnostics Commands
Conducting whole unit replacement
Inserting/Removing Media
Replacing Defective Components
Assist with fault diagnosis and investigation
Configuring Remote Access
Basic Storage Array Configuration
Replacing faulty cables
Tape Management and Maintenance
Rebooting routers, servers, storage devices or other equipment
Operations Tasks List
Updating and Recording of activities in relevant IT Ticket Management System
Coordinating and agreeing attendance time and date with key stakeholders
Provide support either through phone, remote tools, or in person at onsite
Perform installation as needed either through physical or network medium
Coordinate actual activity date and timings including arrival and departure times
Carry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment
Labelling, Patching and Asset Tagging activities
Following specific task instructions and provision necessary reporting as necessary
Requirements
Job Requirements:
Technical Skills
Good general understanding of IT principles such as Networks, Hardware and Domains
Knowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support
Knowledge of server/client operations in a domain environment including Active Directory
Understanding of current and legacy hardware Infrastructure platforms
Hands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment/cable
Good Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment
Ability to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations
Knowledge of TCP/I P standards and networking
Experience with Tape Management activities
Excellent knowledge of best practices around management, control, and monitoring of server infrastructure
Familiarity with backup and recovery software and methodologies
Language skills needed
English Soft Skills
Exceptional customer facing skills
Able to communicate clearly and effectively both with Client and the Customer
Logical and analytical approach to work
Accurate record keeping
Able to work unsupervised
Good timekeeper
Intense focus on quality work
Productive and Efficient Academic Background
Bachelor of Engineering / Technology / Science or Equivalent Work Experience Overall Experience (in yrs.)
5 - 7 years (min
Benefits
Salary and Benefits as per market standard
Show more
Show less","Server Management, Storage and Backup, Hyperconverged Infrastructure (HCI), Tape Storage, Power Distribution Units, SAN Fabric Switches, Network Switches, KVM Units, WAN Optimization Devices, Firewalls, Access Points, Routers, Physical Cabling, Cable Management, Power Cycling, Diagnostics Commands, Whole Unit Replacement, Media Management, Defective Components Replacement, Fault Diagnosis and Investigation, Remote Access Configuration, Basic Storage Array Configuration, Faulty Cable Replacement, Tape Management and Maintenance, Router Server and Storage Device Reboots, IT Ticket Management System, Stakeholder Coordination, Phone Remote and Onsite Support, Installation (Physical and Network), Coordination of Activity Timings, Tool and Laptop Carriage, Labeling Patching and Asset Tagging, Task Instruction Following, Reporting, Network Principles, Hardware Principles, Domain Principles, Infrastructure Architecture, Server/Client Operations, Active Directory, Hardware Infrastructure Platforms, Equipment Installation and Troubleshooting, Rack and Stack, IMAC and BreakFix Activities, Defective Spare Identification and Replacement, TCP/IP Standards, Networking, Tape Management, Server Infrastructure Management, Backup and Recovery Software, Backup and Recovery Methodologies, English Language, Customer Facing Skills, Clear Communication, Logical and Analytical Approach, Accurate Record Keeping, Unsupervised Work, Timekeeping, Quality Focus, Productivity, Efficiency, Engineering Degree, Technology Degree, Science Degree, Equivalent Work Experience, 57 Years Experience","Company Name: Not specified
Job Title: Infrastructure Support Engineer
Experience: 5-7 years
Skills Needed: The ideal candidate should have a good understanding of IT principles, knowledge of infrastructure hardware architecture, hands-on experience in installation and troubleshooting of infrastructure equipment, familiarity with TCP/IP standards, experience with tape management activities, knowledge of server infrastructure best practices, backup and recovery software, and excellent communication skills. Additionally, the candidate should possess exceptional customer-facing skills, logical and analytical approach to work,",0.1551724108278835,0.4357844
Data Center Engineer | Infrastructure Operations,Henry Ford Health,"Rochester Hills, MI",https://www.linkedin.com/jobs/view/data-center-engineer-infrastructure-operations-at-henry-ford-health-3776123670,2023-12-20,Oak Park,United States,Associate,Onsite,"General Summary
As a Data Center Engineer this position will be responsible for performing a wide range of complex technical work within the primary data center as well as smaller remote computer rooms, MDFs, and IDFs throughout the organization. He or she will follow standard procedures to perform duties related to data center cabling, server installation and decommission, and basic power/cooling configuration and maintenance. They will also perform routine data center maintenance including room and cabinet cleanings, server migration and consolidation. This position may include off shift hours, weekends, and holidays and some travel between Henry Ford Health locations.
Principle Duties And Responsibilities
Implement changes, moves, adds, decommissions, or updates in IT rooms
Process visitors to the Data Center to safeguard the integrity of data/equipment\
Review and approve changes to the environment following established Change Management standards and practices
Maintain inventory of spare computer parts and network cables\
Create/print cable labels for supporting IT teams
Create formal recommendations for process improvements
Writes, maintains, and publishes operational documentation
Other duties as required to maintain the Henry Ford Health Data Center complex
Education/Experience Required
High School Diploma or G.E.D. equivalent required.
Associates Degree (IT related field) preferred.
Five plus (5+) years of IT experience.
Extensive knowledge of all types of IT equipment preferred.
Cable management best practices including use of tracing devices preferred.
Equipment rack layout/design/assembly/configuration preferred.
Configure and code devices such as PDUs, CRACs, and ATS preferred.
IT equipment installation and decommission preferred.
Proficient in MS Office products including VISIO preferred.
Ability to occasionally work nights, weekends, and holidays.
Prepared to work at multiple Henry Ford Health facilities as needed.
Certifications/Licensures Required
ITIL certification preferred.
Additional Information
Organization: Corporate Services
Show more
Show less","Data center operations, Cabling, Server installation and decommissioning, Power and cooling configuration and maintenance, Data center maintenance, Change management, Inventory management, Documentation, IT equipment installation and decommissioning, Microsoft Office Suite, VISIO, ITIL certification","Company Name: Henry Ford Health
Job Title: Data Center Engineer
Experience: 5+ years of IT experience
Skills Needed: Extensive knowledge of IT equipment, cable management best practices, equipment rack layout/design/assembly/configuration, configuring and coding devices, IT equipment installation and decommission, proficiency in MS Office products including VISIO, ability to work nights, weekends, and holidays, ITIL certification preferred.",0.2622950787086805,0.7311436
Data Analyst,NR Consulting,"Troy, MI",https://www.linkedin.com/jobs/view/data-analyst-at-nr-consulting-3768024112,2023-12-20,Oak Park,United States,Associate,Onsite,"Summary
Ability to analyze existing tools and databases. Demonstrated experience in handling large data sets. Strong numeric and problem-solving capabilities. Ability to multi-task projects in an effective and productive manner. Able to prioritize work by dividing time, attention and effort Must be able to communicate verbally and in technical writing to all levels of the organization in a proactive, contextually appropriate manner. Adjust positively to quickly changing priorities and shifting goals in a fast-paced environment. Good understanding of business process Required hands-on experience with Microsoft Excel Experience in of relational databases and proficiency in writing queries is highly desired (Oracle SQL, PL/SQL) Experience working with ETL tools. (Informatica experience is a plus). Salesforce experience is as an admin/developer is a plus. Experience with various Software Development Methodologies such as Agile, SCRUM, Waterfall, etc.
Show more
Show less","Data analysis, Data handling, Numeric skills, Problem solving, Multitasking, Prioritization, Communication, Technical writing, Business process, Microsoft Excel, Relational databases, SQL, PL/SQL, ETL tools, Informatica, Salesforce, Agile, SCRUM, Waterfall","Company: Not specified

Job Title: Data Analyst

Years of Experience: Not specified

Skills Needed: Strong analytical skills, experience with handling large data sets, problem-solving capabilities, multitasking abilities, effective communication (verbal and written), ability to prioritize work, adaptability to changing priorities, understanding of business processes, hands-on experience with Microsoft Excel, knowledge of relational databases and writing queries (Oracle SQL, PL/SQL), experience with ETL tools (Informatica preferred), Salesforce experience as an",0.37419354370364205,0.68764496
Data Developer,Epsilon,"Southfield, MI",https://www.linkedin.com/jobs/view/data-developer-at-epsilon-3782266857,2023-12-20,Oak Park,United States,Associate,Onsite,"Job Description
The Data Engineer position will focus on designing, developing, and supporting our Hadoop data solutions in Spark and Python (PySpark) while working with other components of the Hadoop ecosystem such as HDFS, Hive, Hue, Impala, Zeppelin, Jupyter. A successful candidate will work closely with business and portfolio leads to understand requirements then design and build innovative data solutions.
Job Duties & Responsibilities.
Design and development centered around PySpark, Python and Hadoop Framework.
Working with gigabytes/terabytes of data and must understand the challenges of transforming and enriching such large datasets.
Provide effective solutions to address the business problems – strategic and tactical.
Collaboration with team members, project managers, business analysts and QA teams in conceptualizing, estimating and developing new solutions and enhancements.
Work closely with the stake holders to define and refine the big data platform to achieve sales, product, and strategic objectives.
Collaborate with other technology teams and architects to define and develop cross-function technology stack interactions.
Read, extract, transform, stage and load (ETL) data to multiple targets, including Hadoop and Oracle.
Ingest and streamline incoming files of various layouts/formats as part of Source Prep process.
Develop scripts around Hadoop framework to automate processes and existing flows.
Modify existing programming/code for new requirements.
Estimate work, and track progress through SDLC with JIRA/Confluence
Unit testing and debugging. Perform root cause analysis (RCA) for any failed processes.
Convert business requirements into technical design specifications and execute on them.
Participate in code reviews and keep applications/code base in sync with version control (GIT/Bitbucket).
Effective communication, self-motivation, and ability to work independently while remaining fully aligned within a distributed team environment.
Required Skills
Bachelor’s or Master’s degree in Computer science (or Engineering equivalent).
3+ years of experience with big data ingestion, transformation and staging.
Analysis, design and implementation experience with Hadoop distributed frameworks, including Python & Spark (SparkSQL, PySpark), HDFS, Hive, Impala, Hue, Cloudera Hadoop, Zeppelin, Jupyter, etc.
Extensive experience handling large volumes of data (measured in Terabytes/Billions of Transactions)
Proficient knowledge of SQL with any RDBMS
Familiarity with RDD and Data Frames within Spark
Working knowledge of data analytics
Troubleshooting and complex problem-solving skills
Knowledge of Oracle databases and PL/SQL
Working knowledge of Linux/Unix environments and comfort with Unix Shell scripts (ksh, bash)
Basic Hadoop administration knowledge.
DevOps Knowledge is an advantage
Ability to work within deadlines and effectively prioritize and execute on tasks
Strong communication skills (verbal and written) with ability to communicate across teams, internal and external at all levels
Preferred Skills
Working knowledge of Oracle databases and PL/SQL.
Hadoop Admin & Dev-Ops.
ETL Skills (Familiarity with Talend or other ETL tools a plus.
Good analytical thinking and problem-solving skills.
Ability to diagnose and troubleshoot problems quickly.
Motivated to learn new technologies, applications, and domains.
Possess appetite for learning through exploration and reverse engineering.
Strong time management skills.
Ability to take full ownership of tasks and projects.
Team player with excellent interpersonal skills.
Good verbal and written communication.
Possess Can-Do attitude to overcome any kind of challenges.
Preferred Certifications (Any Of These)
CCA Spark and Hadoop Developer.
MapR Certified Spark Developer (MCSD).
MapR Certified Hadoop Developer (MCHD).
HDP Certified Apache Spark Developer.
HDP Certified Developer.
Additional Information
About Epsilon
Epsilon is a global advertising and marketing technology company positioned at the center of Publicis Groupe. Epsilon accelerates clients’ ability to harness the power of their first-party data to activate campaigns across channels and devices, with an unparalleled ability to prove outcomes. The company’s industry-leading technology connects advertisers with consumers to drive performance while respecting and protecting consumer privacy. Epsilon’s people-based identity graph allows brands, agencies and publishers to reach real people, not cookies or devices, across the open web. For more information, visit epsilon.com.
When you’re one of us, you get to run with the best.
For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon has been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. Check out a few of these resources to learn more about what makes Epsilon so EPIC
Our Culture https //www.epsilon.com/us/about-us/our-culture-epsilon
Life at Epsilon https //www.epsilon.com/us/about-us/epic-blog
DE&I https //www.epsilon.com/us/about-us/diversity-equity-inclusion
CSR https //www.epsilon.com/us/about-us/corporate-social-responsibility
Great People Deserve Great Benefits
We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.
Epsilon is an Equal Opportunity Employer.
Epsilon’s policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories. Epsilon will provide accommodations to applicants needing accommodations to complete the application process.
REF216743S
Show more
Show less","Hadoop, Spark, Python, PySpark, HDFS, Hive, Hue, Impala, Zeppelin, Jupyter, RDD, Data Frames, SQL, RDBMS, PL/SQL, Unix, Shell scripts, Oracle databases, Linux, ETL, Talend, DevOps, CCA Spark and Hadoop Developer, MapR Certified Spark Developer (MCSD), MapR Certified Hadoop Developer (MCHD), HDP Certified Apache Spark Developer, HDP Certified Developer","Company: Epsilon
Job Title: Data Engineer
Experience: The ideal candidate should have a Bachelor’s or Master’s degree in Computer Science (or Engineering equivalent) and a minimum of 3 years of experience in big data ingestion, transformation, and staging.
Skills Needed: The candidate must have experience with Hadoop distributed frameworks, Python & Spark (SparkSQL, PySpark), HDFS, Hive, Impala, Hue, Cloudera Hadoop, Zeppelin, Jupyter, etc.",0.1497504143105916,0.63529575
"Data Research Analyst, gt.school (Remote) - $60,000/year USD",Crossover,"Detroit, MI",https://www.linkedin.com/jobs/view/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457098,2023-12-20,Oak Park,United States,Associate,Remote,"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?
Are you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.
At gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.
But that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.
If you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!
What You Will Be Doing
Engineering generative AI prompts in Python/JavaScript/JSON
Analyze AI outputs and iterate on prompts to reach desired outcomes
Leverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models
Research topics to support the product engineering team
What You Won’t Be Doing
Collecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.
Working on unimportant projects - you'll be tasked with projects that are mission-critical
Data Research Analyst Key Responsibilities
Create technical functionalities that revolutionize the way education is delivered.
Basic Requirements
Excellent written and verbal English communication skills
Proficient in Python, R, JavaScript, or another OOP language
2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)
Consistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST
Must be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously
About Gt.school
GT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.
There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!
Working with Crossover
This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD/hour, which equates to $60,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic.
What to expect next:
You will receive an email with a link to start your self-paced, online job application.
Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.
Important!
If you do not receive an email from us:
First, emails may take up to 15 minutes to send, refresh and check again.
Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well.
Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.
If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply.
Crossover Job Code: LJ-4880-US-Detroit-DataResearchAn.007
Show more
Show less","Python, JavaScript, JSON, Generative AI, Product Development, Data Science, Machine Learning, Natural Language Processing, Algorithms, Data Analytics, Machine Learning Models, Research, Education Technology, EdTech, OOP Languages, SQL, Technical Writing, R, Communication Skills, Project Management","Company Name: Gt.school
Job Title: Data Research Analyst
Experience: 2+ years of work experience in a technical field
Skills Needed: Excellent written and verbal English communication skills, proficiency in Python, R, JavaScript, or another OOP language, ability to work 40 hours per week, proactive communicator, strategic problem solver
Summary: Gt.school, an EdTech Startup, is seeking a Data Research Analyst to revolutionize education using cutting-edge technology and generative AI. The",0.19599999782752,0.5410907
Application Developer (Data Analytics),TekWissen ®,"Detroit, MI",https://www.linkedin.com/jobs/view/application-developer-data-analytics-at-tekwissen-%C2%AE-3784437308,2023-12-20,Oak Park,United States,Associate,Hybrid,"Title: Application Developer III
Work Location: Detroit, MI
Duration: 12 Months
Job Type: Contract
Work Type: Hybrid
Dept: Business Analytics & Cl
Pay Rate: $55-
$55/hr.
Overview:
TekWissen Group is a workforce management provider throughout the USA and many other countries in the world. Our client is a health insurance company. It offers different types of health care coverage plans that include individual and family, dental and vision, plans for employers, etc.
Engagement Description
Responsible for leading complex projects and independently executing analyses that support the healthcare value portfolio.
Translates technical results into answers for healthcare business needs and applies a strong understanding of healthcare industry when creating those solutions.
Partners effectively outside of the business team to execute work.
Works closely with team members to fully understand the business question and source associated data required for a solution.
Executes work efficiently, bringing forward process enhancements with a continuous improvement mindset.
Works closely with clients, business analysts and team members to understand the business requirements that drive the analysis and design of quality technical solutions.
These solutions must be aligned with business and IT strategies and are in compliance with the organization's architectural standards.
Application Developers are involved in the full systems life cycle and therefore are responsible for designing, coding, testing, implementing and supporting application software that is delivered on time and within budget. Responsibilities beyond development of software may include participation in component and data architecture design, technology planning, product evaluation, advanced testing processes and buy vs. build recommendations.
Individuals also provide input to project plans related to the Application Development initiative.
Application Developers have a strong knowledge of programming languages used by the organization.
They have experience in systems design and have a solid understanding of development, database development, testing, and integration methodologies.
Knowledge of current and emerging IT products, services and processes is required.
Work Complexity
Works on major projects as a project team member, sometimes as a project lead.
Works on projects that may span a broad range of applications.
Supports multiple applications.
Expertise in multiple technical environments and possesses business knowledge that spans one or more business areas.
Top 3 Required Skills/Experience
Minimum 7 years’ experience in Advanced Data Analytics.
Proficient in advanced functions in SQL.
Advanced understanding of data warehousing and data mining concepts such as: DataMart design, fact tables, dimension tables, data views within data marts/data warehouses, data models such as star schemas and snowflake schemas.
Required Skills/Experience – The rest of the required skills/experience. Include:
Ability to recognize data patterns, quantify potential issues and identify solutions.
Ability to standardize, harmonize, clean, prepare and use data for developing datasets, reporting and analysis.
Ability to perform root cause analysis on external and internal processes and data to identify opportunities for improvement and answer questions
Assemble large, complex data sets that meet functional / non-functional business requirements.
Conduct data gathering and analysis to understand business requirements.
Provide direction for short and long-term solutions and provide the team direction to ensure understanding of business goals and direction. Provide input from a business and IT perspective.
Preferred Skills/Experience – Optional but preferred skills/experience. Include:
Healthcare Experience
Experience with big data tools: Hadoop, Spark, and scripting languages: Python or Scala
Solid working knowledge of Microsoft tools and software (i.e., Excel, Visio, Access, PowerPoint)
Display innovation in identifying, proposing, and overseeing the execution of business solutions.
Written and verbal communication skills, interpersonal skills.
Ability to work independently, or within a team environment.
Education/Certifications – Include:
Bachelors Degree in Computer Science, Information Systems, Business, Mathematics, Healthcare Information Technology or similar degree required.
Master’s Degree preferred.
Education/ Experience
Bachelor's degree in related field preferred.
5 years of application programming and analysis experience required.
Has a broad level of understanding surrounding information systems and application architecture standards.
Demonstrated ability to analyze and interpret complex problems or processes that span multiple business areas, identify and understand requirements, and develop alternate solutions.
Experience designing, developing and testing applications using proven or emerging technologies.
Show more
Show less","Advanced Data Analytics, SQL, Data warehousing, Data mining, Star schema, Snowflake schema, Data standardization, Data harmonization, Data cleaning, Data preparation, Data gathering, Data analysis, Hadoop, Spark, Python, Scala, Microsoft tools, Excel, Visio, Access, PowerPoint, Communication skills, Team environment","The job title is Application Developer III at TekWissen Group, located in Detroit, MI, for a 12-month contract position. The candidate must have a minimum of 7 years of experience in Advanced Data Analytics, be proficient in advanced SQL functions, and have an advanced understanding of data warehousing and data mining concepts. Other required skills include the ability to recognize data patterns, clean and prepare data, perform root cause analysis, and provide direction for developing datasets. Preferred skills include Healthcare Experience, knowledge",0.20594965418617683,0.64287025
Data Center Engineer,VeeAR Projects Inc.,"Auburn Hills, MI",https://www.linkedin.com/jobs/view/data-center-engineer-at-veear-projects-inc-3767593066,2023-12-20,Oak Park,United States,Associate,Hybrid,"Job Description
The Data Center Engineer is responsible for implementing large scale projects that entails renovating multiple data centers throughout NAFTA. The Data Center Engineer will evaluate data center electrical systems, products, and components to understand where all risks are present. Once all risks are identified, create a multiple year project that entails mitigating electrical and mechanical risks to the data centers. The Data Center Engineer will be responsible for initial identification, project creation, project design, project budget, and project implementation. Experience in development of MOPs/SOP/EOPs for carrying out systems operations. The Data Center Engineer must provide electrical, mechanical, and technical direction while ensuring compliance with quality and safety standards for all corporate data centers. The Data Center Engineer has and understanding of industrial/commercial electrical one-line drawings along with understanding State and Local Code requirements. The job responsibilities encompass a broad spectrum, covering all the areas of project management: project planning, cost management, time management, quality and safety management, and contract administration. The Data Center Engineer must be able to manage multiple large-scale projects that require communication across many different IT departments. Assist other data center engineers with break fix incidents. The Data Center Engineer is on call 24 x 7 in a rotation order.
Requirements
Bachelor's degree in Mechanical, Electrical Engineering, or IT required.
Minimum of 3 years' experience in facilities infrastructure.
Must understand As-Built drawings and electrical and mechanical operations of a Data Center.
Knowledge of various data center technologies and a strong understanding of high-availability data centers.
Understanding of network design principles.
Minimum of 3 years' experience in budget/finance experience.
Minimum of 3 years' experience in project management.
Read and interpret electrical and mechanical blueprints
On call 24 x 7 in a rotation order.
Able to lift 30 lbs.
Preferred Qualifications:
Master's degree
UST and AST Certification
PMP Certification
Capable of leading design and planning sessions including leading the collection of business requirements, determining the scope of the project, and aligning business needs with the appropriate technology.
Exceptional program/project management track record.
Excellent team work skills.
Strategic thinker with the ability to grasp business goals, strategies, and challenges.
Proven ability to multi-task is critical, excellent communication skills, both written and verbal, strong conflict management skills.
Carries out responsibilities in a professional, courteous manner at all times.
Show more
Show less","Electrical Engineering, Mechanical Engineering, IT, Data Center Technologies, Project Management, Facilities Infrastructure, AsBuilt Drawings, Network Design, Quality and Safety Standards, UST and AST Certification, PMP Certification, Conflict Management, Communication Skills","Company: Not specified
Job Title: Data Center Engineer
Experience: Minimum of 3 years

Skills Needed:
- Bachelor's degree in Mechanical, Electrical Engineering, or IT required
- Minimum of 3 years' experience in facilities infrastructure
- Knowledge of As-Built drawings and electrical/mechanical operations of a Data Center
- Understanding of various data center technologies and high-availability data centers
- Knowledge of network design principles
- Minimum of 3 years' experience in budget/finance",0.2857142827435489,0.6302316
Data Analyst III- Adobe Campaign Specialist,AAA Life Insurance Company,"Livonia, MI",https://www.linkedin.com/jobs/view/data-analyst-iii-adobe-campaign-specialist-at-aaa-life-insurance-company-3784639743,2023-12-20,Oak Park,United States,Associate,Hybrid,"By joining AAA Life, you will have the opportunity to strengthen the name and reputation of the brand that millions have come to rely upon for financial piece of mind. We are company dedicated to our members and our employees. We value the unique attributes and contributions of our associates to build an inclusive, collaborative and innovative workplace where all employees are engaged and feel they belong. Delivering our company’s promise to members is what drives each of our associates every day.
We offer a dynamic work environment, excellent benefits, and competitive compensation, that will allow you will exercise your potential to innovate, finding ways to increase efficiency and enhance our business processes.
Are you a Data Analyst with experience in Adobe Campaign? Our Data Analyst III ensures that AAA Life Insurance makes effective business and operational decisions. As a Data Analyst, you will be at the forefront of transforming data into actionable insights. This role involves extensive use of Adobe Campaign and will regularly extract, analyze, and visualize data to provide valuable recommendations that drive marketing strategies and decision-making.
Responsibilities
Use Adobe Campaign to pull together cross-channel customer data create and customize campaigns.
Set up new Adobe campaign workflows for mail and email
Lead & develop automated, easy to understand reports and ad hoc analyses to address specific marketing questions and provide insights to guide decision making.
Utilize statistical techniques and data analysis tools (i.e., Python, R, SQL) to gather, clean, analyze, and provide recommendations regarding large datasets from various sources, identifying trends, patterns, and key performance metrics.
Collaborate closely with marketing teams to interpret data and provide actionable insights to optimize marketing campaigns, customer segmentation, and overall strategy.
Develop and implement data governance and quality assurance processes.
Create and maintain Power BI reports and dashboards to translate complex data into clear visualizations that marketing staff can easily interpret and use to inform their strategies.
Lead and develop key performance indicators (KPIs), tracking marketing initiatives against established goals, and providing regular updates to stakeholders.
Conduct A/B tests and statistical analyses to evaluate the effectiveness of marketing strategies, making data-driven recommendations for improvements.
Collaborate with marketing teams to segment audiences effectively and personalize marketing approaches based on data-driven insights.
Qualifications
Bachelor in Statistics, Marketing, Economics, Computer Science, or related technical field. Master’s degree is a plus.
A minimum of five years’ experience working as a Data Analyst, Marketing Analyst, or similar role.
Expert in Adobe Campaign experience strongly preferred
Able to set up new Adobe campaign workflows for mail and email
strongly preferred
Understands architecture needed to support very large weekly campaigns
strongly needed
Extensive experience in data analysis tools and programming languages (i.e., Python, R, SQL).
Ability to create and interpret reports and dashboards using Power BI, Tableau, or similar data visualization tools.
Proficiency with marketing analytics tools and platforms (i.e., Google Analytics, Adobe Analytics).
Show more
Show less","Adobe Campaign, Python, R, SQL, Power BI, Marketing Analytics, Google Analytics, Adobe Analytics, Tableau, Statistics, Data Analysis, Data Visualization, Machine Learning, Artificial Intelligence, Big Data, Data Governance, Data Quality Assurance, A/B Testing, Marketing Strategy, Customer Segmentation, Key Performance Indicators (KPIs), DataDriven Insights","Company: AAA Life
Job Title: Data Analyst III
Experience: Minimum of five years
Skills Needed: Bachelor's degree in Statistics, Marketing, Economics, Computer Science, or related field. Master's degree is a plus. Expertise in Adobe Campaign, setting up new Adobe campaign workflows, understanding architecture for large campaigns. Proficiency in Python, R, SQL for data analysis. Ability to create and interpret reports using Power BI, Tableau. Familiarity with marketing analytics tools like Google Analytics",0.2678062647173319,0.68886113
Labs - Data Scientist - Senior Associate,PwC,"Detroit, MI",https://www.linkedin.com/jobs/view/labs-data-scientist-senior-associate-at-pwc-3782246830,2023-12-20,Oak Park,United States,Mid senior,Onsite,"Specialty/Competency:
Data Science
Industry/Sector:
Not Applicable
Time Type:
Full time
Travel Requirements:
Up to 20%
A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
Responsibilities
As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities, coaching them to deliver results.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Use a broad range of tools and techniques to extract insights from current industry or sector trends.
Review your work and that of others for quality, accuracy and relevance.
Know how and when to use tools available for a given situation and can explain the reasons for this choice.
Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Our mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.
Basic Qualifications
Job Requirements and Preferences
:
Minimum Degree Required
Bachelor Degree
Additional Educational Requirements
Bachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college.
Minimum Years Of Experience
2 year(s)
Preferred Qualifications
Degree Preferred
:
Master Degree
Preferred Fields Of Study
Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research
Additional Educational Preferences
PhD highly preferred
Preferred Knowledge/Skills
Demonstrates thorough abilities and/or a proven record of success:
Exploring new analytical technologies and evaluate their technical and commercial viability;
Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools;
Working across various data mediums: text, audio, imagery, sensory, and structured data;
Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;
Testing and rejecting hypotheses around data processing and ML model building;
Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;
Building ML pipelines that ingest, clean data, and make predictions;
Focusing on AI and ML techniques that are broadly applicable across all industries;
Staying abreast of new AI research from leading labs by reading papers and experimenting with code;
Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients;
Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);
Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;
Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);
Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;
Building ML models and systems, interpreting their output, and communicating the results; and,
Moving models from development to production; conducting lab research and publishing work.
Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:
Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;
Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);
Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;
Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;
Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;
Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,
Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.
Learn more about how we work: https://pwc.to/how-we-work
PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.
All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.
For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.
Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines
For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate
Show more
Show less","AI, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Blockchain, Augmented Reality, Drones, Internet of Things, Virtual Reality, 3D Printing, Programming Languages:, Python, R, Java, JavaScript, C++, Unix, Data Storage Technologies:, SQL, NoSQL, Postgres, Neo4j, Hadoop, Cloudbased databases, Parquet, Data Processing Tools:, Python (Numpy Pandas etc.), Spark, Cloudbased solutions, Machine Learning Libraries:, Python (scikitlearn genism etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy, NLU/NLP domain:, Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS, Visualization tools:, Python (Matplotlib Seaborn bokeh etc.), JavaScript (d3), Third party libraries (Power BI Tableau Data Studio), Productionization and containerization technologies:, GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS","Company: PwC

Job Title: Senior Associate in Data Science

Experience: Minimum of 2 years

Skills Needed: The candidate must have a Bachelor's degree in Computer and Information Science, Mathematics, Computer Engineering, or related fields. Preferred qualifications include a Master's degree or PhD. The candidate should have experience in exploring new analytical technologies, working on data pipelines, experimenting with AI and ML techniques, understanding ML algorithms, open-source deep learning frameworks, text pre-processing, building ML models,",0.0976863738545212,0.53072643
"BMH - Data Scientist - Southfield, MI",Barton Malow,"Southfield, MI",https://www.linkedin.com/jobs/view/bmh-data-scientist-southfield-mi-at-barton-malow-3752888814,2023-12-20,Oak Park,United States,Mid senior,Onsite,"Company:
Barton Malow Holdings
Job Location:
Southfield, MI
Position:
Data Scientist
REQ ID:
10769
Position Summary
Barton Malow is seeking an experienced Data Scientist with a strong data science background to join the Data and Automation team. This position collaborates closely with a cross-functional team, including IT, Application Developers, and Data Engineers to develop and deliver AI-powered products. The position’s primary responsibilities will include partnering between data engineering and business stakeholders to develop custom data models and algorithms to drive business solutions.
Key Job Responsibilities
Apply your passion for problem-solving through exploring data.
Partner and educate business partners and leaders on the field of data science.
Develop machine learning models through all phases of development, from design through training, evaluation, validation, and implementation.
Use portfolio of data applications including storytelling with data using Power BI.
Collaborate with the team working with Databricks and continue to learn more as necessary.
Engage in solving architectural challenges related to data lakes, lake houses, warehouses, change data capture, messaging, event streaming and real-time data pipelines.
Leverage your familiarity with databases and their querying languages to effectively manage and manipulate data within a variety of data storage systems.
Required Knowledge, Education, Experience, Skills, And Abilities
5+ years of relevant business experience working with data engineering and data science teams.
Bachelor’s degree in Statistics, Economics, Data Science, or Data Science. Preferred Master's coursework in an academic field related to Data Science.
Demonstrated ability to apply a scientist's/engineer's approach to solving problems.
Familiarity with DevOps/DataOps practices.
Prior experience with statistical programming languages and developing data models in Python/R/SQL.
Proficient in Power BI for data visualization and communication of data stories.
Proficient in deployment of models through platforms such as AWS SageMaker, Azure ML, Datarobot.
Proficient in popular business collaboration tools such as Microsoft Office, Google Apps, Apple Pages, Slack, Teams, etc.
Work Environment/Job Conditions
This position may require up to 30% travel.
This may increase/decrease depending on the team member's location and the needs of the team.
Show more
Show less","Data Science, AI, Machine Learning, Data Analytics, Data Visualization, Data Modeling, Python, R, SQL, Power BI, Business Intelligence, Data Pipelines, Data Lakes, Data Warehouses, Change Data Capture, Messaging, Event Streaming, RealTime Data, DevOps, DataOps, Agile, AWS SageMaker, Azure ML, Datarobot, Microsoft Office, Google Apps, Apple Pages, Slack, Teams","Company: Barton Malow Holdings  
Job Title: Data Scientist  
Experience: 5+ years  
Location: Southfield, MI  

The Data Scientist at Barton Malow Holdings will collaborate with cross-functional teams to develop AI-powered products, partnering with data engineering and business stakeholders to create custom data models and algorithms. Key responsibilities include problem-solving through data exploration, developing machine learning models, utilizing Power BI for data storytelling, and engaging in architectural challenges related to data lakes and real-time data pipelines. 

The",0.3407407373673526,0.87668014
"Senior Data Scientist, Product Growth",Jerry,"Detroit, MI",https://www.linkedin.com/jobs/view/senior-data-scientist-product-growth-at-jerry-3789686109,2023-12-20,Oak Park,United States,Mid senior,Remote,"We'd love to hear from you if you like:
Making a big impact with a Forbes Top Startup Employer
Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category)
Solving problems in a huge market ($2T market size)
Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc.
About the opportunity:
We are looking for a Senior Data Scientist to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models.
Working with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will leverage data and insights to drive growth and retention for one of our emerging product groups (car repair marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap and new investment opportunities.
How you will make an impact:
Partner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product
Design, run, and analyze A/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps
Build key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams
Transform and refine raw production data for analytical needs
Continually improve our data governance and data consistency standards within our database
Work with data engineering team on data tracking, integrity, and security as needed
Work with other data scientists to evolve, optimize and integrate machine learning models
Who you are:
Intellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions.
Creative problem-solver: No challenge is too complex, no issue is too hard.
Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited.
Strong communicator: Able to drive alignment and communicate effectively to different audiences.
Ideal profile:
Bachelor’s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline
2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment
Experience designing and implementing A/B tests, and analyzing user experience
Hands-on experience with SQL (advanced proficiency)
Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.
Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at
recruiting@getjerry.com
About Jerry:
Jerry is America’s first and only AllCar™ app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets.
Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all.
We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers — and we’re just getting started.
Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing.
Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that’s disrupting a massive market.
Show more
Show less","Data Scientist, Predictive modelling, Data Transformation, Data Governance, Data Consistency, Data Engineering, A/B Testing, User Experience Analysis, SQL, Data Analytics, Machine Learning, Artificial Intelligence, Product Management, Software Engineering, Product Design, Business Leadership, Consumerfacing Web or Mobile App Experience","Company: Jerry
Job Title: Senior Data Scientist
Experience: 2+ years
Skills:
- Bachelor’s degree in Mathematics, Statistics, Economics, Computer Science or related field
- Experience as a data scientist or product analyst in a consumer-facing web or mobile app environment
- Designing and implementing A/B tests, analyzing user experience
- Proficiency in SQL
- Strong analytical skills and data-driven decision making
- Ability to work collaboratively with cross-functional teams
- Strong communication skills",0.17659137364056854,0.4571808
"Data Analyst, Junior - Remote | WFH",Get It Recruit - Information Technology,"Troy, MI",https://www.linkedin.com/jobs/view/data-analyst-junior-remote-wfh-at-get-it-recruit-information-technology-3784096613,2023-12-20,Oak Park,United States,Mid senior,Remote,"We are seeking a passionate analytics professional who thrives on delving into data to extract meaningful insights. Embracing both structured and unstructured data, you recognize the significance of transforming complex datasets into actionable information to tackle challenges. Join a team where your skills as a Data Analyst can contribute to a greater mission and make a positive impact.
Your Role
As a client-facing Data Analyst working with our Army team, you will collaborate closely with clients to understand their questions and needs. Dive into their data-rich environments, extract and evaluate data, and help clients interpret information to drive readiness and soldier well-being.
How You’ll Make a Difference
As a vital member of our team, you will:
Utilize your technical expertise to foster client and stakeholder relationships at Army Commands.
Research, develop, and test data methodologies, generating cross-functional solutions through the collection, interpretation, evaluation, and analysis of large datasets.
Contribute to impactful work and guide decision-making across multiple organizations.
Apply your analytical mindset by simplifying technical requirements and trends based on your audience.
Present data findings and recommendations effectively using your knowledge of databases, and scripting languages such as SQL, Python, R, and Microsoft Office Suite.
Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes.
Create data visualizations using various formats like graphs, tables, and PowerPoint slides.
Merge consulting and big data to develop data-centric solutions across the Army Mission.
You Bring
Experience with coding in R or Python.
Proficiency in ETL and EDA processes to answer questions and solve problems.
Skills in visualizing data to identify or communicate key insights.
Familiarity with machine learning, statistical modeling, or optimization algorithms.
Knowledge of basic concepts in mathematics and statistics.
Ability to communicate complex analytical insights to a non-technical audience.
Bachelor’s degree in CS, Computer Engineering, Industrial and Systems Engineering, Mathematics, or Statistics.
Nice To Have
Experience with R Shiny, Flask, HTML, and UI/UX-centric development.
Knowledge of database development and architecture design.
Familiarity with defining data governance and management requirements.
Experience with version control management using the Git framework.
Exposure to deploying solutions in AWS, Azure, or GCP.
Familiarity with data visualization tools, including Tableau, Qlik, or Power BI.
Experience mentoring junior staff or leading teams.
Background in supporting Army or DoD clients.
Secret clearance.
Master's degree in Data Science, CS, Mathematics, Engineering, Physics, or Statistics.
Clearance
Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.
Create Your Career
We value your growth and offer various opportunities for professional and leadership development. Our inclusive culture supports diversity, and we encourage you to bring your whole self to work.
Support Your Well-Being
Our comprehensive benefits package includes wellness programs, paid holidays, paid parental leave, a generous 401(k) match, and more. Enjoy the option for flexible schedules and remote and hybrid work locations.
Your Candidate Journey
Discover what to expect during your journey with us, from connection to career development. We prioritize relationships and offer resources to guide you every step of the way.
Compensation
Your contributions matter, and we celebrate them by providing competitive compensation, health, life, and retirement benefits, professional development, tuition assistance, and more.
Work Model
Our people-first culture prioritizes flexibility and collaboration, whether in person or remotely. Embrace the benefits of working from a Booz Allen or client site facility if the position is listed as remote or hybrid.
EEO Commitment
We are an equal employment opportunity/affirmative action employer committed to fostering change regardless of race, color, ethnicity, religion, sex, national origin, age, marital status, sexual orientation, gender identity, disability, veteran status, or any other status protected by applicable law.
Employment Type: Full-Time
Show more
Show less","SQL, Python, R, Microsoft Office Suite, Data Visualization, ETL, EDA, Machine Learning, Statistical Modeling, Optimization Algorithms, Mathematics, Statistics, Communication, R Shiny, Flask, HTML, UI/UX Development, Database Development, Database Architecture Design, Data Governance, Data Management, Git, AWS, Azure, GCP, Tableau, Qlik, Power BI, Data Science, Computer Science, Engineering, Physics","Company: Booz Allen Hamilton

Job Title: Data Analyst for Army Team

Experience: Bachelor’s degree in CS, Computer Engineering, Industrial and Systems Engineering, Mathematics, or Statistics, with experience in coding in R or Python. Master's degree in Data Science, CS, Mathematics, Engineering, Physics, or Statistics is a plus.

Skills Needed:
- Proficiency in ETL and EDA processes
- Ability to visualize data effectively
- Familiarity with machine learning, statistical modeling, and",0.18594104096914352,0.50448805
Senior Data Engineer - XC,Bosch USA,"Plymouth, MI",https://www.linkedin.com/jobs/view/senior-data-engineer-xc-at-bosch-usa-3581292494,2023-12-20,Oak Park,United States,Mid senior,Remote,"Company Description
As one of the largest North American automotive suppliers, Bosch develops Driver Assistance functions like Adaptive Cruise Control (ACC), Predictive Emergency Brake Systems (PEBS), Lane Departure Warning/Keeping Systems (LDW, LKS), Predictive Pedestrian Protection, Road Sign recognition, head light control, Advanced Parking Assistance, and many more.
We develop state of the art systems as well as advanced features leading to partly/highly automated driving; we have all of the necessary sensors in our portfolio (e.g. radar, camera, ultrasonic sensors, etc.) Join us to become part of the exciting and growing field of Driver Assistance.
Job Description
We are on the mission to turn latest technology into outstanding Bosch products and services. In our team we are developing the perception of the next generation of automatic parking systems. We are driving the development of the computer vision, ultrasonic sensor perception and creating the necessary SW to turn the sensor raw information into a vector space representation.
This vector space representation is the foundation for industry leading automatic parking functions. With our latest sensor generations, we have successfully introduced machine learning in our products. This was the first step on an exciting journey. There is a lot of opportunity ahead.
When you are the kind of person who combines a deep software engineering background with a we “can make it happen” attitude, let’s have a more detailed chat.
As a Senior Data Engineer you will develop and operate data pipelines delivering data from our engineering and the customer fleet to power our machine learning pipelines and provide data for decision making.
You will shape the future of automatic parking systems and establish best practices for embedded AI projects.
You will enable function developers to make use of your pipeline artifacts
As part of an agile team your ideas will be heard and impact the decision-making process. With our goal to invent for life, you will work on solutions that are both, innovative and ethical.
You will collaborate with scientists, electrical engineers, and machine learning engineers, ML Ops engineers to have real world impact.
Lifelong learning is crucial for long term success and we encourage you to stay current with latest research by visiting conferences and sharing your knowledge throughout the enterprise.
Qualifications
Basic Qualifications:
Education: Bachelor's or Master's degree in Computer Science, Electric Engineering, other Engineering discipline or foreign equivalent
3+ years of experience with building data pipelines within a Cloud or Cloud-hybrid setup; in-depth understanding of relational database systems (e.g. Oracle, MS SQLServer).
3+ years of experience with distributed computing frameworks (e.g. k8s, Spark)
3+ years of experience in object-oriented software development, (e.g. Python, Java, or Go).
2+ years of experience with Linux.
Preferred
Education: successfully completed Master's degree in Computer Science or other engineering discipline
Experience with recent non-relational storage technologies (NoSQL and distributed)
Experience with workflow automation tools (e.g. Jenkins, Ansible)
Experience with ECU SW re-simulation
Experience with various messaging systems (e.g. Kafka)
Experience in designing data models and choice of respective data formats
Experience with in-vehicle data collection skills, structured and analytical connectivity
Additional Information
All your information will be kept confidential according to EEO guidelines.
By choice, we are committed to a diverse workforce - EOE/Protected Veteran/Disabled.
BOSCH is a proud supporter of STEM (Science, Technology, Engineering & Mathematics) Initiatives
FIRST Robotics (For Inspiration and Recognition of Science and Technology)
AWIM (A World In Motion)
Show more
Show less","Data Pipelines, Cloud Computing, Oracle, MS SQL Server, Kubernetes, Spark, Python, Java, Go, Linux, NoSQL, Ansible, Jenkins, Kafka, Data Modeling, Data Formats, InVehicle Data Collection, Structured Connectivity, Analytical Connectivity","Company Name: Bosch
Job Title: Senior Data Engineer
Experience: 3+ years
Skills Needed: 
- Bachelor's or Master's degree in Computer Science, Electric Engineering, or other Engineering discipline
- 3+ years of experience with building data pipelines in a Cloud or Cloud-hybrid setup and relational database systems
- 3+ years of experience with distributed computing frameworks
- 3+ years of experience in object-oriented software development using Python, Java, or Go
- ",0.21705426131575964,0.32853425
"Software Engineer Senior (GCP, BigQuery, DataFlow, Cloud SQL,)",RAISSO,"Dearborn, MI",https://www.linkedin.com/jobs/view/software-engineer-senior-gcp-bigquery-dataflow-cloud-sql-at-raisso-3788473174,2023-12-20,Oak Park,United States,Mid senior,Hybrid,"Position Title: Software Engineer Senior (GCP, BigQuery, DataFlow,
Cloud SQL
)
Work Hours: 40
Location Dearborn, MI
Duration: 24 Months
Position Description
We're seeking an experienced Software Engineer who is familiar with Lean Agile practices. You will work on analyzing and manipulating large datasets supporting the enterprise by activating data assets to support Enabling Platforms and analytics in the Google Cloud Platform. You will be responsible for designing the transformation and modernization on Google Cloud Platform, as well as landing data from source application to GCP. Experience with large scale solution and operationalization of data warehouses, data lakes and analytics platforms on Google Cloud Platform or other cloud environment is a must. We are looking for candidates who have a broad set of technology skills across these areas and who can demonstrate an ability to design right solutions with appropriate combination of GCP and 3rd party technologies for deploying on Google Cloud Platform. You will: Work in collaborative environment including pairing and mobbing with other cross-functional engineers Work on a small agile team to deliver working, tested software Work effectively with fellow data engineers, product owners, data champions and other technical experts Demonstrate technical knowledge/leadership skills and advocate for technical excellence Develop exceptional Analytics data products using streaming, batch ingestion patterns in the Google Cloud Platform with solid Datawarehouse principles.
Skills Required
Work as part of an implementation team from concept to operations, providing deep technical subject matter expertise for successful deployment. Implement methods for automation of all parts of the pipeline to minimize labor in development and production. This includes designing and deploying a pipeline with automated data lineage. Identify, develop, evaluate and summarize Proof of Concepts to prove out solutions. Test and compare competing solutions and report out a point of view on the best solution. Integration between GCP Data Catalog and Informatica EDC. Design and build production data engineering solutions to deliver our pipeline patterns using Google Cloud Platform (GCP) services: BigQuery, DataFlow, Pub/Sub, BigTable, Data Fusion, DataProc, Cloud Compose, Cloud SQL, Compute Engine, Cloud Functions, and App Engine.
Skills Preferred
Strong drive for results and ability to multi-task and work independently - Self-starter with proven innovation skills - Ability to work with cross-functional teams and all levels of management - Demonstrated commitment to quality and project timing - Demonstrated ability to document complex systems - Experience in creating and executing detailed test plans
Experience Required
In-depth understanding of Google's product technology (or other cloud platform) and underlying architectures - 5+ years of application development experience required - 5+ years of SQL development experience - 3+ years of GCP experience - Experience working in GCP based Big Data deployments (Batch/Real-Time) leveraging Big Query, Big Table, Google Cloud Storage, PubSub, Data Fusion, Dataflow, Dataproc, Airflow etc. - 2 + years professional development experience in Java or Python. - Work with data team to analyze data, build models and integrate massive datasets from multiple data sources for data modelling Implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production. Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management - Extracting, Loading, Transforming, cleaning, and validating data - Designing pipelines and architectures for data processing - 1+ year of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java/ Python etc. - 1+ year of hands-on GCP experience with a minimum solution designed and implemented at production scale
Experience Preferred
Architecting and implementing next generation data and analytics platforms on GCP - Experience in building solution architecture, provision infrastructure, secure and reliable data-centric services and application in GCP - Experience with Informatica EDC is preferred - Experience with development eco-system such as Git, Jenkins and CICD. Exceptional problem solving and communication skills - Experience in working with Agile and Lean methodologies - Team player and attention to detail - Performance tuning experience
Education Required
Bachelor's degree in computer science or related scientific field IT or related Associated topics: data architect, data center, data integrity, data manager, data management, data scientist, data warehousing, sql, sybase, Teradata
Education Preferred
Master's degree in computer science or related field GCP Professional Data Engineer Certified 2+ years mentoring engineers In-depth software engineering knowledge
Show more
Show less","Lean Agile, Data Analysis, Data Manipulation, Google Cloud Platform, Data Warehouses, Data Lakes, Analytics Platforms, BigQuery, DataFlow, Cloud SQL, Data Catalog, Informatica EDC, Pub/Sub, BigTable, Data Fusion, DataProc, Cloud Compose, Compute Engine, Cloud Functions, App Engine, Java, Python, SQL, Git, Jenkins, CICD, Data Architect, Data Center, Data Integrity, Data Manager, Data Management, Data Scientist, Data Warehousing, Sybase, Teradata","Company Name: Not specified
Job Title: Senior Software Engineer
Experience: The ideal candidate should have 5+ years of application development experience, 5+ years of SQL development experience, 3+ years of GCP experience, and 2+ years of professional development experience in Java or Python.
Skills Needed: The candidate should have experience working with GCP based Big Data deployments, expertise in GCP services such as BigQuery, DataFlow, Pub/Sub, etc., ability to design and",0.1818181796396603,0.71676195
"Lead Data Scientist (Bangkok based, relocation provided)",Agoda,"Detroit, MI",https://www.linkedin.com/jobs/view/lead-data-scientist-bangkok-based-relocation-provided-at-agoda-3736663939,2023-12-20,Oak Park,United States,Mid senior,Hybrid,"About Agoda
Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.
Get to Know Our Team
The Data department , based in Bangkok , oversees all of Agoda’s data-related requirements. Our ultimate goal is to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as operational and analytical databases, queue systems, BI tools, and data science technology. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company’s culture of diversity and experimentation. The role the Data team plays at Agoda is critical as business users, product managers, engineers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the Data department, but also the reward.
The Opportunity
Please note -The role will be based in Bangkok.
We are looking for ambitious and agile data scientists that would like to seize the opportunity to work on some of the most challenging productive machine learning and big data platforms worldwide, processing some 600B events every day and making some 5B predictions.
As part of the Data Science and Machine Learning (AI/ML) team you will be exposed to real-world challenges such as: dynamic pricing, predicting customer intents in real time, ranking search results to maximize lifetime value, classifying and deep learning content and personalization signals from unstructured data such as images and text, making personalized recommendations, innovating algorithm-supported promotions and products for supply partners, discovering insights from big data, and innovating the user experience. To tackle these challenges, you will have the opportunity to work on one of the world’s largest ML infrastructure employing dozens of GPUs working in parallel, 30K+ CPU cores and 150TB of memory.
In This Role, You’ll Get to
Design, code, experiment and implement models and algorithms to maximize customer experience, supply side value, business outcomes, and infrastructure readiness
Mine a big data of hundreds of millions of customers and more than 600M daily user generated events, supplier and pricing data, and discover actionable insights to drive improvements and innovation
Work with developers and a variety of business owners to deliver daily results with the best quality
Research discover and harness new ideas that can make a difference
What You’ll Need To Succeed
4+ years hands-on data science experience
Excellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks
Significant proficiency in SQL and languages like Python, PySpark and/or Scala
Can lead, work independently as well as play a key role in a team
Good communication and interpersonal skills for working in a multicultural work environment
It’s Great if You Have
PhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields
Experience in NLP, image processing and/or recommendation systems
Hands on experience in data engineering, working with big data framework like Spark/Hadoop
Experience in data science for e-commerce and/or OTA
We welcome both local and international applications for this role. Full visa sponsorship and relocation assistance available for eligible candidates.
#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #shanghai #beijing #shenzhen #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #hongkong #budapest #jakarta #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #tokyo #osaka #kualalumpur #malta #amsterdam #oslo #manila #warsaw #krakow #doha #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4
Equal Opportunity Employer
At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.
We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .
To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.
Show more
Show less","Data Science, Machine Learning, Data science technology, Operational & Analytical Databases, Queue Systems, Business Intelligence Tools, SQL, Python, Spark/Hadoop, Scala, PySpark, NLP, Image processing, Recommendation Systems, Statistics, Coding, API, MySQL, MATLAB, Pandas, C, C++, Java, Nginx, R, Hadoop, Tableau, Power BI, QlikView, Google Analytics","Company Name: Agoda
Job Title: Data Scientist
Experience: The ideal candidate should have 4+ years of hands-on data science experience.
Skills Needed: The candidate should have an excellent understanding of AI/ML/DL and Statistics, proficiency in coding using open source libraries and frameworks, significant proficiency in SQL and languages like Python, PySpark, and/or Scala. Additionally, the candidate should be able to work independently as well as in a team, possess good communication and interpersonal skills for a",0.131621186034437,0.5658313
Senior Data Scientist,Trane Technologies,"Davidson, NC",https://www.linkedin.com/jobs/view/senior-data-scientist-at-trane-technologies-3777359426,2023-12-20,Salisbury,United States,Mid senior,Onsite,"Be a part of our mission!
As a world leader in creating comfortable, sustainable and efficient environments, it’s our responsibility to put the planet first. For us at Trane Technologies, sustainability is not just how we do business—it is our business. Do you dare to look at the world's challenges and see impactful possibilities? Do you want to contribute to making a better future? If the answer is yes, we invite you to consider joining us in boldly challenging what’s possible for a sustainable world.
If this sounds exciting to you, read on to learn more about who we are and what we believe in:
We uplift others –
we believe in providing an opportunity for all and building a culture that is diverse, inclusive, and respectful. We lift each other up and care about the success and well-being of others.
We make an impact
– we believe that what we do has the potential to change the world. We succeed together by striving daily to create a lasting, positive impact on the planet.
We thrive at work and at home
– we are supported by meaningful benefits, compensation, learning and development solutions, and opportunities for rewarding careers. We are firmly committed to the well-being and safety of our people.
This position is eligible for a Hybrid work schedule (3 or more days on-site a week) and will be based out of our Davidson, NC location
As a
Senior Data Scientist,
you will be responsible for leveraging advanced analytics and machine learning techniques to develop predictive models and algorithms that optimize HR processes and decision-making. They will collaborate with cross-functional teams to identify opportunities for AI implementation, enabling automation and efficiency in HR functions such as talent acquisition, performance management, and employee engagement. This role requires a deep understanding of HR data, statistical analysis, and the ability to translate complex insights into actionable recommendations for HR leaders.
What You Will Do
Develop and implement predictive models and algorithms using advanced analytics and machine learning techniques to optimize HR processes and decision-making.
Extract, clean, and analyze large datasets to derive meaningful insights and identify patterns and trends related to HR metrics, talent management, and employee engagement.
Collaborate with cross-functional teams to identify opportunities for AI implementation in HR functions
Translate complex technical concepts into actionable recommendations for HR leaders and stakeholders, effectively communicating the value and impact of data-driven solutions.
Stay up-to-date with the latest trends and advancements in data science, machine learning, and AI technologies, continuously learning and adapting to drive innovation in HR analytics.
Ensure data privacy and security by adhering to relevant regulations and best practices in data handling and analysis.
Conduct regular evaluations and assessments of implemented models and algorithms to measure their effectiveness and make necessary improvements.
Collaborate with IT, HR, and other analytics teams to ensure seamless integration and deployment of AI-enabled HR solutions.
What We Expect Of You
3+ years of experience in data science or analytics roles, with a focus on analytics and machine learning.
Proficiency in programming languages such as Python, R, or SQL for data extraction, cleaning, and analysis.
Excellent communication skills to effectively convey complex technical concepts to non-technical stakeholders.
Strong analytical and problem-solving skills to derive insights from large datasets.
Bachelor's or master's degree in data science, computer science, statistics, or a related field (preferred)
Base Compensation Range is $111,450 to $148,050
Disclaimer: This base salary range is based on US national averages. Actual base pay could be a result of seniority, merit, geographic location where the work is performed
We are committed to achieving workforce diversity reflective of our communities. We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identify, national origin, pregnancy, age, marital status, disability, status as a protected veteran, or any legally protected status.
2309369
Show more
Show less","Data Science, Machine Learning, AI, Python, R, SQL, Predictive Modeling, Data Analysis, Statistical Analysis, Data Visualization, Communication, ProblemSolving, Data Privacy, Data Security, HR Analytics, Talent Management, Employee Engagement","Company Name: Trane Technologies
Job Title: Senior Data Scientist
Experience: 3+ years of experience in data science or analytics roles
Skills Needed: Proficiency in programming languages such as Python, R, or SQL, excellent communication skills, strong analytical and problem-solving skills, Bachelor's or master's degree in data science, computer science, statistics, or a related field.",0.16040100046632874,0.21531345
ETL Datastage/Developer,HTC Global Services,"Concord, NC",https://www.linkedin.com/jobs/view/etl-datastage-developer-at-htc-global-services-3747065068,2023-12-20,Salisbury,United States,Mid senior,Onsite,"About HTC Global Services:
Shaping careers since 1990 - our long tenured employees are a testimony of the work culture. Join our global employee base of 12,000 and help us bring human expertise to tech in order to deliver purposeful solutions that amplify value.
Job Description:
The
Application Developer will participate in the full development lifecycle for Middle Office technology team projects including requirements gathering, technical design, development, testing, and implementation The team is looking for an experienced Sr. developer to take participate in a broad variety of application development initiatives across the front office line of business.
Major Responsibilities:
Collaborate with IT and Business partners to design, develop, and troubleshoot end to end technical solutions.
Develop high-quality software components in an environment of custom built applications and third-party products.
Test the resulting components in accordance with company standards and as defined in approved testing plans.
Investigate, analyze, and document reported defects – raising issues as appropriate.
Analyze production applications and debug errors upon failures.
Perform maintenance programming and correction of identified defects.
Create and maintain technical documentation using defined technical documentation templates that meet SDLC standards.
Required Skills / Qualifications:
Bachelor's degree in computer science or related discipline.
Ability to work as part of a team, communicate effectively at all organizational levels with written and verbal communication skills.
Analytical, problem solving, and troubleshooting skills.
Familiar with Agile development methodologies.
Self-directed, self-starter, and motivated with the ability to work with minimal supervision.
Strong organizational skills and ability to prioritize tasks.
10+ Years of Data Stage Design, Development and Deployment experience.
OR
10+ Years of OBIEE RPD Design, Development and Deployment experience using Analysis and/or BI Publisher.
Preferred Skills:
Experience and knowledge of Middle Office Trade Settlement, Corporate Actions, Pricing, Portfolio Accounting and Pricing domain. Any one of the domain experience is a big plus.
Excellent communication ( written and oral), with senior leaders and peers, facilitation, interpersonal and collaborative skills.
Ability to perform tasks of high complexity and to modify processes, plans and designs as needed.
Experience building large integrated enterprise applications.
Database Platforms:
Oracle
Data Integration Tools:
Data Stage
Application Development Languages:
UNIX shell scripting
Reporting Platforms:
Oracle Business Intelligence (OBIEE)
Scheduling Utilities:
Autosys
Automation and Productivity Tools:
GitHub
Jenkins
Jira
Industry Applications:
Murex
Benefits:
HTC’s competitive package includes besides compensation Health, Dental, Vision, Disability Cover, both short and long term, Life Insurance, Flexible Spending, 401k, and Paid Vacation.
Move ahead:
Our success as a company is built on practicing inclusion and embracing diversity. HTC Global Services is committed to providing a work environment free from discrimination and harassment, where all employees are treated with respect and dignity. Together we work to create and maintain an environment where everyone feels valued, included, and respected. At HTC Global Services, our differences are embraced and celebrated. HTC is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce. HTC is proud to be recognized as a National Minority Supplier and an equal opportunity employer of protected veterans.
EEO/M/F/V/H
Show more
Show less","UNIX shell scripting, Data Stage, Oracle Business Intelligence (OBIEE), Autosys, GitHub, Jenkins, Jira, Murex, Agile, Oracle","Company Name: HTC Global Services
Job Title: Application Developer
Experience Required: 10+ years

Job Description:
HTC Global Services is seeking an Application Developer to join their Middle Office technology team. The ideal candidate will be responsible for participating in the full development lifecycle of projects, collaborating with IT and Business partners, developing high-quality software components, testing components, debugging errors, and creating technical documentation. The role requires strong communication skills, analytical abilities, problem-solving skills, and familiarity with Agile development",0.1881188091810852,0.8303098
Senior Data Engineer,Trane Technologies,"Davidson, NC",https://www.linkedin.com/jobs/view/senior-data-engineer-at-trane-technologies-3743034197,2023-12-20,Salisbury,United States,Mid senior,Onsite,"At Trane TechnologiesTM and through our businesses including Trane® and Thermo King®, we create innovative climate solutions for buildings, homes, and transportation that challenge what’s possible for a sustainable world. We're a team that dares to look at the world's challenges and see impactful possibilities. We believe in a better future when we uplift others and enable our people to thrive at work and at home. We boldly go.
This position is eligible for a Hybrid work schedule (3 or more days onsite a week) and will be based out of our Davidson, NC location
Job Summary：
Develop and administer the People Analytics data management and analytics platforms. This role manages workforce data management and infrastructure, provides communication support / training, and administers data standards and support for the entire People analytics team. This role provides subject matter expertise on key HR reporting tools and data infrastructure.
Responsibilities
HR Data Management: Own all aspects of HR data, including acquisition, integration, transformation, quality, and governance.
Data Infrastructure: Design and maintain a scalable HR data infrastructure, following best practices for modeling, warehousing, and architecture.
Data Integration: Collaborate with HR, IT, and stakeholders to develop efficient data pipelines for extracting, transforming, and loading HR data.
Data Transformation: Cleanse, normalize, and enrich HR data, ensuring accuracy and consistency. Implement data quality checks and validation processes.
Data Governance: Establish and enforce data governance policies, ensuring compliance with privacy regulations and internal standards.
Performance Optimization: Monitor and optimize performance of data infrastructure, pipelines, and transformation processes.
Data Security: Implement robust security measures to protect HR data and comply with standards.
Collaboration and Leadership: Collaborate with cross-functional teams, mentor junior engineers, and provide data engineering support.
Qualifications
3+ years working in analytics
Proven experience as a Data Engineer, preferably in HR data management.
Strong knowledge of data engineering, modeling, warehousing, and architecture.
Proficiency in SQL and relational databases (e.g., MySQL, PostgreSQL).
Experience with data integration tools and technologies.
Programming skills in Python, Java, or relevant languages.
Familiarity with cloud-based data platforms (e.g., AWS, Azure, Google Cloud).
Proven experience as a Data Engineer, preferably in HR data management.
Bachelor’s degree
Key Competencies
Customer focus- The need to design solutions with a customer first perspective. The ability meet customers where they are, understand business needs and co-create solutions
Attention to detail- A natural disposition to distrust all data. The need to quality check every number is critical given the importance of the information we own and the seniority of leaders information flows to
Delivering Results- Ability to independently deliver results consistently with a focus on incremental value
Base Compensation Range is $114,450 to $148,050
Disclaimer: This base salary range is based on US national averages. Actual base pay could be a result of seniority, merit, geographic location where the work is performed
We offer competitive compensation and comprehensive benefits and programs. We are an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, pregnancy, age, marital status, disability, status as a protected veteran, or any legally protected status.
2307949
Show more
Show less","Data Engineering, Data Management, Data Governance, Data Infrastructure, Data Modeling, Data Integration, Data Warehousing, Data Quality, Data Transformation, Cloudbased Data Platforms, SQL, Relational Databases, Python, Java, AWS, Azure, Google Cloud","Company: Trane TechnologiesTM
Job Title: Data Engineer - People Analytics
Experience: 3+ years
Skills Needed: Data engineering, modeling, warehousing, and architecture, SQL and relational databases (e.g., MySQL, PostgreSQL), data integration tools and technologies, programming skills in Python, Java, or relevant languages, familiarity with cloud-based data platforms (e.g., AWS, Azure, Google Cloud).

This position at Trane TechnologiesTM in Davidson, NC involves developing and administering the People",0.21409921417665947,0.66117746
Sr Logistics Data Engineer,Trane Technologies,"Davidson, NC",https://www.linkedin.com/jobs/view/sr-logistics-data-engineer-at-trane-technologies-3774889169,2023-12-20,Salisbury,United States,Mid senior,Onsite,"At Trane TechnologiesTM and through our businesses including Trane® and Thermo King®, we create innovative climate solutions for buildings, homes, and transportation that challenge what’s possible for a sustainable world. We're a team that dares to look at the world's challenges and see impactful possibilities. We believe in a better future when we uplift others and enable our people to thrive at work and at home. We boldly go.
Job Summary
The Data Engineer will be responsible for developing a data ecosystem to incorporate supply chain related data into a unified and integrated data model. This model will serve as a foundation to all analytical efforts within the company’s Supply Chain function, enabling them to make higher quality decisions faster and with a higher degree of confidence. This position will be seen as vital to the execution of our vision and design of the data model from processes that ingest and process incoming data, enhance data products with analytical insights, and enforce standards and quality measurements to ensure that everything is working properly.
Work Arrangement: Hybrid
work schedule (3 or more days onsite a week) and will be based out of our Davidson, NC location.
Responsibilities
Developing large-scale data pipelines to ingest, move, transform, and integrate data to help generate insights and meet reporting needs
Design and build the end-to-end solution to move data from various sources into a unified cloud-based data hub
Liberate inaccessible data by partnering with process owners to capture and integrate information currently stored in closed-loop systems
Document requirements and translate into system design specifications
Educate functional analysts on proper methods of extracting and using data
Execute and coordinate requirements management and change management processes
Documentation of each of the created data products
Qualifications
Bachelors degree
3-5 years of experience
Understanding of database design principles
Experience writing SQL is required
Hands-on experience using Google BigQuery and Data Fusion a plus
Highly self‐motivated, self‐directed, and attentive to detail
Ability to effectively prioritize and execute tasks.
Strong project management and communication skills
Prior experience with ERPs or TMS software is preferred
Supply chain knowledge preferred
Optimize database run times
Support existing data pipelines
Monitor and troubleshoot data pipeline issues
Key Competencies and Success Factors
Project Management: Partners and collaborates with cross-functional leaders to align objectives, set project KPIs, identify gaps and solutions and oversee overall project implementation.
Problem Solving: Identifies/anticipates potential problems, performs root cause analysis, evaluates robustness of corrective action plan, and oversees plan implementation
Communication: Must be able to communicate in a clear, concise, and persuasive manner
Attention to Detail: Follows all standard work thoroughly and ensures that all standards are met
Dealing with Ambiguity: Able to fill in gaps in understanding and requirements and work with customers to improve clarity
Innate Curiosity – constant drive to learn more, ask questions, seek better outcomes
What’s In It For You
Benefits kick in day one!
6% 401K match, plus an additional 2% of eligible pay in core contributions
3 weeks of vacation per calendar year, plus paid holidays
Benefits*: https://www.tranetechnologies.com/en/index/careers/benefits.html
Base Pay Range: $100,000 - $135,000 / year and will include a bonus plan
Disclaimer: This base pay range is based on US national averages. Actual base pay could be a result of seniority, merit, geographic location where the work is performed.
We offer competitive compensation and comprehensive benefits and programs. We are an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, pregnancy, age, marital status, disability, status as a protected veteran, or any legally protected status.
2309131
Show more
Show less","Data Engineering, BigQuery, Data Fusion, SQL, Cloudbased data hub, ERPs, TMS, Supply chain knowledge, Project Management, Problem Solving, Communication, Attention to Detail, Dealing with Ambiguity, Database design principles","Company: Trane TechnologiesTM
Job Title: Data Engineer
Experience: 3-5 years
Skills Needed: The Data Engineer will be responsible for developing a data ecosystem to incorporate supply chain related data into a unified and integrated data model. This includes developing large-scale data pipelines, designing and building end-to-end solutions to move data into a cloud-based hub, liberating inaccessible data, documenting requirements, educating functional analysts on data extraction, executing requirements management processes, and documenting created data products. Qual",0.17943106996135966,0.69865
Contracts Data Analyst,Ingersoll Rand,"Davidson, NC",https://www.linkedin.com/jobs/view/contracts-data-analyst-at-ingersoll-rand-3782840317,2023-12-20,Salisbury,United States,Mid senior,Onsite,"Ingersoll Rand is committed to achieving workforce diversity reflective of our communities. We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.
This position supports the growing Service CARE Contracts Business aligning with Strategic corporate initiatives to dramatically grow recurring revenue in our Services business. This position will work with a team who is responsible for the management of contracts totaling over $140MM annual revenue, with profitability per year of approx $89MM and growing.
Job Summary
The CARE Contracts Specialist is responsible for activating, managing, and analyzing agreements covered under the CARE Service offerings. This position interacts daily with Sales, Service, and Operations personnel and will successfully utilize honed data processing, sales development, and analytical skills to ensure those personnel effectively execute on the company’s contracted CARE services. The position is critical for maintaining Ingersoll Rand’s level of service excellence for customers, both internal and external, as well as for the continued growth of the Services Recurring Revenue business model.
Responsibilities
Accurately establish, monitor, and manage contract information in contract administration systems, including Siebel, Salesforce, and SharePoint.
Setup invoicing according to contracts, manage recurring invoicing, and monitor invoice and revenue totals utilizing proper accounting practices.
Ensure documentation for contract modifications is accurate and complete.
Issue and support contract modifications and coordinate updates to all applicable systems.
Compile data for cost analysis and profitability tracking.
Enforce all Sarbanes-Oxley requirements.
Ensure accurate application of pricing increases and communicate effects.
Manage contract terminations process ensuring prompt and accurate financial reconciliation.
Manage contract renewal process.
Support all company goals for services contracts.
Respond to all customer issues in a professional and timely manner.
Additional Requirements
Position requires skills to address problems from multiple sources. A high-level of independent initiative and persistence is required to answer customer and sales team questions and resolve problems. Excellent analytic skills and attention to detail are required to maintain accurate financial accountability, including customer invoicing. The successful candidate will be able to quickly and independently learn about new offerings, systems, and technologies, as well as identify and tenaciously overcome obstacles. The CARE Contracts Specialist must be able to identify systems’ processing challenges and their potential consequences, and be confident and proactive when raising these and other issues. Typical processing problems include payment calculations, pricing validation, and long-term contracted services scheduling.
Qualifications
Bachelor’s degree preferred
Experience in CRM databases. Preferably expertise in Siebel, Oracle, or Salesforce.
Advanced database and analytic skills.
Highly developed proficiency in MS Office Suite, especially Excel, Outlook, and SharePoint.
Familiarity with financial metrics, accounting practices & processes, invoicing, and sales reporting are also highly preferred.
5 years of professional experience, with minimum 2-3 years of experience in a customer-facing role (sales, inside sales, direct sales-support, customer service, etc) for an industrial/manufacturing/Fortune 500 required. Ideal candidate will have had exposure to both industrial sales support functions and contract administration.
#WEC
Ingersoll Rand Inc. (NYSE:IR), driven by an entrepreneurial spirit and ownership mindset, is dedicated to helping make life better for our employees, customers and communities. Customers lean on us for our technology-driven excellence in mission-critical flow creation and industrial solutions across 40+ respected brands where our products and services excel in the most complex and harsh conditions. Our employees develop customers for life through their daily commitment to expertise, productivity and efficiency. For more information, visit www.IRCO.com.
Show more
Show less","Siebel, Salesforce, SharePoint, Excel, Outlook, MS Office Suite, Oracle, CRM databases, Financial metrics, Accounting practices, Invoicing, Sales reporting","Company: Ingersoll Rand Inc.
Job Title: CARE Contracts Specialist
Experience: 5 years of professional experience, with minimum 2-3 years in a customer-facing role
Skills:
- Experience in CRM databases such as Siebel, Oracle, or Salesforce
- Advanced database and analytic skills
- Proficiency in MS Office Suite, especially Excel, Outlook, and SharePoint
- Familiarity with financial metrics, accounting practices, invoicing, and sales reporting
- Strong attention to detail",0.22222221993778316,0.7412011
Sr. Data Analytics Auditor,Ahold Delhaize,"Salisbury, NC",https://www.linkedin.com/jobs/view/sr-data-analytics-auditor-at-ahold-delhaize-3778384322,2023-12-20,Salisbury,United States,Mid senior,Onsite,"Address:
USA-NC-Salisbury-2085 Harrison Road
Store Code:
Internal Audit (5101835)
Ahold Delhaize is one of the world's largest food retail groups and a leader in both supermarkets and e-Commerce. Its family of great, local brands serves more than 50 million customers each week in Europe, the United States and Indonesia. Together, these brands employ more than 420,000 associates in more than 7,000 grocery and specialty stores. Our Global Support Office (GSO) is based in Zaandam in the Netherlands, but GSO associates also work in all the countries we serve. This team supports all our great local brands in finance, HR, IT, legal, communications, sustainable retailing, and other key functions. .
Job Objective:
As a Senior Data Analytics Auditor, you will work as part of our global internal audit team to translate our vision of being data driven internal audit function into reality. You will take this vision and partner with our US internal audit management team to initiate, build, and develop the data analytics capability of our full US team. Furthermore, you will help our business partners achieve their goals and objectives by managing risk.
A sharp, critical thinker who thrives in a team environment and enjoys collaborating. You use independent and creative thought to acquire information, analyze sophisticated situations and tackle problems. You excel in and enjoy communicating and you listen carefully to understand. You embrace technology and can adapt and thrive in a fast-paced, changing environment.
Essential Functions:
Maintaining proactive relationships with business management teams to stay in-sync with a constantly evolving business environment;
Interpreting data and anticipate potential outcomes and impact;
Identifying potential control weaknesses through data driven analysis;
Crafting impactful recommendations to assist management in better managing their risks;
Communicating audit results to senior leaders; and
Attending learning programs, training and networking sessions while preparing yourself to become a future leader in our organization.
Qualifications:
Bachelor’s degree or equivalent experience and relevant business experience in fields such as Mathematics, Computer Science, or Statistics
4-6 years’ experience in a professional work environment
At least 2 years of data analytics or data engineering experience, preferably in a retail environment
Critical thinking skills – use independent thought to acquire information and analyze sophisticated situations
Effective communication skills – convey information and ideas concisely; both verbally and in writing
Project management skills – work in and/or lead teams to optimally perform work and prioritize assignments within challenging deadlines
Experience and exposure with working in a Microsoft Azure (or equivalent) Data Platform environment
Experience with Databricks and Azure Data Factory
Experience and an understanding of infrastructure as code concepts and utilizing code management tools (i.e., GitHub)
Proficiency in Python/PySpark, and SQL
Aptitude and desire to understand how technology (i.e. data analytics, general IT processes, robotic process automation, machine learning, etc.) impacts business processes
Already possess or have a willingness to gain credentials in your field
Ability to travel within the US 10-20%
Preferred Qualifications:
Business Acumen – the ability to understand organizational processes and objectives as well as acquire organizational insight through effective relationships
Influence/Persuasion – the ability to collaborate with others to remove organizational barriers and use persuasive techniques to reach consensus
Experience in the field of auditing technology control disciplines such as robotic process automation, security, application development, change management and computer operations
Experience with tools such as ACL, Tableau, Alteryx, Power BI, Microsoft Access or other related data analytics tools
Knowledge/experience with SAP and/or other ERP systems
Experience in and/or passion for retail
The GSO sets global strategies frameworks, facilitates the sharing of best practice and encourages economies of scale. Great examples include sharing technology and digital know-how, so we can continue to lead in online and in-store retailing, setting global targets for healthy and sustainable products-including reducing food waste, use of plastics and making our products healthier to use and eat, and championing development for our future leaders-from learning about the digital mindset to leading our stores of the future.
Under the federal Transparency in Coverage rule, group health plans are required to make publicly available machine-readable files that include in-network rates and out-of-network allowed amounts and billed charges. Click
the link
to view the in-network rates and out-of-network allowed amounts and billed charges under the welfare benefits plan in which GSO participates
We are an equal opportunity employer. We comply with all applicable federal, state and local laws. Qualified applicants are considered without regard to sex, race, color, ancestry, national origin, citizenship status, religion, age, marital status (including civil unions), military service, veteran status, pregnancy (including childbirth and related medical conditions), genetic information, sexual orientation, gender identity, legally recognized disability, domestic violence victim status or any other characteristic protected by law.
Job Requisition: 348167_external_USA-NC-Salisbury_1242023
#AholdDelhaizeUS
Show more
Show less","Data Analytics, Data Engineering, Python, PySpark, SQL, Microsoft Azure, Databricks, Azure Data Factory, GitHub, Infrastructure as Code, Business Acumen, Influence, Persuasion, Robotic Process Automation, Security, Application Development, Change Management, Data Analytics Tools, SAP, ERP, Retail","Company Name: Ahold Delhaize
Job Title: Senior Data Analytics Auditor
Experience: 4-6 years of relevant professional work experience
Skills Needed: 
- Bachelor’s degree in Mathematics, Computer Science, or Statistics
- 2 years of data analytics or data engineering experience, preferably in a retail environment
- Critical thinking skills
- Effective communication skills
- Project management skills
- Experience with Microsoft Azure Data Platform, Databricks, and Azure Data Factory
- Proficiency",0.16890594823788596,0.52571017
Volunteer: Educational Data Scientist at Nature Counter by CrowdDoing,CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-educational-data-scientist-at-nature-counter-by-crowddoing-at-crowddoing-3774593311,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Educational Data Scientist at Nature Counter by CrowdDoing
The Educational Data Scientist works closely with the Learning Analytics Specialist to analyze and interpret complex datasets related to user learning. They use statistical tools and methods to uncover insights and patterns that can inform improvements in the learning materials.
Responsibilities include
Collecting, processing, and analyzing user data related to the learning experience.
Using advanced statistical methods to interpret data and extract insights.
Collaborating with the instructional design team to apply data insights for iterative improvements.
Ensuring the privacy and security of user data.
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine learning, Artificial intelligence, Virtual assistants, Blockchain, Project management, Human resources, Collaboration, Educational data science, Learning analytics, Statistical analysis, Data interpretation, Instructional design, Data privacy, Data security","Company: CrowdDoing
Job Title: Educational Data Scientist at Nature Counter

Experience: Not specified

Skills needed: 
- Experience in analyzing and interpreting complex datasets related to user learning
- Proficiency in using statistical tools and methods to uncover insights and patterns
- Ability to collaborate with instructional design team to apply data insights for improvements
- Knowledge of ensuring privacy and security of user data",0.3142857106575964,0.61415195
Volunteer: Wildfire Prevention Financing Data Scientist- CrowdDoing Volunteer,CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-wildfire-prevention-financing-data-scientist-crowddoing-volunteer-at-crowddoing-3773454585,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Wildfire Prevention Financing Data Analyst- CrowdDoing Volunteer
-Prevention derivatives is driven by the thesis that there is an under-valuation of passive risk (or the cost of inaction) and an under-prioritization of positive risk. Correspondingly for wildfires as an example, there is an under-recognition of the potential shared value upside of preventative action through social innovation and social interventions (such as goats & sheep that prevent wildfires). CrowdDoing.world's aim is to guarantee positive risk through leveraging existing liabilities to allow for the implications of prescriptive analytics to be financed. The under-pricing of passive risk means that liabilities are treated as either costs of doing business or un-predictable risks even for entirely preventable risks. Risk management offices have been too biased towards avoiding taking the wrong risks rather than ensuring that institutions make their own luck by seizing the abundant positive risk opportunities in social innovation. Meanwhile, the bias against positive risk leaves social innovations not to get adopted even if there would be remarkable benefits to all stakeholders if they were adopted
In the framework of Prevention Derivatives, we want to create a predictive machine learning (ML) model that for a given geographical region will estimate likely savings (losses) due-to protection (damages) of stakeholders’ properties, business profits, common health, and regional ecology resulting in applying risk prevention solutions (or doing nothing instead). Goal of these notes is to analyze ML model’s design, offer a potential improvement and to discuss existing approaches for data collection, and training and testing the model. It is important to notice that the model is applied to the entire selected or target region. Therefore, a geographical region
R
is the smallest unit we apply modeling to.
Data science will be utilized in the following ways
Explore/Visualize data currently available on Wildfires
Identify trends and patterns in Historical data
Quantify historical losses in dollars based on property destruction, casualties, acres burnt, etc.
Build predictive models to identify areas of high wildfire risk based on factors such as weather, vegetation, topography, etc.
Visualization of Model outcomes
Scenario building (changing input variables and observing impact on outcome)
Tools - R, Python, MATLAB, SQL, PowerPoint
Knowledge or Interest in anyone or more
Programming for Data Science
Mathematics
Statistics
Predictive Analytics
Prescriptive Analytics
Machine Learning - Supervised/Unsupervised learning
Artificial Intelligence
Data Mining
Computer Science
Monte Carlo Simulations This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine learning, Artificial intelligence, Virtual assistants, Blockchain, Microleadership, Service learning, Project management, Human resource management, Data science, Data visualization, Predictive analytics, Prescriptive analytics, Computer science, Monte Carlo simulations, R, Python, MATLAB, SQL, PowerPoint, Programming for data science, Mathematics, Statistics, Supervised learning, Unsupervised learning","Company Name: CrowdDoing
Job Title: Wildfire Prevention Financing Data Analyst
Experience: Volunteer position
Skills Needed: Programming for Data Science, Mathematics, Statistics, Predictive Analytics, Prescriptive Analytics, Machine Learning (Supervised/Unsupervised learning), Artificial Intelligence, Data Mining, Computer Science, Monte Carlo Simulations. Proficiency in R, Python, MATLAB, SQL, PowerPoint. Interest in social innovation and risk management. Ability to analyze and visualize data related to wildfires, identify trends and",0.16915422645776096,0.4721084
Volunteer: Wildfire Prevention Financing Data Scientist- CrowdDoing Volunteer,CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-wildfire-prevention-financing-data-scientist-crowddoing-volunteer-at-crowddoing-3773458203,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Wildfire Prevention Data Scientist CrowdDoing Volunteer
-Prevention derivatives is driven by the thesis that there is an under-valuation of passive risk (or the cost of inaction) and an under-prioritization of positive risk. Correspondingly for wildfires as an example, there is an under-recognition of the potential shared value upside of preventative action through social innovation and social interventions (such as goats & sheep that prevent wildfires). CrowdDoing.world's aim is to guarantee positive risk through leveraging existing liabilities to allow for the implications of prescriptive analytics to be financed. The under-pricing of passive risk means that liabilities are treated as either costs of doing business or un-predictable risks even for entirely preventable risks. Risk management offices have been too biased towards avoiding taking the wrong risks rather than ensuring that institutions make their own luck by seizing the abundant positive risk opportunities in social innovation. Meanwhile, the bias against positive risk leaves social innovations not to get adopted even if there would be remarkable benefits to all stakeholders if they were adopted
In the framework of Prevention Derivatives, we want to create a predictive machine learning (ML) model that for a given geographical region will estimate likely savings (losses) due-to protection (damages) of stakeholders’ properties, business profits, common health, and regional ecology resulting in applying risk prevention solutions (or doing nothing instead). Goal of these notes is to analyze ML model’s design, offer a potential improvement and to discuss existing approaches for data collection, and training and testing the model. It is important to notice that the model is applied to the entire selected or target region. Therefore, a geographical region R is the smallest unit we apply modeling to.
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Tools - R, Python, MATLAB, SQL, PowerPoint
Knowledge or Interest in anyone or more
Programming for Data Science
Mathematics
Statistics
Predictive Analytics
Prescriptive Analytics
Machine Learning - Supervised/Unsupervised learning
Artificial Intelligence
Data Mining
Computer Science
Monte Carlo Simulations
Expectations
Identify papers on Simulation of Wildfires, Catastrophe Modeling
Review and present Technical papers in a way that everyone can understand
Assist in Model development and testing by contributing in finding data and programming
Identify/Collect data relevant to wildfire Impact
Work cross-functionally
Traits
Mathematically inclined, highly analytical, creative problem solver, can conduct analyses independently or with minimal supervision.
Show more
Show less","Machine Learning, Artificial Intelligence, Data Mining, Predictive Analytics, Prescriptive Analytics, Supervised Learning, Unsupervised Learning, SQL, Python, R, MATLAB, Monte Carlo Simulations, PowerPoint, Statistics, Data Science, Computer Science","Company Name: Match4Action Foundation
Job Title: Wildfire Prevention Data Scientist CrowdDoing Volunteer
Experience: Volunteer opportunity
Skills Needed: R, Python, MATLAB, SQL, PowerPoint, Programming for Data Science, Mathematics, Statistics, Predictive Analytics, Prescriptive Analytics, Machine Learning (Supervised/Unsupervised learning), Artificial Intelligence, Data Mining, Computer Science, Monte Carlo Simulations
Description: Match4Action connects volunteers with skills to support remote or local projects for social impact. The",0.17302798745139175,0.5652107
"Volunteer: Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing,",CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-risk-prevention-data-scientist-volunteer-forest-fire-prevention-derivatives-crowddoing-at-crowddoing-3773407628,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing,
See more detailed background on CrowdDoing's forest fire prevention derivatives
https //drive.google.com/file/d/1dBp_HUr-tCCNaeGoSDfPrirRPbaoV3X4/view?usp=sharing
Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing,
Bobby Fishkin, lead author
In 2018, Sacramento was named the ""the Most Polluted City on Earth"" due to ""smoke from Camp Fire,"" This proposal aims to prevent that from happening again through adopting a systemic approach and collaborating with stakeholders to actively prevent future such events. The insurance industry, along with institutional chief risk officers, have begun to recognize the importance of moving from ""loss compensation to loss prevention.""
CrowdDoing and Project Heather propose launching a prevention derivative with two new stakeholders (a) contingent payers who pay in proportion to the reduction in risk, and (b) impact investors who finance social innovations in which their return is similarly proportional to the reduction in risk. It will build on existing precedents for contingent contracts involving social- innovation-based risk prevention.
Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing, Duties and Responsibilities
Managing analytics database
Implementing processes that improve and lead to greater data quality
Conducting statistical analyses to develop strategies
Documenting all processes and research
Building new algorithms and model training
Executing projects involving analytics
Identifying data patterns and trends
Analyzing data to develop predictive models
Creating, managing, and maintaining analytically rigorous data
Noting anomaly detection and running diagnostics
Performing graphical model analysis
Possessing a solid machine learning foundation
Participating in software-focused marketing efforts
Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing, Requirements and Qualifications
Expert in statistical modeling/data mining
Experienced with SQL Server
Experienced in data analysis, predictive modeling, and data mining techniques
Able to analyze problems and strategize for better solutions
Excellent verbal and written communication skills
Able to multitask, prioritize, and manage time effectively
Comfortable in both a leadership and team-player role
Creative problem solver who thrives when presented with a challenge
Goal-oriented, organized team player
Encouraging to team and staff; able to mentor and lead
Bachelor’s degree in computer science, engineering, mathematics or related field; Master’s degree in computer science, mathematics or related field preferred
Four years of relevant industry experience
Strong familiarity and hands-on experience with SQL and statistical software packages (Python, R, SAS)
Knowledge of tools and techniques in machine learning
Expert in relational database design and concepts
Expert in one or more programming languages (C/C++, Python, Perl, Java)
Experience in genetic algorithms, logistic and linear regression, PCA, decision tree anal
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine Learning, Artificial Intelligence, Virtual Assistants, Blockchain, Social Impact Currency, Project Management, Human Resource Business Partners, Data Analysis, Predictive Modeling, Data Mining, Statistical Modeling, SQL Server, Python, R, SAS, C/C++, Perl, Java, Genetic Algorithms, Logistic Regression, Linear Regression, PCA, Decision Tree Analysis","Company: CrowdDoing
Job Title: Risk Prevention Data Scientist Volunteer - Forest Fire Prevention Derivatives
Experience: Four years of relevant industry experience
Skills Needed: Expert in statistical modeling/data mining, SQL Server experience, data analysis, predictive modeling, and data mining techniques, strong familiarity with SQL and statistical software packages (Python, R, SAS), knowledge of tools and techniques in machine learning, relational database design, programming languages (C/C++, Python, Perl, Java), experience in genetic algorithms,",0.2168674673718682,0.45305967
"Volunteer: Risk Prevention Data Scientist Virtual Volunteer Wildfire Prevention Derivatives, CrowdDoing,",CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-risk-prevention-data-scientist-virtual-volunteer-wildfire-prevention-derivatives-crowddoing-at-crowddoing-3773999734,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Risk Prevention Data Scientist Virtual Volunteer Wildfire Prevention Derivatives, CrowdDoing,
You can see a 35 minute video on prevention derivatives here
https //www.youtube.com/watch?v=btdpHKlZj2c&feature=youtu.be
Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing, Duties and Responsibilities
Implementing processes that improve and lead to greater data quality
Conducting statistical analyses to develop strategies
Documenting all processes and research
Building new algorithms and model training
Executing projects involving analytics
Identifying data patterns and trends
Analyzing data to develop predictive models
Creating, managing, and maintaining analytically rigorous data
Noting anomaly detection and running diagnostics
Performing graphical model analysis
Possessing a solid machine learning foundation
Participating in software-focused marketing efforts
Risk Prevention Data Scientist Volunteer Forest Fire Prevention Derivatives, CrowdDoing, Requirements and Qualifications
Expert in statistical modeling/data mining
Experienced with SQL Server
Experienced in data analysis, predictive modeling, and data mining techniques
Able to analyze problems and strategize for better solutions
Excellent verbal and written communication skills
Able to multitask, prioritize, and manage time effectively
Comfortable in both a leadership and team-player role
Creative problem solver who thrives when presented with a challenge
Goal-oriented, organized team player
Encouraging to team and staff; able to mentor and lead
Bachelor’s degree in computer science, engineering, mathematics or related field; Master’s degree in computer science, mathematics or related field preferred
Four years of relevant industry experience
Strong familiarity and hands-on experience with SQL and statistical software packages (Python, R, SAS)
Knowledge of tools and techniques in machine learning
Expert in relational database design and concepts
Expert in one or more programming languages (C/C++, Python, Perl, Java)
Experience in genetic algorithms, logistic and linear regression, PCA, decision tree analysis and statistical methods
Up-to-date on latest industry trends; able to articulate trends and potential clearly and confidently
Good interpersonal skills and communication with all levels of management
Able to work in a fast-paced environment
The only way CrowdDoing.world can realize its impact potential is through virtual volunteers,service learners(http //blog.reframeit.com/service-learning-and-skilled-volunteering/), and micro-leaders (https //real-leaders.com/leveraging-micro-leadership-to-make-aspirational-goals-achievable/) coming together.
If you have any questions about processes for joining crowddoing as a volunteer please write to volunteerorientation@crowddoing.world
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine learning, Artificial intelligence, Virtual assistants, Blockchain, CrowdDoing, Data analysis, Predictive modeling, Data mining, SQL, Python, R, SAS, Relational database design, C/C++, Perl, Java, Genetic algorithms, Logistic regression, Linear regression, PCA, Decision tree analysis, Statistical methods","Company: CrowdDoing
Job Title: Risk Prevention Data Scientist Volunteer for Forest Fire Prevention Derivatives
Experience: Four years of relevant industry experience
Skills Needed: Expertise in statistical modeling/data mining, experienced with SQL Server, data analysis, predictive modeling, and data mining techniques, strong familiarity with SQL and statistical software packages (Python, R, SAS), knowledge of tools and techniques in machine learning, proficiency in programming languages (C/C++, Python, Perl, Java), experience in genetic algorithms,",0.2239999973484089,0.45193964
"Volunteer: Medicinal Foods, Data Scientist Volunteer",CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-medicinal-foods-data-scientist-volunteer-at-crowddoing-3773191304,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Medicinal Foods for Stress, Sleep and Anxiety is recruiting Medicinal Foods, Data Scientist Volunteer.
We're helping to build medicinal foods literacy and citizen science of foods & herbs for Stress, Sleep and Anxiety.
Here is the main package for your review to determine if you are interested docs.google.com/document/d/1bT47d5eDE2NVW606d1Y7TeKp1hDHyP_JBuJ94Cyy0B4/edit?usp=sharing .
Please feel free to view this powerpoint to get an overview of this initiative docs.google.com/presentation/d/12aEqwiRctIx3QcvK6HNFy4uJ5TgRffxQ7xPLEINNyJw/edit?usp=sharing
Did you know that there are thousands of foods and herbs that can impact our mental health in positive ways? CrowdDoing is a global virtual collaboration to research medicinal foods for stress, sleep and anxiety. Our project has the goal of advancing integration across fields of research and to build medicinal foods literacies in the population. We're recruiting virtual volunteer service learning project managers.
This role is for Medicinal Foods, Medicinal Foods Service Learning Micro-Leadership Project Management. CrowdDoing aims to make each role flexible, allowing you to become engaged according to your own schedule. You will have the chance to assume micro-leadership responsibilities in keeping with your aspirations and availability. https //real-leaders.com/leveraging-micro-leadership-to-make-aspirational-goals-achievable/.
Please get in touch if you would be interested in supporting us through the role of
Medicinal Foods, Data Scientist Volunteer
We are looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve our initiative. We will rely on you to build data products to extract valuable business and impact insights.
In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research.
Your goal will be to help our initiative analyze information to make better decisions about recommendations.
Medicinal Foods, Data Scientist Volunteer Responsibilities
Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Medicinal Foods, Data Scientist Volunteer Requirements
Proven experience as a Data Scientist
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred
""To help support you joining the right part of CrowdDoing for you, please use this form https //docs.google.com/forms/d/e/1FAIpQLSftd6E0tyV2uq7mMty1rZ80BB2MSGhbnof9gRBvaQXbrttIkg/viewform?usp=sf_link""
Mission Statement CrowdDoing.world's Foods.& Herbs for Stress,Sleep & Anxie
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine Learning, Artificial Intelligence, Data Science, Data Mining, Operations Research, R, SQL, Python, Scala, Java, C++, Tableau, Hadoop, Statistics, Algebra, Problem Solving, Communication, Presentation, Computer Science, Engineering, Data Frameworks","Company: Match4Action/CrowdDoing
Job Title: Medicinal Foods, Data Scientist Volunteer
Experience: Proven experience as a Data Scientist
Skills Needed: Experience in data mining, understanding of machine-learning and operations research, knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset, experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop), analytical mind and business acumen, strong math skills (",0.19597989711560315,0.51472723
Volunteer: CrowdDoing Medicinal Foods - Data Science,CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-crowddoing-medicinal-foods-data-science-at-crowddoing-3773121842,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
CrowdDoing Medicinal Foods seeks Amazon Web Services (AWS) ecosystem experts who have experience using python as the primary programming language for analysis.
About The Project
Use citizen science to gather and validate data about the different foods and food-preparations from both traditional knowledge and current scientific inquiry.
Primary Skills
Ability to access/interact with database directly. Solutions include
PG Admin - SQL graphical user interface.
SQL Alchemy - Python Json library package to work directly with relational databases.
Ability to export data from rds. Solutions include
CSV - Preferred, due to it’s tabular format.
JSON - Viable if used with python, but would likely require transformation into tabular format.
Ability to perform analysis on a static portion of the database. Solutions include
Allow data to be queried for a certain time period.
Clone rds and periodically update it, to create a pseudo data warehouse.
""To help support you joining the right part of CrowdDoing for you, please use this form https //docs.google.com/forms/d/e/1FAIpQLSftd6E0tyV2uq7mMty1rZ80BB2MSGhbnof9gRBvaQXbrttIkg/viewform?usp=sf_link""
The only way CrowdDoing.world can realize its impact potential is through virtual volunteers,service learners(http //blog.reframeit.com/service-learning-and-skilled-volunteering/), and micro-leaders (https //real-leaders.com/leveraging-micro-leadership-to-make-aspirational-goals-achievable/) coming together.
See this brief video aboutMicro-leadership at CrowdDoing (https //www.youtube.com/watch?v=mhdB2YJ8Ocs&app=desktop). Micro-leadership means that each person adopts a dimension of responsibility for a collective problem in our society through collaborating on that area creatively individually and together through social innovation.
You are also welcome to see more background on CrowdDoing at our Youtube Channel (https //www.youtube.com/channel/UCVoL7fai7oa95fBo44FC0gA?sub_confirmation=1).
Instagram (https //www.instagram.com/crowddoing.world/),
Facebook (https //www.facebook.com/CrowdDoing-515295062320613) ,
LinkedIn (https //www.linkedin.com/company/18910309/).
You can see a CrowdDoing Volunteering FAQ here.
https //docs.google.com/document/d/1zCkbEQX8PHh8k85BS0iIhsJJxADqdH3Kpn1PDbI1Uno/edit?usp=sharing
If you have any questions about processes for joining crowddoing
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine Learning, Artificial Intelligence, Virtual Assistants, Blockchain, Project Management, Human Resource Business Partners, Amazon Web Services (AWS), Python, SQL Alchemy, JSON, CSV, RDS, Data Warehousing, Database Interaction, Data Analysis, MicroLeadership, Service Learning","Company Name: Match4Action Foundation
Job Title: CrowdDoing Medicinal Foods AWS Ecosystem Expert
Experience: Not specified
Skills Needed: 
- Experience using Python as the primary programming language for analysis
- Ability to access/interact with databases directly using tools such as PG Admin and SQL Alchemy
- Proficiency in exporting data from RDS in formats like CSV and JSON
- Capability to perform analysis on a static portion of the database by querying for a certain time period or creating",0.2457142826540408,0.6810905
"Volunteer: Cloud Data Engineer,CloudData Virtual Volunteer Job for CrowdDoing",CrowdDoing,"El Dorado Hills, CA",https://www.linkedin.com/jobs/view/volunteer-cloud-data-engineer-clouddata-virtual-volunteer-job-for-crowddoing-at-crowddoing-3773454588,2023-12-20,Newcastle,United States,Associate,Onsite,"Match4Action connects those wanting to volunteer their skills with those in need for remote or local project support, advice, collaboration and mentoring.
Our smart technology platform uses the latest machine learning, artificial intelligence and virtual assistants to match the demand for resources for social impact with the skills and resources available, anywhere in the world. We use blockchain to create and manage a social impact currency.This unique, self sustainable open platform has one key purpose accelerating social impact through collaboration and linking local projects with our global presence.
CrowdDoing aims to leverage micro-leadership, service learning and massively multi-disciplinary collaboration supported with project managers and human resource business partners. Collaborate with people whom you can learn from while changing the world virtually together.
crowddoing.world
http //www.linkedin.com/company/m4a-foundation
https //www.linkedin.com/company/crowddoing/
https //www.facebook.com/Match4ActionFoundation/
https //www.facebook.com/groups/219137818932726/
Project Medicinal Foods for Stress, Sleep and Anxiety
Key Responsibilities
Work with the team to evaluate business needs and priorities, liaise with key business partners and address team needs related to data systems and management.
Translate business requirements into technical specifications; establish and define details, definitions, and requirements of applications, components and enhancements.
Participate in project planning; identifying milestones deliverables and resource requirements; track activities and task execution.
Generate design, development, test plans, detailed functional specifications documents, user interface design, and process flow charts for execution of programming.
Develop data pipelines / APIs using Python, SQL, potentially Spark and AWS, Azure or GCP Methods.
Use an analytical, data-driven approach to drive a deep understanding of fast changing business.
Build large-scale batch and real-time data pipelines with data processing frameworks in AWS, Azure or GCP cloud platform.
Virtual catch up meeting every week with the team
Comfortable working in a startup phase non-profit organization
We hope you will be able to contribute about 10 hours a week within a 4-6 week period with no less than 3 month Commitment.
Qualification
1 years of experience in data engineering with an emphasis on data analytics and reporting.
1 years of experience with at least one of the following cloud platforms Microsoft Azure, Amazon Web Services (AWS), Google Cloud Platform (GCP), others.
1 years of experience in SQL, data transformations, statistical analysis, and troubleshooting across more than one Database Platform (Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Warehouse, etc.).
1 years of experience in the design and build of data extraction, transformation, and loading processes by writing custom data pipelines.
1 years of experience with one or more of the following scripting languages Python, SQL, Kafka and/or other.
1 years of experience designing and building solutions utilizing various Cloud services such as EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API gateway, etc.
The only way CrowdDoing.world can realize its impact potential is through virtual volunteers,service learners(http //blog.reframeit.com/service-learning-and-skilled-volunteering/), and micro-leaders (https //real-leaders.com/leveraging-micro-leadership-to-make-aspirational-goals-achievable/) coming together.
See this brief video about Micro-leadership at CrowdDoing (https //www.youtube.com/watch?v=mhdB2YJ8Ocs&app=desktop). Micro-leadership means that each person adopts a dimension of responsibility for a collective problem in our society through collaborating on that area creatively individually and together through social innovation.
You are also welcome to see more background on CrowdDoing at our Youtube Channel (https //www.youtube.com/channel/UCVoL7fai7oa95fBo44FC0gA?sub_confirmation=1).
<
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Machine Learning, Artificial Intelligence, Virtual Assistants, Blockchain, Social Impact Currency, MicroLeadership, Service Learning, Project Managers, Human Resource Business Partners, Python, SQL, Spark, AWS, Azure, GCP, Data Pipelines, APIs, Statistical Analysis, Database Platforms, Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Warehouse, Data Extraction, Data Transformation, Data Loading, Custom Data Pipelines, Scripting Languages, Kafka, Cloud Services, EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API Gateway","Company: Match4Action / CrowdDoing
Job Title: Data Engineer - Project Medicinal Foods for Stress, Sleep and Anxiety
Experience: 1 year
Skills Needed: Data engineering with a focus on data analytics and reporting, experience with cloud platforms (Microsoft Azure, AWS, GCP), SQL proficiency, data transformation and statistical analysis across multiple Database Platforms, designing and building data pipelines using Python and SQL, familiarity with cloud services like EC2, S3, EMR, etc.
The job",0.18765431842902,0.5799432
"Job - Data Engineer  (DDR memory, data scientist with Python, Elasticsearch ) - JV",Cube Hub Inc.,"Folsom, CA",https://www.linkedin.com/jobs/view/job-data-engineer-ddr-memory-data-scientist-with-python-elasticsearch-jv-at-cube-hub-inc-3627343537,2023-12-20,Newcastle,United States,Mid senior,Onsite,"Position Title: Database Engineer (DDR memory, Data scientist Elasticsearch
)
Job Location: Folsom, California
Job Duration: 6 months
Please note: This role will be 100% Remote in any US location
There is some flexibility on the start and end time.
Will be required to join a late night call at least once a week.
The sponsor would be willing to conside familiar with
DDR memory, Data scientist with Python
experience.
He would also like for candidates to be
familiar with Elasticsearch
experience
Description
Database Engineer works on a multidisciplinary project in collaboration with software and hardware engineers in the design, development, and utilization of database enhancement tools.
Your Responsibility Includes But Will Not Be Limited To
Creating production-quality software systems of enterprise-scale, crafting data pipelines handling enterprise data loads, connecting heterogeneous systems, and providing analytical capabilities that can grow.
Develop tools, technologies, frameworks that will enable us to move faster and decide better.t.
Are comfortable designing, implementing, validating, and preparing datasets for future algorithms.
Develop code to scrub, consolidate, analyze, and visualize data
Create code that's simple, clean, and follows design patterns.
Have a solid understanding of
elastic
and other index-based
search technologies
Qualifications
You must possess the below minimum qualifications to be initially considered for this position.
Preferred qualifications are in addition to the requirements and are considered a plus factor in identifying top candidates.
Knowledge and/or experience listed below would be obtained through a combination of your school work and/or classes and/or research and/or relevant previous job and/or internship experiences .
Minimum Qualifications
Must have experience with database use and design.
Must have Data scientist
Coding proficiency in
python
Basic knowledge of platform architecture and memory
Experience working with data belonging to a statistical pipeline.
Extraction, sanitization, analysis, visualization, and automation.
Preferred Qualifications
Hands-on with elastic search or other search technologies.
Familiarity with at least one UI framework, libraries like React.
Familiar with s
cripting - shell, Bash, PowerShell
, etc, you should identify and automate boring tasks.
Know clean code rules
Familiarity with
github
Minimum Educational Requirement: Bachelor's degree or higher - no exceptions
Show more
Show less","DDR memory, Elasticsearch, Python, Shell, Bash, PowerShell, React, GitHub","Company: Not specified
Job Title: Database Engineer
Experience: Must have experience with database use and design, Data scientist, Coding proficiency in Python, basic knowledge of platform architecture and memory, experience working with data belonging to a statistical pipeline.
Skills: Familiarity with Elasticsearch, hands-on experience with search technologies, familiarity with at least one UI framework, experience with scripting languages like shell, Bash, PowerShell, knowledge of clean code rules, familiarity with GitHub.
",0.27999999688088895,0.68627477
"Urgent Hiring || Bigdata Developer with BI ||Rancho Cordova, CA- Day one onsite Hybrid",Echo IT Solutions,"Rancho Cordova, CA",https://www.linkedin.com/jobs/view/urgent-hiring-bigdata-developer-with-bi-rancho-cordova-ca-day-one-onsite-hybrid-at-echo-it-solutions-3723235498,2023-12-20,Newcastle,United States,Mid senior,Onsite,"Hi,
Greetings to you!!!
This is
Lakshmi
from
Echo IT Solutions INC.
JOB: Bigdata Developer with BI
Location : Rancho Cordova, CA- 2 Days onsite in a Week
Contract: 12+ months
Job Description
Our client is looking for a
BI and Big Data Developer
who has experience in Apache Spark data lake and delta lake development in PySpark. In addition, this developer should also know Oracle SQL programming.
Responsibilities And Duties
Develop ETL and ELT processes using various data sources including from/to SQL and Oracle databases and Apache Spark Data Lake and Delta Lake
Develop and maintain Python code (PySpark) for Apache Spark data lake and Delta Lake management and queries
Languages
Desired Technical Knowledge:
Python including PySpark
T-SQL / SQL
Apache Spark, Apache Airflow, and related technologies
Microsoft SQL Server
Cloud Technologies such as Azure and AWS
NOTE: Please refer any of your friends or colleagues if you are unavailable or not interested
Thanks & Regards,
LAKSHMI
US Technical Recruiter
ECHO IT Solutions Inc.
2695 Villa Creek Drive, Suite - B275
Farmers Branch, Tx-75234
www.echoitsol.com
lakshmi@echoitsol.com
Direct : +1 4697066685
""For our open requirements, please visit
Current Openings
""
Show more
Show less","Apache Spark, PySpark, TSQL, SQL, Oracle SQL, Microsoft SQL Server, Python, Azure, AWS, Apache Airflow","Company Name: Echo IT Solutions Inc.
Job Title: Bigdata Developer with BI
Experience: 2+ years
Skills Needed: Apache Spark, PySpark, Oracle SQL, ETL/ELT processes, Python, T-SQL/SQL, Apache Airflow, Microsoft SQL Server, Cloud Technologies (Azure/AWS)",0.18478260575200853,0.79706204
Lead Analytic Data Analyst,Highmark Health,"Pennsylvania, United States",https://www.linkedin.com/jobs/view/lead-analytic-data-analyst-at-highmark-health-3762974571,2023-12-20,Zion,United States,Mid senior,Onsite,"Company :
Highmark Health
Job Description :
JOB SUMMARY
Due to confidentiality restrictions, only US citizens will be eligible to fill this role.
This job understands healthcare data from end-to-end and analyzes raw and analytic data for the enterprise. The incumbent cleanses, validates, audits, and compares data from various sources. Provides business process and industry domain knowledge to projects while working with engineering and business teams on requirements and outcomes. The incumbent delivers data profiling, conducts testing and systems validation to troubleshoot data anomalies and monitors data management metrics and data loads. Working with data quality teams, ensures business alignment and analytic value of derived data is met. Provides guidance and education to Senior, Intermediate and Associate staff. Responsible for customer relationship management.
ESSENTIAL RESPONSIBILITIES
Verify analytic data for the enterprise by conducting end-to-end analysis of data, including cleansing, validating, auditing, and comparing data from various sources.
Confirm the accuracy of new data sources used by the analytic entities of the enterprise. This includes all aspects of the process from testing of source data to the interconnections of this data to internal sources.
Routinely monitor data sources used for analytics to assure the continued updates of data are meeting quality standards
Drive functional efforts for programs across multiple projects, including guidance and education of Senior and Intermediate individual contributors. Also responsible for management of relationships with customers of the function or domain of analytics.
Responsible for requirements solicitation from key stakeholders leveraging expert knowledge.
Other duties as assigned.
EDUCATION
Required
Bachelor's Degree in Computer Systems Analysis, Data Processing, Healthcare Informatics or Management Information Systems, or closely related discipline
Substitutions
None
Preferred
Master's Degree in Management Information Systems, or Healthcare Informatics
EXPERIENCE
Required
7 - 10 years of Business Analyst Experience, or
7 - 10 years of Data Analytics Experience
5 -7 years of Healthcare Industry Experience
Preferred
5 - 7 years of Data Warehousing Experience, or
7 - 10 years of Healthcare Industry Experience
Familiarity with the Google Cloud Platform (GCP)
LICENSES AND CERTIFICATIONS
Required
None
Preferred
None
SKILLS
SQL
SAS
Microsoft Office
Problem-Solving
Communication Skills
Requirements Analysis
Testing Skills
Language (other Than English)
None
Travel Requirement
0% - 25%
PHYSICAL, MENTAL DEMANDS and WORKING CONDITIONS
Position Type
Office-Based
Teaches / trains others regularly
Constantly
Travel regularly from the office to various work sites or from site-to-site
Rarely
Works primarily out-of-the office selling products/services (sales employees)
Never
Physical work site required
Yes
Lifting: up to 10 pounds
Occasionally
Lifting: 10 to 25 pounds
Rarely
Lifting: 25 to 50 pounds
Never
Disclaimer:
The job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title. It may not contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees to do this job.
Compliance Requirement:
This position adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies.
As a component of job responsibilities, employees may have access to covered information, cardholder data, or other confidential customer information that must be protected at all times. In connection with this, all employees must comply with both the Health Insurance Portability Accountability Act of 1996 (HIPAA) as described in the Notice of Privacy Practices and Privacy Policies and Procedures as well as all data security guidelines established within the Company’s Handbook of Privacy Policies and Practices and Information Security Policy. Furthermore, it is every employee’s responsibility to comply with the company’s Code of Business Conduct. This includes but is not limited to adherence to applicable federal and state laws, rules, and regulations as well as company policies and training requirements.
Pay Range Minimum:
$78,900.00
Pay Range Maximum:
$146,000.00
Base pay is determined by a variety of factors including a candidate’s qualifications, experience, and expected contributions, as well as internal peer equity, market, and business considerations. The displayed salary range does not reflect any geographic differential Highmark may apply for certain locations based upon comparative markets.
Highmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, age, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, age, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.
EEO is The Law
Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Sexual Orientation/Gender Identity (
https://www.eeoc.gov/sites/default/files/migrated_files/employers/poster_screen_reader_optimized.pdf
)
We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact number below.
For accommodation requests, please contact HR Services Online at HRServices@highmarkhealth.org
California Consumer Privacy Act Employees, Contractors, and Applicants Notice
Show more
Show less","SQL, SAS, Microsoft Office, Problem Solving, Communication Skills, Requirements Analysis, Testing Skills, Language (other than English), Data Analytics, Business Analyst, Data Warehousing, Google Cloud Platform (GCP), Healthcare Informatics, Data Profiling, Data Management Metrics, Data Validation, Data Auditing, Data Cleansing, Healthcare Industry","Company: Highmark Health

Job Title: Data Analyst

Experience: The ideal candidate should have 7-10 years of Business Analyst or Data Analytics experience, along with 5-7 years of experience in the Healthcare Industry. Preferred experience includes 5-7 years of Data Warehousing or 7-10 years in the Healthcare Industry.

Skills Needed: The candidate should have skills in SQL, SAS, Microsoft Office, problem-solving, communication, requirements analysis, testing, and familiarity with the Google",0.10097087215956266,0.5592783
Senior Data Analyst - Data Management with Security Clearance,ClearanceJobs,"Pennsylvania, United States",https://www.linkedin.com/jobs/view/senior-data-analyst-data-management-with-security-clearance-at-clearancejobs-3776417545,2023-12-20,Zion,United States,Mid senior,Onsite,"The Alaka`ina Foundation Family of Companies (FOCs) is looking for a Sr. Data Analyst with background in the Military Healthcare System to support a team developing data governance and a data management model to support a future state data framework/design that enhances system performance, data management, and analytics. The Alaka`ina Foundation Family of Companies has partnered with the Defense Health Agency (DHA) to deliver world class, data-driven decision science analytics of military healthcare operations and the delivery of healthcare services worldwide. Alaka`ina and its partners will lead the way for DHA to expand its current analytical services to incorporate leading-edge technologies and advanced skills. DESCRIPTION OF RESPONSIBILITIES:
Assess current state data and analytic maturity and identify gaps in policy, procedure, personnel, structure, and function (capability) and make appropriate recommendations to government directed data teams.
Assist in the development of KPIs (Key performance Indicators) and processes to measure performance.
Assist in the development of data models utilizing the Data Administration Management Association (DAMA) Framework.
Conduct analysis and assessments of current functions/processes, organizational structure, governance structure (to include policies/ procedures/ stakeholders), performance management practices, and tools/technologies in use.
Perform detailed data and analytic maturity assessments that includes, but not limited to, the following assessment areas: current requirements, functions, processes, and management organizational and governance structure, tools and technology solutions in place.
Assist in the development of courses of action for implementation of industry-based models and frameworks.
Conduct analysis and assessment of existing architectures, infrastructures, and interfaces to data sources, tools supporting automated data loads, security concerns, analytic models, and data visualization.
Develop, maintain, and utilize data management techniques such as relational databases to manage the flow of information between organizations and various information systems within the DHA, MHS or other Government agencies where appropriate.
Assist in the collection, organization, analysis, and visualization of the Military Health Systems data structures supporting a Gap Analysis, Stakeholder Analysis, Use Case applications, and a Data Management & Analytics Model/Framework report.
Support the development of stakeholder engagement and communication plan.
Support the development of dissemination and implementation plans.
Creates and improves data solutions that enable smooth data delivery and oversees gathering, processing, maintaining, and analyzing data.
Other duties as assigned. REQUIRED DEGREE/EDUCATION/CERTIFICATIONS: Bachelor's or Master's degree in Data Science, Analytics, Epidemiology, or a related field. REQUIRED SKILLS AND EXPERIENCE:
Minimum of 3 years of experience in data analysis, preferably in a healthcare or government setting.
Strong knowledge of statistical and analytical tools and techniques, data visualization, and business intelligence tools.
Experience in designing and implementing data analysis strategies and methodologies, including the use of big data platforms and tools.
Excellent communication and interpersonal skills, with the ability to work effectively with interdisciplinary teams and stakeholders.
Strong analytical and problem-solving skills, with the ability to interpret and communicate complex data insights to diverse audiences.
Experience in managing and analyzing large and complex data sets, including electronic health records (EHRs) and claims data.
Ability to maintain confidentiality and comply with applicable regulations and standards.
Ability to critically examine and evaluate, problem-solve.
Ability to deliver products on time, on schedule, within budget. Flexibility and ability to adapt to rapidly changing and often time-constrained environment.
Able to read, write, speak, and understand English.
Demonstrated ability to organize/participate/lead working groups to develop analytic products and byproducts or to develop/understand processes leading to effective optimization of analytic efforts.
Demonstrated ability to undertake and complete multiple tasks with multiple deadlines simultaneously.
Demonstrated advanced proficiency in Microsoft Office products PLUS additional software/hardware skills and capabilities.
Proven ability to synthesize disparate data from multiple sources and coalesce into an accurate and useful analytic product, incorporating Service and MHS strategic goals for use by leadership in both tactical and strategic decision making. DESIRED SKILLS AND EXPERIENCE:
Familiarity with the Data Administration Management Association (DAMA) Framework.
Experience with Data warehouse management.
Experience developing data governance.
Strong conceptual abilities.
Excellent multitasking abilities.
Exceptional analytical abilities. REQUIRED CITIZENSHIP AND CLEARANCE:
U.S. Citizenship Required.
Ability to obtain an Active Secret Clearance or Tier III background check. The Alaka`ina Foundation Family of Companies (FOCs) is a fast-growing government service provider. Employees enjoy competitive salaries. Eligible employees enjoy a 401K plan with company match; medical, dental, disability, and life insurance coverage; tuition reimbursement; paid time off; and 11 paid holidays. We are an Equal Opportunity/Affirmative Action Employer. We are proud to state that we do not discriminate in employment decisions on the basis of race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. If you are a person with a disability and you need an accommodation during the application process, please click here to request accommodation. We E-Verify all employees. The Alaka`ina Foundation Family of Companies (FOCs) is comprised of industry-recognized government service firms designated as Native Hawaiian Organization (NHO)-owned and 8(a) certified businesses. The Family of Companies (FOCs) includes Ke`aki Technologies, Laulima Government Solutions, Kūpono Government Services, and Kapili Services, Po`okela Solutions, Kīkaha Solutions, LLC, and Pololei Solutions, LLC. Alaka`ina Foundation activities principally benefit the youth of Hawaii through charitable efforts which includes providing innovative educational programs that combine leadership, science & technology, and environmental stewardship. For additional information, please visit www.alakainafoundation.com
#ClearanceJobs
Show more
Show less","Data analysis, Statistical tools, Analytical tools, Data visualization, Business intelligence tools, Data analysis strategies, Methodologies, Big data platforms, Communication skills, Interpersonal skills, Teamwork, Analytical skills, Problemsolving skills, Data management, Data governance, Data warehouse management, Microsoft Office, DAMA Framework, Multitasking, Active Secret Clearance, Tier III background check","Company: The Alaka`ina Foundation Family of Companies (FOCs)

Job Title: Senior Data Analyst

Experience: Minimum of 3 years of experience in data analysis, preferably in a healthcare or government setting.

Skills Needed:
- Bachelor's or Master's degree in Data Science, Analytics, Epidemiology, or a related field.
- Strong knowledge of statistical and analytical tools, data visualization, and business intelligence tools.
- Experience in designing and implementing data analysis strategies and methodologies.
- Excellent communication and",0.17132215828081385,0.688415
Data Scientist,Burtch Works,United States,https://www.linkedin.com/jobs/view/data-scientist-at-burtch-works-3231314683,2023-12-20,Zion,United States,Mid senior,Remote,"We are looking for a skilled data scientist to join a team of Data Scientists with a top consulting company with a focus on consumer data and acting as the voice of the customer. Responsibilities include being ready to be a key contributor supporting measurement of our Marketing campaigns and our Unified Personalization Platform (UPP) initiative. The person in this role is primarily focused on designing and measuring the impact of marketing controlled tests, A/B and observational studies. We expect all data scientists to be hands on with respect to analyzing a retailer database, using the full suite of technical tools including Python, Spark, SQL, Azure, Tableau, Excel, and other specific internal tools – to create timely, relevant, and actionable insights.
Qualifications:
Bachelor's degree in mathematics, statistics, analytics, data science, or related discipline
Experience in extracting insights from large databases, translating market research into actionable solutions and presenting findings and recommendations to clients
Experience using Python, or other similar statistical software to develop analytical solutions.
Experience with data wrangling, data cleaning and prep, dimensionality reduction.
Experience with A/B testing and statistical analysis (ANOVA, ANCOVA)
Keywords:
Media Campaign management, Python, Databricks, GitHub, Coding, Organization, Communication, Data Science, Marketing, A/B testing, statistical analysis, computer science, customer analytics, customer data, data mining, data cleaning, ETL pipelines, modeling, data visualization
Show more
Show less","Python, SQL, R, Tableau, Spark SQL, Matplotlib, NumPy, Pandas, Databricks, Microsoft Azure, GitHub, Git, Analytical tools, Dimensionality reduction, Statistical analysis, Machine learning, Data mining, Data Wrangling, Data cleaning, Natural Language Processing","Company: Top consulting company
Job Title: Data Scientist
Experience: Not specified
Skills Needed: 
1. Bachelor's degree in mathematics, statistics, analytics, data science, or related discipline
2. Experience in extracting insights from large databases and translating market research into actionable solutions
3. Proficiency in Python or similar statistical software for developing analytical solutions
4. Experience with data wrangling, data cleaning, and dimensionality reduction
5. Familiarity with A/B testing and statistical analysis",0.36966824241683705,0.6735301
Data Scientist,ECOM,United States,https://www.linkedin.com/jobs/view/data-scientist-at-ecom-3789893642,2023-12-20,Zion,United States,Mid senior,Remote,"🌟
Data Scientist
(𝐏𝐞𝐫𝐦𝐚𝐧𝐞𝐧𝐭 & 𝐑𝐞𝐦𝐨𝐭𝐞 𝐟𝐫𝐨𝐦 𝐭𝐡𝐞 𝐔𝐧𝐢𝐭𝐞𝐝 𝐒𝐭𝐚𝐭𝐞𝐬) 🌟
Join our partner client's forward-thinking organization and make a difference with your data science skills! 🚀
As a Data Scientist, you'll work with other data scientists and data engineers using machine learning, artificial intelligence, and statistical methods to answer critical questions and produce actionable insights for business units.
A successful candidate will work on agile scrum squads and should be excited by digital enablement, innovation and new ideas, and have a passion for learning.
💡
What You'll Do:
✅ Develop Data Science products in an agile scrum squad
✅ Build and test ML algorithms, forecasting models, and optimization models
✅ Mine complex data for patterns and trends
✅ Conduct hands-on analysis in text, quantitative, statistical, financial, and operational domains
✅ Collaborate with model developers for scalable solutions
✅ Provide thought leadership through research and experimentation
🎓
Requirements:
✔️ BSc degree in a quantitative discipline with 5 years' experience as a Data Scientist or Master’s ✔️ MSc with 4 years' experience, or PhD with 1 year of experience
✔️ Strong knowledge of ML, statistical software, and techniques
✔️ Experience with models like decision trees, random forests, neural networks, and metrics such as F1 score and ROC AUC
✔️ Proficiency in Python, R, RapidMiner, or Matlab
✔️ Familiarity with linear regression and statistical techniques (e.g., t-tests, least squares, confidence intervals)
✔️ Agile/Scrum development and DevOps experience for rapid prototyping in cloud solutions.
💼
Benefits & Compensation:
✔️ Competitive pay and incentives + 10-15% bonus
✔️ Company-sponsored pension and 401(k) plans
✔️ Comprehensive medical, dental, vision, and life insurance programs
✔️ Skills development training with tuition reimbursement
🔗 Ready to advance your Data Science career? Apply now and be part of our partner client's exciting journey! ⚡
IMPORTANT:
This position is fully remote anywhere in the US with the exception of the following *states:
California
Colorado
Illinois
Kentucky
Massachusetts
Montana
Nebraska
New York
Oregon
Washington State
𝐔𝐧𝐟𝐨𝐫𝐭𝐮𝐧𝐚𝐭𝐞𝐥𝐲, 𝐰𝐞 𝐰𝐢𝐥𝐥 𝐛𝐞 𝐮𝐧𝐚𝐛𝐥𝐞 𝐭𝐨 𝐜𝐨𝐧𝐬𝐢𝐝𝐞𝐫 𝐲𝐨𝐮𝐫 𝐚𝐩𝐩𝐥𝐢𝐜𝐚𝐭𝐢𝐨𝐧 𝐢𝐟 𝐲𝐨𝐮 𝐥𝐢𝐯𝐞 𝐢𝐧 𝐚𝐧𝐲 𝐨𝐟 𝐭𝐡𝐞 𝐚𝐛𝐨𝐯𝐞 *𝐬𝐭𝐚𝐭𝐞𝐬. 𝐓𝐡𝐞 𝐜𝐨𝐦𝐩𝐚𝐧𝐲 𝐚𝐫𝐞 𝐚𝐥𝐬𝐨 𝐮𝐧𝐚𝐛𝐥𝐞 𝐭𝐨 𝐨𝐟𝐟𝐞𝐫 𝐬𝐩𝐨𝐧𝐬𝐨𝐫𝐬𝐡𝐢𝐩 𝐨𝐫 𝐬𝐮𝐩𝐩𝐨𝐫𝐭 𝐯𝐢𝐬𝐚 𝐭𝐫𝐚𝐧𝐬𝐟𝐞𝐫 𝐚𝐭 𝐭𝐡𝐢𝐬 𝐭𝐢𝐦𝐞.
𝐏𝐥𝐞𝐚𝐬𝐞 𝐝𝐨 𝐧𝐨𝐭 𝐚𝐩𝐩𝐥𝐲 𝐢𝐟 𝐲𝐨𝐮 𝐚𝐫𝐞 𝐨𝐧𝐥𝐲 𝐢𝐧𝐭𝐞𝐫𝐞𝐬𝐭𝐞𝐝 𝐢𝐧 𝐜𝐨𝐧𝐭𝐫𝐚𝐜𝐭 𝐨𝐩𝐩𝐨𝐫𝐭𝐮𝐧𝐢𝐭𝐢𝐞𝐬 𝐚𝐬 𝐭𝐡𝐢𝐬 𝐢𝐬 𝐚 𝐩𝐞𝐫𝐦𝐚𝐧𝐞𝐧𝐭 𝐩𝐨𝐬𝐢𝐭𝐢𝐨𝐧.
Show more
Show less","Data Science, Agile, Scrum, Machine Learning, Artificial Intelligence, Statistical Methods, Python, R, RapidMiner, Matlab, Linear Regression, Statistical Techniques, Ttests, Least Squares, Confidence Intervals, DevOps, Cloud Solutions","Company Name: Not specified
Job Title: Data Scientist
Experience: 5 years of experience as a Data Scientist with a Bachelor's degree in a quantitative discipline, 4 years with a Master's degree, or 1 year with a PhD.
Skills Needed: Strong knowledge of machine learning and statistical techniques, experience with ML models like decision trees and neural networks, proficiency in Python, R, RapidMiner, or Matlab, familiarity with linear regression and statistical techniques, agile/scrum development experience,",0.2162162134585036,0.69674313
Data Scientist,ASK Consulting,United States,https://www.linkedin.com/jobs/view/data-scientist-at-ask-consulting-3775000571,2023-12-20,Zion,United States,Mid senior,Remote,"""All candidates must be directly contracted by ASK Consulting on their payroll and cannot be subcontracted. We are unable to provide sponsorship at this moment"".
job Title: Data Scientist
Location: Remote
Duration: 12 months
Pay rate : 90 hr
job Description:
Required Skills:
Data Science experience
AI ML
GCP
Python and SQL
Great communication skills
Big Data
Strong modeling techniques
Strong analytics
Roles and Responsibilities:
4+ years of professional experience as a data scientist or statistical modeler in at least one of the following: identity and fraud, credit risk, telecommunications, financial services, payment, ecommerce, B2B or B2C, marketing, insurance, or security analytics arena.
4+ years working with Python and SQL.
Experience with state-of-the-art machine learning algorithms such as deep neural networks, support vector machines, boosting algorithms, random forest etc.
Preferred Experience conducting advanced feature engineering and data dimension reduction in Big Data environment is preferred professional experience as a data scientist or statistical modeler in identity and fraud, credit risk, telecommunications, financial services, payment, ecommerce, B2B or B2C, marketing, insurance, or security analytics arena is a plus Strong SQL skills in Big Data environment (Hive/ Impala etc.) a plus
Proficient with any programming languages such as Python , Java, Scala a plus Experience working with very large datasets, knowledge of distributed computing tools (Hadoop Streaming, MapReduce, Spark) a plus
Exposure to Visualization tools such as Tableau a plus Extensive knowledge in fraud prevention methods and detection tools a plus Strong knowledge of credit bureau data and business problems in financial services and/or telecommunications a plus
About ASK:
ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With 5 nationwide offices, two global delivery centers, and employees in 42 states-ASK Consulting connects people with amazing opportunities
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.
Show more
Show less","Data Science, AI/ML, GCP, Python, SQL, Big Data, Modeling, Analytics, Neural Networks, Support Vector Machines, Boosting Algorithms, Random Forest, Feature Engineering, Data Dimension Reduction, Hive, Impala, Java, Scala, Hadoop Streaming, MapReduce, Spark, Tableau, Fraud Prevention, Fraud Detection","The job title is Data Scientist at ASK Consulting, a remote position lasting for 12 months with a pay rate of $90 per hour. The ideal candidate should have 4+ years of experience in data science, AI, ML, GCP, Python, SQL, big data, strong modeling techniques, and analytics. Responsibilities include working with Python and SQL, utilizing advanced machine learning algorithms, feature engineering, and data dimension reduction in a Big Data environment. Preferred skills include proficiency in SQL skills in",0.2702702665493955,0.8019643
Data Scientist,Insight Global,United States,https://www.linkedin.com/jobs/view/data-scientist-at-insight-global-3780036274,2023-12-20,Zion,United States,Mid senior,Remote,"A large delivery service client of Insight Global is looking to hire a Data Scientist on a contract basis. This person will be joining the analytics team at this company and they will help to guide measurement, strategy, and tactical decision-making across the company across a variety of teams and levels.
Qualifications:
A degree in Math, Physics, Statistics, Economics, Computer Science, or a similar domain
4+ years of experience in data analytics, consulting, or related role
Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc
Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python
Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau)
The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way
Show more
Show less","Data Analytics, Consulting, Funnel Optimization, User Segmentation, Cohort Analyses, Time Series Analyses, Regression Models, SQL, ETL, A/B Testing, Statistical Analysis, Matlab, R, SAS, Python, Chartio, Looker, Tableau, Hypothesis Testing, Experimentation, DataDriven Problem Solving","Insight Global is seeking a Data Scientist for a contract position with a large delivery service client. The ideal candidate will hold a degree in a quantitative field and have at least 4 years of experience in data analytics, consulting, or a related role. Skills required include experience with various data analysis techniques, proficiency in SQL, ETL, and statistical analysis using tools like Matlab, R, SAS, or Python. Additionally, the candidate should be familiar with analytics and visualization tools such as Chartio, Look",0.4456521693123819,0.8543127
Data Scientist,Charter Global,United States,https://www.linkedin.com/jobs/view/data-scientist-at-charter-global-3776601713,2023-12-20,Zion,United States,Mid senior,Remote,"Role: Senior Data Scientist - Data Intelligence
Location: Remote & Hybrid (Monthly once in Reston, Virginia).
(Preference will be given to the candidates who are located in Virginia or Maryland or Washington, DC states).
Duration: 12+ Months contract
PURPOSE :
Identifies and solves business problems by using various numerical techniques, algorithms, and models in statistical modeling, machine learning, operations research, and data mining. Uses advanced analytical capabilities to support data science initiatives. Communicates across product teams and with customers and educates on artificial intelligence, machine learning, and statistical models. Acting as a liaison and interface between analytics, business units, and other departments.
ESSENTIAL FUNCTIONS :
20% Leads data mining and extraction activities and applies algorithms to derive insights.
20% Use data to understand the data profile and its limitations and apply it to business solutions.
15% Collaborates with business units to innovate organizational performance.
15% Explores data patterns using existing data science tools.
10% Translates business priorities to data science deliverables.
10% Implements new data products and builds robust and scalable software.
10% Leads/Guides DS on implementing best practices for projects and applies artificial intelligence techniques to achieve concrete business goals while managing limited resources and constraints around data.
Qualifications :
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable
accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education Level: Bachelor's Degree
Education Details: Statistics, Mathematics, Computer Science or related field
Experience: 5 years of relevant work experience.
In Lieu of Education :
In lieu of a Bachelor's degree, an additional 4 years of relevant work experience is required in addition to the required work experience.
Preferred Qualifications:
Knowledge, Skills, and Abilities (KSAs)
Ability to work independently without detailed guidance., Advanced.
Ability to communicate effectively and document objectives and procedures., Advanced.
Ability to leverage a variety of data science tools and frameworks., Advanced.
Knowledge in model evaluation, tuning and performance, operationalization, and scalability of scientific techniques., Advanced.
Knowledge of software engineering principles and practices., Advanced
Proficiency in statistical modeling applications., Advanced
Proficiency in advanced SQL in multiple syntaxes., Advanced
Experience working on Cloud Technologies, preferably AWS & SageMaker.
Best Regards,
-------
David Roy | Senior Recruiter – US Staffing | Charter Global Inc. | https://www.charterglobal.com
One Glenlake Parkway | Suite 525 | Atlanta, GA 30328
A CMMI LEVEL 3 COMPANY.
Show more
Show less","Statistics, Mathematics, Computer Science, Data Mining, Machine Learning, Operations Research, Artificial Intelligence, Data Extraction, Scalable Software, Data Analytics, Data Science Tools, Cloud Technologies, AWS, SageMaker, SQL, Software Engineering","Company: Charter Global Inc.
Job Title: Senior Data Scientist - Data Intelligence
Experience: 5 years of relevant work experience
Skills Needed:
- Ability to work independently without detailed guidance
- Ability to communicate effectively and document objectives and procedures
- Ability to leverage various data science tools and frameworks
- Proficiency in model evaluation, tuning, and performance
- Proficiency in statistical modeling applications and advanced SQL
- Knowledge of software engineering principles and practices
- Experience working on Cloud Technologies, preferably",0.3223880567609713,0.5683317
Data Scientist,Aclat Inc.,United States,https://www.linkedin.com/jobs/view/data-scientist-at-aclat-inc-3669833387,2023-12-20,Zion,United States,Mid senior,Remote,"Hello,
We are hiring OPT, CPT, H4 EAD and GC Candidates.
We are a consulting firm. We provide entry-level to senior-level contract(W2) job opportunities for Embedded, Firmware, automotive, Validation, Hardware, Test Engineer, Electrical, Electronics, and Mechanical engineer positions.
Also, we provide training and placement for new graduate students & we sponsor H1B & GC.
Interested candidates do share your resume in the following given details or for further details reach out to us by the given contact details:
pmanisha@aclatinc.com
+1 8474838783
*WE ARE LOOKING FOR W2 PROFILES ONLY*
Responsibilities
7+ experience as a Data Scientist you will work as part of our global Data Science team to provide data driven AI solutions for our internal customers using state-of-the-art Machine Learning methods and tools.
Strong knowledge of Machine Learning Algorithms and techniques
Must have knowledge of Statistical techniques.
Expert with NLP and must have worked on a couple of projects using Transformers (ex: BERT, GPT)
Would be great if worked on a Questions-Answer model in the past projects.
Super comfortable with Python, Spark, SQL
Hands-on experience on either AWS/GCP/Azure
Good knowledge of Deep Learning, Transformers.
Experience with building Deep learning models.
Job Description:
Big data engineering in spark(databricks recommended not a must-have) - (Ex: 2 years experience, expertise: 8 out of 10, add any other comments)
Python flask/Gunicorn API dev
API Integration with Azure cognitive services or similar search enginers
Experience with Azure computer vision API’s
Understanding of OpenAI (good to have, not a must have)
Data App development experience ( preferably in Dash App)
API monitoring/scaling experience in Kubernetes
Mlflow/Mlops/Datascience background.
Show more
Show less","Data Science, Machine Learning Algorithms, Statistical Techniques, Natural Language Processing, Transformers, QuestionAnswer Model, Python, Spark, SQL, AWS, GCP, Azure, Deep Learning, Big Data Engineering, Databricks, Flask, Gunicorn, API Integration, Azure Cognitive Services, Computer Vision API, OpenAI, Dash App, Kubernetes, Mlflow, Mlops","Company Name: Not specified
Job Title: Data Scientist
Experience: 7+ years

Skills needed:
- Strong knowledge of Machine Learning Algorithms and techniques
- Must have knowledge of Statistical techniques
- Expertise in NLP and experience with Transformers (ex: BERT, GPT)
- Proficiency in Python, Spark, SQL
- Hands-on experience in AWS/GCP/Azure
- Good understanding of Deep Learning and Transformers
- Experience in building Deep learning models
- Big data",0.31275719842639166,0.6775298
Data Scientist,Oscar,United States,https://www.linkedin.com/jobs/view/data-scientist-at-oscar-3784586587,2023-12-20,Zion,United States,Mid senior,Remote,"We have partnered with an innovative productivity software company, who is looking to expand their Data Science team. Their AI platform is designed to make company knowledge accessible to all employees, driving collaboration and productivity within your business.
As a Staff-level Scientist, you should have at least 6 years of Data Science experience, working closely with LLMs.
Ideal candidates will have the following experience:
Product-centric Data Science work
Experience of tuning and delivering LLMs like GPT, LLAMA, BERT, etc
AWS (Sagemaker, Redshift, ElasticSearch)
RAG Architecture
This is a fully remote position, paying up to $240k base.
Show more
Show less","Data Science, Large Language Models (LLMs), GPT, LLAMA, BERT, AWS, Sagemaker, Redshift, ElasticSearch, RAG Architecture","Company: Innovative productivity software company
Job Title: Staff-level Data Scientist
Experience: At least 6 years of Data Science experience
Skills needed: 
- Working closely with LLMs
- Product-centric Data Science work
- Experience with tuning and delivering LLMs like GPT, LLAMA, BERT, etc
- AWS (Sagemaker, Redshift, ElasticSearch)
- RAG Architecture
- Fully remote position with a base pay of up to $240k",0.5413533787302844,0.84912
Healthcare Data Scientist,"The Mice Groups, Inc.",United States,https://www.linkedin.com/jobs/view/healthcare-data-scientist-at-the-mice-groups-inc-3783877579,2023-12-20,Zion,United States,Mid senior,Remote,"Our Client is seeking a Healthcare Data Scientist for a W2 only, fully-remote, extendable 3-month contract position. This position pays $50-65/hr. W2.
Responsibilities:
Analyze healthcare claims, referral, and clinical data to identify trends, and recognize outliers.
Build predictive models to gauge capacity, identify denials, estimate revenue for certain types of care or interventions.
Required Skills:
5+ years of experience with SQL, Python, and building/deploying machine learning solutions.
Experience with EPIC data models is preferred.
Pay for this position is based on market location and may vary depending on job-related knowledge, skills, and experience. As a contractor you may also be eligible for health benefits such as health, dental, and vision as well as access to a 401K plan.
Applicants should apply via The Mice Groups Inc. website (www.micegroups.com) or through this careers site posting.
We are an equal opportunity employer and value diversity at The Mice Groups Inc. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The Mice Groups Inc. values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Privacy Policy
One of the basic principles The Mice Groups follows in designing and operating this website is that we ask for only the information we need to provide the service you’ve requested.
The Mice Groups does not currently collect personal identifying information via its website except (i) to the extent that you provide this information in an online job application and (ii) to the extent that your web browser provides personal identifying information.
The Mice Groups will use your personally identifying information solely for the purpose for which you submitted the information. The Mice Groups may, however, aggregate certain elements of your personal identifying information with the information of other users of our website to analyze the usefulness and popularity of various web pages on its website.
The Mice Groups reserves the right to change this policy at any time by posting a new privacy policy at this location. Questions regarding this statement should be directed to info@micegroups.com
Show more
Show less","healthcare data, SQL, Python, machine learning, EPIC data models","Company: The Mice Groups Inc.
Job Title: Healthcare Data Scientist
Experience: 5+ years
Skills Needed: SQL, Python, building/deploying machine learning solutions, experience with EPIC data models
Description: The Mice Groups Inc. is looking for a Healthcare Data Scientist for a fully-remote 3-month contract position, paying $50-65/hr. Responsibilities include analyzing healthcare claims data, building predictive models, and identifying trends. Required skills include 5+ years of",0.21754385666580486,0.74446243
Data Scientist- Contract-to-Hire - Remote,"Kelly Science, Engineering, Technology & Telecom",United States,https://www.linkedin.com/jobs/view/data-scientist-contract-to-hire-remote-at-kelly-science-engineering-technology-telecom-3769048790,2023-12-20,Zion,United States,Mid senior,Remote,"Kelly® Technology is seeking a Data Scientist for an IT Product company developing highly customizable ERP applications and their integrations with AI/ML technologies.
Data Scientist
Client: Software Applications Development / Custom ERP Applications
Remote from these states GA, NC, VA, FL, TX, CO, HI
Contract 6 months – to Hire
Type of Contract: W2 with Health and 401k Benefits or C2C
M-F, 40 hours/week, flexible hours
Travel: once a year for 4 days, domestic
JOB OVERVIEW
Will contribute to design and development efforts for the big data solutions including data lake, Business Intelligence Solutions, Machine Learning, Data Pipeline, and cloud-based data warehouse products.
Analyze data for trends and patterns, and interpret data with clear objectives in mind
Implement analytical models in production by collaborating with software developers and machine-learning engineers
Identify and integrate new datasets that can be leveraged through the product capabilities, and work closely with the engineering team in the development of data products
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big-data stores; perform data and error analysis to improve models; clean and validate data for uniformity and accuracy
SKILLS/KNOWLEDGE/ABILITITES
Five or more years of experience in data science
Proficiency with data mining, mathematics, and statistical analysis
Experience in Python, SQL, R, Keras, TensorFlow with .NET integration
Experience developing/implementing analytic solutions in the Amazon or Azure cloud that leverage relational, in-memory, NoSQL, document and/or graph databases
Strong expertise in creation and administration of data models.
Advanced experience in pattern recognition and predictive modeling
Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects
EDUCATION
Bachelor’s degree (or equivalent) in statistics, applied mathematics, or related discipline. Master’s degree strongly preferred.
We are interested in every qualified candidate who is eligible to work in the United States. However, we do not sponsor visas for this role.
This policy is applied in a nondiscriminatory manner regardless of race, gender, ethnic origin, or any other classification protected by law.
Show more
Show less","Data Science, Data Mining, Mathematics, Statistical Analysis, Python, SQL, R, Keras, TensorFlow, .NET, Amazon Cloud, Azure Cloud, Relational Databases, Inmemory Databases, NoSQL Databases, Document Databases, Graph Databases, Data Modeling, Pattern Recognition, Predictive Modeling, Data Analytics, Data Warehousing, Business Intelligence, Machine Learning, Data Pipelines, Big Data","Company Name: Kelly® Technology
Job Title: Data Scientist
Experience: Five or more years of experience in data science
Skills Needed: Proficiency in data mining, mathematics, and statistical analysis, experience in Python, SQL, R, Keras, TensorFlow with .NET integration, developing/implementing analytic solutions in Amazon or Azure cloud, expertise in data modeling, pattern recognition, and predictive modeling. Advanced degree in statistics, applied mathematics, or related discipline preferred. Ability to work effectively in a",0.30666666354755556,0.6881913
Data Scientist,"Client Resources, Inc.",United States,https://www.linkedin.com/jobs/view/data-scientist-at-client-resources-inc-3762670467,2023-12-20,Zion,United States,Mid senior,Remote,"CRi is seeking a Senior Corporate Data Scientist for a Client to produce Data Science solutions in support of senior management’s strategic goals. In this role, you would use analysis and scientific methods to predict the behavior and attitudes of customers and prospects in order to increase profitable acquisition, retention and cross-selling. A primary focus of this role involves proposing, developing and implementing predictive models. The department is moving from a SAS-oriented focus to deploying models with Docker and AWS Sagemaker.
Key Responsibilities:
Developing end-to-end Data Science solutions to support strategic objectives and senior management's goals. This includes collaborating with the business to understand and define the problem statement, data extraction and transformation, model training and tuning, and deployment.
Analyzing general economic trends
Participating on teams throughout the company that require advanced analysis
Qualifications:
Master’s degree in analytical-focused discipline such as Data Science, Mathematics or relevant discipline….
OR
relevant work experience
6+ years’ experience in the field of business intelligence, application development, database development, ETL, or machine learning.
2 years’ experience building, training, and deploying machine learning (ML) models with Amazon SageMaker on the Amazon Web Services (AWS) Cloud.
2 years’ of Python programming experience
Experience with visual analytics tools such as Tableau or PowerBI.
Excellent written and verbal communication skills to interact with senior management, marketing personnel, technical personnel, actuaries and representatives from other business units and outside suppliers.
Ability to effectively provide leadership to operational teams.
Preferred:
Spark or PySpark experience
Project management experience
Insurance Industry experience
Show more
Show less","Data Science, Predictive Modeling, Docker, AWS Sagemaker, SAS, Business Intelligence, Application Development, Database Development, ETL, Machine Learning, Python, Tableau, PowerBI, Spark, PySpark, Project Management","Company: CRi
Job Title: Senior Corporate Data Scientist
Experience: 6+ years
Skills Needed: Master's degree in analytical-focused discipline or relevant work experience, 6+ years of experience in business intelligence, application development, database development, ETL, or machine learning, 2 years of experience building, training, and deploying ML models with Amazon SageMaker on AWS, 2 years of Python programming experience, experience with visual analytics tools like Tableau or PowerBI, excellent written",0.34821428205516586,0.7865393
Data Scientist,Artemis Consultants,United States,https://www.linkedin.com/jobs/view/data-scientist-at-artemis-consultants-3783134322,2023-12-20,Zion,United States,Mid senior,Remote,"We are seeking an experienced and passionate Data Scientist who has strong theoretical knowledge and practical experience in operations research techniques such as mathematical programming (Linear & Non-Linear programming), Heuristic/ Metaheuristics algorithms & Stochastic modeling.
Bachelor’s or Master’s (preferred) degree in in a quantitative or technical field such as Computer Science, Data Science, Computer Engineering or equivalent
4+ years of experience in Data Science and 2+ years of experience building optimization models for various business use cases
Strong theoretical background & practical industry experience in Operations Research techniques such as Mathematical Programming (Linear Programming, Non-Linear Programming, Mixed-Integer Linear Programming), Heuristic/ Metaheuristics algorithms & Stochastic modeling
Experience running optimization models in Python using packages like PuLP, PYOMO, CVXPY etc.
Experience working with CPLEX
Demonstrated interest in learning about emerging data science and optimization tools and techniques
Strong communication, problem solving, and organizational skills
Ability to work collaboratively with variety of business, data science & technical stakeholders
Show more
Show less","Mathematical Programming, Linear Programming, NonLinear Programming, MixedInteger Linear Programming, Heuristic Algorithms, Metaheuristic Algorithms, Stochastic Modeling, PuLP, PYOMO, CVXPY, CPLEX, Python, Data Science, Optimization, Problem Solving, Communication, Organizational Skills, Collaboration","Company: Not specified
Job title: Data Scientist
Experience: 4+ years in Data Science, 2+ years in building optimization models
Skills needed: Bachelor's or Master's degree in a quantitative field, strong theoretical knowledge in Operations Research techniques, experience with mathematical programming, heuristic/metaheuristics algorithms, and stochastic modeling, proficiency in Python for optimization models, familiarity with packages like PuLP, PYOMO, CVXPY, and CPLEX, interest in emerging data science and",0.40993788370047457,0.79185987
Data Scientist,Recurring Decimal,United States,https://www.linkedin.com/jobs/view/data-scientist-at-recurring-decimal-3782252731,2023-12-20,Zion,United States,Mid senior,Remote,"Key Skills required:
10 plus years industry experience, with 4+ years of industry experience with data science
4+ years of hands-on expertise in ML paradigms.
Proficient in NLP techniques, Explainable AI, and ML frameworks.
Proficient in multiple optimization paradigms such as combinatorial optimization, gradient methods, or Bayesian optimization.
Efficiency in SQL, Hive, Scala is required
Expertise in modern advanced analytical tools and programming languages such as Python, Scala.
Experience with building end-to-end reusable pipelines from data acquisition to model output delivery
Quick learner, adaptable, with the ability to work independently in a fast-paced environment
Strong oral and written communication skills. Ability to conduct meetings and make professional presentations, and to explain complex concepts and technical material to non-technical users
Show more
Show less","Data Science, Machine Learning, Explainable AI, Natural Language Processing, Combinatorial Optimization, Gradient Methods, Bayesian Optimization, SQL, Hive, Scala, Python, Data Pipeline, FastPaced Environment, Oral Communication, Written Communication","Company: Not specified
Job Title: Data Scientist

Experience: 10+ years of industry experience, with at least 4 years in data science. 4+ years of hands-on expertise in machine learning paradigms.

Skills required:
- Proficiency in NLP techniques, Explainable AI, and ML frameworks.
- Knowledge in optimization paradigms like combinatorial optimization, gradient methods, or Bayesian optimization.
- Efficiency in SQL, Hive, Scala.
- Expertise in modern analytical",0.4827586160513675,0.78930175
Data Scientist,PREDICTif Solutions,"Texas, United States",https://www.linkedin.com/jobs/view/data-scientist-at-predictif-solutions-3778853630,2023-12-20,Zion,United States,Mid senior,Remote,"Data Scientist
PREDICTif is growing quickly and there is high demand for the services we provide. We have been consulting leaders in the analytics space for nearly two decades supporting the needs of some of the largest companies in North America. Enterprise, SMB, and Start-up clients come to us for our deep experience with Big Data, Advanced Analytics, Machine Learning, Artificial Intelligence and more. As an AWS consulting partner, we build solutions on AWS that help our customers solve challenging business needs and deliver amazing results.
The Role:
The Data Scientist will be responsible for building large-scale data mining and ML/AI solutions. You will be part of a fast-paced, entrepreneurial team focused on leveraging AWS services like Amazon SageMaker to build innovative solutions.
Principal Accountabilities:
Work alongside machine learning experts, technologists, product managers and other analysts to solve complex business problems. Identify what data to collect, devise methods to extract it, and develop processes to transform raw data into insights.
Help build a foundation for state-of-the-art technical capabilities to support ongoing and planned data analytics projects. Stay on top of AWS technological advancements to provide forward-thinking recommendations to clients.
Investigate data visualization and summarization techniques for conveying key findings related to applied analytics.
Establish strong working relationships with business analysts to understand requirements and determine optimal technologies.
Analyze technical needs and infrastructure design to determine integration with AWS cloud architecture.
Follow AWS best practices, internal standards, budgets, and processes. Plan how code will integrate with AWS services like S3, Lambda, DynamoDB and RDS.
Collaborate with project managers to estimate costs of AWS services needed for proposed solutions.
Develop overall implementation plans leveraging AWS.
Communicate proposed AWS solutions to clients with detailed documents.
Provide support installing, customizing, and integrating AWS cloud services.
Support development teams to review code integrating with AWS services and assist QA testing of functionalities.
Provide support for AWS-related issues in development or implementation.
Capture AWS architecture details for traceability.
Required:
Strong communication skills are a must. Ability to articulate solutions in both business and technological terms.
Advanced degree in quantitative discipline like math, statistics, or computer science.
Expertise in machine learning, natural language processing, and using AWS AI services like SageMaker.
Strong programming skills and experience with tools like Python, R, PySpark, etc.
Knowledge of AWS big data services like EMR, Redshift, Kinesis, and Athena.
Ability to build partnerships, drive consensus, and communicate solutions.
Produce high quality work using AWS tools and services.
Ability to manage multiple tasks and quickly switch between them.
Construct plans to execute priorities utilizing AWS cloud architecture.
Benefits Highlights
We provide our employees with the benefits they need. From top-tier medical coverage and generous 401(k) contributions to flexible paid time off, PREDICTif promotes a healthy balance between work and life.
Medical, dental and vision insurance
PTO and paid holidays
Retirement benefits
Bonus opportunities
Casual dress
Personal development
Abundant refreshments
Equity opportunities
Culture
We are customer-obsessed innovators at the forefront of innovation. We consistently exceed expectations and live by the highest value.
·
Customer Obsession
Everything we do starts with our customers. We listen to them, understand their needs, culture, and current state, and then work backwards to find the best-fit solutions. We work vigorously to become your trusted partner. Our clients 100% satisfaction is our top priority.
·
Integrity
We earn trust by ensuring everything we do is with the highest level of integrity. We believe in transparency and strive to leave our clients better for having worked with us. We take your ethics to heart and together, become better corporate citizens.
·
People First
Our purpose is to matter to our clients and our people. Advancing our team members’ skillset is critical to our success. Every team member is given the respect and space to grow, allowing them to thrive. We seek out and reward excellence and find it frequently in our crew of thinkers and innovators, who will always deliver their best to our clients.
·
Take Pride
We take pride in the work that we perform for our customers. We strive to achieve the highest standard of quality in all our deliverables, ensuring our customers receive maximum return on their investments. We stand behind our products and services. We take our responsibility to our customers, their success, and our industry seriously.
Show more
Show less","AWS, Amazon SageMaker, Machine Learning, Artificial Intelligence, S3, Lambda, DynamoDB, RDS, Python, R, PySpark, EMR, Redshift, Kinesis, Athena, Customer Obsession, People First, Take Pride","Company Name: PREDICTif
Job Title: Data Scientist
Experience: Nearly two decades in consulting leaders in the analytics space
Skills Needed:
- Strong communication skills to articulate solutions in business and technological terms
- Advanced degree in a quantitative discipline like math, statistics, or computer science
- Expertise in machine learning, natural language processing, and using AWS AI services like SageMaker
- Strong programming skills with tools like Python, R, PySpark
- Knowledge of AWS big data services",0.22462202791802918,0.7396064
Staff Data Scientist - Policy & Economics,Airbnb,United States,https://www.linkedin.com/jobs/view/staff-data-scientist-policy-economics-at-airbnb-3777399533,2023-12-20,Zion,United States,Mid senior,Remote,"Airbnb was born in 2007 when two Hosts welcomed three guests to their San Francisco home, and has since grown to over 4 million Hosts who have welcomed more than 1 billion guest arrivals in almost every country across the globe. Every day, Hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way.
The Community You Will Join
Policy & Communications is at the heart of how Airbnb works with communities and stakeholders around the world. We're accepting applications for a position as a Senior Policy Economist (part of Airbnb’s Data Science organization) supporting this team to ensure these engagements are data-driven. Candidates should have a strong background in data modeling and analytics, and demonstrated skill in organizing, communicating, and presenting analysis via visualizations, dashboards, maps, and other tools.
The Difference You Will Make
The position offers an opportunity to provide meaningful insights both within Airbnb and to communities across the world. As a result, the role requires working with cross-functional partners throughout the organization (policy/comms, business, legal, finance, data science), as well as external partners outside of Airbnb (experts, academics, policy- makers, media). Candidates should be able to navigate these environments, operating independently and driving their own agenda, but must also work well with partners. A teamwork mentality and “no task too big or too small” attitude is key.
The scope of work includes quantitative analysis of high-impact, high-visibility topics including housing, tourism, economic development/impact, taxes, and regulation. Because of this visibility, translation of sometimes complex analyses into accessible and scalable resources is key. You will not only be the trusted data expert on the team, but also a storyteller.
A Typical Day
Regulatory impact analysis and modeling, as well as guidance to policy team members
Using AI/ML models to derive insights from legislation and other unstructured data sources
Collaboration with academics and experts on policy research topics
Mapping and spatial analysis of data
Amazing visualizations to convey key concepts.
Converting insights into “Data Journalism” useful for our communications team
Building prototypes, dashboards, and other tools to scale data usage across a large org
Your Expertise
Advanced degree in a quantitative field.
6+ years experience in data modeling & analysis.
Ability to perform complex strategic analysis.
Excellent project management, communication, and teamwork skills
Causal inference techniques (e.g. econometric regressions & quasi-experimental techniques)
Knowledge of data tools including: R/Python, SQL, Data Visualization, GIS, Excel
Exposure to the policy and economics domain, or adjacent domains
Your Location:
This position is US - Remote Eligible. The role may include occasional work at an Airbnb office or attendance at offsites, as agreed to with your manager. While the position is Remote Eligible, you must live in a state where Airbnb, Inc. has a registered entity. Click here for the up-to-date list of excluded states. This list is continuously evolving, so please check back with us if the state you live in is on the exclusion list. If your position is employed by another Airbnb entity, your recruiter will inform you what states you are eligible to work from.
Our Commitment To Inclusion & Belonging
Airbnb is committed to working with the broadest talent pool possible. We believe diverse ideas foster innovation and engagement, and allow us to attract creatively-led people, and to develop the best products, services and solutions. All qualified individuals are encouraged to apply.
We strive to also provide a disability inclusive application and interview process. If you are a candidate with a disability and require reasonable accommodation in order to submit an application, please contact us at: reasonableaccommodations@airbnb.com. Please include your full name, the role you’re applying for and the accommodation necessary to assist you with the recruiting process.
We ask that you only reach out to us if you are a candidate whose disability prevents you from being able to complete our online application.
How We'll Take Care Of You
Our job titles may span more than one career level. The actual base pay is dependent upon many factors, such as: training, transferable skills, work experience, business needs and market demands. The base pay range is subject to change and may be modified in the future. This role may also be eligible for bonus, equity, benefits, and Employee Travel Credits.
Pay Range
$185,000—$245,000 USD
Show more
Show less","Data modeling, Data analytics, Visualization, Data storytelling, Data journalism, Statistics, Econometrics, R, Python, SQL, Data visualization tools, GIS, Excel, Economics, Policy, Regulation","Company Name: Airbnb
Job Title: Senior Policy Economist
Experience: 6+ years
Skills Needed: Advanced degree in a quantitative field, experience in data modeling & analysis, project management, communication, teamwork skills, causal inference techniques, knowledge of data tools including R/Python, SQL, Data Visualization, GIS, Excel, exposure to policy and economics domain.

The job involves working as a Senior Policy Economist within Airbnb's Data Science organization, supporting the Policy & Communications team to ensure data-driven engagements",0.18661257380561125,0.7288414
Data Scientist,PeerSource,"Florida, United States",https://www.linkedin.com/jobs/view/data-scientist-at-peersource-3762672496,2023-12-20,Zion,United States,Mid senior,Remote,"PeerSource is currently recruiting for a
Data Scientist
on a
Contract-to-hire
basis. This position is fully remote, but the candidate must be located in 1 of the following states: FL, NC, TX, VA, CO, HI, GA, TN.
Summary
This person is an outstanding critical thinker, skilled in tackling intricate issues and devising sophisticated biz solutions. Your role encompasses the design and development of our large-scale data solutions, encompassing data lake, BI Solutions, ML, Data Pipeline, and cloud data warehouse products. Direct experience in design and implementation in domains like ML, AI, operational research, or statistical methods is essential.
Required Skills
5+ years of experience in machine learning techniques, probabilistic reasoning, data science, and/or optimization
Strong technical skills working with SQL (including broad exposure to all language constructs), Data Integration / ETL, APIs, and web services, all with .NET integration
Must have very strong Python Skills and experience.
R and Keras are a plus
Strong ability with Machine Learning tools, including Azure ML
Power BI with ML integration is a plus
Proven ability in creating explainable models and implementing advanced algorithms into production
Experience in implementing supervised and unsupervised machine learning techniques, analysis of variance (ANOVA) and statistical significance test
Acts as a key contributor to all phases of the design and development lifecycle of analytic applications utilizing various technology platforms
Experience developing/implementing analytic solutions in Azure cloud that leverage relational, in-memory, NoSQL, document and/or graph databases
Familiarity with DevOps and CI/CD, as well as Agile tools and processes, including Git and Azure DevOps will be very helpful in this environment
Strong analytical skills, able to translate complex business requirements into sound architectural solutions
Experience designing and implementing data pipelines for analytical model consumption of structured, semi-structured, and/or unstructured data in batch and real-time environments
Good understanding of dimensional data modeling, data transformation & designing analytical data structures
Bachelor's degree in Statistics or Mathematics required
No third parties. H1 sponsorship is not available.
PeerSource is a nationwide technology recruiting firm that prioritizes building strong relationships with the talented professionals we are fortunate to serve. We offer contract, contract-to-hire, and direct hire opportunities throughout the US and support W2 as well as independent consultants working on a Corp-to-Corp basis. W2 benefits with PeerSource include health, dental, vision, and life insurance as well as a matching retirement plan. Contact us for more details!
Show more
Show less","Machine Learning, Probabilistic Reasoning, Data Science, Optimization, SQL, Data Integration, ETL, APIs, Web Services, .NET, Python, R, Keras, Azure ML, Power BI, Explainable Models, Supervised Learning, Unsupervised Learning, ANOVA, Statistical Significance Test, Azure Cloud, Relational Databases, InMemory Databases, NoSQL Databases, Document Databases, Graph Databases, DevOps, CI/CD, Agile, Git, Azure DevOps, Analytical Skills, Data Pipelines, Dimensional Data Modeling, Data Transformation, Analytical Data Structures, Statistics, Mathematics","Company Name: PeerSource  
Job Title: Data Scientist  
Experience: 5+ years  
Skills Needed:  
- Proficiency in machine learning techniques, probabilistic reasoning, data science, and/or optimization  
- Strong technical skills in SQL, Data Integration/ETL, APIs, web services, and .NET integration  
- Advanced Python skills; familiarity with R and Keras  
- Experience with Azure ML and Power BI with ML integration  
- Ability to create explainable models and implement advanced algorithms",0.2499999970958662,0.81236005
"Azure Data Engineer --  6+ Months contract -- Chicago, IL (Hybrid)",Lorven Technologies Inc.,"Chicago, IL",https://www.linkedin.com/jobs/view/azure-data-engineer-6%2B-months-contract-chicago-il-hybrid-at-lorven-technologies-inc-3744869797,2023-12-20,East Chicago,United States,Mid senior,Hybrid,"Job Title: Azure Data Engineer
Location: Chicago, IL (Hybrid)
Duration: 6+ Months contract
Required Skills
9+ years of experience.
Azure, Azure Data Factory, ETL
Machine Learning, PowerBI and Tableau are nice to have
Show more
Show less","Azure, Azure Data Factory, ETL, Machine Learning, PowerBI, Tableau","Company: Not specified
Job Title: Azure Data Engineer
Experience: 9+ years
Location: Chicago, IL (Hybrid)
Duration: 6+ Months contract
Skills Needed: 
- Proficiency in Azure and Azure Data Factory
- Experience in ETL (Extract, Transform, Load)
- Knowledge of Machine Learning
- Familiarity with PowerBI and Tableau is a plus",0.5789473634764544,0.89005005
Senior Principal Data Scientist (Melbourne FL),Northrop Grumman,"Melbourne, FL",https://www.linkedin.com/jobs/view/senior-principal-data-scientist-melbourne-fl-at-northrop-grumman-3769700242,2023-12-20,Palm Bay,United States,Mid senior,Onsite,"At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work - and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Are you motivated to work in an environment that will challenge you, force you to continuously innovate, and work on solutions that make a difference for your customers?
Northrop Grumman Aerospace Systems relies on our team to provide the insights needed to drive performance across a broad range of strategic activities.
We are looking for a passionate
Senior Principal Data Scientist
in
Melbourne Florida
to design and develop automated, end-to-end, ETL pipelines, Artificial Intelligence/Machine Learning (AI/ML) solutions, and Data Analytics/Visualization solutions from disparate data sources.
You will share in the ownership of the technical vision and direction for advanced analytics systems that change the way we see and use data. We are looking for people who are self-motivated, hardworking, and have demonstrated the ability to find innovative solutions to complex technical problems.
Job Responsibilities
Design, develop, and maintain a scalable Extract, Transform, and Load (ETL) pipelines.
Enable storing, searching, processing, and securing of extremely large structured or unstructured data sets.
Data preparation/cleaning, integration, and automation from heterogeneous sources
Ensure data integrity and system availability
Identify, evaluate, and recommend core technologies and strategies
Monitor and optimize system performance
Decomposition of user requirements into logical functions/components
Basic Qualifications for Sr. Principal Data Scientist:
Bachelor's degree in STEM with 9 years of related experience; Masters degree in STEM with 7 years of related experience. PhD with 4 years of related experience.
Understanding of elastic data storage and archive storage lifecycle management
Experience with Data Science practices for prescriptive, predictive, diagnostic, descriptive, and cognitive analytics through automation, storage elasticity, and on-demand self service provisioning of all data types and lifecycles.
Experience with Tableau development or similar data application development.
Experience with SQL (structure query language) and relational databases.
Experience with graphic design background, creating user interfaces, and user focused dashboards.
Excellent communication skills and customer facing experience.
Proven ability to learn and master new technologies and techniques.
US Citizenship with the ability to obtain/maintain an active DoD Secret Clearance.
Must be able to obtain Program Access (PAR) within a reasonable amount of time
Preferred Qualifications:
Master's degree in STEM with 7 years of related experience.
5+ years of experience working with ETL techniques and frameworks.
Expert in Python, SQL, and data visualization tools.
Development experience utilizing Hadoop, Spark, PowerShell, and automation scripts.
Familiarity with Data Virtualization and Data Cataloging tools (e.g. Denodo, Collibra).
Experience with NoSQL Databases (e.g., MongoDB, Neo4J, etc.)
CompTIA Security+ Certification.
Current DOD Top Secret clearance.
Salary Range:
$123,400 - $185,000
The above salary range represents a general guideline; however, Northrop Grumman considers a number of factors when determining base salary offers such as the scope and responsibilities of the position and the candidate's experience, education, skills and current market conditions.
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO . U.S. Citizenship is required for most positions.
Show more
Show less","ETL, Artificial Intelligence, Machine Learning, Data Analytics, Data Visualization, Elastic data storage, Data Science, Tableau, SQL, Relational databases, Graphic design, Hadoop, Spark, PowerShell, Automation scripts, Data Virtualization, Data Cataloging, Denodo, Collibra, NoSQL Databases, MongoDB, Neo4J, CompTIA Security+ Certification","Company: Northrop Grumman
Job Title: Senior Principal Data Scientist
Experience: Bachelor's degree in STEM with 9 years of related experience; Masters degree in STEM with 7 years of related experience. PhD with 4 years of related experience.
Skills Needed: Understanding of elastic data storage, data science practices, Tableau development, SQL, graphic design, Python, Hadoop, Spark, PowerShell, NoSQL databases, CompTIA Security+, data visualization tools, Data Virtualization,",0.13888888713348768,0.5991664
Senior Principal Data Scientist (Melbourne FL) with Security Clearance,ClearanceJobs,"Melbourne, FL",https://www.linkedin.com/jobs/view/senior-principal-data-scientist-melbourne-fl-with-security-clearance-at-clearancejobs-3770052090,2023-12-20,Palm Bay,United States,Mid senior,Onsite,"At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work - and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Responsibilities
Are you motivated to work in an environment that will challenge you, force you to continuously innovate, and work on solutions that make a difference for your customers? Northrop Grumman Aerospace Systems relies on our team to provide the insights needed to drive performance across a broad range of strategic activities. We are looking for a passionate Senior Principal Data Scientist in Melbourne Florida to design and develop automated, end-to-end, ETL pipelines, Artificial Intelligence/Machine Learning (AI/ML) solutions, and Data Analytics/Visualization solutions from disparate data sources. You will share in the ownership of the technical vision and direction for advanced analytics systems that change the way we see and use data. We are looking for people who are self-motivated, hardworking, and have demonstrated the ability to find innovative solutions to complex technical problems. Job Responsibilities:
Design, develop, and maintain a scalable Extract, Transform, and Load (ETL) pipelines.
Enable storing, searching, processing, and securing of extremely large structured or unstructured data sets.
Data preparation/cleaning, integration, and automation from heterogeneous sources
Ensure data integrity and system availability
Identify, evaluate, and recommend core technologies and strategies
Monitor and optimize system performance
Decomposition of user requirements into logical functions/componentsBasic Qualifications for Sr. Principal Data Scientist:
Bachelor's degree in STEM with 9 years of related experience; Masters degree in STEM with 7 years of related experience. PhD with 4 years of related experience.
Understanding of elastic data storage and archive storage lifecycle management
Experience with Data Science practices for prescriptive, predictive, diagnostic, descriptive, and cognitive analytics through automation, storage elasticity, and on-demand self service provisioning of all data types and lifecycles.
Experience with Tableau development or similar data application development. * Experience with SQL (structure query language) and relational databases.
Experience with graphic design background, creating user interfaces, and user focused dashboards.
Excellent communication skills and customer facing experience. * Proven ability to learn and master new technologies and techniques.
US Citizenship with the ability to obtain/maintain an active DoD Secret Clearance. * Must be able to obtain Program Access (PAR) within a reasonable amount of timePreferred Qualifications:
Master's degree in STEM with 7 years of related experience.
5+ years of experience working with ETL techniques and frameworks.
Expert in Python, SQL, and data visualization tools.
Development experience utilizing Hadoop, Spark, PowerShell, and automation scripts.
Familiarity with Data Virtualization and Data Cataloging tools (e.g. Denodo, Collibra).
Experience with NoSQL Databases (e.g., MongoDB, Neo4J, etc.)
CompTIA Security+ Certification.
Current DOD Top Secret clearance.Salary Range: $123,400 - $185,000 The above salary range represents a general guideline; however, Northrop Grumman considers a number of factors when determining base salary offers such as the scope and responsibilities of the position and the candidate's experience, education, skills and current market conditions. Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO . U.S. Citizenship is required for most positions.
Show more
Show less","Data Science, AI/ML, Data Analytics, Data Visualization, ETL, Data Storage, Data Security, SQL, Python, Tableau, Hadoop, Spark, PowerShell, Data Virtualization, Data Cataloging, NoSQL Databases, CompTIA Security+, DOD Top Secret Clearance, Data Cleaning, Automation, Programming, Machine Learning, Cloud Computing, System Administration, Problem Solving","Company: Northrop Grumman  
Job Title: Senior Principal Data Scientist  
Experience: Bachelor's degree in STEM with 9 years of related experience; Masters degree in STEM with 7 years of related experience; PhD with 4 years of related experience.  
Skills Needed: Elastic data storage and archive storage lifecycle management, Data Science practices, Tableau development, SQL and relational databases, graphic design, Python, data visualization tools, Hadoop, Spark, PowerShell, NoSQL Databases, Comp",0.14960629737491474,0.6063951
Data Engineer - Scala(U.S. remote),Railroad19,"Palm Bay, FL",https://www.linkedin.com/jobs/view/data-engineer-scala-u-s-remote-at-railroad19-3783320904,2023-12-20,Palm Bay,United States,Mid senior,Remote,"Railroad19, Inc.
is hiring
remote
Senior Data Engineers
to be a solid technical resource on a dynamic and growing team of accomplished engineers.
Our ideal candidate is passionate about creating well-architected solutions containing thoroughly tested code. The ability to communicate effectively and develop relationships by empathizing with client goals is a highly valued skill within our company culture.
Core Responsibilities:
Develop new and enhance existing application services
Writing tests to maintain code quality
Understand and adapt to our client's evolving business requirements within the television advertising domain.
Participate in detailed technical design sessions to understand client needs and provide productive feedback
Identify new opportunities, tools, and services to enhance the software platform
Support and troubleshoot issues, identify the root cause, and proactively recommend corrective actions
Skills & Experience:
Scala 2.12 + development experience
Passionate about developing clean and maintainable code with little or no side-effects
Experience building Restful APIs in Scala using Spark 2.4
Strong hands-on experience with AWS running spark jobs on ephemeral EMR clusters on AWS and S3.
Experience with relational and non-relational databases
Willingness to learn new technologies and takes pride in keeping up with the latest technologies and practices within the Scala and Spark development community
Excellent oral and written communication skills
Strong analytical and problem-solving skills
Self-directed and can effectively deliver solutions with little oversight
A bachelor's or master's degree in computer science, computer engineering, or other technical disciplines or equivalent work experience is preferred but not required.
$120,000 - $160,000 a year
Salary is commensurate with experience.
We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal-opportunity workplace.
#Hiringnow
We are actively hiring (Data Engineers)
#remote #Scala #DataEngineering #ApacheSpark
Show more
Show less","Scala, Spark, AWS, EMR, S3, Restful APIs, Relational databases, Nonrelational databases","Railroad19, Inc. is seeking remote Senior Data Engineers to join their dynamic and growing team. The ideal candidate should have a passion for creating well-architected solutions with thoroughly tested code and possess strong communication skills to empathize with client goals. Responsibilities include developing and enhancing application services, writing tests, adapting to client requirements in television advertising, participating in technical design sessions, identifying new opportunities, and troubleshooting issues. Required skills and experience include Scala 2.12 development, building Restful APIs",0.29861110750385805,0.8472637
Senior Supply Chain Data Scientist with Security Clearance,ClearanceJobs,"Lexington Park, MD",https://www.linkedin.com/jobs/view/senior-supply-chain-data-scientist-with-security-clearance-at-clearancejobs-3753459424,2023-12-20,Saint Marys City,United States,Mid senior,Hybrid,"Description: NSI requires a Senior Supply Chain Data Scientist to support the Score Technology and Analytics Center. The Sr Supply Chain Data Scientist will work with clients to develop DoD supply chain analytics requirements and capabilities - including, but not limited to, the development of data pipelines, database queries and procedures, supply chain models, and visualizations/dashboards. Desired Skills: Experience with NAVSUP and DLA supply chain data sources. Strong problem-solving and critical thinking skills. Experience working with and creating data architectures. Preferred to have experience with NAVAIR, United States Navy, and United States Marine Corps aviation data systems and business processes. Excellent written and verbal communication skills for coordinating across teams. Demonstrated ability to handle immediate-term projects, as well as the ability to shape and execute long-term analysis plans. Experience collaborating on cross-functional, cross-team projects in an Agile environment. Experience using analytics tools, such as Tableau (Prep, Desktop, and Server), R, Python, and relational databases. Experience applying advanced statistical techniques, concepts, and Natural Language Processing (NLP) models. Location: Lexington Park, MD Education: MS degree Supply Chain Management, Supply Chain Analytics, or similar field. BS accepted with additional experience. Experience: 8 years' experience in DoD supply chain data analysis. 4 years' experience in data modeling, data visualization, and data analysis. Security Clearance: Secret Clearance is Required. Must be U.S. citizen. Special Notes/Instructions: NSI is a privately held, small but quickly growing company with headquarters in Lexington Park, Maryland within 5 miles of the Patuxent River Naval Air Station. Established in 2004, we are now celebrating 19 years of excellence in providing quality products and services to the Department of Defense. Our benefits package includes medical, dental, vision, Long Term Disability, Life Insurance, Short Term Disability, paid time off, paid holidays, flexible spending account, employee assistance program, tuition assistance program, 401k Plan with company match as well as a fun and enthusiastic work environment! To Apply: NSI offers a team-oriented work environment and a competitive compensation and employee benefits package. If you have a commitment to excellence and want to join our team of top caliber professionals, we invite you to submit your resume electronically by visiting our careers website at: https://n-s-i.us/careers/apply/. Quality, Integrity, Teamwork, Success - that's NSI! NSI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
Show more
Show less","Supply Chain Analytics, Data Modeling, Data Visualization, Data Analysis, Tableau, R, Python, Relational Databases, Advanced Statistical Techniques, Concepts, Natural Language Processing (NLP), Agile, DoD, NAVSUP, DLA, NAVAIR, United States Navy, United States Marine Corps, Microsoft Azure, Git","Company: NSI (National Solutions, Inc.)

Job Title: Senior Supply Chain Data Scientist

Experience: 8 years' experience in DoD supply chain data analysis, 4 years' experience in data modeling, data visualization, and data analysis.

Skills Needed: Experience with NAVSUP and DLA supply chain data sources, strong problem-solving and critical thinking skills, experience working with and creating data architectures, preferred experience with NAVAIR, United States Navy, and United States Marine Corps aviation data systems",0.22424242158751154,0.7563307
"Data Analyst, Junior","Digital Enterprise Solutions, Inc. (DESI)","Patuxent River, MD",https://www.linkedin.com/jobs/view/data-analyst-junior-at-digital-enterprise-solutions-inc-desi-3768173336,2023-12-20,Saint Marys City,United States,Mid senior,Hybrid,"Digital Enterprise Solutions, Inc. (DESI) is seeking a
Junior Data Analyst
to join our team of qualified, diverse individuals. This is a Full Time (Regular) Exempt (Salary) position located in Patuxent River, MD 20670. Onboarding will require 1-2 visits to Naval Air Station (NAS) Patuxent River, MD (Pax). Initial onboarding activities will be virtual and telework maximized/permitted to the greatest extent possible, however, will require on-site work one day per week at NAS Pax (St. Mary's County Maryland).
Roles / Responsibilities
Perform data collection, data analysis, testing, and troubleshooting on large data sets.
Extract, transform, and load data using TOAD, SQL and/or Informatica.
Provide configuration and/or data management of data, information, files, and documents.
Education/Experience Requirements
To be considered for this position, you must meet the education and experience listed below:
High School diploma or GED is required.
Bachelor's degree in computer science, information systems or similar discipline is preferred.
BS/BA OR AA/AS degree and one year related experience -OR- HS and 2 years related experience.
Minimum Qualifications
To be considered for this position, you must minimally meet the knowledge, skills, and abilities listed below:
Experience developing and executing SQL queries.
Advanced proficiency in Excel (e.g., pivot tables, macros, VBA)
Excellent written and verbal communication skills.
US Citizenship is required due to US government contract requirement.
Ability to obtain and maintain a SECRET clearance (interim required to start).
Preferred Qualifications
Candidates with experience or knowledge in these desired skills will be given preferential consideration:
Familiarity with visualization tools such as Qlik or Tableau.
Experience developing/creating reports with Business Objects or other BI query tools.
Active SECRET clearance.
This position is contingent upon customer approval.
Eligible for our External Referral Program.
All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity, religion, national origin, disability, veteran status, age, marital status, pregnancy, genetic information, or other legally protected status.
For a listing of all DESI open positions, please visit the “Careers” section of our website at https://www.ilikedesi.com/careers
Show more
Show less","Data Analysis, Data Collection, Testing, Troubleshooting, Data Integration, Informatica, TOAD, SQL, Data Management, Data Configuration, Tableau, Qlik, Business Objects, VBA, Macros, Pivot Tables, Excel, Written Communication, Verbal Communication, Secret Clearance","Company Name: Digital Enterprise Solutions, Inc. (DESI)
Job Title: Junior Data Analyst
Experience: 
- High School diploma or GED is required.
- Bachelor's degree in computer science, information systems or similar discipline is preferred.
- BS/BA OR AA/AS degree and one year related experience -OR- HS and 2 years related experience.
Skills Needed:
- Experience developing and executing SQL queries.
- Advanced proficiency in Excel (e.g., pivot tables, macros, V",0.3311688280317086,0.64774156
Sr. Research Specialist/Data Analyst (Aviation) - Ability to Obt with Security Clearance,ClearanceJobs,"Patuxent River, MD",https://www.linkedin.com/jobs/view/sr-research-specialist-data-analyst-aviation-ability-to-obt-with-security-clearance-at-clearancejobs-3753450050,2023-12-20,Saint Marys City,United States,Mid senior,Hybrid,"Are you a highly motivated Senior Research Specialist/Data Analyst? Do you have a passion for developing creative solutions to complex tactical and force design challenges? Then AMERICAN SYSTEMS Senior Research Specialist/Aviation Operational Data Analyst position is for you! Join us today! As a Senior Research Specialist/Data Analyst, you will
Join an engaged, 100% employee-owned company
Work with a team of supportive, driven, highly skilled Subject Matter Experts
Provide real time data analysis to support aviation operations and operational test at the Joint Simulation Environment (JSE), Patuxent River, MD and other elite aviator training facilities
Receive a robust benefits package that includes our Employee Stock Ownership Plan! (ESOP) A week in the life of the Senior Research Specialist/Data Analyst includes:
Apply standard research methodologies to gather, process, and analyze data. Use relevant database software to effectively organize and present data and generate reports.
Generate compelling visualizations of quantitative datasets.
Develop institutional knowledge of the mission of Modeling & Simulation Enterprise Applications (MSEA), including the team's major customers.
Participate in meetings with the team. Support preparations for customer interactions.
Present and summarize data effectively in oral and written communication. Job Requirements Job Requirements
Ability to obtain a Secret Clearance (US Citizenship required)
Master's degree in Scientific Discipline; Data Science, Computer Science, Engineering, Information Technology, Mathematics, or Physics or equivalent experience.
At least 10 years of relevant work experience Required Knowledge, Skills, & Abilities:
Data collection and metrics creation
Skilled in programming (R, Python), statistics, SQL, data visualization, and other data analysis fundamentals
Able to analyze, interpret, summarize, and present data effectively
Demonstrated ability to apply advanced principles, theories, and concepts to solve uniquely complex problems
Able to conceptualize and develop solutions, formulate problem statements, and develop analysis methods and approaches
Excellent communication skills, both oral and written; experience in packaging analytic results in report format as well as in the development and presentation of oral briefings; interact with and advise senior levels of leadership
Ability to work in an unstructured environment Founded in 1975, AMERICAN SYSTEMS is one of the largest employee-owned companies in the United States. We are a government services contractor focused on delivering Strategic Solutions to complex national priority programs with 100+ locations worldwide. Through our focus on quality, strong cultural beliefs and innovation we deliver excellence every day. Company Awards:
Forbes National Best Midsize Companies
Energage National Best Workplaces, National
Washington Post Best Workplaces, Veteran Hiring Awards:
GOLD AWARD by U.S. Department of Labor HIRE Vets Medallion
BEST FOR VETS: EMPLOYER by Military Times
TOP 10 MILITARY FRIENDLY EMPLOYER by MilitaryFriendly.com AMERICAN SYSTEMS is committed to pay transparency for our applicants and employee-owners. The salary range for this position is$100,000-135,000. Actual compensation will be determined based on several factors permitted by law. AMERICAN SYSTEMS provides for the welfare of its employees and their dependents through a comprehensive benefits program by offering healthcare benefits, paid leave, retirement plans, insurance programs, and education and training assistance. EOE Minorities/Women/Disabled/Veterans/Gender Identity/Sexual Orientation
Show more
Show less","Data collection, Metrics creation, Programming (R Python), Statistics, SQL, Data visualization, Data analysis fundamentals, Data interpretation, Data summarization, Data presentation, Advanced principles, Theories, Concepts, Complex problemsolving, Solution conceptualization, Development, Problem statement formulation, Analysis methods, Analysis approaches, Communication skills, Report writing, Oral briefings, Unstructured environment","Company: AMERICAN SYSTEMS
Job Title: Senior Research Specialist/Aviation Operational Data Analyst
Experience: At least 10 years of relevant work experience
Skills Needed: Ability to obtain a Secret Clearance, Master's degree in Scientific Discipline or equivalent experience, Data collection and metrics creation, Programming skills (R, Python), Statistics, SQL, Data visualization, Ability to analyze, interpret, summarize, and present data effectively, Excellent communication skills, Problem-solving abilities

This position at AMERICAN SYSTEMS",0.22388059444060793,0.68441343
Data Systems Analyst – Advance,Chenega MIOS SBU,"Patuxent River, MD",https://www.linkedin.com/jobs/view/data-systems-analyst-%E2%80%93-advance-at-chenega-mios-sbu-3639936174,2023-12-20,Saint Marys City,United States,Mid senior,Hybrid,"Patuxent River, MD
Are you ready to enhance your skills and build your career in a rapidly evolving business climate? Are you looking for a career where professional development is embedded in your employer’s core culture? If so, Chenega Military, Intelligence & Operations Support (MIOS) could be the place for you! Join our team of professionals who support large-scale government operations by leveraging cutting-edge technology and take your career to the next level!
Chenega Agile Real-Time Solutions (CARS) was created with the purpose of providing integrated enterprise IT support to Federal customers both CONUS and OCONUS. CARS employs Subject Matter Experts (SMEs) with decades of experience working in the Federal marketplace.
Summary
Chenega Agile Real-Time Solutions (CARS) is looking for Data Systems Analyst – Advance our team in the Patuxent River area. This team supports a Department of Defense (DoD) client.
Duties And Responsibilities
Discover opportunities for data acquisition and data systems integration; perform research, design, and development for databases and data processing systems; develop data systems, architectures, and models.
Leverage high-performance computing infrastructures into systems architecture.
Recommend the best architectures, tools, and technologies to address organizational needs.
Other duties as assigned.
Minimum Qualifications
Graduate degree and 7+ years of relevant experience OR
High school diploma or GED equivalent, active CSWF Certifications: CSWF Code 421, 422, or CISM, CISSP, and GSLC
Active Top Secret w/SCI eligible clearance
Knowledge, Skills, And Abilities
Ability to obtain Secret clearance
Ability to work independently and yet be effective within a team setting
Must be capable of managing multiple efforts with time-related constraints in a fast-paced contracting environment.
Demonstrated ability to effectively communicate and collaborate with diverse internal and external stakeholder groups and individuals.
Friendly presence, helpful attitude, good interpersonal skills, and ability to work well with others.
Excellent skills in Microsoft Word, Excel, and other Office applications.
Experience working in a home office setting as well as the ability to train end users on frequently asked technical issues.
Ability to provide technical assistance and support over the phone with good phone skills and a professional demeanor.
Previous customer service experience strongly desired.
Good problem-solving skills with the ability to visualize a problem or situation and think abstractly to solve it.
How you’ll grow
At Chenega MIOS, our professional development plan focuses on helping our team members at every level of their careers to identify and use their strengths to do their best work every day. We believe there’s always room to learn from entry-level employees to senior leaders.
We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their careers.
Benefits
At Chenega MIOS, we know that great people make a great organization. We value our team members and offer them a broad range of benefits.
Learn more about what working at Chenega MIOS can mean for you.
Chenega MIOS’s culture
Our positive and supportive culture encourages our team members to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them be healthy, centered, confident, and aware. We offer well-being programs and continuously look for new ways to maintain a culture where we excel and lead healthy, happy lives.
Corporate citizenship
Chenega MIOS is led by a purpose to make an impact that matters. This purpose defines who we are and extends to our relationships with our clients, team members, and communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities.
Learn more about Chenega’s impact on the world.
Chenega MIOS News- https://chenegamios.com/news/
Tips from your Talent Acquisition team
We Want Job Seekers Exploring Opportunities At Chenega MIOS To Feel Prepared And Confident. To Help You With Your Research, We Suggest You Review The Following Links
Chenega MIOS web site - www.chenegamios.com
Glassdoor - https://www.glassdoor.com/Overview/Working-at-Chenega-MIOS-EI_IE369514.11,23.htm
LinkedIn - https://www.linkedin.com/company/1472684/
Facebook - https://www.facebook.com/chenegamios/
Chenega Corporation and family of companies is an EOE.
Equal Opportunity Employer/Veterans/Disabled
Native preference under PL 93-638.
We participate in the E-Verify Employment Verification Program.
Show more
Show less","Data Systems Analysis, Data Acquisition, Data Systems Integration, Research, Design, Development, Database, Data Processing Systems, HighPerformance Computing Infrastructures, Systems Architecture, Microsoft Word, Microsoft Excel, Office Applications, Secret Clearance","Company Name: Chenega Agile Real-Time Solutions (CARS)
Job Title: Data Systems Analyst
Location: Patuxent River, MD
Experience: Graduate degree and 7+ years of relevant experience or High school diploma/GED equivalent with active CSWF Certifications
Skills Needed: Ability to obtain Secret clearance, work independently and in a team setting, manage multiple efforts in a fast-paced environment, communicate effectively, proficiency in Microsoft Word, Excel, and Office applications, technical assistance and customer service",0.19105690830590258,0.7811787
Sr Aviation Ops Data Analyst with Security Clearance,ClearanceJobs,"Lexington Park, MD",https://www.linkedin.com/jobs/view/sr-aviation-ops-data-analyst-with-security-clearance-at-clearancejobs-3760175892,2023-12-20,Saint Marys City,United States,Mid senior,Hybrid,"Position Summary As a Senior Research Specialist - Aviation Operational Data Analyst for the Analysis and Reporting Tool (ART) engineering and analysis team, you will be joining a strong team providing real time data analysis to support aviation operations and operational test at the Joint Simulation Environment (JSE), Patuxent River, MD and other elite aviator training facilities. You will be supporting decision-makers by quantifying naval warfighting capabilities and limitations under realistic employment conditions; developing empirical or theoretical estimates for the performance of fleet systems and platforms; and developing creative solutions to complex tactical and force design challenges. **MUST BE A US CITIZEN** Essential Duties and Responsibilities
Apply standard research methodologies to gather, process, and analyze data. Use relevant database software to effectively organize and present data and generate reports.
Generate compelling visualizations of quantitative datasets.
Develop institutional knowledge of the mission of MSEA, including the team's major customers.
Participate in meetings with the team. Support preparations for customer interactions.
Present and summarize data effectively in oral and written communication. Requirements Required Experience:
10 years of relevant work experience in data collection and metrics creation.
Skilled in programming (R, Python), statistics, SQL, data visualization, and other data analysis fundamentals.
Analyze, interpret, summarize, and present data effectively.
Demonstrated ability to apply advanced principles, theories, and concepts to solve uniquely complex problems.
Conceptualize and develop solutions, formulate problem statements, and develop analysis methods and approaches.
Excellent communication skills, both oral and written; experience in packaging analytic results in report format as well as in the development and presentation of oral briefings; interact with and advise senior levels of leadership.
Ability to work in an unstructured environment. Education / Certifications
MS in Scientific Discipline; Data Science, Computer Science, Engineering, Information Technology, Mathematics, or Physics or equivalent experience.
PHD preferred. Desired Skill, Experience, or Certifications
Experience with supporting Special Access Program (SAP) efforts.
Aviation experience Clearance
Must be able to obtain DoD Secret security clearance.
Show more
Show less","R, Python, SQL, Data visualization, Analytics, Statistics, Data analysis, Programing, Data mining, Database management, Scientific computing, Mathematics, Physics, Computer science, Engineering","Company: Analysis and Reporting Tool (ART)
Job Title: Senior Research Specialist - Aviation Operational Data Analyst
Experience: 10 years
Skills Needed: Programming (R, Python), statistics, SQL, data visualization, data collection, metrics creation, advanced problem-solving, communication skills, data analysis fundamentals, ability to work in an unstructured environment
Education/Certifications: MS in Scientific Discipline (Data Science, Computer Science, Engineering, Information Technology, Mathematics, or Physics) or equivalent experience; PH",0.30344827258026164,0.7447084
People Data Scientist,Roblox,"San Mateo, CA",https://www.linkedin.com/jobs/view/people-data-scientist-at-roblox-3756047330,2023-12-20,Alameda,United States,Mid senior,Hybrid,"Every day, tens of millions of people come to Roblox to explore, create, play, learn, and connect with friends in 3D immersive digital experiences– all created by our global community of developers and creators.
At Roblox, we’re building the tools and platform that empower our community to bring any experience that they can imagine to life. Our vision is to reimagine the way people come together, from anywhere in the world, and on any device. We’re on a mission to connect a billion people with optimism and civility, and looking for amazing talent to help us get there.
A career at Roblox means you’ll be working to shape the future of human interaction, solving unique technical challenges at scale, and helping to create safer, more civil shared experiences for everyone.
WHY PEOPLE SCIENCE AND ANALYTICS?
The People Science & Analytics team at Roblox supports our People, Places, & Systems group in all areas of applied statistics, data science for internal operations. Our team works to deliver a wide range of insights and solutions for Roblox, from developing industry-leading hiring assessments, to conducting job analysis and qualitative research, to architecting data analytics systems and tools. Reporting to the Senior Director, People Science and Analytics, in this role you will join a world-class group of learning and data scientists who are focused on collecting and using qualitative and quantitative data to guide decisions and to design and support Roblox's approach to leadership, people development, and organizational design and culture.
This role is based onsite at our HQ in San Mateo, CA.
You Will
Partner with the teams within the People, Places, & Systems organization to identify key metrics, trends, and analytical needs.
Collaborate with the Assessment team on assessment design and scoring.
Clean and structure telemetry data to extract useful information, and create scoring models and analytics for game-based assessments.
Create, test, and maintain data pipeline code.
Design statistical experiments, conduct data analysis, and visualization for structured and unstructured data from a variety of different sources.
Experiment on, analyze, and visualize structured and unstructured data from a variety of sources.
Apply expertise in psychometrics, quantitative analysis, data mining, and applied statistics to improve new assessment and people science methods.
You Have
PhD in Mathematics, Statistics, Data Science, Psychometrics (or related field)
Industry experience in psychometrics and assessments
2+ Experience cleaning, collecting and extracting messy data structures (i.e., MOOCs, ITSs, Games, etc.)
3+ years of advanced data reporting, visualization, and dashboard creation
2+ years of operational testing experience
3+ years of SQL experience for data extraction, manipulation, and analyses; including stored procedures, complex joins, creation of views, and database scripting
You Are
A team player. You take initiative, are proactive, and drive toward team goals
A strong communicator. You understand that analysis must be presented in meaningful ways and participate in spirited discussions about the findings. You can explain technical concepts to non-technical audiences and discuss appropriate tradeoffs.
Highly self-driven. You are perpetually curious and consistently work to improve your skills by learning the latest modeling techniques, data tools, and domain knowledge. You excel in environments with freedom and autonomy and are excited by exploring a new problem space.
A data expert. You are familiar with data analysis with SQL and a scripting language such as python or R. You are comfortable throughout different phases of data product development and can take a project from end to end.
For roles that are based at our headquarters in San Mateo, CA: The starting base pay for this position is as shown below. The actual base pay is dependent upon a variety of job-related factors such as professional background, training, work experience, location, business needs and market demand. Therefore, in some circumstances, the actual salary could fall outside of this expected range. This pay range is subject to change and may be modified in the future. All full-time employees are also eligible for equity compensation and for benefits.
Annual Salary Range
$189,100—$231,650 USD
You’ll Love
Industry-leading compensation package
Excellent medical, dental, and vision coverage
A rewarding 401k program
Flexible vacation policy
Roflex - Flexible and supportive work policy
Roblox Admin badge for your avatar
At Roblox HQ:
Free catered lunches five times a week and several fully stocked kitchens with unlimited snacks
Onsite fitness center and fitness program credit
Annual CalTrain Go Pass
Roblox provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
Show more
Show less","SQL, Python, R, Data Analysis, Data Mining, Psychometrics, Statistical Experiments, Data Visualization, Data Pipelines, Data Structures, Machine Learning, Data Science, Data Analytics Systems, Leadership, People Development, Organizational Design, Organizational Culture","Company: Roblox
Job Title: Data Scientist - People Science & Analytics
Experience: Ph.D. in Mathematics, Statistics, Data Science, Psychometrics (or related field), 2+ years in psychometrics and assessments, 2+ years cleaning and extracting messy data structures, 3+ years in data reporting, visualization, and dashboard creation, 2+ years in operational testing, 3+ years in SQL for data extraction and manipulation.
Skills Needed: Strong team player, excellent communicator",0.11832060896072492,0.7089463
Customer Service Representative/Data Analyst/Data Entry Clerk Part Time,Drmartens,"Quesnel, British Columbia, Canada",https://ca.linkedin.com/jobs/view/customer-service-representative-data-analyst-data-entry-clerk-part-time-at-drmartens-3756472400,2023-12-20,Quesnel,Canada,Mid senior,Hybrid,"Summary:
The Data Analyst will be responsible for analyzing and interpreting large datasets to provide valuable insights and recommendations to the business. They will work closely with cross-functional teams to gather and analyze data, develop reports, and provide customized solutions to help the organization gain a competitive edge.
Responsibilities:
Analyze large data sets using advanced statistical techniques and tools to uncover trends, opportunities, and insights.
Develop, maintain and analyze performance metrics and reports that support data-driven decision-making processes.
Collaborate with stakeholders to identify business questions and translate them into data and analysis requirements.
Develop models and algorithms to help optimize business processes and drive efficiencies.
Design and execute A/B tests and experiments to identify opportunities for optimization.
Identify data quality issues and help to develop solutions to improve data integrity, accuracy, and completeness.
Manage data collection, cleansing, and manipulation processes to ensure data is readily accessible and easy to work with.
Prepare and present data-driven reports and insights to stakeholders, highlighting key findings and recommendations.
Qualifications:
1+ years of relevant experience in data analysis, preferably in the Internet and New Media industry.
Proven experience in analyzing large and complex datasets using SQL, R, Python, or related tools.
Strong analytical, critical thinking, and problem-solving skills.
Excellent communication and collaboration skills, with the ability to work effectively in a team environment.
Experience with data visualization tools such as Tableau, Power BI, or related tools.
Knowledge of statistical modeling, hypothesis testing, and A/B testing methodologies.
Familiarity with data management and ETL processes.
If you are interested in this position, please send your resume, contact information and salary requirements to : hiring@jobsai.live
Powered by Webbtree
Show more
Show less","Data Analysis, Data Interpretation, Statistical Techniques, Data Manipulation, Performance Metrics, Reporting, DataDriven Decision Making, A/B Testing, Data Quality, Data Integrity, Data Accessibility, Data Visualization, SQL, R, Python, Tableau, Power BI, Statistical Modeling, Hypothesis Testing, ETL","Company: Webbtree

Job Title: Data Analyst

Experience: 1+ years

Skills Needed:
- Analyzing large datasets using SQL, R, Python, or related tools
- Developing and analyzing performance metrics and reports
- Collaborating with stakeholders to translate business questions into data requirements
- Developing models and algorithms to optimize business processes
- Conducting A/B tests and experiments for optimization
- Identifying and resolving data quality issues
- Managing data collection, cleansing, and manipulation processes
",0.360515017807659,0.7289382
Senior DevOps Engineer in Bigdata,HP,"Corvallis, OR",https://www.linkedin.com/jobs/view/senior-devops-engineer-in-bigdata-at-hp-3743273680,2023-12-20,Monmouth,United States,Mid senior,Hybrid,"Responsible for deployment through all Software Development lifecycle stages across distributed systems with a goal of using industry standards and continuous improvements in release processes to ensure scalability and consistency. Conversant with all the technical as well as Cloud operations and infrastructure aspects for integrated operations and capable in the utilization of various automation tools which may be required for process automation and testing. Creates real-time monitoring, alerting, response and fault analysis to achieve HP's solution and business performance requirement and ensures deployments meet needed security and compliance requirements through the entirety of the product lifecycle.
Responsibilities
Takes on leadership role in a team that implements DevOps infrastructure projects.
Creates, maintains, and iterates on the organization's CI/CD processes for new and existing services.
Designs and implements secure automation solutions for development, testing, and production environments.
Develops complex solutions for operational administration, system/data backup, disaster recovery, and security/performance monitoring.
Builds and deploys automation, monitoring, and analysis solutions.
Manages the organization's continuous integration and delivery pipeline to maximize efficiency.
Implements industry best practices for system hardening and configuration management.
Seeks understanding of customer/end-user requirements and project KPIs.
Knowledge & Skills
Advanced knowledge of configuration management tools.
Full understanding of system administration in cloud environments.
Proficiency with continuous integration tools.
Demonstrated expertise in scripting languages including Bash, Python.
Significant experience maintaining and developing highly-available, fault-tolerant systems at scale.
Expert level of understanding of software development lifecycle best practices.
Demonstrated expertise with Kubernetes/EKS, AWS services, Terraform, Helm Charts.
Extra Knowledge
Javascript
Airflow, JupyterHub, Flux/gitops, Terragrunt
Scope & Impact
Acts as a leader within the software DevOps function.
Directly influences the nature of the work delivered.
Takes responsibility for code and overall delivery quality with results impacting departmental effectiveness for multiple quarters.
Complexity
Moderate to high.
Education & Experience
Bachelor's degree in relevant area or demonstrated competence. Typically 7-10 years of relevant experience.
HP occasionally offers work authorization sponsorship for critical need roles. However, this opportunity currently does not offer work authorization sponsorship.
Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets. The typical base pay range for this role across the U.S. is
$150,000-169,000
. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.
About HP
You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you.
So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.
HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.
Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are.
From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!
Show more
Show less","DevOps, CI/CD, Automation, Cloud computing, Security, Compliance, Bash, Python, Kubernetes, EKS, AWS services, Terraform, Helm Charts, Javascript, Airflow, JupyterHub, Flux/gitops, Terragrunt","Company: HP
Job Title: Senior DevOps Engineer
Experience: 7-10 years
Skills Needed: Proficiency in configuration management tools, cloud system administration, continuous integration tools, Bash and Python scripting, maintaining fault-tolerant systems, software development lifecycle best practices, Kubernetes/EKS, AWS services, Terraform, Helm Charts
Responsibilities: Leading DevOps infrastructure projects, designing and implementing CI/CD processes, creating secure automation solutions, developing operational solutions, building automation and monitoring solutions",0.1774580312130152,0.6837565
Data Engineer - Scala(U.S. remote),Railroad19,"Pueblo, CO",https://www.linkedin.com/jobs/view/data-engineer-scala-u-s-remote-at-railroad19-3782856438,2023-12-20,Pueblo,United States,Mid senior,Remote,"Railroad19, Inc.
is hiring
remote
Senior Data Engineers
to be a solid technical resource on a dynamic and growing team of accomplished engineers.
Our ideal candidate is passionate about creating well-architected solutions containing thoroughly tested code. The ability to communicate effectively and develop relationships by empathizing with client goals is a highly valued skill within our company culture.
Core Responsibilities:
Develop new and enhance existing application services
Writing tests to maintain code quality
Understand and adapt to our client's evolving business requirements within the television advertising domain.
Participate in detailed technical design sessions to understand client needs and provide productive feedback
Identify new opportunities, tools, and services to enhance the software platform
Support and troubleshoot issues, identify the root cause, and proactively recommend corrective actions
Skills & Experience:
Scala 2.12 + development experience
Passionate about developing clean and maintainable code with little or no side-effects
Experience building Restful APIs in Scala using Spark 2.4
Strong hands-on experience with AWS running spark jobs on ephemeral EMR clusters on AWS and S3.
Experience with relational and non-relational databases
Willingness to learn new technologies and takes pride in keeping up with the latest technologies and practices within the Scala and Spark development community
Excellent oral and written communication skills
Strong analytical and problem-solving skills
Self-directed and can effectively deliver solutions with little oversight
A bachelor's or master's degree in computer science, computer engineering, or other technical disciplines or equivalent work experience is preferred but not required.
$120,000 - $160,000 a year
Salary is commensurate with experience.
We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal-opportunity workplace.
#Hiringnow
We are actively hiring (Data Engineers)
#remote #Scala #DataEngineering #ApacheSpark
Show more
Show less","Scala 2.12, Spark 2.4, RESTful APIs, AWS, S3, EMR clusters, Cloud Computing, Relational databases, Nonrelational databases, Data structures, Algorithms, Design Patterns, Software Testing, Troubleshooting, Problem Solving, Analytical Skills, Communication Skills, Teamwork, Apache Spark, Hadoop, Python, Java, Linux, SQL, NoSQL","Company Name: Railroad19, Inc.

Job Title: Senior Data Engineer

Experience: Not specified

Skills Needed: 
- Scala 2.12 + development experience
- Experience building Restful APIs in Scala using Spark 2.4
- Strong hands-on experience with AWS running spark jobs on ephemeral EMR clusters on AWS and S3
- Experience with relational and non-relational databases
- Passionate about developing clean and maintainable code
- Willingness to learn new technologies",0.3478260837219072,0.85879207
Inventory Optimization Analyst (Data Scientist)***Analyste optimisation d'inventaire,IPEX by Aliaxis,"Oakville, Ontario, Canada",https://ca.linkedin.com/jobs/view/inventory-optimization-analyst-data-scientist-analyste-optimisation-d-inventaire-at-ipex-by-aliaxis-3784371476,2023-12-20,Hamilton,Canada,Mid senior,Onsite,"IPEX is one of the North American leading providers of advanced plastic piping systems. Our mission is to shape a better tomorrow by connecting people with water and energy.
We currently have an exciting opportunity for an experienced Data Scientist to work in our Supply Chain Department as
Inventory Optimization Analyst
.
This role is based in our Oakville office, on a hybrid schedule, and reports to the
Director, End-To-End Supply Chain Planning
.
Do not miss the opportunity to join a broad family of people-centric professionals, thought leaders and rapid thinkers, entrepreneurs in spirit and status quo-fighters!
Job Summary
The Inventory Optimization Analyst ensures that the inventory planning models are optimized to achieve and exceed organization objectives for service to customers and inventory health, for a large portfolio of finished goods products.
The selected candidate acts as a focal point for root cause analysis on inventory levels above or below targets, using large datasets and data modelling, and collaborating with cross functional stakeholders to problem solve and bring inventory into optimal levels.
Principal Activities
Create models using inventory data to provide the minimum and maximum inventory targets within corporate inventory objectives
Provide regular reporting on the Corporate KPIs for Inventory Quality Ratio (IQR), and conducts root cause analysis with corrective action plans
Implement efficient workflows to engage key stakeholders as needed for action on inventory optimization
Prepare inventory lists for evaluation by stakeholders
Perform regular follow-ups with cross functional stakeholders to address inventories that do not meet the IQR objective.
Partner with our Supply Planners for root cause analysis and corrective actions identification
Collaborate with our Demand Planners to confirm demand, to validate any inventories that may be too low or in excess
Connect regularly with our Purchasing team on inventory planning parameters for purchased items
Work with our Inventory Deployment team on actions related to excess inventory by location
Provide expertise on best practice for inventory and data optimization, including data modelling, reporting, and analytics.
Monitor and report on progress, resolve bottlenecks, and escalate in a timely manner
Use good judgement to intervene as needed to achieve KPIs for inventory and fill rates.
Job Requirements
University degree with a specialty in Data Science, Supply Chain, Data Analytics, or Mathematics and Statistics discipline.
5+ year of relevant inventory optimization and data modelling experience, preferably within an industrial manufacturing or CPG environment; or other relevant transferable experience
Strong analytical skills, ability to administer, clean, interpret, and analyze large datasets to provide business insights for decision-making.
Proven experience with Power BI development (DAX) and Excel macros using VBA. Experience with data visualization and analysis using Power BI is highly desirable
Strong ability to explain data findings, including creating and delivering PowerPoint presentations, and facilitating working sessions
Proficiency in Microsoft Office and experience with process mapping using MS Visio
Familiarity with data modelling and data analysis
Experience with SAP Inventory Planning and optimization, is an asset
Knowledge of SQL databases and Python is a nice-to-have
Strong communication (written as well as spoken), interpersonal, and coordination skills
Factual approach to problem solving and challenges
Ability to work both independently and as a team player
High attention to detail with a process improvement mindset
Adept at working in a fast-moving environment and consistency meeting deadlines
IPEX is committed to providing accommodations for people with disabilities throughout the recruitment process and, upon request, will work with qualified job applicants to provide suitable accommodation in a manner that takes into account the applicant’s accessibility needs due to disability. Accommodation requests are available to candidates taking part in all aspects of the selection process for IPEX jobs. To request an accommodation, please contact HR at HR@ipexna.com
Show more
Show less","Data Science, Supply Chain, Data Analytics, Mathematics, Statistics, Inventory Optimization, Data Modelling, Power BI, DAX, Excel, VBA, Data Visualization, Data Analysis, PowerPoint, Microsoft Office, Process Mapping, MS Visio, SAP Inventory Planning, SQL, Python, Communication, Interpersonal Skills, Coordination, Problem Solving, Teamwork, Attention to Detail, Process Improvement","Company: IPEX
Job Title: Inventory Optimization Analyst
Experience: 5+ years
Skills Needed: University degree in Data Science, Supply Chain, Data Analytics, or Mathematics and Statistics. Strong analytical skills, proficiency in Power BI development and Excel macros using VBA. Experience in data visualization, Microsoft Office, and process mapping. Familiarity with SAP Inventory Planning, SQL databases, and Python. Excellent communication, problem-solving, and teamwork abilities. High attention to detail, ability to work",0.21026894615168493,0.532516
Sr. Data Scientist,Sagen,"Oakville, Ontario, Canada",https://ca.linkedin.com/jobs/view/sr-data-scientist-at-sagen-3774671386,2023-12-20,Hamilton,Canada,Mid senior,Hybrid,"Job Summary
Reporting to the VP Modeling, Senior Data Scientist will contribute to the various stages of Machine Learning Model (ML) development and deployment pipelines in a dynamic business environment.
Responsibilities
Support the development, calibration, validation implementation, automation, optimization, and monitoring of high impact ML models using Python & R
Develop an in-depth understanding of the business needs and collaborate with other team members towards concept testing and prototype development related to finance, actuarial and risk management reports/data requirements
Responsible for collecting, parsing, visualizing, and analyzing large data sets from multiple sources to build predictive models or ad hoc data exploration
Code, test and deploy analytics pipelines to create robust and scalable advanced analytical applications to drive customer-centric automation
Ensures that advanced analytics pipelines are auditable, secure and will serve multiple user groups
Contribute to the knowledge base with centralized documentation and code bank and facilitate workshops for the end users
Skills And Qualifications
University degree in Computer Science/IT or any other data and compute intensive field
2-4 years of hands-on experience in various stages of the Machine Learning Model Lifecycle (Feature Engineering, Feature Selection, Hyperparameter tuning, Model Evaluation, etc.)
Solid experience in Python, PySpark, and Shell Scripting (Linux OS)
Experience in NLP, Computer Vision, Deep Learning, or Generative AI would be a plus
Proficient in using libraries such as NumPy, Pandas, Scikit-learn, Spark ML, etc.
Display a sense of urgency, ensuring timely and high-quality deliverables to stakeholders
Demonstrated willingness to learn and ado pt new tools/techniques, and open to share the knowledge with others
S agen is committed to creating a diverse and inclusive work culture that closely matches the diversity of our customers. We encourage applications from all backgrounds and abilities to ensure we get the best, most creative and diverse talent across our business.
Sagen will provide accommodations to applicants with disabilities throughout the selection process to meet their individual needs.
As an Employer Partner of the Canadian Center for Diversity and Inclusion and a member of the Black North Initiative, Sagen encourages you to apply and join a fantastic organization.
Apply Now
Show more
Show less","Machine Learning, Python, R, Data Analysis, Data Visualization, Predictive Modeling, NLP, Computer Vision, Deep Learning, Generative AI, PySpark, Shell Scripting, NumPy, Pandas, Scikitlearn, Spark ML","Company Name: Sagen
Job Title: Senior Data Scientist
Experience: 2-4 years
Skills Needed: University degree in Computer Science/IT or data-intensive field, hands-on experience in various stages of Machine Learning Model Lifecycle, proficiency in Python, PySpark, and Shell Scripting, experience in NLP, Computer Vision, Deep Learning or Generative AI is a plus, familiarity with libraries such as NumPy, Pandas, Scikit-learn, Spark ML, ability to deliver",0.2847682088581641,0.5730009
Inventory Optimization Analyst (Data Scientist),IPEX by Aliaxis,"Oakville, Ontario, Canada",https://ca.linkedin.com/jobs/view/inventory-optimization-analyst-data-scientist-at-ipex-by-aliaxis-3778821655,2023-12-20,Hamilton,Canada,Mid senior,Hybrid,"IPEX is one of the North American leading providers of advanced plastic piping systems. Our mission is to shape a better tomorrow by connecting people with water and energy.
We currently have an exciting opportunity for an experienced Data Scientist to work in our Supply Chain Department as
Inventory Optimization Analyst
.
This role is based in our Oakville office, on a hybrid schedule, and reports to the
Director, End-To-End Supply Chain Planning
.
Do not miss the opportunity to join a broad family of people-centric professionals, thought leaders and rapid thinkers, entrepreneurs in spirit and status quo-fighters!
Job Summary
The Inventory Optimization Analyst ensures that the inventory planning models are optimized to achieve and exceed organization objectives for service to customers and inventory health, for a large portfolio of finished goods products.
The selected candidate acts as a focal point for root cause analysis on inventory levels above or below targets, using large datasets and data modelling, and collaborating with cross functional stakeholders to problem solve and bring inventory into optimal levels.
Principal Activities
Create models using inventory data to provide the minimum and maximum inventory targets within corporate inventory objectives
Provide regular reporting on the Corporate KPIs for Inventory Quality Ratio (IQR), and conducts root cause analysis with corrective action plans
Implement efficient workflows to engage key stakeholders as needed for action on inventory optimization
Prepare inventory lists for evaluation by stakeholders
Perform regular follow-ups with cross functional stakeholders to address inventories that do not meet the IQR objective.
Partner with our Supply Planners for root cause analysis and corrective actions identification
Collaborate with our Demand Planners to confirm demand, to validate any inventories that may be too low or in excess
Connect regularly with our Purchasing team on inventory planning parameters for purchased items
Work with our Inventory Deployment team on actions related to excess inventory by location
Provide expertise on best practice for inventory and data optimization, including data modelling, reporting, and analytics.
Monitor and report on progress, resolve bottlenecks, and escalate in a timely manner
Use good judgement to intervene as needed to achieve KPIs for inventory and fill rates.
Job Requirements
University degree with a specialty in Data Science, Supply Chain, Data Analytics, or Mathematics and Statistics discipline.
5+ year of relevant inventory optimization and data modelling experience, preferably within an industrial manufacturing or CPG environment; or other relevant transferable experience
Strong analytical skills, ability to administer, clean, interpret, and analyze large datasets to provide business insights for decision-making.
Proven experience with Power BI development (DAX) and Excel macros using VBA. Experience with data visualization and analysis using Power BI is highly desirable
Strong ability to explain data findings, including creating and delivering PowerPoint presentations, and facilitating working sessions
Proficiency in Microsoft Office and experience with process mapping using MS Visio
Familiarity with data modelling and data analysis
Experience with SAP Inventory Planning and optimization, is an asset
Knowledge of SQL databases and Python is a nice-to-have
Strong communication (written as well as spoken), interpersonal, and coordination skills
Factual approach to problem solving and challenges
Ability to work both independently and as a team player
High attention to detail with a process improvement mindset
Adept at working in a fast-moving environment and consistency meeting deadlines
#LI-MD2
IPEX is committed to providing accommodations for people with disabilities throughout the recruitment process and, upon request, will work with qualified job applicants to provide suitable accommodation in a manner that takes into account the applicant’s accessibility needs due to disability. Accommodation requests are available to candidates taking part in all aspects of the selection process for IPEX jobs. To request an accommodation, please contact HR at HR@ipexna.com
Show more
Show less","Data Science, Supply Chain Management, Data Analytics, Mathematics, Statistics, Inventory Optimization, Data Modelling, Power BI, DAX, Excel Macros, VBA, PowerPoint, Microsoft Office, MS Visio, SAP Inventory Planning, SQL, Python, Communication Skills, Interpersonal Skills, Coordination Skills, Problem Solving, Teamwork, Attention to Detail, Process Improvement","Company: IPEX  
Job Title: Inventory Optimization Analyst  
Experience: 5+ years  
Skills Needed: University degree in Data Science, Supply Chain, Data Analytics, or Mathematics and Statistics; strong analytical skills; experience with Power BI and Excel macros; proficiency in Microsoft Office and MS Visio; familiarity with data modeling and analysis; knowledge of SAP Inventory Planning and optimization is an asset; familiarity with SQL databases and Python is a plus; strong communication and interpersonal skills; ability to work independently and",0.20437955951598677,0.5406735
Customer Service Representative/Data Analyst/Data Entry Clerk,Dooleyboyer,"Bundaberg, Queensland, Australia",https://au.linkedin.com/jobs/view/customer-service-representative-data-analyst-data-entry-clerk-at-dooleyboyer-3742321859,2023-12-20,Bundaberg,Australia,Mid senior,Hybrid,"Customer Service Representative/Data Analyst/Data Entry Clerk /Office will be responsible for analyzing and interpreting large datasets to provide valuable insights and recommendations to the business. They will work closely with cross-functional teams to gather and analyze data, develop reports, and provide customized solutions to help the organization gain a competitive edge.
Responsibilities:
Analyze large data sets using advanced statistical techniques and tools to uncover trends, opportunities, and insights.
Develop, maintain and analyze performance metrics and reports that support data-driven decision-making processes.
Collaborate with stakeholders to identify business questions and translate them into data and analysis requirements.
Develop models and algorithms to help optimize business processes and drive efficiencies.
Design and execute A/B tests and experiments to identify opportunities for optimization.
Identify data quality issues and help to develop solutions to improve data integrity, accuracy, and completeness.
Manage data collection, cleansing, and manipulation processes to ensure data is readily accessible and easy to work with.
Prepare and present data-driven reports and insights to stakeholders, highlighting key findings and recommendations.
Qualifications:
1+ years of relevant experience in data analysis, preferably in the Internet and New Media industry.
Proven experience in analyzing large and complex datasets using SQL, R, Python, or related tools.
Strong analytical, critical thinking, and problem-solving skills.
Excellent communication and collaboration skills, with the ability to work effectively in a team environment.
Experience with data visualization tools such as Tableau, Power BI, or related tools.
Knowledge of statistical modeling, hypothesis testing, and A/B testing methodologies.
Familiarity with data management and ETL processes.If you are interested in this position, please send your resume, contact information and salary requirements to : hrteam@jobsolutionsai.online
Powered by Webbtree
Show more
Show less","Data Analysis, Data Interpretation, Data Mining, Statistical Techniques, Reporting, Datadriven Decision Making, Business Intelligence, Machine Learning, A/B Testing, Data Quality Management, Data Collection, Data Cleansing, Data Manipulation, Data Visualization, Tableau, Power BI, SQL, R, Python, Statistical Modeling, Hypothesis Testing, ETL Processes","Company: Webbtree
Job Title: Customer Service Representative/Data Analyst/Data Entry Clerk
Experience: 1+ years
Skills Needed: Data analysis, statistical techniques, performance metrics, data-driven decision-making, SQL, R, Python, data visualization, statistical modeling, A/B testing, data management, ETL processes.",0.2056074739627915,0.5191381
Senior Staff AI Data Engineer,Recruiting from Scratch,"Bozeman, MT",https://www.linkedin.com/jobs/view/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759708633,2023-12-20,Bozeman,United States,Mid senior,Hybrid,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/
This is a hybrid role based in our
Palo Alto,
San
Francisco or Chicago
offices and will require you to be in office Tuesdays and Thursdays.
What’s so interesting about this role?
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.
What’s the job?
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.
Responsibilities:
Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure
What We’ll Love About You
Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)
We’ll really swoon if you have
2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects
What You'll Love About Us
Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/
Show more
Show less","Data Engineering, Machine Learning, Data Mining, Data Cleaning, Data Normalization, Data Modeling, Pandas, R, Airflow, KubeFlow, NLP, Python, Java, Bash, SQL, Git, Snowflake, Kubernetes, Docker, Helm, Spark, PySpark, AWS, GCP, Azure, DynamoDB, ETL, Kafka, Storm, SparkStreaming, Applied Machine Learning","Company Name: Recruiting from Scratch
Job Title: Data Engineer Lead
Experience: 5+ years of experience as a data engineer, including 2+ years of technical leadership experience
Skills Needed: 
- Bachelor's in Computer Science, Mathematics, Physics, or related fields
- Experience in statistical analysis & visualization using Pandas or R
- Designing and building data pipelines for ML/DL models
- Coding skills in Python, Java, bash, SQL, and Git version control
",0.1743970295902878,0.5348172
Senior Staff AI Data Engineer,Recruiting from Scratch,"Bozeman, MT",https://www.linkedin.com/jobs/view/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3773086804,2023-12-20,Bozeman,United States,Mid senior,Hybrid,"Who is Recruiting from Scratch :
Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.
https://www.recruitingfromscratch.com/
This is a hybrid role based in our
Palo Alto
or
San
Francisco
offices and will require you to be in office Tuesdays and Thursdays.
What’s so interesting about this role?
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety.
What’s the job?
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.
Responsibilities:
Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn’t always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams
Build data processing streams for cleaning and modeling text data for LLMs
Research and evaluate new technologies in the big data space to guide our continuous improvement
Collaborate with multi-functional teams to help tune the performance of large data applications
Work with Privacy and Security team on data governance, risk and compliance initiatives
Work on initiatives to ensure stability, performance and reliability of our data infrastructure
What We’ll Love About You
Bachelors in Computer Science, Mathematics, Physics, or a related fields
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Experience in statistical analysis & visualization on datasets using Pandas or R
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines)
We’ll really swoon if you have
2+ years of experience of technical leadership in building data engineering pipelines for AI
Previous experience in building data pipeline for conversational AI APIs and recommender systems
Experience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming
Strong understanding of applied machine learning topics
Be familiar with legal compliance (with data management tools) data classification, and retention
Consistent track record of managing and implementing complex data projects
What You'll Love About Us
Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events
Base Pay Range
$160,000—$280,000 USD
https://www.recruitingfromscratch.com/
Show more
Show less","AI, Machine Learning, Data Engineering, Data Science, Data Mining, Data Normalization, Data Modeling, Data Visualization, Data Preprocessing, Data Postprocessing, Pandas, R, Python, Java, Bash, SQL, Git, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, PySpark, AWS, GCP, Azure, NoSQL, DynamoDB, ETL, Kafka, Storm, SparkStreaming","Company Name: Recruiting from Scratch
Job Title: Data Engineer Lead
Experience: 5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience
Skills Needed:
- Bachelor's in Computer Science, Mathematics, Physics, or related fields
- Experience in statistical analysis & visualization using Pandas or R
- Designing and building highly available, distributed systems for data extraction, ingestion, normalization,",0.17877094776470426,0.58238345
Senior Database Developer,Winsupply,"Dayton, OH",https://www.linkedin.com/jobs/view/senior-database-developer-at-winsupply-3728065163,2023-12-20,Dayton,United States,Mid senior,Hybrid,"Position Summary
The Database Engineer (DBE) needs a thorough understanding of relational database theory and practice, along with in-depth knowledge of data systems and database methodology, design and modeling. This individual must be analytical and adept at problem solving, can strategically design and implement production databases, and provide support for specific applications. The DBE focuses on the logical and physical aspects of the database and application data contained within. They are responsible for developing, implementing, and overseeing database policies and procedures to ensure the integrity of data. The Database Engineer will also monitor and ensure system performance issues do not arise due to database related issues. The database engineer is a person who can bridge the gaps and interact with the other portions of IT. A DBE is someone who can communicate on both a technical level and a business level. They must be able to partner with the infrastructure team, the application development team and the information management team.
Accountabilities/Responsibilities
Database Architecture, Design and Implementation
The DBE is responsible for the architecture, design and implementation of database systems and components in support of information management goals. This includes the database and data life cycle. It includes understanding and applying the science and art of data modeling practiced via modern methods, tools and interfaces. The DBE is involved in gathering business requirements, logical modeling, physical modeling, implementing the model and maintaining the model.
Data Availability, Control, Governance and Integrity
The DBE, in partnership with the data owner, is responsible for the accessibility, availability and integrity of the database and data. The DBE is responsible for defining and implementing the appropriate strategy and methods to maintain control and governance of the database and the data, as defined and mandated by the owner. This includes understanding and accounting for all the potential data access interfaces and methods, and ensuring proper security and auditing measures are in place. A critical success factor is identifying, understanding and reconciling the associated business and technical requirements for data and information management.
Data Centric Application Design and Programming
The DBE is responsible for ensuring proper and adequate data centric techniques are used in the design, development and implementation of applications. This includes taking advantage of built in database management system features and functions such as constraints, functions and triggers. The DBE is responsible for understanding and applying the science and art of coding and implementing SQL (DDL, DML and PSM) via modern methods, tools and interfaces. Leading, guiding and reviewing data centric application development is a fundamental task. As appropriate, the DBE is also involved in all aspects of maintaining, modernizing and enhancing existing database applications that are based on DDS, high level language record level access and other non-SQL interfaces.
Database Performance and Scalability
The DBE is responsible for identifying, understanding, reconciling and meeting the data serving performance and scalability requirements. This includes applying the best practices of indexing, work management and set-at-a-time SQL requests. The DBE is responsible for understanding and applying the science and art of monitoring, analyzing and tuning data access and data processing via modern methods, tools and interfaces. The DBE is involved in planning, sizing and configuring database systems to meet business and technical requirements. This should include the set up and use of prototypes, proofs of concept, proofs of technology and realistic benchmarks.
Competencies for Success
Analytical and Critical Thinking
Complex Problem Solving
Collaboration and Communication
Planning and Organizing
Presentation Skills
Proficient with SQL
Knows the Data
Qualifications/Experience
Minimum Qualifications
Greater than 8 years related professional experience
Associate’s degree in Computer Science or related field
Similar work experience, technical skills or relevant certification may be considered in place of bachelor's degree; must maintain awareness of changing technology
At least 5 years’ experience with MariaDB
Desired Qualifications
Bachelor’s degree in Computer Science or related field
Certification directly related to computer programming
Physical Demands
The physical demands here are representative of those that must be met to successfully perform the essential job functions with or without reasonable accommodations:
Sitting for extended periods of time
Dexterity of hands and fingers to operate a computer keyboard, mouse, power tools, and other computer components
Winsupply is an equal opportunity employer, so it encourages all qualified individuals to apply including minorities, veterans, women, and those with disabilities.
Show more
Show less","Database Architecture, Database Design, Database Implementation, Data Availability, Data Control, Data Governance, Data Integrity, Data Centric Application Design, Data Centric Programming, SQL, Performance Tuning, Scalability, Prototyping, Proof of Concept, Proof of Technology, Data Analysis, Presentation Skills, MariaDB","The job is for a Database Engineer at Winsupply. The role requires more than 8 years of professional experience and an Associate's degree in Computer Science or related field. Skills needed include proficiency in SQL, knowledge of data systems and database methodology, analytical thinking, problem-solving abilities, and collaboration and communication skills. The responsibilities of the role include database architecture, design, and implementation, ensuring data availability, control, governance, and integrity, data-centric application design and programming, database performance, and scalability.",0.20551378187096817,0.62502104
Volunteer: Nutrition Center Data Analyst - Jeremiah's Inn,VolunteerMatch,"Brooklyn, NY",https://www.linkedin.com/jobs/view/volunteer-nutrition-center-data-analyst-jeremiah-s-inn-at-volunteermatch-3780546752,2023-12-20,Manhattan,United States,Associate,Onsite,"HUNGER FREE AMERICA (formerly known as the New York City Coalition Against Hunger) is a national nonprofit group building a nonpartisan, grass-roots membership movement to enact the policies and programs needed to end domestic hunger and ensure that all Americans have sufficient access to nutritious food.
Our long-term goal is not just to ameliorate the problem, but also to build the people’s movement necessary to enact the economic and public policies needed to end hunger entirely. Given that hunger drains our economy and tears at our moral and civic fabric, we know that eliminating it will boost the nation both economically and spiritually. Towards that end, we’ve adopted the motto ""Ending hunger lifts us all.""
Jeremiah’s Inn (JI) is a community of individuals and organizations committed to helping those in our community who suffer from the devastating effects of substance use disorder and Food Insecurity.
As a
Nutrition Center Data Analyst Volunteer
, (in partnership with Hunger Free America - AmeriCorps
Senior 55+ Volunteer Program
) you will work independently with the exceptions of contact with staff overseeing the Data Collection Project. The project includes analyzing data collected via surveys from our clients to better inform ourselves and the stakeholders on the current Pantry demographics, needs and wants.
This is a virtual role, with deadlines set at first meeting with staff members. This is a high priority project; we foresee an average of 3 hours per week to complete the project. There is a possibility of new projects coming available as well.
If you are 55 or older we invite you to join our community of Senior Volunteers (55+) where you gain access to our group events, training, events, volunteer recognition, community, monetary reimbursement, and an extensive list of volunteer opportunities that are remote or in-person across the U.S.
Use this link to sign up for this opportunity and become a Hunger Free America AmeriCorps Senior (55+) Volunteer! https //www.tfaforms.com/5057256?acctid=0012E00002V6Ypc
This is a volunteer opportunity provided by VolunteerMatch, in partnership with LinkedIn for Good.
Show more
Show less","Data Analysis, Data Interpretation, Data Visualization, Data Modeling, Data Reporting, SQL, Tableau, Google Forms, Microsoft Office Suite, Virtual Collaboration Tools, Survey Design, Statistical Analysis, Project Management, Client Engagement, Community Outreach","Company: Hunger Free America
Job Title: Nutrition Center Data Analyst Volunteer
Experience: N/A (open to volunteers aged 55 and older)
Skills: Data analysis, ability to work independently, communication skills
Description: Hunger Free America is a national nonprofit organization aiming to end domestic hunger. The Nutrition Center Data Analyst Volunteer will analyze survey data to inform pantry demographics and needs. This virtual role requires approximately 3 hours per week with the potential for additional projects. Volunteers aged 55 and above can join",0.24827585859096318,0.7765944
Internal Audit-New York-Associate-Data Analytics,Goldman Sachs,"New York, NY",https://www.linkedin.com/jobs/view/internal-audit-new-york-associate-data-analytics-at-goldman-sachs-3787393483,2023-12-20,Manhattan,United States,Associate,Onsite,"Job Description
Role
Internal Audit – Data Analytics, Embed DA
Internal Audit
What We Do
Internal Audit’s mission is to independently assess the firm’s internal control structure, including the firm’s governance processes and controls, risk management, capital and anti-financial crime framework. In addition, it is also to raise awareness of control risk and monitor the implementation of management’s control measures.
In Doing So, Internal Audit
Communicates and reports on the effectiveness of the firm’s governance, risk management and controls that mitigate current and evolving risk
Raise awareness of control risk
Assesses the firm’s control culture and conduct risks; and
Monitors management’s implementation of control measures
Goldman Sachs Internal Audit is organized into global teams comprising of business and technology auditors that cover all the firm’s businesses and functions - securities, investment banking, consumer and investment management, risk management, finance, cyber-security and technology risk, and engineering
Who We Look For
Goldman Sachs Internal Audit comprises individuals from diverse backgrounds including chartered accountants, developers, risk management professionals, cybersecurity professionals, and data scientists. We are organized into global teams comprising business and technology auditors to cover all the firm’s businesses and functions, including securities, investment banking, consumer and investment management, risk management, finance, cyber-security and technology risk, and engineering.
Embed - Data Analytics
In Internal Audit, we ensure that Goldman Sachs maintains effective controls by assessing the reliability of financial reports, monitoring the firm’s compliance with laws and regulations, and advising management on developing smart control solutions. Embed Data Analytics team leverages its programming and analytical capabilities to build innovative data driven solutions. The team works closely with auditors to understand their pain points and develop data-centric solutions to address the same
Your Impact
As part of the third line of defense, you will be involved in independently assessing the firm’s overall control environment and its effectiveness as it relates to current and emerging risks and communicating the results to local/ global management. In doing so, you will be supporting the provision of independent, objective and timely assurance around the firm’s internal control structure, thereby supporting the Audit Committee, Board of Directors and Risk Committee in fulfilling their oversight responsibilities.
We are looking for a strong data scientist, passionate about using data to challenge the norm, to join our Embed Data Analytics team. The candidate will work closely with the audit teams to build innovative and reusable analytical tools that will help make audit testing more efficient and provide meaningful insights into firm’s control environment
Responsibilities
Execute on DA strategy developed by IA management within the context of audit responsibilities, such as risk assessment, audit planning, creation of reusable tools and providing innovative solutions to complex problems
Partner with audit teams to help identify risks associated with businesses and facilitate strategic data sourcing and develop innovative solutions to increase efficiency and effectiveness of audit testing
Build production ready analytical tools to automate repeatable and reusable processes within IA
Build and manage relationships and communications with Audit team members
Basic Qualifications
Bachelor’s in Computer Science, Math, or Statistics
Experience with RDBMS/ SQL
Proficiency in programming languages, such as Python, Java, or C++
Knowledge of basic statistics, including descriptive statistics, data distribution models, Time Series Analysis, correlation, and regression, and its application to data
Strong team player with excellent communication skills (written and oral). Ability to communicate what is relevant and important in a clear and concise manner and ability to handle multiple tasks
Strong contributing member of Data Science team and help build analytical capabilities for Internal Audit Division
Driven and motivated and constantly taking initiative to improve performance
Preferred Qualifications
Experience with Advanced data analytics tools and techniques
Well versed with Python/SQL Coding
Familiarity with Text analytics and NLP using python
Familiarity with machine learning algorithms and exposure to supervised and unsupervised learning - Linear/Logistic Regression, SVM, Random Forest and Boosting, Clustering and Patterns Recognition techniques
Experience with analytical/ statistical programs such as SAS, SPSS, and R
Experience with visualization tools (Spotfire, Qlikview or Tableau) is a plus
Creativity/Innovation, i.e., ability to create new ways to improve current processes and develop practical solutions that add value to department
Exposure to Financial Industry Investment/Retail or Commercial Baking is a plus
About GS
The Goldman Sachs Group, Inc. is a leading global investment, consumer and commercial banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.
Show more
Show less","Internal Audit, Data Analytics, Risk Management, Cybersecurity, SQL, Python, Java, C++, Statistics, Machine Learning, SAS, SPSS, R, Spotfire, Qlikview, Tableau","Company: Goldman Sachs
Job Title: Internal Audit – Data Analytics, Embed DA
Experience: Not specified
Skills Needed: Bachelor’s in Computer Science, Math, or Statistics, experience with RDBMS/ SQL, proficiency in programming languages like Python, Java, or C++, knowledge of basic statistics, strong communication skills, ability to handle multiple tasks, familiarity with advanced data analytics tools, Python/SQL coding, text analytics, NLP, machine learning algorithms, analytical programs like SAS, SPSS",0.16888888644898767,0.64592034
Data Center Engineer,Index Exchange,"New York, NY",https://www.linkedin.com/jobs/view/data-center-engineer-at-index-exchange-3772009459,2023-12-20,Manhattan,United States,Associate,Onsite,"We shaped the earliest forms of ad tech, and we’re looking for the technical expertise to help shape its future. Our customers have unique problems that can only be solved at internet scale, and that’s where the technical skills of our team make a real difference.
Our exchange handles over 350 billion requests every day (for comparison Google serves an estimated 9 billion searches a day), all running in our own global data centers. Every member of our technology team has an enormous amount of autonomy in building and managing our systems to support and enable our growing level of scale. Through the transparency of our technology, dedication to innovation and integrity, and long-standing customer relationships, we lead through change.
What’s it like to work at Index?
We have more than 550 Indexers around the globe dedicated to building a safe and transparent marketplace that provides a trusted experience for consumers.
Index is an exciting and fast-paced place to work. We’re built on our values of change, support, learning and teaching, trust, and intention. We pride ourselves on our independence and openness, not only in our technology, but in our teams, too. Our diverse and inclusive culture celebrates how we can leverage our unique differences to help drive Index forward.
Our culture of success is truly supportive and collaborative. In working together across our teams, we’re continually investing in the people and technology to solve the industry’s most complex problems. As we extend the promise of ad tech to every channel, we’re looking for talented engineers to help advance Index, and the industry, forward.
Are you ready to join the programmatic evolution?
Index Exchange funds the open web. Content and journalism across the internet are funded through advertising, and we are the engine that helps to make that happen transparently, safely and efficiently. Handling hundreds of billions of auctions per day within milliseconds requires an intense understanding of the exchange and the ecosystem that we live in.
Our business is growing significantly every year and is poised to grow even faster. Our people and our platforms are the foundation and enabler of that growth. We are significantly expanding our technology teams, and are looking for technologists with a passion for high performance software development, and a drive to deliver software products and platforms that enable and empower industries at a global scale.
About The Role
We’re looking for a Data Center Engineer to join Index Exchange. Index’s scale spans the globe, our transactions happen 24x7 in our global data centers, and every second that passes millions of requests are evaluated across our exchange. In order to achieve our mission, global efficiency and reliability are absolutely key, as every millisecond quite literally counts in our business. Your responsibilities will span across a wide range of duties, including managing the physical infrastructure, ensuring high availability, implementing security protocols, and coordinating with various teams to maintain optimal performance and uptime of the global Exchange. A solid understanding of network architecture and practices along with a good knowledge of Linux are requirements. Your expertise and attention to detail will be instrumental in maintaining a secure, efficient, and resilient environment for our critical technical operations.
Here’s What You’ll Be Doing
Datacenter Operations Management: Take charge of day-to-day operations, ensuring all systems are running smoothly, including power distribution, cooling systems, networking/compute infrastructure, and environmental monitoring.
Infrastructure Maintenance: Oversee the regular maintenance and upgrades of equipment to ensure optimal performance and reliability.
Power and Cooling Management: Implement and manage power and cooling strategies to meet the datacenter's requirements while optimizing energy efficiency.
Security and Safety Protocols: Enforce and maintain strict security protocols and safety measures to safeguard the datacenter facility, its assets, and personnel.
Vendor Management: Collaborate with external vendors and contractors to procure equipment, services, and maintenance contracts as needed.
Documentation and Reporting: Maintain accurate and up-to-date records, including equipment inventories, service contracts, incident reports, and performance metrics. Provide regular reports to management on datacenter performance and improvements.
Regulatory Compliance: Ensure compliance with industry standards, regulations, and guidelines pertaining to datacenter operations, security, and safety.
Team Coordination: Coordinate with various teams, including IT, NOC, Neteng, Cloud Platform, to address operational challenges and maintain seamless communication and collaboration.
Here's What You Need
Years of proven experience as a Datacenter Engineer or similar role.
Strong knowledge of datacenter infrastructure, including power distribution, cooling systems, cabling, and rack configurations.
Familiarity with environmental monitoring and management tools such as Grafana, Pagerduty, Jira, Confluence
Strong understanding of safety and security protocols in a datacenter environment.
Rack, cable and configure Linux-based servers and other network hardware
Performs the full range of operation and maintenance; to include but not limited to; scheduled and unscheduled; installations, decommissioning, inspections, analysis, troubleshooting, and repairs.
Test, analyze and repair defective servers
Assist in the monitoring of bandwidth, server, switch and router health across the network and capably diagnose, troubleshoot and escalate any problems
Set standards of excellence for all data center operations
Bending, lifting, stretching, reaching, standing and walking
Excellent problem-solving skills and the ability to handle high-pressure situations.
Strong project management skills with a track record of successful project execution.
Effective communication and leadership skills to coordinate with internal teams and external vendors.
Knowledge of industry standards and best practices related to datacenter operations and facility management.
Ability to lift up to 40 lbs
Workplace Requirement
International travel up to 50% of your time and as needed up to three days in the office
The base salary for this role is
$120,000 – $160,000 USD.
The total compensation package may vary depending on job related knowledge, skills and experience.
This posting will close on December 15th 2023
Why You’ll Love Working Here
Comprehensive health, dental, and vision plans at no cost to you
Time off and flexible work schedules
Retirement plan with a 5% company match
Stock options and equity packages
Generous parental leave
Monthly wellness stipend plus fitness discounts and quarterly wellness group activities
Community engagement opportunities and donation-matching program
Annual virtual company retreats and regular community-led team events
One day off per year to volunteer
A workplace that supports a diverse, equitable, and inclusive environment – learn more here
Notification
Index Exchange is aware that there have been recent scams directed toward candidates regarding job interviews and offers.
Please be vigilant and do not accept interview requests, job offers, or other hiring-related documents from anyone other than our dedicated recruitment team, from the domain of @indexexchange.com. Our interview process consists of several steps, including phone screens and video interviews. We do not conduct interviews via an email questionnaire or request money at any point in the process.
If you do receive these requests, please let us know immediately at: report.scam@indexexchange.com.
We remain dedicated to resolving this matter and we appreciate your support.
Equal employment opportunity
At Index Exchange, we believe that successful products are built by teams just as diverse as the audience who uses them. As such, we are committed to equal employment opportunities. We celebrate diversity of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or veteran status. Additionally, we realize that diversity is deeper than any status or classification—diversity is the human experience. For those who show grit, passion, and humility—Index will welcome you.
Accessibility For Applicants With Disabilities
Index Exchange is committed to working with and providing access and reasonable accommodations to applicants with disabilities. Please let us know if you’d like to request a reasonable accommodation.
Show more
Show less","Data Center Engineer, Datacenter Operations Management, Infrastructure Maintenance, Power and Cooling Management, Security and Safety Protocols, Vendor Management, Documentation and Reporting, Regulatory Compliance, Team Coordination, Linux, Grafana, Pagerduty, Jira, Confluence, Project Management, Communication and Leadership Skills, Industry Standards and Best Practices, Lifting up to 40 lbs, International Travel, Health Dental and Vision Plans, Time Off and Flexible Work Schedules, Retirement Plan with a 5% Company Match, Stock Options and Equity Packages, Generous Parental Leave, Monthly Wellness Stipend, Community Engagement Opportunities, DonationMatching Program, Annual Virtual Company Retreats, Team Events, Oneday Off per Year to Volunteer, Diverse Equitable and Inclusive Environment, Accessibility For Applicants With Disabilities","Company: Index Exchange

Job Title: Data Center Engineer

Experience: Proven years of experience as a Datacenter Engineer or similar role

Skills Needed: Strong knowledge of datacenter infrastructure including power distribution, cooling systems, cabling, and rack configurations. Familiarity with environmental monitoring and management tools. Ability to rack, cable, and configure Linux-based servers and other network hardware. Strong understanding of safety and security protocols in a datacenter environment. Excellent problem-solving skills and ability to handle high-pressure",0.1356382963593538,0.49714965
Health Outcomes Data Analyst,Elevance Health,"Cincinnati, OH",https://www.linkedin.com/jobs/view/health-outcomes-data-analyst-at-elevance-health-3777084773,2023-12-20,Covington,United States,Mid senior,Onsite,"Description
Job Title
: Health Outcomes Data Analyst
Location
: This position will work a hybrid model (remote and office). The ideal candidate will live within 50 miles of one of our Elevance Health PulsePoint locations. Norfolk, VA; Atlanta, GA; Indianapolis, IN; Cincinnati, OH; and St Louis, MO.
The Health Outcomes Data Analyst is responsible for analyzing, reporting and developing recommendations on data related to multiple, varied business metrics.
How You Will Make An Impact
Analyzes data and summarizes performance using summary statistical procedures.
Creates data models to track trends in cost and quality.
Develops and analyzes business performance reports (e.g. for claims data, provider data, utilization data) and provides notations of performance deviations and anomalies.
Creates and publishes periodic reports, makes necessary recommendations, and develops ad hoc reports as needed.
Present initiates and findings to leadership.
May require taking business issue and devising best way to develop appropriate diagnostic and/or tracking data that will translate business requirements into usable decision support tools.
Creates and maintains databases to track business performance.
Minimum Requirements
Requires a BS/BA degree in related field and a minimum of 2 years related operational and/or data analysis experience, experience in database structures, and standard query and reporting tools; or any combination of education and experience which would provide an equivalent background.
Preferred Skills, Capabilities, And Experiences
SQL, Excel, and PowerPoint skillsets strongly preferred.
Tableau or Power BI skills preferred.
Python or R skills preferred.
Cost analysis, predictive analysis, trend analysis experience preferred.
Preferred education backgrounds: Actuarial Science, Data Science, Mathematics, Statistics, Economics, Healthcare Economics, Healthcare Informatics, Finance, HealthCare Finance.
If this job is assigned to any Government Business Division entity, the applicant and incumbent fall under a 'sensitive' work designation and may be subject to additional requirements beyond those associates outside Government Business Divisions. Requirements include but are not limited to more stringent and frequent background checks and/or government clearances, segregation of duties principles, role specific training, monitoring of daily job functions, and sensitive data handling instructions. Associates in these jobs must follow the specific policies, procedures, guidelines, etc. as stated by the Government Business Division in which they are employed.
Please be advised that Elevance Health only accepts resumes for compensation from agencies that have a signed agreement with Elevance Health. Any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Elevance Health.
Who We Are
Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. We are a Fortune 25 company with a longstanding history in the healthcare industry, looking for leaders at all levels of the organization who are passionate about making an impact on our members and the communities we serve.
How We Work
At Elevance Health, we are creating a culture that is designed to advance our strategy but will also lead to personal and professional growth for our associates. Our values and behaviors are the root of our culture. They are how we achieve our strategy, power our business outcomes and drive our shared success - for our consumers, our associates, our communities and our business.
We offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few.
Elevance Health operates in a Hybrid Workforce Strategy. Unless specified as primarily virtual by the hiring manager, associates are required to work at an Elevance Health location at least once per week, and potentially several times per week. Specific requirements and expectations for time onsite will be discussed as part of the hiring process. Candidates must reside within 50 miles or 1-hour commute each way of a relevant Elevance Health location.
The health of our associates and communities is a top priority for Elevance Health. We require all new candidates in certain patient/member-facing roles to become vaccinated against COVID-19. If you are not vaccinated, your offer will be rescinded unless you provide an acceptable explanation. Elevance Health will also follow all relevant federal, state and local laws.
Elevance Health is an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to age, citizenship status, color, creed, disability, ethnicity, genetic information, gender (including gender identity and gender expression), marital status, national origin, race, religion, sex, sexual orientation, veteran status or any other status or condition protected by applicable federal, state, or local laws. Applicants who require accommodation to participate in the job application process may contact elevancehealthjobssupport@elevancehealth.com for assistance.
Show more
Show less","SQL, Excel, PowerPoint, Tableau, Power BI, Python, R, Cost analysis, Predictive analysis, Trend analysis, Actuarial Science, Data Science, Mathematics, Statistics, Economics, Healthcare Economics, Healthcare Informatics, Finance, HealthCare Finance","Company Name: Elevance Health  
Job Title: Health Outcomes Data Analyst  
Experience: Minimum of 2 years related operational and/or data analysis experience  
Skills Needed:  
- Proficiency in SQL, Excel, and PowerPoint  
- Strongly preferred skills in Tableau or Power BI  
- Preferred skills in Python or R  
- Experience in cost analysis, predictive analysis, and trend analysis  
- Background in Actuarial Science, Data Science, Mathematics, Statistics, Economics, Healthcare Economics, Healthcare",0.1564885478612115,0.64538
Analyst - Business Data (Call Center),EssilorLuxottica,"Mason, OH",https://www.linkedin.com/jobs/view/analyst-business-data-call-center-at-essilorluxottica-3784468023,2023-12-20,Covington,United States,Mid senior,Onsite,"Requisition ID:
822353
Position:
Full-Time
We are EssilorLuxottica, a global leader in the design, manufacture and distribution of ophthalmic lenses, frames and sunglasses. The Company brings together the complementary expertise of two industry pioneers, one in advanced lens technologies and the other in the craftsmanship of iconic eyewear, to create a vertically integrated business that is uniquely positioned to address the world’s evolving vision needs and the global demand of a growing eyewear industry.
With over 180,000 dedicated employees in 150 countries driving our iconic brands, our people are creative, entrepreneurial and celebrated for their unique perspectives and individuality. Committed to vision, we enable people to “see more and be more” thanks to our innovative designs and lens technologies, exceptional quality and cutting-edge processing methods. Every day we impact the lives of millions by changing the way people see the world.
Our portfolio of more than 150 renowned brands span various categories, from frames, lenses and instruments to brick and mortar and digital distribution as well as mid-range to premium segments. Our Shared Services Team, accompany and enable others within the EssilorLuxottica collective to achieve their targets. They keep people and projects running smoothly, ensuring every part of our business is provided for and well taken care of.
GENERAL FUNCTION
The Analyst, Business Data conducts detailed analyses of Luxottica’s North America Contact Center (NACC) operations performance using varied sources of data. The Analyst, Business Data will have working knowledge and understanding of all NACC KPI’s and targets and will use their analytical skills to partner with leadership to provide insight into key trends in performance, demand drivers, cost and opportunities.
Major Duties And Responsibilities
In partnership with the Manager/Sr. Manager, evaluate and support the implementation of analytical solutions that will lead to high quality, accurate data and trending
Able to deliver analytical reporting using varied sources of data, including but not limited to, workforce management, quality, custom channel applications, and CTI/CRM/IVR solutions for all channels
Analyze complex data, identify anomalies, and provide useable insight to business intelligence leaders
Provide ongoing analysis of existing reporting structure and make efforts to provide recommended enhanced solutions in an effort to drive reporting efficiency
Ensure accurate documentation for data elements, reports, and processes
Develops understanding of underlying data, data structures, and business uses of data
Follows processes and protocols for ensuring the quality of reporting outcomes and analyses; identifies ways to ensure data integrity and validates reporting results to deliver a high degree of confidence in the final outcome
Maintain comprehensive inventory of all reports and associated data sources
Maintain and publish standard reports for executive operations
Maintain databases and develop weekly / monthly metrics reports
Perform ad hoc analyses as needed, support UAT and special projects as assigned
Basic Qualifications
Bachelor’s degree in analytics, mathematics or related field
2+ years of relevant experience in business, statistical or data analysis
Ability to assimilate facts/data from various sources & develop analyses that provide key business insight
Ability to identify obstacles & develop solutions
Strong organizational and time management
Proficiency using Microsoft Excel
Proficiency using Microsoft SQL
Knowledge of Business Objects
Effective communicator – written and verbal
Preferred Qualifications
Experience with Telephonic platforms
Experience working with call center data/metrics
Employee pay is determined by multiple factors, including geography, experience, qualifications, skills and local minimum wage requirements. In addition, you may also be offered a competitive bonus and/or commission plan, which complements a first-class total rewards package Benefits/Incentive Information including health benefits, PTO, 401K, paid family leave, tuition reimbursement, and eyewear discounts.
Upon request and consistent with applicable laws, EssilorLuxottica will provide reasonable accommodations to individuals with disabilities who need assistance in the application and hiring process. To request a reasonable accommodation, please call the Luxottica Ethics Compliance Hotline at 1-888-887-3348 (be sure to provide your name and contact information so that we may follow up in a timely manner) or email HRCompliance@luxotticaretail.com.
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, gender, national origin, social origin, social condition, being perceived as a victim of domestic violence, sexual aggression or stalking, religion, age, disability, sexual orientation, gender identity or expression, citizenship, ancestry, veteran or military status, marital status, pregnancy (including unlawful discrimination on the basis of a legally protected pregnancy or maternity leave), genetic information or any other characteristics protected by law. Native Americans receive preference in accordance with Tribal Law.
Show more
Show less","Business Objects, Microsoft SQL, Microsoft Excel, Telephony, Analytics, Data Analysis, Business Intelligence","Company Name: EssilorLuxottica
Job Title: Analyst, Business Data
Experience: 2+ years
Skills Needed: Bachelor’s degree in analytics, mathematics or related field, ability to analyze data from various sources, proficiency in Microsoft Excel and SQL, knowledge of Business Objects, experience with telephonic platforms and call center data/metrics, strong organizational and time management skills, effective communication skills (written and verbal).",0.1240310059086744,0.38608658
Data Warehouse Analyst,Elevance Health,"Cincinnati, OH",https://www.linkedin.com/jobs/view/data-warehouse-analyst-at-elevance-health-3784000388,2023-12-20,Covington,United States,Mid senior,Onsite,"Description
BioPlus Specialty Pharmacy is now part of CarelonRx (formerly IngenioRx), and a proud member of the Elevance Health family of companies. Together, CarelonRx and BioPlus offer consumers and providers an unparalleled level of service that’s easy and focused on whole health. Through our distinct clinical expertise, digital capabilities, and broad access to specialty medications across a wide range of conditions, we deliver an elevated experience, affordability, and personalized support throughout the consumer’s treatment journey.
Data Warehouse Analyst
Location:
The preferred location of this role is in St. Louis, MO. This position is part of Elevance Health hybrid work model (remote and office). Ideal candidate can will lives within 50 miles of one of our PulsePoint Locations.
The
D
ata Warehouse Analyst
is responsible for partnering with internal and external business clients and IT to fulfill information needs and support business decisions.
How You Will Make An Impact
Maintains information policies and procedures to support current and future data information needs and ensures proper data definitions, ownership, use and integrity of data.
Analyzes business user needs, documents information requirements, facilitates the identification of potential gaps in available data and collaborates with business areas to determine best means for acquiring the data needed.
Collaborates with IT resources on the creation and maintenance of the content of the data warehouse, establishes and maintains general knowledge of data warehouse data structure design, definitions, capabilities, SQL, and data integrity issues, completes metadata assessment and reviews feedback to determine changes, ensures that data definitions are clear and current, and communicates changes to data definitions to all users.
Collaborates with IT resources and data owners to define business objectives and definitions for databases including business rules, sources, purge archive criteria, and reload schedule.
Analyzes transactional data stores and develops data warehouse models to optimize the warehouse data stores for reporting and analytics.
Prototypes, builds, and tests extraction, transformation, and load (ETL or ELT).
Prototypes, builds, and tests data quality processes and related jobs.
Ensures data warehouse metadata is collected and maintained.
Prototypes, builds, and tests Power BI reports and dashboards.
Minimum Requirements
Requires Bachelor's degree in related field and a minimum of 1 year experience in data analysis, data modeling, and working with automated data warehouse systems; or any combination of education and experience which would provide an equivalent background.
Preferred Skills, Capabilities And Experiences
Knowledge of and skill in Power BI functionality
Knowledge of and skill in Tableau functionality
Knowledge of and skill in relational database platforms including DB2, SQL Server, and Oracle
Good understanding of Data Warehouse architecture and design and ETL processes
Strong analytical and problem-solving skills
Experience in SQL, GQL, SAS, and Tableau
Strong analytical and problem-solving ability strongly preferred.
Please be advised that Elevance Health only accepts resumes for compensation from agencies that have a signed agreement with Elevance Health. Any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Elevance Health.
Who We Are
Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. We are a Fortune 25 company with a longstanding history in the healthcare industry, looking for leaders at all levels of the organization who are passionate about making an impact on our members and the communities we serve.
How We Work
At Elevance Health, we are creating a culture that is designed to advance our strategy but will also lead to personal and professional growth for our associates. Our values and behaviors are the root of our culture. They are how we achieve our strategy, power our business outcomes and drive our shared success - for our consumers, our associates, our communities and our business.
We offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few.
Elevance Health operates in a Hybrid Workforce Strategy. Unless specified as primarily virtual by the hiring manager, associates are required to work at an Elevance Health location at least once per week, and potentially several times per week. Specific requirements and expectations for time onsite will be discussed as part of the hiring process. Candidates must reside within 50 miles or 1-hour commute each way of a relevant Elevance Health location.
The health of our associates and communities is a top priority for Elevance Health. We require all new candidates in certain patient/member-facing roles to become vaccinated against COVID-19. If you are not vaccinated, your offer will be rescinded unless you provide an acceptable explanation. Elevance Health will also follow all relevant federal, state and local laws.
Elevance Health is an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to age, citizenship status, color, creed, disability, ethnicity, genetic information, gender (including gender identity and gender expression), marital status, national origin, race, religion, sex, sexual orientation, veteran status or any other status or condition protected by applicable federal, state, or local laws. Applicants who require accommodation to participate in the job application process may contact elevancehealthjobssupport@elevancehealth.com for assistance.
Show more
Show less","Data Warehouse, SQL, Data Analysis, Data Modeling, Power BI, Tableau, DB2, SQL Server, Oracle, ETL, SAS, GQL, Data Warehouse Architecture, Data Warehouse Design","Company: Elevance Health (formerly BioPlus Specialty Pharmacy)

Job Title: Data Warehouse Analyst

Experience: Requires a Bachelor's degree in a related field and a minimum of 1 year experience in data analysis, data modeling, and working with automated data warehouse systems.

Skills Needed: Knowledge of Power BI and Tableau functionality, relational database platforms such as DB2, SQL Server, and Oracle, Data Warehouse architecture and design, ETL processes, analytical and problem-solving skills, experience in SQL, G",0.1624548717430828,0.683794
Data Analyst,Robert Half,"Melbourne, Victoria, Australia",https://au.linkedin.com/jobs/view/data-analyst-at-robert-half-3780086337,2023-12-20,Melbourne,Australia,Associate,Hybrid,"The Company
Robert Half has been exclusively retained to appoint a newly created role of Data Analyst for a Global Construction Solutions Enterprise, based at its Melbourne headquarters.
Our client is a global industry leader with ongoing acquisitive and organic growth plans, providing access solutions to the commercial, industrial and construction sectors.
The Role
Reporting directly to the Managing Director (APAC), this role will suit a developing Data Analyst professional, joining an organisation that invests in its employee's development.
This role has two key areas of responsibility:
1. To provide timely analysis on
business performance issues and data analysis management
across the Australian and APAC business operations to include:
APAC Reporting & Financial Statement Close Process (FSCP) required for global for monthly and quarterly deliverables.
Analysis of existing Financial & Business cases & Data Analysis, assessment of existing and future Project Pipeline
2. To assist in the Managing Director in
delivering business transformation projects in the APAC region
by supporting feasibilities and analysis of Transformation and Projects Initiatives
Some of the more specific responsibilities will include ;
Analysis & Reporting
Provide accurate and timely variance and financial analysis on the APAC region results.
Preparation of monthly/quarterly regional reports.
Developing business cases, feasibility reports and cost/benefit analysis for solutions and proposals.
Manage the administration of the Australian and APAC Division's job evaluation tool
Assist with the development of the APAC business strategy.
Compiling charts, tables, and other elements of internal and external data visualisation.
Business Transformation
Work with project teams to validate and document current state processes and contribute to the development of efficient and customer focused future state processes.
Provide appropriate data analysis to support project initiatives.
Map, analyse and model processes.
Establish, update, monitor and report on project progress, action registers, risk, and issues log to ensure transparency of issues, conflicting priorities, and escalations are actioned.
Your Profile
You are a highly competent Data Analyst, with sound financial literacy, with an ability to identify issues and areas for improvement through analysis and have demonstrated implementing new processes and systems.
Essential to the role are:
A 'hands on' problem solver and critical thinker.
Work collaboratively within the project team, internal stakeholders, subcontractors, clients & consultants to achieve positive project and community outcomes.
Strong 'can do' attitude with clear ownership of decisions.
Minimum of 2 years in a similar role within the construction industry.
Strong Microsoft Excel and PowerPoint skills.
Excellent written, numeracy and verbal communication skills.
Experience within the Engineering and or Construction industries, highly desirable.
You will be joining a transparent, non-hierarchical culture with a strong commitment to flexible/hybrid work.
Apply Today
Please send your resume by clicking on the apply button. Your application will be assessed within 3-5 working days. Please note only shortlisted candidates will be contacted.
Learn more about our recruitment services: https://www.roberthalf.com.au/contact-us
PLEASE NOTE THAT ONLY APPLICANTS WITH FULL WORKING RIGHTS IN AUSTRALIA WILL BE CONSIDERED
Show more
Show less","Data Analysis, Business Intelligence, Financial Analysis, Reporting, Data Visualization, Project Management, Process Mapping, Process Modeling, Risk Management, Issue Management, Microsoft Excel, Microsoft PowerPoint, Communication Skills, Construction Industry, Engineering","Company: Robert Half
Job Title: Data Analyst
Experience: Minimum of 2 years in a similar role within the construction industry
Skills Needed: Strong financial literacy, ability to identify issues and areas for improvement through analysis, hands-on problem solver, critical thinker, strong Microsoft Excel and PowerPoint skills, excellent communication skills, experience within Engineering and Construction industries (highly desirable)",0.20786516600508145,0.5430796
Environmental Data Analyst,Hays,"Melbourne, Victoria, Australia",https://au.linkedin.com/jobs/view/environmental-data-analyst-at-hays-3770108755,2023-12-20,Melbourne,Australia,Associate,Hybrid,"Data Projects I Environmental Data | Geospatial Data
Long Term Contract Till 14 January 2025 with 1 x 6-month extension
Hybrid work arrangement (3 days' in the office)
Must be an Australian Citizen
Your new company
Our client is a well-known federal govt organisation - they are embarking on an aspirational period of growth and transformation driven by significant programs of work. They are on the lookout for highly experienced Environmental Data Analyst for contract position. The Senior Data Analyst is required to improve the routine collection and application of climatic data, to develop and deliver a wide range of routine and specialised climate services.
Accountabilities:
Install software on appropriate hardware and on cloud systems. Maintain data back-ups on cloud systems
Provide and maintain technical documentation, working with project team members, partner countries, and international collaborators
Develop relevant administrator training and reference material
Provide and maintain technical documentation, working with project team members, partner countries, and international collaborators.
What you’ll need to succeed:
Mandatory Skills
A bachelor’s degree or postgraduate qualification in computer science or related field is highly desirable; or equivalent work experience.
Demonstrated working knowledge and significant experience in the design, development, and coding of web database applications (Linux, PostgreSQL, Python, HTML,/PHP, and JavaScript)
Strong experience in management of data – analysis, reporting and communicating
Experience with AWS, Apache, Bootstrap, Leaflet, and Highcharts would be advantageous
Experience in the evaluation and analysis of spatio-temporal datasets originating from manual and automated Pacific observations
Must be an Australian Citizen
What you'll get in return
· Excellent and long term contract opportunity within a growing team.
· Flexible work arrangement
What you need to do now
If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV to Kanika.Behl@hays.com.au
Show more
Show less","Linux, PostgreSQL, Python, HTML, PHP, JavaScript, AWS, Apache, Bootstrap, Leaflet, Highcharts, Spatiotemporal datasets, Web database applications","Company: Federal Government Organization
Job Title: Senior Data Analyst - Environmental Data
Experience: Significant experience in the field
Skills Needed: Bachelor’s degree or postgraduate qualification in computer science or related field, working knowledge of web database applications (Linux, PostgreSQL, Python, HTML/PHP, JavaScript), data management expertise, experience with AWS, Apache, Bootstrap, Leaflet, Highcharts, evaluation and analysis of spatio-temporal datasets, Australian Citizenship.",0.29803921230296043,0.76696235
Data Engineer,Virtusa,"Melbourne, Victoria, Australia",https://au.linkedin.com/jobs/view/data-engineer-at-virtusa-3771831341,2023-12-20,Melbourne,Australia,Associate,Hybrid,"Implementation experience in BigData Platform ; preferably in Cloudera Hadoop platform
Minimum 2 years of Development experience using Hadoop eco system tools & utilities: MapReduce, Spark, Kafka, Sqoop, Impala, Hive etc
Ability to work independently and also contribute to overall architecture and design
Experience in writing Shell scripts in Linux Platform
Knowledge on API management concepts and design
Developed Apache Spark applications and comfortable developing in Python. (Preferred)
Performed debugging and performance tuning of Spark applications.
Show more
Show less","BigData Platform, Cloudera Hadoop, MapReduce, Spark, Kafka, Sqoop, Impala, Hive, Shell scripting, API management, Apache Spark, Python, Debugging, Performance tuning","Company: Not specified
Job Title: Big Data Platform Implementation Specialist
Experience: Minimum 2 years
Skills Needed: Implementation experience in Cloudera Hadoop platform, Development experience with Hadoop ecosystem tools (MapReduce, Spark, Kafka, Sqoop, Impala, Hive), Ability to work independently and contribute to architecture and design, Proficiency in writing Shell scripts in Linux, Knowledge of API management concepts and design, Experience in developing Apache Spark applications (Python preferred), Proficient in debugging and",0.5950413173225872,0.75136876
Data Analyst,Hays,"Melbourne, Victoria, Australia",https://au.linkedin.com/jobs/view/data-analyst-at-hays-3789795833,2023-12-20,Melbourne,Australia,Associate,Hybrid,"Federal Govt Opportunity (12 months contract)
Melbourne CBD based
Australian citizenship mandatory
Baseline clearance would be highly regarded
Your new company
You will be working with a federal government organisation that is responsible for providing essential services to the public. Our client is seeking an experienced Data analyst to work with technical and business areas.
This role represents an exciting opportunity for a Data Analyst to join a multidisciplinary team. We are seeking experienced data analyst to support projects, through conceptual/canonical/logical modelling, analysis of existing system integrations and data flows and data modelling to support development of new business systems.
Your new role
As a Data Analyst, you will be responsible for analysing large datasets and providing insights to support decision-making processes. You will work closely with stakeholders to understand their requirements and provide data-driven solutions.
Conduct data modelling on existing and emerging transactional business systems and application interfaces to inform data architecture;
Assist in documenting research, data findings and approach activities as part of a project team;
Analyse and model the vast amounts of data that enter or exit business systems and application interfaces;
Work as a part of an application delivery team, alongside solution architects, business analysts, developers and testers to deliver on project-based objectives to drive delivery of outcomes; and
Work under limited direction and be accountable for undertaking planning, analysis, design, development, and delivery activities within tight timeframes.
What you'll need to succeed
To be considered for this role, you will have:
● A degree in Computer Science, Mathematics, Statistics or related field.
● Baseline or NV1 clearance is highly regarded
● Minimum of 5 years’ experience as a Data Analyst with:
Strong knowledge of database structure systems, data analytics, and data modelling techniques;
Demonstrated ability to understand and translate existing system and business data flows into data models supporting long-term solutions;
Demonstrated ability to validate business data objects for accuracy and completeness.
● Demonstrated analytical skills in: Designing data for web services and system integrations; Maintaining conceptual, logical and physical data models along with corresponding metadata; and Analysing data-related system integration challenges and subsequent proposal of appropriate solutions.
● Demonstrated experience using SQL coding language to analyse data that enter/exit business systems using tools such as SQL Server Management Studio
● Excellent communication skills and the ability to work collaboratively with stakeholders.
What you'll get in return
● Demonstrated experience modelling data for systems integration and experience with data migration
● Well-developed team collaboration and communication skills: Demonstrated ability to work under limited direction with competing priorities and be accountable for completion of work; and Demonstrated ability to adapt and work in a constantly changing environment.
● Competitive remuneration package.
What you'll get in return
· Excellent and long term contract opportunity within a growing team.
· Flexible work arrangement
What you need to do now
If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV to Kanika.Behl@hays.com.au
Show more
Show less","Data analysis, Data modelling, Database structure systems, SQL coding language, SQL Server Management Studio, Data migration, Team collaboration, Communication skills, Data integration, Datarelated system integration challenges, Conceptual/canonical/logical modelling, Analytical skills","Company: Federal Government Organisation
Job Title: Data Analyst
Experience: Minimum of 5 years
Skills Needed: 
- Degree in Computer Science, Mathematics, Statistics, or related field
- Baseline or NV1 clearance highly regarded
- Strong knowledge of database structure systems, data analytics, and data modelling techniques
- Demonstrated ability in data modelling for web services and system integrations
- Experience using SQL coding language for data analysis
- Excellent communication and collaboration skills
Benefits:
- Competitive",0.26911314688961835,0.66501653
Data Engineer - Security,CyberSec People,"Melbourne, Victoria, Australia",https://au.linkedin.com/jobs/view/data-engineer-security-at-cybersec-people-3765182933,2023-12-20,Melbourne,Australia,Mid senior,Remote,"The Role
Join one of the largest Cyber Security Operations by data volume in the southern hemisphere as a Data Insights Engineer and play a crucial role in enhancing their data analysis and visualisation capabilities.
You'll have the opportunity to develop and refine their data analysis algorithms, craft dynamic dashboards, and work on middleware essential for data workflows across various diverse technologies. Your expertise will empower our team and clients with actionable insights, driving rapid, data-informed decisions.
Your Day to Day :
Develop robust data pipelines using advanced technologies like Spark, Flink, Hive, or Kafka, facilitating scalable data workflows.
Efficiently manage and optimise big data platforms, ensuring top performance for our Security Operations Center (SOC).
Create sophisticated algorithms for data analysis, aiding our SOC operations and Security Services product suite in detection, investigation, and response tasks.
Design and maintain dynamic dashboards offering insightful data visualisations for strategic and operational security activities.
Collaborate with SOC analysts to determine data needs and develop seamless integration solutions with our existing security infrastructure.
What you bring:
Strong programming skills in Python, Scala, Java, or C/C++.
Experience with relational and NoSQL databases with expert SQL skills
Proven ability in building scalable and robust data pipelines
Competency in managing and administrating major big data platforms and ecosystems.
Bonus Points:
Knowledge in machine learning and data mining techniques for enhanced security data insights.
Experience in report and dashboard creation using tools such as Tableau, Kibana, Grafana, or Superset.
Familiarity with SIEM platforms and integrating data insights within these frameworks.
Background in software development and CI/CD practices.
If you are wanting a chance to showcase your superb data skills in the Cyber Security industry protecting one of the most crucial threat landscapes in Australia this is not an opportunity you want to miss.
Show more
Show less","Data analysis, Algorithms, Dashboards, Middleware, Spark, Flink, Hive, Kafka, Big data platforms, Security Operations Center (SOC), Python, Scala, Java, C/C++, SQL, Data pipelines, Machine learning, Data mining, Tableau, Kibana, Grafana, Superset, SIEM platforms, Software development, CI/CD","Company: Unnamed Cyber Security Operations  
Job Title: Data Insights Engineer  
Experience: Not specified  
Skills Needed:  
- Strong programming skills in Python, Scala, Java, or C/C++  
- Experience with relational and NoSQL databases and expert SQL skills  
- Ability to build scalable and robust data pipelines  
- Competency in managing and administrating major big data platforms and ecosystems  
- Knowledge in machine learning and data mining techniques  
- Experience in report and dashboard creation using tools like Tableau",0.35797665015912433,0.8041836
"SR. ANALYST, DATA-HYBRID",Independence Health System - Westmoreland Area,"Greensburg, PA",https://www.linkedin.com/jobs/view/sr-analyst-data-hybrid-at-independence-health-system-westmoreland-area-3770864770,2023-12-20,Blairsville,United States,Mid senior,Onsite,"Job Details
Description
Job Summary
As a key member of the Independence Health System Business Intelligence team, the Senior Data Analyst leads expert understanding in design, modeling, and delivery of complex data analyses. The Senior Analyst will operate as a champion of using data to make decisions. By utilizing data derived from multiple disparate data sources and the strategic imperatives identified from leadership, the Senior Analyst will conceptualize, develop, and implement data strategies to drive appropriate results. The Senior Analyst will work closely with key stakeholders to identify needs and deliver effective solutions to model data in innovative ways. To successfully perform the role, the Senior Analyst must understand data modeling, data normalization and standardization, outlier identification, and data cleaning, advanced data practices. Further, the Senior Data Analyst is responsible for understanding data visualization techniques to make the outcomes of data analytics consumable to the operational end user.
Essential Job Functions
Develops industry standard techniques to model and aggregate data.
Investigates variation of data and derives solutions to solve data quality issues.
Articulate in the operations of many different disparate data sources to identify the right choice for data analysis.
Work collaboratively with IT, Quality, Nursing Informatics, Finance, and other members of the Business Intelligence team to model appropriately.
Develop and implement data collection systems, data analytics, and other strategies that optimize analytical report out.
Create data models ready for interactive, user-friendly visualizations to convey data in an exploratory way using tools such as advanced Excel, Tableau, or other reporting capabilities.
Leads data dissemination projects. Adheres to project deadlines and desired deliverables.
Creates collaboratively the standard for data modeling with other Business Intelligence team members.
Manages overall data usage structure for Independence Health.
Ensure adherence to compliance requirements, regulations, and policies.
Design, create, test, and deploy ETL queries and reports.
Monitors data model performance, usage, and communicating functional and technical issues.
Researches, suggests, and implements industry trends in healthcare analytics.
Identify, analyze, and interpret results, trends, or patterns in complex data sets.
Practices advanced analytical and design skills, including the ability to abstract information from real-world processes to understand information and operational flows.
Participate in improvement initiatives and develops data extracts needed to identify risks, weaknesses, opportunities or other relevant data.
Communicates status of tasks/issues and results in an efficient and effective manner.
Demonstrates a working understanding of operations and pertinent data flows that allows for design and implementation of analytics.
Demonstrates ability to produce and deliver products or presentations to diverse audience of technical and non-technical stakeholders.
Works with management to prioritize business information and needs.
Demonstrates advanced knowledge of healthcare concepts to assist with advanced analytics.
Seeks to continuously learn how analytics integrate with operational decisions and advocates for major operational issues to be solved with data-driven decisions.
Works with end users to optimize data processes to streamline manual analytics.
Leads initiatives to continually improve the quality of data in organization.
Other related duties as assigned.
Qualifications
Bachelor’s Degree in Data Sciences, Mathematics, Statistics, Biostatistics, Healthcare Management, Business, or related field and 4-6 years of data analysis, data visualization, reporting, and/or analytics experience.
Superior computer skills with knowledge of SQL and relevant software experience.
Excellent Microsoft Office skills in all applicable programs, including Excel.
Business Intelligence, data visualization and delivery experience, such as Tableau, Qlikview, Excel advanced reporting, etc.
Strong leadership ability, good organizational skills, independent and critical thinking skills, sound judgment, and knowledge of legal aspects and liability of nursing practice.
Strong ability to communicate complex and/or controversial topics and concepts to a wide and diverse audience such as Leadership, Management, or departmental teams.
Preferred Qualifications
Master’s Degree in related field preferred.
Tableau, Data Warehousing, SQL, or other analytical related certifications preferred.
Experience with healthcare softwares such as Meditech Expanse, Cerner, Allscripts, Meditech Business Clinical Analytics, etc.
Experience in Healthcare preferred.
Strong experience in Tableau or other data visualization software.
Strong experience with data modeling and mining, including blending, combining and marrying disparate data solutions.
Enterprise data warehouse or other data aggregation experience.
Familiarity with highly complex logical data design, mapping and conversion.
Familiarity with R or Python coding.
License, Certification & Clearances
Act 34-PA Criminal Record Check from the PA State Police system
Supervisory Responsibilities
This position has no direct supervisory responsibilities but could serve as a coach and mentor for other positions in the department.
Position Type/Expected Hours of Work
Incumbent will be scheduled based on operational need (rotate shifts, standby, on-call, etc.).
AAP/EEO
Excela Health is an Equal Opportunity Employer. It is the policy of Excela Health to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, marital status, non-job related disability, veteran status, or genetic information, or any other protected class. Excela Health will conform to the spirit as well as the letter of all applicable laws and regulations.
Ability to perform the Essential Functions listed on the Physical Conditions and ability to perform the Essential Functions on the Working Condition chart below.
Actively promotes a Lean work culture by performing team member duties to encourage consistent use of LEAN principles and processes, including continually seeking work process improvements. Recognizes the necessity of taking ownership of one’s own motivation, morale, performance and professional development. Strives for behavior consistent with being committed to Excela’s missions, vision and values.
Work Environment
Effective March 2020 or during pandemic: goggles, face shield and mask are required according to CDC guidelines
When lift requirement is in excess of 50#, lift assistance (2 person) and/or transfer device is required.
Essential – Absolute Necessity.
Marginal – Minimal Necessity.
Constantly – 5.5 to 8 hours or more or 200 reps/shift.
Frequently – 2.5 to 5.5 hours or more or 32-200 reps/shift.
Occasionally – 0.25 to 2.5 hours or 2-32 reps/shift.
Rarely – Less than 0.25 hours or less than 2 reps/shift.
Physical Condition
Essential
Marginal
Constantly
Frequently
Occasionally
Rarely
Never
Extreme Heat
X
Extreme Cold
X
Heights
X
Confined Spaces
X
Extreme Noise(>85dB)
X
Mechanical Hazards
X
Use of Vibrating Tools
X
Operates Vehicle
X
Operates Heavy Equipment
X
Use of Lifting/Transfer Devices
X
Rotates All Shifts
X
8 Hours Shifts
X
X
10-12 Hours Shifts
X
On-Call
X
Overtime(+8/hrs/shift; 40/hr/wk)
X
X
Travel Between Sites
X
Direct Patient Care
X
Respirator Protective Equipment
X
Eye Protection
X
Head Protection (hard hat)
X
Hearing Protection
X
Hand Protection
X
Feet, Toe Protection
X
Body Protection
X
Latex Exposure
X
X
Solvent Exposure
X
Paint (direct use) Exposure
X
Dust (sanding) Exposure
X
Ethylene Oxide Exposure
X
Cytotoxic (Chemo) Exposure
X
Blood/Body Fluid Exposure
X
Chemicals (direct use) Exposure
X
Mist Exposure
X
Wax Stripper (direct use)
X
Non-Ionizing Radiation Exposure
X
Ionizing Radiation Exposure
X
Laser Exposure
X
Physical Demand
When lift requirement is in excess of 50#, lift assistance (2 person) and/or transfer device is required.
Essential
Marginal
Constantly
Frequently
Occasionally
Rarely
Never
Bending (Stooping)
X
X
Sitting
X
X
Walking
X
X
Climbing Stairs
X
X
Climbing Ladders
X
Standing
X
X
Kneeling
X
Squatting (Crouching)
X
Twisting/Turning
X
Keyboard/Computer Operation
X
X
Gross Grasp
X
X
Fine Finger Manipulation
X
X
Hand/Arm Coordination
X
X
Pushing/Pulling(lbs. of force)
X
<10#
Carry
X
<10#
Transfer/Push/Pull Patients
X
Seeing Near w/Acuity
X
X
Feeling (Sensation)
X
Color Vision
X
Hearing Clearly
X
X
Pulling/Pushing Objects Overhead
Reaching Above Shoulder Level
Reaching Forward
X
X
Lifting Floor to Knuckle
X
<10#
Lifting Seat Pan to Knuckle
X
<10#
Lifting Knuckle to Shoulder
X
Lifting Shoulder to Overhead
X
When lift requirement is in excess of 50#, lift assistance (2 person) and/or transfer device is required. Indep
Show more
Show less","Data Analytics, Statistics, Data Visualization, Tableau, SQL, Microsoft Office Suite, Data Modeling, Data Quality, Data Mining, ETL, Advanced Excel, Qlikview, Power BI, Data Warehousing, Data Collection, Data Interpretation, R, Python, Healthcare Software, Meditech Expanse, Cerner, Allscripts, Meditech Business Clinical Analytics, Healthcare Concepts, Healthcare Analytics, Data Standardization, Data Normalization, Data Cleaning, Outlier Identification","Company: Independence Health System

Job Title: Senior Data Analyst

Experience: Bachelor’s Degree in Data Sciences, Mathematics, Statistics, Biostatistics, Healthcare Management, Business, or related field and 4-6 years of data analysis, data visualization, reporting, and/or analytics experience.

Skills Needed: Superior computer skills with knowledge of SQL and relevant software experience, excellent Microsoft Office skills, data visualization and delivery experience (e.g. Tableau, Qlikview, Excel advanced reporting), strong",0.14141413985636622,0.5752585
"Principal Data Engineer, CNN",Warner Bros. Discovery,"United, PA",https://www.linkedin.com/jobs/view/principal-data-engineer-cnn-at-warner-bros-discovery-3790372348,2023-12-20,Blairsville,United States,Mid senior,Remote,"Every great story has a new beginning, and yours starts here.
Welcome to Warner Bros. Discovery… the stuff dreams are made of.
Who We Are…
When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the
storytellers
bringing our characters to life, the
creators
bringing them to your living rooms and the
dreamers
creating what’s next…
From brilliant creatives, to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive.
Your New Role…
CNN is looking for a seasoned Principal Data Engineer to cultivate a data-driven culture within the organization. We are looking for someone who is inherently motivated, thrives in both autonomous and collaborative team settings, and harbors a deep passion for the transformative power of data. This pivotal role involves orchestrating sophisticated analytic solutions, integrating novel data sources, and meticulously organizing data to unveil insights that propel our strategic business initiatives.
Your Role Accountabilities…
Craft, scale, and optimize internal processes, focusing on the automation of manual procedures, the refinement of data delivery, and the redesign of infrastructure to boost scalability.
Develop and maintain advanced data pipelines to ensure efficient and reliable ETL processes from various affiliate marketing platforms and advertising partners in real-time and batch modes.
Architect a unified data warehousing solution that consolidates affiliate and advertising data, ensuring consistency, reliability, and accessibility across the organization.
Collaborate with business stakeholders to understand key performance indicators (KPIs), integrating these metrics into data models to track affiliate performance.
Engage with both internal and external data contributors to streamline and unify disparate data sources, from proprietary datasets to external partnerships.
Design and build robust ETL processes that accommodate the diverse data formats and structures from multiple partners, while adhering to strict data security and privacy standards.
Innovate and refine reports, and dashboards for internal stakeholders, combining analytical rigor and creative thinking to render data into compelling visual insights.
Execute and maintain regular and ad-hoc reporting protocols to inform decision-making, taking proactive steps to address data anomalies and recommend strategies based on business intelligence.
Establish automated reporting and alerting systems for business stakeholders, providing them with timely and actionable insights on affiliate marketing and advertising campaigns.
Continuously evaluate and integrate state-of-the-art data technologies and tools to keep the company at the forefront of data capabilities in analytics.
Drive the optimization of data storage and query performance, reducing costs and improving efficiency in accessing and analyzing large datasets.
Cultivate a comprehensive understanding of the organization's data landscape to distinguish between actual performance issues and data discrepancies.
Qualifications & Experience…
A minimum of 8 years of experience in data engineering.
Demonstrated proficiency with SQL, Python, and Amazon Web Services (AWS) stack (S3, EC2, Redshift, etc.), including database architecture, table design, and complex data aggregations.
Expertise in BI tools such as Looker, Domo, Tableau, or similar platforms.
Proven track record of working with both structured and unstructured data sets and providing comprehensive data requirements.
Exceptional communication skills and the ability to collaborate effectively.
Advanced data visualization capabilities and a solid foundation in statistical analysis.
Logical and critical thinking skills with a knack for identifying, expressing, and troubleshooting data-related challenges
An entrepreneurial spirit driven by a quest for data acquisition, utilization, interpretation, and the dissemination of analytics-driven decisions.
Nice-to-Haves
BA/BS degree in Mathematics, Statistics, Computer Science, Engineering, or other related quantitative field
Experience with API data extraction and database integration.
Background in digital media data analytics, covering web and mobile platforms.
Prior involvement in data integration or ETL-centric projects.
Familiarity with Big Data technologies such as Hadoop, Hive, Spark, Parquet, or similar systems.
How We Get Things Done…
This last bit is probably the most important! Here at WBD, our guiding principles are the core values by which we operate and are central to how we get things done. You can find them at www.wbd.com/guiding-principles/ along with some insights from the team on what they mean and how they show up in their day to day. We hope they resonate with you and look forward to discussing them during your interview.
The Legal Bits…
Warner Bros. Discovery embraces the opportunity to build a workforce that reflects the diversity of our society and the world around us. Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, and genetic information, marital status, citizenship status, military status, protected veteran status or any other category protected by law.
If you’re a qualified candidate and you require adjustments or accommodations to search for a job opening or apply for a position, please contact us at recruitadmin@wbd.com.
Show more
Show less","Data Engineering, DataDriven Culture, Data Analytics, Data Warehousing, Data Integration, Data Visualization, Data Security, Data Privacy, SQL, Python, Cloud Computing, Amazon Web Services (AWS), Business Intelligence (BI), Looker, Domo, Tableau, Hadoop, Hive, Spark, Parquet, Big Data","Company: Warner Bros. Discovery
Job Title: Principal Data Engineer
Experience: A minimum of 8 years of experience in data engineering
Skills Needed: Proficiency in SQL, Python, and Amazon Web Services (AWS) stack, expertise in BI tools, advanced data visualization capabilities, logical and critical thinking skills, strong communication skills, background in digital media data analytics, familiarity with Big Data technologies
Summary: Warner Bros. Discovery is seeking a seasoned Principal Data Engineer to drive a data-driven culture within",0.1408934689410848,0.54316604
"Senior Data Scientist, Acquisition",Grammarly,"Maine, United States",https://www.linkedin.com/jobs/view/senior-data-scientist-acquisition-at-grammarly-3774284640,2023-12-20,Maine,United States,Mid senior,Hybrid,"Grammarly is excited to offer a
remote-first hybrid working model
. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.
All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków.
This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.
Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.
The opportunity
Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the
Fortune
500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of
Inc.
’s best workplaces, a Glassdoor Best Place to Work, one of
TIME
’s 100 Most Influential Companies, and one of
Fast Company
’s Most Innovative Companies in AI.
To achieve our ambitious goals, we’re looking for a Senior Data Scientist to join our incredible team and work on core marketing measurement and optimization projects. The ideal candidate will have strong technical expertise and marketing domain knowledge and collaborate with cross-functional teams to develop solutions and drive data-driven actions. The person in this role will advance our statistical rigor, testing, and measurement methodologies, define a framework to measure the impact of our marketing channels, leverage Grammarly’s internal data and Google Ads platform data to solve ambiguous marketing problems and provide data-driven solutions.
The Grammarly data teams are trusted subject matter experts who uncover new insights to inform marketing, product, and growth strategies. We have large datasets and are looking for folks with deep technical and analytical skills who can break down complex business problems and provide solutions with high impact and visibility for marketing and the company. Our teams have the freedom to innovate and uncover breakthroughs—and, in turn, influence the marketing roadmap.
Your impact
As a Senior Data Scientist, You Will
Lead testing and measurement efforts for our key online marketing channels, especially paid searches, such as Google and Bing.
Develop cross-channel measurement models such as MediaMixModeling to optimize budget allocation.
Collaborate with Engineering and Marketing teams to drive LTV bidding optimizations and their impact measurement for our digital marketing channels.
Measure the effectiveness of Individual Marketing channels and Cross-Channels by building/leveraging different attribution models and experimentation methods.
Devise a solution to inform marketing strategy and drive measurement in a cookieless world.
Analyze the impact of our overall marketing budget to understand its full-funnel impact and how it influences Grammarly for Business conversions.
Run elasticity analysis to drive discussions and identify opportunities for spending re-allocation across countries.
Conduct deep-dive analyses into marketing channel performance and user behavior.
We’re Looking For Someone Who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
Is able to collaborate in person 2 weeks per quarter, traveling when necessary to the hub where the team is based.
Has 8+ years of relevant work experience.
Has experience as an influential and effective thought partner to marketing teams.
Demonstrates strong communication, proactiveness, creativity, and prioritization skills.
Has strong analytical and critical thinking skills and a strong bias toward actionable insights.
Has the ability to work in a fast-paced, dynamic environment.
Has practical experience in data analysis, statistics, and marketing measurement.
Is proficient in SQL, Python, R, Scala, or an equivalent language.
Support for you, professionally and personally
Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.
Compensation And Benefits
Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
Disability and life insurance options
401(k) and RRSP matching
Paid parental leave
Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
Home office stipends
Caregiver and pet care stipends
Wellness stipends
Admission discounts
Learning and development opportunities
Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.
Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.
United States
Zone 1: $197,000 - $253,000year (USD)
Zone 2: $177,000 - $228,000/year (USD)
Zone 3: $168,000 - $215,000/year (USD)
Zone 4: $157,000 - $202,000/year (USD)
We encourage you to apply
At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).
Please note that EEOC is optional and specific to US-based candidates.
#NA
All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.
Show more
Show less","Data analysis, Statistics, Marketing measurement, Google Ads, SQL, Python, R, Scala, Machine Learning, Artificial Intelligence, Data visualization, Marketing strategy, Attribution modeling, Experimentation, Communication, Proactiveness, Creativity, Prioritization, Analytical thinking, Critical thinking, Actionable insights, Fastpaced environment, Adaptability, Grit, Empathy, Remarkability","Company: Grammarly
Job Title: Senior Data Scientist
Experience: 8+ years of relevant work experience
Skills Needed: Strong technical expertise, marketing domain knowledge, collaboration with cross-functional teams, statistical rigor, testing, measurement methodologies, data-driven actions, analytical and critical thinking skills, bias toward actionable insights, proficiency in SQL, Python, R, Scala, or equivalent language.",0.1115879814798578,0.38339362
"Senior Data Scientist, SEO",Grammarly,"Maine, United States",https://www.linkedin.com/jobs/view/senior-data-scientist-seo-at-grammarly-3776412364,2023-12-20,Maine,United States,Mid senior,Hybrid,"Grammarly is excited to offer a
remote-first hybrid working model
. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.
All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków.
This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.
Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.
The opportunity
Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.
To achieve our ambitious goals, we’re looking for a Senior Data Scientist to join our Data Engineering and Intelligence team. This candidate will partner with our SEO Marketing team to accelerate SEO growth at Grammarly. The ideal candidate will have a strong track record of delivering impactful analytical projects within the SEO domain and partner with cross-functional peers to guide and influence decision-making.
The Grammarly data teams are trusted subject matter experts who uncover new insights to inform marketing, product, and growth strategies that drive outcomes at the highest levels of the company. We have large datasets and are looking for folks with deep technical and analytical skills who can break down complex business problems and provide solutions with high visibility and impact for the company.
Grammarly’s Data teams have the freedom to innovate and uncover breakthroughs—and, in turn, influence our marketing, product, and growth roadmap. The complexity of the technical questions we face is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.
Your impact
In This Role, You Will
Become a part of the core team focused on SEO growth for the company – a company-level objective.
Own the metric development for the SEO space, partnering with cross-functional members to ensure clear and actionable insights.
Design and run SEO experiments leveraging advanced statistical methodologies, including causal inference.
Be the Data science thought leader for the cross-functional working group and provide evidenced-based guidance.
Provide actionable insights and recommendations to improve our SEO performance by leveraging your deep expertise in the SEO and Data Science fields.
Co-own the strategy, prioritization, and roadmap for SEO growth at the company.
Collaborate directly with Marketing, Growth, and Engineering teams.
Apply machine learning to identify the most critical web architecture components that drive beneficial SEO growth.
Recruit, guide, and mentor junior and mid-level Data Scientists to create a best-in-class Data Science organization.
Collaborate with other Data Scientists to continue to enhance the methodologies and practices used across the team that leverage the newest technological developments in the industry.
We’re Looking For Someone Who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
Is able to collaborate in person 2 weeks per quarter, traveling when necessary to the hub where the team is based.
Holds a PhD or master’s degree in a quantitative field.
Has 8+ years of relevant work experience with a proven track record of applying data science methods within the SEO domain.
Is fluent in SQL with strong data exploration and manipulation skills.
Is proficient in Python, R, or similar programming language.
Has an understanding of causal inference methods and their application and ability to apply machine learning techniques when necessary.
Has firm knowledge of experiment design and A/B and MVT testing.
Is comfortable working with clickstream and web event-related data.
Has a self-starting growth mindset and strong communication skills, translating technical insights into impactful business recommendations.
Is a creative problem-solver who simplifies problems to their core elements.
Support for you, professionally and personally
Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.
Compensation And Benefits
Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
Disability and life insurance options
401(k) and RRSP matching
Paid parental leave
Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
Home office stipends
Caregiver and pet care stipends
Wellness stipends
Admission discounts
Learning and development opportunities
Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.
Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.
United States
Zone 1: $226,000 - $262,000/year (USD)
Zone 2: $203,000 - $236,000/year (USD)
Zone 3: $192,000 - $223,000/year (USD)
Zone 4: $181,000 - $210,000/year (USD)
We encourage you to apply
At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).
Please note that EEOC is optional and specific to US-based candidates.
#NA
All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.
Show more
Show less","Data Science, AI, SEO, Statistical methodologies, Causal inference, Machine learning, Python, R, SQL, Experiment design, A/B testing, MVT testing, Clickstream analysis, Web event analysis, Data exploration, Data manipulation","Company Name: Grammarly  
Job Title: Senior Data Scientist  
Experience: 8+ years  
Skills Needed: - Hold a PhD or master's degree in a quantitative field  
- 8+ years of relevant work experience in applying data science methods within the SEO domain  
- Fluent in SQL with strong data exploration and manipulation skills  
- Proficient in Python, R, or similar programming language  
- Understanding of causal inference methods and their application, ability to apply machine learning techniques  
- Knowledge of",0.12737127219626032,0.243815
"Data Engineer, Data Platform",Grammarly,"Maine, United States",https://www.linkedin.com/jobs/view/data-engineer-data-platform-at-grammarly-3689960992,2023-12-20,Maine,United States,Mid senior,Hybrid,"Grammarly is excited to offer a
remote-first hybrid working model
. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.
All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków.
This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.
Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.
The opportunity
Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.
To achieve our ambitious goals, we’re looking for a Data Engineer to join our Data Engineering Platform team. This person will build highly automated, low latency core datasets that will help data engineers and end users across Grammarly to work with analytical data at scale.
Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.
Your impact
As a Data Engineer on our Data Engineering Platform team, you will:
Drive improvements to make our analytics effortless by creating and adjusting core data models and storage structures, all while understanding the needs of our users.
Make analytical data and metrics usable within a few minutes of real world events occuring, and build streaming processes for the output derived events and aggregate data.
Model structure, storage, and access of data at very high volumes for our data lakehouse.
Improve developer productivity and self-serve solutions by contributing components to our stream data processing framework(s).
Own data engineering's infrastructure-as-code for provisioning services that allow our engineers to deploy mature software installations within a few hours.
Build a world-class process that will allow our systems to scale.
Mentor other back-end engineers on the team and help them grow.
Build and contribute to AWS high-scale distributed systems on the back-end.
We’re Looking For Someone Who
Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.
Has experience with Python, Scala, or Java.
Has experience with designing database objects and writing relational queries
Has experience designing and standing up APIs and services.
Has experience with system design and building internal tools.
Has experience handling applications that work with data from data lakes.
Has at least some experience building internal Admin sites.
Has good knowledge of and at least some experience with AWS (or, alternatively, has deep expertise in Azure or GCE and is willing to learn AWS in a short time frame).
Can knowledgeably choose an open source or third-party service to accomplish what they need or, alternatively, can devise a quick and simple solution on their own.
Support for you, professionally and personally
Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.
Compensation And Benefits
Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
Disability and life insurance options
401(k) and RRSP matching
Paid parental leave
Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
Home office stipends
Caregiver and pet care stipends
Wellness stipends
Admission discounts
Learning and development opportunities
Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.
Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.
United States
Zone 1: $167,000 - $242,000/year (USD)
Zone 2: $150,000 – $218,000/year (USD)
Zone 3: $142,000 – $206,000/year (USD)
Zone 4: $134,000 – $194,000/year (USD)
We encourage you to apply
At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).
Please note that EEOC is optional and specific to US-based candidates.
#NA
All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.
Show more
Show less","Python, Scala, Java, AWS, Azure, GCE, SQL, Data Warehousing, Data Mining, Streaming Data Processing, Data Lakehouse, Software Installation, System Design, Internal Tool Development, API Design, Service Design","Company: Grammarly
Job Title: Data Engineer
Experience: The ideal candidate should have experience with Python, Scala, or Java, designing database objects, writing relational queries, designing and standing up APIs and services, system design, building internal tools, handling applications with data from data lakes, and building internal Admin sites.

Skills Needed:
- Proficiency in Python, Scala, or Java
- Experience in designing database objects and writing relational queries
- Experience in designing and standing up APIs and services
",0.0956521725440454,0.27274162
Principal Data Scientist,Northrop Grumman,"Virginia, United States",https://www.linkedin.com/jobs/view/principal-data-scientist-at-northrop-grumman-3785895544,2023-12-20,Whitman,United States,Associate,Onsite,"At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work - and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman Mission Systems (MS) Sector (ASO) Advanced Strategic Operations (SPM) Supplier Performance Management team is seeking a Principal Data Scientist to lead the implementation of strategic enterprise and sector execution initiatives. In support of MS Sector, the individual will be responsible for developing new technical principles and leading technical aspects of strategic initiatives, ensuring cost, schedule and quality objectives are met through the use of advanced analytics, multi-disciplined leadership, and continuous improvement techniques. This individual will develop and apply advanced technical principles, theory, and concepts across the MS Sector Divisions to support strategic planning, execute strategic projects, develop operational business opportunities, and drive schedule and cost reductions while maintaining absolute quality. The individual will interact and consult regularly with MS Executive Leadership Team (ELT), Program Leadership, and supporting Functional Leadership.
Key Responsibilities
Participate in the planning, design, development and implementation of solutions to address ongoing business performance opportunities and performance improvement.
Work in a fast-paced, Agile/Scrum based environment.
Implement process changes to improve business outcomes.
Develop impactful predictive modelling, Monte Carlo simulations and advanced analytics
Support cross-team development efforts for multiple projects, including data cleanup, ingestion, and linkage with other data sets.
Develop data architectures and data management solutions.
Document design, deployment and operating procedures for each work product.
Present data in a meaningful way to executive management.
Other duties as assigned.
Basic Qualifications
Bachelor's degree in engineering, business, or related field
5+ years of relevant experience (or 3+ years with a master's degree)
Ability to communicate effectively to all levels of an organization with the ability to translate concepts into practical application
Demonstrated experience working with systems to ingest, process, store, analyze and visualize data
Ability to obtain a DoD Secret clearance
Preferred Qualifications:
Master's degree in information technology, data science, industrial engineering, or related field
Demonstrated proficiency with SQL and Python or R
Demonstrated knowledge of SQL database management
Demonstrated knowledge and application of: Lean, Six Sigma, ToC, and Scaled Agile
Understanding of advanced descriptive, diagnostic, predictive, and prescriptive analysis techniques and methodology
Familiarity with SAP
Familiarity with Tableau
Familiarity with an Oracle based data warehouse
Salary Range:
$107,300 - $160,900
The above salary range represents a general guideline; however, Northrop Grumman considers a number of factors when determining base salary offers such as the scope and responsibilities of the position and the candidate's experience, education, skills and current market conditions.
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO . U.S. Citizenship is required for most positions.
Show more
Show less","Agile, Scrum, Monte Carlo simulations, SQL, Python, R, SAP, Tableau, Oracle, Lean, Six Sigma, ToC, Scaled Agile, Descriptive analysis, Diagnostic analysis, Predictive analysis, Prescriptive analysis","Company: Northrop Grumman
Job Title: Principal Data Scientist
Experience: 5+ years of relevant experience
Skills Needed: Bachelor's degree in engineering, business, or related field, ability to communicate effectively, experience with data analysis and visualization, ability to obtain a DoD Secret clearance, proficiency with SQL and Python or R, knowledge of Lean, Six Sigma, ToC, and Scaled Agile methodologies, familiarity with SAP, Tableau, and Oracle based data warehouse.",0.1690721629058136,0.56449044
Senior Data Engineer (Azure),Energy Jobline,"Chatham, MA",https://www.linkedin.com/jobs/view/senior-data-engineer-azure-at-energy-jobline-3772979435,2023-12-20,Barnstable,United States,Mid senior,Hybrid,"Senior Data Engineer - Azure
A leading financial services corporation is currently recruiting a Senior Data Engineer with five years’ experience in ETL development coupled with strong capabilities in Azure cloud tools such as Azure Data Factory, Azure Synapse Analytics, Azure Data Lake, Azure Blob Storage, Azure Databricks, Azure Analysis service as our client rebuilds their technology estate moving to a cloud focused data driven environment leveraging the latest tools/technologies. Our client is looking to pay up to £67,000 + 15% bonus with on site presence occasionally in London or Chatham.
The ideal Senior Data Engineer will have experience migrating legacy applications into optimised data pipelines within a regulated environment.
Core Responsibilities
Leading solutions for data engineering
Maintain the integrity of both the design and the data that is held within the architecture
Champion and educate people in the development and use of data engineering best practices
Support the Head of Data Engineering and lead by example
Contribute to the development of database management services and associated processes relating to the delivery of data solutions
Provide requirements analysis, documentation, development, delivery and maintenance of data platforms.
Develop database requirements in a structured and logical manner ensuring delivery is aligned with business prioritisation and best practice
Design and deliver performance enhancements, application migration processes and version upgrades across a pipeline of BI environments.
Provide support for the scoping and delivery of BI capability to internal users.Experience requirements:
5+ years Data Engineering / ETL development experience
Strong capabilities in Azure Cloud Solutions (etc. Databricks)
Experience working within a regulated environment / finance / insurance / energy
5+ years data design experience in an MI / BI / Analytics environment
Excellent Data Warehouse with substantial experience in extracting, reporting and manipulating data from a data warehouse environment
Significant technical skills such as Transact SQL language, relational database skills
Evidence of delivering complex data platforms and solutions
Microsoft SQL Server 2019 certification£67,000/ 15% bonus / Flexible working / 28 Days Holiday / Medical Cover / Life Cover / 13% Pension / Flexible Benefits
Senior Data Engineer - Azure
Show more
Show less","Data Engineering, ETL Development, Azure Cloud Solutions, Azure Data Factory, Azure Synapse Analytics, Azure Data Lake, Azure Blob Storage, Azure Databricks, Azure Analysis Service, Legacy Application Migration, Data Pipelines, Database Management Services, Data Platforms, Database Requirements, Business Prioritization, Performance Enhancements, Application Migration, Version Upgrades, BI Environments, BI Capability, Data Warehouse, Data Extraction, Data Reporting, Data Manipulation, Transact SQL, Relational Databases, Complex Data Platforms, Complex Data Solutions, Microsoft SQL Server 2019","Company: Leading financial services corporation
Job Title: Senior Data Engineer - Azure
Experience: 5+ years
Skills Needed: ETL development, Azure Data Factory, Azure Synapse Analytics, Azure Data Lake, Azure Blob Storage, Azure Databricks, Azure Analysis Service, migration of legacy applications, data engineering best practices, database management, data platform development, Transact SQL language, Microsoft SQL Server 2019 certification.",0.2775510173581008,0.7344996
w2::DataStage Developer::Local to AZ/GA,TALENDICA,"Chandler, AZ",https://www.linkedin.com/jobs/view/w2-datastage-developer-local-to-az-ga-at-talendica-3788160357,2023-12-20,Phoenix,United States,Mid senior,Hybrid,"Hi,
Role
- DataStage Developer in Chandler AZ and Kennesaw GA – Onsite – Local Candidates
Location-
Chandler AZ and Kennesaw GA – Onsite – Local Candidates
Duration : Long term
Job Description
7-10 years of experience as DataStage developer.
Experience with DataStage v11.7 & QualityStage.
Experience with MS SQL and ETL, Packages and Functions.
Highly motivated self-starter able to work w/ minimal oversight.
Strong communication skills with focus on teamwork.
Proficient with agile development routines, Horizon / CICD.
Thanks & Regards,
JIA
|
TALENDICA
SENIOR TECHNICAL RECRUITER
44, Saratoga Ln, Monroe Township, NJ - 08831
Email:
jia@talendica.com
Hangout/Skype:
jia@talendica.com
www.talendica.com
Follow Us On
If you are not interested in receiving our e-mails then please reply with a ""REMOVE"" in the subject line. We are sorry for the inconvenience caused to you.
Show more
Show less","DataStage Developer, DataStage v11.7, QualityStage, SQL, ETL, Packages, Functions, Agile Development, CICD, Horizon","The job is for a DataStage Developer position at Talendica, requiring 7-10 years of experience. The role is based in Chandler, AZ and Kennesaw, GA for local candidates, with a long-term duration. The ideal candidate should have experience with DataStage v11.7 & QualityStage, MS SQL, ETL, Packages, and Functions. Additionally, proficiency in agile development routines, Horizon/CICD, strong communication skills, and the ability to work independently are desired",0.3253012003099144,0.8048525
