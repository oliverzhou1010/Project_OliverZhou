{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(context=\"notebook\", \n",
    "              style=\"white\")\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import (BartTokenizer,\n",
    "                          BartForConditionalGeneration,\n",
    "                          DataCollatorForSeq2Seq,\n",
    "                          EarlyStoppingCallback,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          Seq2SeqTrainer, \n",
    "                          get_scheduler)\n",
    "import torch\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/oliverzhou/.cache/kagglehub/datasets/asaniczka/data-scientist-linkedin-job-postings/versions/103\n",
      "postings.csv\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/asaniczka/data-scientist-linkedin-job-postings\n",
    "import kagglehub\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"asaniczka/data-scientist-linkedin-job-postings\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "files = os.listdir(path)\n",
    "# Print the names of the files\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_link</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Jefferson Health Plans</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/technical-d...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Phoenixville</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>DeRisk Technologies</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-center...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Avani Tech Solutions Private Limited</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>NBC Sports Next</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables</td>\n",
       "      <td>Bloomington, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title  \\\n",
       "0                 Technical Data Analyst   \n",
       "1     Data Center Engineer - Minneapolis   \n",
       "2                           Data Analyst   \n",
       "3     Data Engineer II - NBC Sports Next   \n",
       "4  Data Analyst - Operational Assessment   \n",
       "\n",
       "                                company      job_location  \\\n",
       "0                Jefferson Health Plans  Philadelphia, PA   \n",
       "1                   DeRisk Technologies   Minneapolis, MN   \n",
       "2  Avani Tech Solutions Private Limited   Minneapolis, MN   \n",
       "3                       NBC Sports Next   Minneapolis, MN   \n",
       "4              National Grid Renewables   Bloomington, MN   \n",
       "\n",
       "                                            job_link  first_seen  \\\n",
       "0  https://www.linkedin.com/jobs/view/technical-d...  2023-12-20   \n",
       "1  https://www.linkedin.com/jobs/view/data-center...  2023-12-20   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  2023-12-20   \n",
       "3  https://www.linkedin.com/jobs/view/data-engine...  2023-12-20   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  2023-12-20   \n",
       "\n",
       "    search_city search_country  job level job_type  \\\n",
       "0  Phoenixville  United States  Associate   Remote   \n",
       "1   Minneapolis  United States  Associate   Onsite   \n",
       "2   Minneapolis  United States  Associate   Onsite   \n",
       "3   Minneapolis  United States  Associate   Remote   \n",
       "4   Minneapolis  United States  Associate   Hybrid   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3  Company Description\\nNBC Sports Next is where ...   \n",
       "4  National Grid Renewables is a leading North Am...   \n",
       "\n",
       "                                          job_skills  \n",
       "0  KNIME, QlikView, SQL, MS Access, MS Excel, Log...  \n",
       "1  Server, Storage, Backup, Networking, Virtualiz...  \n",
       "2  Data Management, HR Data Retention Controls, C...  \n",
       "3  Data Engineering, Data Warehousing, SQL, MySQL...  \n",
       "4  Data Analyst, Operational Assessment, Wind Ene...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings = pd.read_csv(path+'/postings.csv')\n",
    "postings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title', 'company', 'job_location', 'job_link', 'first_seen',\n",
       "       'search_city', 'search_country', 'job level', 'job_type', 'job_summary',\n",
       "       'job_skills'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings.columns\n",
    "# may just need 'title', 'job_summary', 'job_skills'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "postings.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_link</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Jefferson Health Plans</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/technical-d...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Phoenixville</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>DeRisk Technologies</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-center...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Avani Tech Solutions Private Limited</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>NBC Sports Next</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables</td>\n",
       "      <td>Bloomington, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title  \\\n",
       "0                 Technical Data Analyst   \n",
       "1     Data Center Engineer - Minneapolis   \n",
       "2                           Data Analyst   \n",
       "3     Data Engineer II - NBC Sports Next   \n",
       "4  Data Analyst - Operational Assessment   \n",
       "\n",
       "                                company      job_location  \\\n",
       "0                Jefferson Health Plans  Philadelphia, PA   \n",
       "1                   DeRisk Technologies   Minneapolis, MN   \n",
       "2  Avani Tech Solutions Private Limited   Minneapolis, MN   \n",
       "3                       NBC Sports Next   Minneapolis, MN   \n",
       "4              National Grid Renewables   Bloomington, MN   \n",
       "\n",
       "                                            job_link  first_seen  \\\n",
       "0  https://www.linkedin.com/jobs/view/technical-d...  2023-12-20   \n",
       "1  https://www.linkedin.com/jobs/view/data-center...  2023-12-20   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  2023-12-20   \n",
       "3  https://www.linkedin.com/jobs/view/data-engine...  2023-12-20   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  2023-12-20   \n",
       "\n",
       "    search_city search_country  job level           job_type  \\\n",
       "0  Phoenixville  United States  Associate  Data Analyst (BI)   \n",
       "1   Minneapolis  United States  Associate      Data Engineer   \n",
       "2   Minneapolis  United States  Associate  Data Analyst (BI)   \n",
       "3   Minneapolis  United States  Associate      Data Engineer   \n",
       "4   Minneapolis  United States  Associate  Data Analyst (BI)   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3  Company Description\\nNBC Sports Next is where ...   \n",
       "4  National Grid Renewables is a leading North Am...   \n",
       "\n",
       "                                          job_skills  \n",
       "0  KNIME, QlikView, SQL, MS Access, MS Excel, Log...  \n",
       "1  Server, Storage, Backup, Networking, Virtualiz...  \n",
       "2  Data Management, HR Data Retention Controls, C...  \n",
       "3  Data Engineering, Data Warehousing, SQL, MySQL...  \n",
       "4  Data Analyst, Operational Assessment, Wind Ene...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply conditions to create 'job_type'\n",
    "patterns = {\n",
    "    'Data Scientist': r'Data\\s*Scientist|Data\\s*Science|Scientist',  # Match both \"Data Scientist\" and \"Data Science\"\n",
    "    'Data Analyst (BI)': r'Data\\s*Analyst|Data\\s*Research\\s*Analyst|Analyst|Data\\s*Analytics|BI|Business\\s*Intelligence|Analytics|Visualization|Data\\s*Analysis',  # Add \"Data Research Analyst\"\n",
    "    'Data Engineer': r'Data\\s*Engineer|Database\\s*Engineer|Engineer',  # Consider \"Database Engineer\" as well\n",
    "    'Software Engineer': r'Software\\s*Engineer|Developer|Programmer|Software',\n",
    "    'Statistician': r'\\s*Statistician',\n",
    "    'Modeler': r'\\s*Modeler',\n",
    "    'Consultant': r'\\s*Consultant',\n",
    "    'Specialist': r'\\s*Specialist'\n",
    "}\n",
    "\n",
    "# Initialize 'job_type' column with 'Unknown'\n",
    "postings['job_type'] = 'Unknown'\n",
    "\n",
    "# Apply patterns to classify job titles\n",
    "for job_type, pattern in patterns.items():\n",
    "    postings.loc[postings['job_title'].str.contains(pattern, case=False, na=False, regex=True), 'job_type'] = job_type\n",
    "\n",
    "# Show the first few rows\n",
    "postings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_link</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Jefferson Health Plans</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/technical-d...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Phoenixville</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>DeRisk Technologies</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-center...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Avani Tech Solutions Private Limited</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>NBC Sports Next</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables</td>\n",
       "      <td>Bloomington, MN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title  \\\n",
       "0                 Technical Data Analyst   \n",
       "1     Data Center Engineer - Minneapolis   \n",
       "2                           Data Analyst   \n",
       "3     Data Engineer II - NBC Sports Next   \n",
       "4  Data Analyst - Operational Assessment   \n",
       "\n",
       "                                company      job_location  \\\n",
       "0                Jefferson Health Plans  Philadelphia, PA   \n",
       "1                   DeRisk Technologies   Minneapolis, MN   \n",
       "2  Avani Tech Solutions Private Limited   Minneapolis, MN   \n",
       "3                       NBC Sports Next   Minneapolis, MN   \n",
       "4              National Grid Renewables   Bloomington, MN   \n",
       "\n",
       "                                            job_link  first_seen  \\\n",
       "0  https://www.linkedin.com/jobs/view/technical-d...  2023-12-20   \n",
       "1  https://www.linkedin.com/jobs/view/data-center...  2023-12-20   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  2023-12-20   \n",
       "3  https://www.linkedin.com/jobs/view/data-engine...  2023-12-20   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  2023-12-20   \n",
       "\n",
       "    search_city search_country  job level           job_type  \\\n",
       "0  Phoenixville  United States  Associate  Data Analyst (BI)   \n",
       "1   Minneapolis  United States  Associate      Data Engineer   \n",
       "2   Minneapolis  United States  Associate  Data Analyst (BI)   \n",
       "3   Minneapolis  United States  Associate      Data Engineer   \n",
       "4   Minneapolis  United States  Associate  Data Analyst (BI)   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3  Company Description\\nNBC Sports Next is where ...   \n",
       "4  National Grid Renewables is a leading North Am...   \n",
       "\n",
       "                                          job_skills  \n",
       "0  KNIME, QlikView, SQL, MS Access, MS Excel, Log...  \n",
       "1  Server, Storage, Backup, Networking, Virtualiz...  \n",
       "2  Data Management, HR Data Retention Controls, C...  \n",
       "3  Data Engineering, Data Warehousing, SQL, MySQL...  \n",
       "4  Data Analyst, Operational Assessment, Wind Ene...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings[postings['job_type']=='Unknown']['job_title'].value_counts()\n",
    "data = postings[postings['job_type']!='Unknown']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "Cleaning Text: Remove unwanted characters, URLs, and unnecessary whitespace.\n",
    "Lowercasing: Convert all text to lowercase to maintain consistency.\n",
    "Tokenization: Split the text into words or tokens.\n",
    "Stop Words Removal: Remove common words that may not add value to your analysis (e.g., \"and\", \"the\").\n",
    "Stemming/Lemmatization: Reduce words to their base or root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title  \\\n",
       "0                 Technical Data Analyst   \n",
       "1     Data Center Engineer - Minneapolis   \n",
       "2                           Data Analyst   \n",
       "3     Data Engineer II - NBC Sports Next   \n",
       "4  Data Analyst - Operational Assessment   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3  Company Description\\nNBC Sports Next is where ...   \n",
       "4  National Grid Renewables is a leading North Am...   \n",
       "\n",
       "                                          job_skills           job_type  \n",
       "0  KNIME, QlikView, SQL, MS Access, MS Excel, Log...  Data Analyst (BI)  \n",
       "1  Server, Storage, Backup, Networking, Virtualiz...      Data Engineer  \n",
       "2  Data Management, HR Data Retention Controls, C...  Data Analyst (BI)  \n",
       "3  Data Engineering, Data Warehousing, SQL, MySQL...      Data Engineer  \n",
       "4  Data Analyst, Operational Assessment, Wind Ene...  Data Analyst (BI)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['job_title', 'job_summary', 'job_skills', 'job_type']\n",
    "data = data[cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_type\n",
       "Data Scientist       1691\n",
       "Data Engineer        1335\n",
       "Data Analyst (BI)     895\n",
       "Software Engineer     282\n",
       "Specialist             49\n",
       "Consultant             44\n",
       "Statistician           11\n",
       "Modeler                 8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title      0\n",
       "job_summary    0\n",
       "job_skills     0\n",
       "job_type       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['job_title', 'job_summary', 'job_skills'], inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oliverzhou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/oliverzhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/oliverzhou/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"skills.json\", \"r\") as file:\n",
    "    skills_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type</th>\n",
       "      <th>cleaned_job_summary</th>\n",
       "      <th>cleaned_job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>choose jefferson health plan awardwinning notf...</td>\n",
       "      <td>knime qlikview sql ms access ms excel logical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>job responsibility deployment inscope configur...</td>\n",
       "      <td>server storage backup networking virtualizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>success factor knowledge schedule monday frida...</td>\n",
       "      <td>data management hr data retention controls cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>company description nbc sport next sport techn...</td>\n",
       "      <td>data engineering data warehousing sql mysql po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>national grid renewables leading north america...</td>\n",
       "      <td>data analyst operational assessment wind energ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title  \\\n",
       "0                 Technical Data Analyst   \n",
       "1     Data Center Engineer - Minneapolis   \n",
       "2                           Data Analyst   \n",
       "3     Data Engineer II - NBC Sports Next   \n",
       "4  Data Analyst - Operational Assessment   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3  Company Description\\nNBC Sports Next is where ...   \n",
       "4  National Grid Renewables is a leading North Am...   \n",
       "\n",
       "                                          job_skills           job_type  \\\n",
       "0  KNIME, QlikView, SQL, MS Access, MS Excel, Log...  Data Analyst (BI)   \n",
       "1  Server, Storage, Backup, Networking, Virtualiz...      Data Engineer   \n",
       "2  Data Management, HR Data Retention Controls, C...  Data Analyst (BI)   \n",
       "3  Data Engineering, Data Warehousing, SQL, MySQL...      Data Engineer   \n",
       "4  Data Analyst, Operational Assessment, Wind Ene...  Data Analyst (BI)   \n",
       "\n",
       "                                 cleaned_job_summary  \\\n",
       "0  choose jefferson health plan awardwinning notf...   \n",
       "1  job responsibility deployment inscope configur...   \n",
       "2  success factor knowledge schedule monday frida...   \n",
       "3  company description nbc sport next sport techn...   \n",
       "4  national grid renewables leading north america...   \n",
       "\n",
       "                                  cleaned_job_skills  \n",
       "0  knime qlikview sql ms access ms excel logical ...  \n",
       "1  server storage backup networking virtualizatio...  \n",
       "2  data management hr data retention controls cal...  \n",
       "3  data engineering data warehousing sql mysql po...  \n",
       "4  data analyst operational assessment wind energ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Text cleaning for job_summary\n",
    "def clean_text_summary(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Retain keywords (skills) and remove stop words\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens \n",
    "        if word in skills_data or word not in stop_words\n",
    "    ]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Text cleaning for job_skills (only remove special characters and notations)\n",
    "def clean_text_skills(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Assuming your DataFrame is named 'data'\n",
    "# Apply cleaning to job_summary and job_skills\n",
    "data['cleaned_job_summary'] = data['job_summary'].apply(clean_text_summary)\n",
    "data['cleaned_job_skills'] = data['job_skills'].apply(clean_text_skills)\n",
    "\n",
    "# Save the cleaned data\n",
    "data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Preview the cleaned data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Summarization\n",
    "\n",
    "cite: https://towardsdatascience.com/setting-up-a-text-summarisation-project-daae41a1aaa3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'facebook/bart-large-cnn'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#summarizer = pipeline(\"summarization\")\n",
    "summarizer = pipeline(\"summarization\", model='facebook/bart-large-cnn')\n",
    "summarizer.model.config.__getattribute__('_name_or_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverzhou/Library/Python/3.9/lib/python/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# split the dataset into train, val, and test\n",
    "df_train, df_val, df_test = np.split(data.sample(frac=1, random_state=44), [int(0.8*len(data)), int((0.9)*len(data))])\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "df_val.to_csv('val.csv', index=False)\n",
    "df_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your min_length=56 must be inferior than your max_length=30.\n",
      "/Users/oliverzhou/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1399: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' data analyst location hartford ct raleigh nc duration fulltime job description least year experience working healthcare business data analyst health plan'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "ref_summaries = list(df_test['job_type'])\n",
    "texts = list(df_test['cleaned_job_summary'])\n",
    "summarizer(texts[0], max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "100\n",
      "Error summarizing text at index 137: index out of range in self\n",
      "Error summarizing text at index 164: index out of range in self\n",
      "Error summarizing text at index 189: index out of range in self\n",
      "200\n",
      "Error summarizing text at index 276: index out of range in self\n",
      "Error summarizing text at index 292: index out of range in self\n",
      "300\n",
      "Error summarizing text at index 346: index out of range in self\n",
      "Error summarizing text at index 388: index out of range in self\n",
      "400\n",
      "Error summarizing text at index 416: index out of range in self\n",
      "Error summarizing text at index 422: index out of range in self\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' data analyst location hartford ct raleigh nc duration fulltime job description least year experience working healthcare business data analyst health plan',\n",
       " 'Hire a data engineer to revolutionize dating industry. Hire a product manager to help build a software hardware talent innovative company team.',\n",
       " 'Aurora co icr is looking for a data scientist with bayesian statistic background. The data scientist is expected to work independently on',\n",
       " 'Program designed build fundamental understanding operation power grid realtime system operation perspective thorough knowledge wholesale market operate critical knowledge longterm infrastructure planning process.',\n",
       " ' data analyst leatherhead uk salary data analyst want use skill make real impact education world enjoy seeing work bringing people data together best way person']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_summaries = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        # Generate summary using the summarizer\n",
    "        candidate = summarizer(text, min_length=5, max_length=30)\n",
    "        \n",
    "        # Ensure the summarizer returned a valid result\n",
    "        if candidate:\n",
    "            candidate_summaries.append(candidate[0].get('summary_text', 'No summary text found'))\n",
    "        else:\n",
    "            candidate_summaries.append('No summary generated')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exceptions during the summarization process\n",
    "        print(f\"Error summarizing text at index {i}: {e}\")\n",
    "        candidate_summaries.append('Error during summarization')\n",
    "\n",
    "file = open(\"zero-shot-summaries.txt\", \"w\")\n",
    "for s in candidate_summaries:\n",
    "    file.write(s + \"\\n\")\n",
    "file.close()\n",
    "candidate_summaries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(14.4),\n",
       " 'rouge2': np.float64(13.3),\n",
       " 'rougeL': np.float64(14.1),\n",
       " 'rougeLsum': np.float64(14.0)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load the ROUGE metric\n",
    "metric = load(\"rouge\")\n",
    "\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores for candidate summaries against reference summaries.\n",
    "\n",
    "    Args:\n",
    "    - candidates (list of str): List of generated summaries.\n",
    "    - references (list of str): List of reference summaries.\n",
    "\n",
    "    Returns:\n",
    "    - dict: ROUGE scores rounded to 1 decimal place.\n",
    "    \"\"\"\n",
    "    if not candidates or not references:\n",
    "        raise ValueError(\"Candidates and references must not be empty.\")\n",
    "    if len(candidates) != len(references):\n",
    "        raise ValueError(\"Candidates and references must have the same length.\")\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    \n",
    "    # Handle the case where the result is a dictionary of scalar values\n",
    "    if isinstance(result, dict):\n",
    "        result = {key: round(value * 100, 1) for key, value in result.items()}\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected result format: {result}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Ensure candidate_summaries and texts are defined properly\n",
    "calc_rouge_scores(candidate_summaries, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation for baseline: ROUGE Scores Breakdown:\n",
    "1. rouge1 (14.4%):\n",
    "\n",
    "What it measures: Unigram (single-word) overlap between the candidate and reference summaries.\n",
    "Interpretation: 14.4% is relatively low for ROUGE-1, especially in competitive summarization tasks where scores typically range higher (20-40% or more). However, it may still indicate that some key terms and words from the reference are retained.\n",
    "\n",
    "2. rouge2 (13.3%):\n",
    "\n",
    "What it measures: Bigram (two-word) overlap.\n",
    "Interpretation: A score of 13.3% is also on the lower end for bigram overlap. It suggests the candidate summary may not maintain as much of the structure or combinations of words from the reference summary. Higher values (20%+) are typically seen in stronger models.\n",
    "\n",
    "3. rougeL (14.0%):\n",
    "\n",
    "What it measures: Longest common subsequence (LCS) overlap, which evaluates the order of words.\n",
    "Interpretation: A score of 14.0% is relatively low. Stronger models usually produce ROUGE-L scores in the range of 20-30%, indicating that they maintain a better word order and sequence.\n",
    "\n",
    "4. rougeLsum (14.1%):\n",
    "\n",
    "What it measures: Similar to ROUGE-L but focused on the overall summary.\n",
    "Interpretation: This score is slightly higher than ROUGE-L, but still low. A higher ROUGE-Lsum (around 20-30%) indicates the candidate summary closely follows the reference summary's overall structure.\n",
    "\n",
    "### Conclusion\n",
    "For baseline models or simple approaches, these scores may be reasonable, as early-stage or simpler models might achieve ROUGE scores in the range of 10-20%.\n",
    "\n",
    "#### Improvememt:\n",
    "- achieve higher ROUGE Scores (depends on context and use)\n",
    "- may use LLM or Prompt Engineering to prettify the summary we extracted (more smooth and human-sound like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type</th>\n",
       "      <th>cleaned_job_summary</th>\n",
       "      <th>cleaned_job_skills</th>\n",
       "      <th>relevancy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>choose jefferson health plan awardwinning notf...</td>\n",
       "      <td>knime qlikview sql ms access ms excel logical ...</td>\n",
       "      <td>0.232006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>job responsibility deployment inscope configur...</td>\n",
       "      <td>server storage backup networking virtualizatio...</td>\n",
       "      <td>0.375514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>success factor knowledge schedule monday frida...</td>\n",
       "      <td>data management hr data retention controls cal...</td>\n",
       "      <td>0.208206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>company description nbc sport next sport techn...</td>\n",
       "      <td>data engineering data warehousing sql mysql po...</td>\n",
       "      <td>0.653797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>national grid renewables leading north america...</td>\n",
       "      <td>data analyst operational assessment wind energ...</td>\n",
       "      <td>0.209912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>Data Science &amp; Analytics Consultant</td>\n",
       "      <td>Grow your career at a successful, Bristol base...</td>\n",
       "      <td>Data analytics, Data science, SQL, Python, Tab...</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>grow career successful bristol based agency am...</td>\n",
       "      <td>data analytics data science sql python tableau...</td>\n",
       "      <td>0.177982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>To Apply for this Job Click Here\\nSENIOR DATA ...</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Sta...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>apply job click senior data scientist remote c...</td>\n",
       "      <td>data science machine learning python r statist...</td>\n",
       "      <td>0.279391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>Associate/Principal Mechanical Engineer - Data...</td>\n",
       "      <td>Job Advert\\nWe have a fantastic opportunity fo...</td>\n",
       "      <td>Mechanical Engineering, Data Centre Design, Pr...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>job advert fantastic opportunity principal ass...</td>\n",
       "      <td>mechanical engineering data centre design proj...</td>\n",
       "      <td>0.142071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Robert Half partners exclusively with Envelop ...</td>\n",
       "      <td>Python, SQL, Tableau, Power BI, GCP, AWS, Azur...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>robert half partner exclusively envelop risk l...</td>\n",
       "      <td>python sql tableau power bi gcp aws azure data...</td>\n",
       "      <td>0.282636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>Customer Service Representative/Data Analyst/D...</td>\n",
       "      <td>Summary:\\nThe Data Analyst will be responsible...</td>\n",
       "      <td>Data Analysis, Statistical Analysis, Data Visu...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>summary data analyst responsible analyzing int...</td>\n",
       "      <td>data analysis statistical analysis data visual...</td>\n",
       "      <td>0.513301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4309 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_title  \\\n",
       "0                                Technical Data Analyst   \n",
       "1                    Data Center Engineer - Minneapolis   \n",
       "2                                          Data Analyst   \n",
       "3                    Data Engineer II - NBC Sports Next   \n",
       "4                 Data Analyst - Operational Assessment   \n",
       "...                                                 ...   \n",
       "4304                Data Science & Analytics Consultant   \n",
       "4305                              Senior Data Scientist   \n",
       "4306  Associate/Principal Mechanical Engineer - Data...   \n",
       "4307                              Senior Data Scientist   \n",
       "4308  Customer Service Representative/Data Analyst/D...   \n",
       "\n",
       "                                            job_summary  \\\n",
       "0     Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1     Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2     Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3     Company Description\\nNBC Sports Next is where ...   \n",
       "4     National Grid Renewables is a leading North Am...   \n",
       "...                                                 ...   \n",
       "4304  Grow your career at a successful, Bristol base...   \n",
       "4305  To Apply for this Job Click Here\\nSENIOR DATA ...   \n",
       "4306  Job Advert\\nWe have a fantastic opportunity fo...   \n",
       "4307  Robert Half partners exclusively with Envelop ...   \n",
       "4308  Summary:\\nThe Data Analyst will be responsible...   \n",
       "\n",
       "                                             job_skills           job_type  \\\n",
       "0     KNIME, QlikView, SQL, MS Access, MS Excel, Log...  Data Analyst (BI)   \n",
       "1     Server, Storage, Backup, Networking, Virtualiz...      Data Engineer   \n",
       "2     Data Management, HR Data Retention Controls, C...  Data Analyst (BI)   \n",
       "3     Data Engineering, Data Warehousing, SQL, MySQL...      Data Engineer   \n",
       "4     Data Analyst, Operational Assessment, Wind Ene...  Data Analyst (BI)   \n",
       "...                                                 ...                ...   \n",
       "4304  Data analytics, Data science, SQL, Python, Tab...         Consultant   \n",
       "4305  Data Science, Machine Learning, Python, R, Sta...     Data Scientist   \n",
       "4306  Mechanical Engineering, Data Centre Design, Pr...      Data Engineer   \n",
       "4307  Python, SQL, Tableau, Power BI, GCP, AWS, Azur...     Data Scientist   \n",
       "4308  Data Analysis, Statistical Analysis, Data Visu...  Data Analyst (BI)   \n",
       "\n",
       "                                    cleaned_job_summary  \\\n",
       "0     choose jefferson health plan awardwinning notf...   \n",
       "1     job responsibility deployment inscope configur...   \n",
       "2     success factor knowledge schedule monday frida...   \n",
       "3     company description nbc sport next sport techn...   \n",
       "4     national grid renewables leading north america...   \n",
       "...                                                 ...   \n",
       "4304  grow career successful bristol based agency am...   \n",
       "4305  apply job click senior data scientist remote c...   \n",
       "4306  job advert fantastic opportunity principal ass...   \n",
       "4307  robert half partner exclusively envelop risk l...   \n",
       "4308  summary data analyst responsible analyzing int...   \n",
       "\n",
       "                                     cleaned_job_skills  relevancy_score  \n",
       "0     knime qlikview sql ms access ms excel logical ...         0.232006  \n",
       "1     server storage backup networking virtualizatio...         0.375514  \n",
       "2     data management hr data retention controls cal...         0.208206  \n",
       "3     data engineering data warehousing sql mysql po...         0.653797  \n",
       "4     data analyst operational assessment wind energ...         0.209912  \n",
       "...                                                 ...              ...  \n",
       "4304  data analytics data science sql python tableau...         0.177982  \n",
       "4305  data science machine learning python r statist...         0.279391  \n",
       "4306  mechanical engineering data centre design proj...         0.142071  \n",
       "4307  python sql tableau power bi gcp aws azure data...         0.282636  \n",
       "4308  data analysis statistical analysis data visual...         0.513301  \n",
       "\n",
       "[4309 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Read the text summaries\n",
    "with open('zero-shot-summaries.txt', 'r') as file:\n",
    "    summaries = file.read().splitlines()  # Assuming each line in the file is a separate summary\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fill NaN values in 'data[\"cleaned_job_summary\"]' and concatenate with summaries from the file\n",
    "summaries_filled = data[\"cleaned_job_summary\"].fillna(\"\")  # Fill NaN values in the summaries\n",
    "\n",
    "# Assuming that the number of summaries matches the number of rows in the 'cleaned_job_summary' column\n",
    "# Concatenate the original job summaries and the external summaries\n",
    "combined_text = summaries_filled.tolist() + summaries  # Concatenate lists of summaries\n",
    "\n",
    "# Create the TF-IDF matrix for the combined text\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Calculate cosine similarity between the original job summaries and the external summaries\n",
    "cosine_scores = cosine_similarity(tfidf_matrix[:len(data)], tfidf_matrix[len(data):])\n",
    "\n",
    "# The cosine_scores matrix contains the similarity between each original job summary and each external summary\n",
    "# You might want to choose the highest similarity score for each job summary\n",
    "relevancy_scores = cosine_scores.max(axis=1)  # Take the maximum similarity score for each job summary\n",
    "\n",
    "# Add relevancy scores to the dataset\n",
    "data[\"relevancy_score\"] = relevancy_scores\n",
    "\n",
    "# Optionally, save the updated data with relevancy scores to a new CSV file\n",
    "#data.to_csv('updated_data.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['relevancy_score'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LongT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the LongT5 tokenizer and model\n",
    "model_name = \"google/long-t5-tglobal-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define a function for summarization using LongT5\n",
    "def summarize_with_long_t5(text, max_input_length=4096, max_output_length=512):\n",
    "    \"\"\"\n",
    "    Summarize the given text using LongT5.\n",
    "    :param text: The input text to summarize.\n",
    "    :param max_input_length: Maximum token length for input.\n",
    "    :param max_output_length: Maximum token length for output summary.\n",
    "    :return: The generated summary.\n",
    "    \"\"\"\n",
    "    # Truncate input to fit LongT5's maximum input length\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=max_output_length,\n",
    "        min_length=5,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Load test dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "texts = list(df_test['cleaned_job_summary'])\n",
    "\n",
    "# Generate summaries for all texts\n",
    "candidate_summaries = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing index: {i}\")\n",
    "    try:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            candidate_summaries.append('No text provided')\n",
    "            continue\n",
    "\n",
    "        # Summarize the text\n",
    "        candidate = summarize_with_long_t5(text)\n",
    "        candidate_summaries.append(candidate)\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text at index {i}: {e}\")\n",
    "        candidate_summaries.append('Error during summarization')\n",
    "\n",
    "# Display first 5 summaries\n",
    "print(candidate_summaries[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method does not work well as it requires HUGE computational resources. Also, it is not best suited for summarization task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Your min_length=56 must be inferior than your max_length=30.\n",
      "/Users/oliverzhou/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1399: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error summarizing text at index 76: index out of range in self\n",
      "100\n",
      "Error summarizing text at index 137: index out of range in self\n",
      "Error summarizing text at index 164: index out of range in self\n",
      "Error summarizing text at index 189: index out of range in self\n",
      "200\n",
      "Error summarizing text at index 276: index out of range in self\n",
      "Error summarizing text at index 292: index out of range in self\n",
      "300\n",
      "Error summarizing text at index 346: index out of range in self\n",
      "Error summarizing text at index 388: index out of range in self\n",
      "400\n",
      "Error summarizing text at index 416: index out of range in self\n",
      "Error summarizing text at index 422: index out of range in self\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' role data analyst location hartford ct raleigh nc duration fulltime job description least year experience working healthcare business data analyst .',\n",
       " ' hybrid role based role based palo alto san francisco chicago office require office t Tuesday th Thursday . Role based ideally san franc',\n",
       " ' aurora co icr opportunity available experienced motivated data scientist bayesian statistic background essential job responsibility data scientist expected work independently complex technical task require',\n",
       " ' flexible work arrangement hybrid month program participant experience technically challenging handson six month rotation three core function pjm system operation system planning market well',\n",
       " ' data analyst leatherhead uk salary data analyst want use skill make real impact education world enjoy seeing work bringing people data together best way person']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#summarizer = pipeline(\"summarization\")\n",
    "summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
    "summarizer.model.config.__getattribute__('_name_or_path')\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "ref_summaries = list(df_test['job_type'])\n",
    "texts = list(df_test['cleaned_job_summary'])\n",
    "summarizer(texts[0], max_length=30)\n",
    "\n",
    "candidate_summaries = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        # Generate summary using the summarizer\n",
    "        candidate = summarizer(text, min_length=5, max_length=30)\n",
    "        \n",
    "        # Ensure the summarizer returned a valid result\n",
    "        if candidate:\n",
    "            candidate_summaries.append(candidate[0].get('summary_text', 'No summary text found'))\n",
    "        else:\n",
    "            candidate_summaries.append('No summary generated')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exceptions during the summarization process\n",
    "        print(f\"Error summarizing text at index {i}: {e}\")\n",
    "        candidate_summaries.append('Error during summarization')\n",
    "\n",
    "file = open(\"zero-shot-summaries.txt\", \"w\")\n",
    "for s in candidate_summaries:\n",
    "    file.write(s + \"\\n\")\n",
    "file.close()\n",
    "candidate_summaries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(14.3),\n",
       " 'rouge2': np.float64(13.2),\n",
       " 'rougeL': np.float64(13.9),\n",
       " 'rougeLsum': np.float64(13.9)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the ROUGE metric\n",
    "metric = load(\"rouge\")\n",
    "\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores for candidate summaries against reference summaries.\n",
    "\n",
    "    Args:\n",
    "    - candidates (list of str): List of generated summaries.\n",
    "    - references (list of str): List of reference summaries.\n",
    "\n",
    "    Returns:\n",
    "    - dict: ROUGE scores rounded to 1 decimal place.\n",
    "    \"\"\"\n",
    "    if not candidates or not references:\n",
    "        raise ValueError(\"Candidates and references must not be empty.\")\n",
    "    if len(candidates) != len(references):\n",
    "        raise ValueError(\"Candidates and references must have the same length.\")\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    \n",
    "    # Handle the case where the result is a dictionary of scalar values\n",
    "    if isinstance(result, dict):\n",
    "        result = {key: round(value * 100, 1) for key, value in result.items()}\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected result format: {result}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Ensure candidate_summaries and texts are defined properly\n",
    "calc_rouge_scores(candidate_summaries, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is similar to the baseline model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sshleifer/distilbart-cnn-12-6\n",
      "Sample summary: [{'summary_text': ' role data analyst location hartford ct raleigh nc duration fulltime job description least year experience working healthcare business data analyst .'}]\n",
      "Processing row 0/431...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error summarizing text at index 76: index out of range in self\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 34. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 100/431...\n",
      "Error summarizing text at index 137: index out of range in self\n",
      "Error summarizing text at index 164: index out of range in self\n",
      "Error summarizing text at index 189: index out of range in self\n",
      "Processing row 200/431...\n",
      "Error summarizing text at index 276: index out of range in self\n",
      "Error summarizing text at index 292: index out of range in self\n",
      "Processing row 300/431...\n",
      "Error summarizing text at index 346: index out of range in self\n",
      "Error summarizing text at index 388: index out of range in self\n",
      "Processing row 400/431...\n",
      "Error summarizing text at index 416: index out of range in self\n",
      "Error summarizing text at index 422: index out of range in self\n",
      "[' role data analyst location hartford ct raleigh nc duration fulltime job description least year experience working healthcare business data analyst .', ' hybrid role based role based palo alto san francisco chicago office require office t Tuesday th Thursday . Work team remote work team across united state help hire work company funded best investor including sequoia capital lightspeed venture tiger global management az accel .', ' aurora co icr opportunity available experienced motivated data scientist bayesian statistic background essential job responsibility data scientist expected to work independently complex technical task require indepth data analysis methodology datainformation collection .', ' flexible work arrangement hybrid month program participant experience technically challenging handson six month rotation three core function pjm system operation system planning market well shorter rotation many support function including compliance information technology member service risk security program designed .', ' data analyst leatherhead uk salary data analyst want use skill make real impact education world enjoy seeing work bringing people data together best way person want move forward greenfield space could role client really making life teacher child better .']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the summarizer\n",
    "summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
    "print(summarizer.model.config.__getattribute__('_name_or_path'))\n",
    "\n",
    "# Load the dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "ref_summaries = list(df_test['job_type'])\n",
    "texts = list(df_test['cleaned_job_summary'])\n",
    "\n",
    "# Test summarization on a single input\n",
    "print(\"Sample summary:\", summarizer(texts[0], min_length=20, max_length=60, num_beams=4, length_penalty=1.2))\n",
    "\n",
    "# Generate summaries for all texts\n",
    "candidate_summaries = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing row {i}/{len(texts)}...\")\n",
    "    try:\n",
    "        # Generate summary using the summarizer\n",
    "        candidate = summarizer(text, min_length=20, max_length=60, num_beams=4, length_penalty=1.2, early_stopping=True)\n",
    "        \n",
    "        # Ensure the summarizer returned a valid result\n",
    "        if candidate:\n",
    "            candidate_summaries.append(candidate[0].get('summary_text', 'No summary text found'))\n",
    "        else:\n",
    "            candidate_summaries.append('No summary generated')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exceptions during the summarization process\n",
    "        print(f\"Error summarizing text at index {i}: {e}\")\n",
    "        candidate_summaries.append('Error during summarization')\n",
    "\n",
    "# Save summaries to a file\n",
    "with open(\"zero-shot-summaries.txt\", \"w\") as file:\n",
    "    for summary in candidate_summaries:\n",
    "        file.write(summary + \"\\n\")\n",
    "\n",
    "# Display the first few summaries\n",
    "print(candidate_summaries[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(21.7),\n",
       " 'rouge2': np.float64(20.5),\n",
       " 'rougeL': np.float64(21.1),\n",
       " 'rougeLsum': np.float64(21.1)}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_rouge_scores(candidate_summaries, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: num_beams=2, min_length=10, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.7)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.7)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.7)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.7), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.7), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=10, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.6), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.7)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.7)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.7)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.7), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.7), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=20, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.6), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.5), 'rouge2': np.float64(3.5), 'rougeL': np.float64(8.4), 'rougeLsum': np.float64(8.4)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.2), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.2), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.7), 'rouge2': np.float64(3.2), 'rougeL': np.float64(7.5), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.6), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.5), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.6), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.5), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=2, min_length=25, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.6), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.5), 'rougeLsum': np.float64(6.5)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.9), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.7), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.9), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.7), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.9), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.7), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=4, min_length=10, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.0), 'rouge2': np.float64(2.4), 'rougeL': np.float64(5.9), 'rougeLsum': np.float64(5.9)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.9), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.7), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.9), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.7), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.9), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.7), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=4, min_length=20, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.0), 'rouge2': np.float64(2.4), 'rougeL': np.float64(5.9), 'rougeLsum': np.float64(5.9)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(7.8), 'rouge2': np.float64(3.1), 'rougeL': np.float64(7.6), 'rougeLsum': np.float64(7.6)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.7)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(5.9), 'rouge2': np.float64(2.4), 'rougeL': np.float64(5.8), 'rougeLsum': np.float64(5.8)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(5.9), 'rouge2': np.float64(2.4), 'rougeL': np.float64(5.8), 'rougeLsum': np.float64(5.8)}\n",
      "Testing params: num_beams=4, min_length=25, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(5.9), 'rouge2': np.float64(2.4), 'rougeL': np.float64(5.8), 'rougeLsum': np.float64(5.8)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.9)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.8)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.8)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.3), 'rouge2': np.float64(2.6), 'rougeL': np.float64(6.2), 'rougeLsum': np.float64(6.2)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.2), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.1)}\n",
      "Testing params: num_beams=6, min_length=10, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.2), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.9)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.8)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.8)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.2), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.1)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.2), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.1)}\n",
      "Testing params: num_beams=6, min_length=20, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.2), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=30, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.9)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=30, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.8)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=30, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(8.1), 'rouge2': np.float64(3.3), 'rougeL': np.float64(7.8), 'rougeLsum': np.float64(7.8)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=35, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=35, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=35, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.8), 'rouge2': np.float64(2.8), 'rougeL': np.float64(6.6), 'rougeLsum': np.float64(6.6)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=45, length_penalty=0.8\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=45, length_penalty=1.0\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n",
      "Testing params: num_beams=6, min_length=25, max_length=45, length_penalty=1.2\n",
      "Processing row 0/431...\n",
      "Processing row 10/431...\n",
      "Processing row 20/431...\n",
      "Processing row 30/431...\n",
      "Processing row 40/431...\n",
      "Processing row 50/431...\n",
      "Processing row 60/431...\n",
      "Processing row 70/431...\n",
      "Error summarizing text at index 76: index out of range in self\n",
      "ROUGE scores: {'rouge1': np.float64(6.1), 'rouge2': np.float64(2.5), 'rougeL': np.float64(6.0), 'rougeLsum': np.float64(6.0)}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from evaluate import load\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# Load the dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "texts = df_test['cleaned_job_summary'].fillna(\"\").tolist()\n",
    "ref_summaries = df_test['job_type'].fillna(\"\").tolist()\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
    "\n",
    "# Define parameter grid\n",
    "num_beams_values = [2, 4, 6]\n",
    "min_length_values = [10, 20, 25]\n",
    "max_length_values = [30, 35, 45]\n",
    "length_penalty_values = [0.8, 1.0, 1.2]\n",
    "\n",
    "# Create all combinations of parameters\n",
    "parameter_grid = list(product(num_beams_values, min_length_values, max_length_values, length_penalty_values))\n",
    "\n",
    "# Load ROUGE metric\n",
    "metric = load(\"rouge\")\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    return {key: round(value * 100, 1) for key, value in result.items()}\n",
    "\n",
    "# Function to summarize and calculate ROUGE scores\n",
    "def test_parameters(params):\n",
    "    num_beams, min_length, max_length, length_penalty = params\n",
    "    print(f\"Testing params: num_beams={num_beams}, min_length={min_length}, max_length={max_length}, length_penalty={length_penalty}\")\n",
    "    candidate_summaries = []\n",
    "    \n",
    "    for i, text in enumerate(texts[:80]):  # Test on a smaller subset for faster evaluation\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing row {i}/{len(texts)}...\")\n",
    "        try:\n",
    "            summary = summarizer(\n",
    "                text, \n",
    "                min_length=min_length, \n",
    "                max_length=max_length, \n",
    "                num_beams=num_beams, \n",
    "                length_penalty=length_penalty\n",
    "            )\n",
    "            candidate_summaries.append(summary[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing text at index {i}: {e}\")\n",
    "            candidate_summaries.append(\"Error during summarization\")\n",
    "\n",
    "    rouge_scores = calc_rouge_scores(candidate_summaries, ref_summaries[:80])  # Evaluate against references\n",
    "    print(f\"ROUGE scores: {rouge_scores}\")\n",
    "    return params, rouge_scores\n",
    "\n",
    "# Run the grid search\n",
    "results = []\n",
    "for params in parameter_grid:\n",
    "    results.append(test_parameters(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>ROUGE Scores</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>ROUGE-Lsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2, 10, 30, 0.8)</td>\n",
       "      <td>{'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 20, 30, 0.8)</td>\n",
       "      <td>{'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, 10, 30, 1.0)</td>\n",
       "      <td>{'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(2, 25, 30, 1.2)</td>\n",
       "      <td>{'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(2, 25, 30, 0.8)</td>\n",
       "      <td>{'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Parameters                                       ROUGE Scores  \\\n",
       "0   (2, 10, 30, 0.8)  {'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...   \n",
       "9   (2, 20, 30, 0.8)  {'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...   \n",
       "1   (2, 10, 30, 1.0)  {'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...   \n",
       "20  (2, 25, 30, 1.2)  {'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...   \n",
       "18  (2, 25, 30, 0.8)  {'rouge1': 8.5, 'rouge2': 3.5, 'rougeL': 8.4, ...   \n",
       "\n",
       "    ROUGE-1  ROUGE-2  ROUGE-L  ROUGE-Lsum  \n",
       "0       8.5      3.5      8.4         8.4  \n",
       "9       8.5      3.5      8.4         8.4  \n",
       "1       8.5      3.5      8.4         8.4  \n",
       "20      8.5      3.5      8.4         8.4  \n",
       "18      8.5      3.5      8.4         8.4  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Parameters\", \"ROUGE Scores\"])\n",
    "\n",
    "# Extract ROUGE scores into separate columns for sorting\n",
    "results_df['ROUGE-1'] = results_df['ROUGE Scores'].apply(lambda x: x['rouge1'])\n",
    "results_df['ROUGE-2'] = results_df['ROUGE Scores'].apply(lambda x: x['rouge2'])\n",
    "results_df['ROUGE-L'] = results_df['ROUGE Scores'].apply(lambda x: x['rougeL'])\n",
    "results_df['ROUGE-Lsum'] = results_df['ROUGE Scores'].apply(lambda x: x['rougeLsum'])\n",
    "\n",
    "# Sort by ROUGE-1 (or any other metric) and display the top results\n",
    "sorted_results = results_df.sort_values(by=\"ROUGE-1\", ascending=False)\n",
    "sorted_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4,20,35,1.0 have the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sshleifer/distilbart-cnn-12-6\n",
      "Processing row 0/431...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error summarizing text at index 76: index out of range in self\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 35, but your input_length is only 34. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 100/431...\n",
      "Error summarizing text at index 137: index out of range in self\n",
      "Error summarizing text at index 164: index out of range in self\n",
      "Error summarizing text at index 189: index out of range in self\n",
      "Processing row 200/431...\n",
      "Error summarizing text at index 276: index out of range in self\n",
      "Error summarizing text at index 292: index out of range in self\n",
      "Processing row 300/431...\n",
      "Error summarizing text at index 346: index out of range in self\n",
      "Error summarizing text at index 388: index out of range in self\n",
      "Processing row 400/431...\n",
      "Error summarizing text at index 416: index out of range in self\n",
      "Error summarizing text at index 422: index out of range in self\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(16.4),\n",
       " 'rouge2': np.float64(15.2),\n",
       " 'rougeL': np.float64(16.0),\n",
       " 'rougeLsum': np.float64(16.0)}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the summarizer\n",
    "summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
    "print(summarizer.model.config.__getattribute__('_name_or_path'))\n",
    "\n",
    "# Load the dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "ref_summaries = list(df_test['job_type'])\n",
    "texts = list(df_test['cleaned_job_summary'])\n",
    "\n",
    "# Generate summaries for all texts\n",
    "candidate_summaries = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing row {i}/{len(texts)}...\")\n",
    "    try:\n",
    "        # Generate summary using the summarizer\n",
    "        candidate = summarizer(text, min_length=20, max_length=35, num_beams=4, length_penalty=1.0, early_stopping=True)\n",
    "        \n",
    "        # Ensure the summarizer returned a valid result\n",
    "        if candidate:\n",
    "            candidate_summaries.append(candidate[0].get('summary_text', 'No summary text found'))\n",
    "        else:\n",
    "            candidate_summaries.append('No summary generated')\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exceptions during the summarization process\n",
    "        print(f\"Error summarizing text at index {i}: {e}\")\n",
    "        candidate_summaries.append('Error during summarization')\n",
    "\n",
    "calc_rouge_scores(candidate_summaries, texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.13580097097274588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_similarity(candidates, references):\n",
    "    \"\"\"\n",
    "    Calculate average cosine similarity between candidate and reference summaries.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    similarities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        vectors = vectorizer.fit_transform([candidate, reference])\n",
    "        similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    return sum(similarities) / len(similarities)  # Return the average similarity\n",
    "\n",
    "cosine_sim = calculate_cosine_similarity(candidate_summaries, ref_summaries[:len(candidate_summaries)])\n",
    "print(f\"Average Cosine Similarity: {cosine_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type</th>\n",
       "      <th>cleaned_job_summary</th>\n",
       "      <th>cleaned_job_skills</th>\n",
       "      <th>relevancy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Data Analyst</td>\n",
       "      <td>Why Choose Jefferson Health Plans?\\nWe are an ...</td>\n",
       "      <td>KNIME, QlikView, SQL, MS Access, MS Excel, Log...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>choose jefferson health plan awardwinning notf...</td>\n",
       "      <td>knime qlikview sql ms access ms excel logical ...</td>\n",
       "      <td>0.211659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Center Engineer - Minneapolis</td>\n",
       "      <td>Job Responsibilities:\\nDeployment / In-Scope C...</td>\n",
       "      <td>Server, Storage, Backup, Networking, Virtualiz...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>job responsibility deployment inscope configur...</td>\n",
       "      <td>server storage backup networking virtualizatio...</td>\n",
       "      <td>0.568367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Success Factor knowledge\\nSchedule : Monday th...</td>\n",
       "      <td>Data Management, HR Data Retention Controls, C...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>success factor knowledge schedule monday frida...</td>\n",
       "      <td>data management hr data retention controls cal...</td>\n",
       "      <td>0.157747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer II - NBC Sports Next</td>\n",
       "      <td>Company Description\\nNBC Sports Next is where ...</td>\n",
       "      <td>Data Engineering, Data Warehousing, SQL, MySQL...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>company description nbc sport next sport techn...</td>\n",
       "      <td>data engineering data warehousing sql mysql po...</td>\n",
       "      <td>0.647218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Operational Assessment</td>\n",
       "      <td>National Grid Renewables is a leading North Am...</td>\n",
       "      <td>Data Analyst, Operational Assessment, Wind Ene...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>national grid renewables leading north america...</td>\n",
       "      <td>data analyst operational assessment wind energ...</td>\n",
       "      <td>0.108068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>Data Science &amp; Analytics Consultant</td>\n",
       "      <td>Grow your career at a successful, Bristol base...</td>\n",
       "      <td>Data analytics, Data science, SQL, Python, Tab...</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>grow career successful bristol based agency am...</td>\n",
       "      <td>data analytics data science sql python tableau...</td>\n",
       "      <td>0.164750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>To Apply for this Job Click Here\\nSENIOR DATA ...</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Sta...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>apply job click senior data scientist remote c...</td>\n",
       "      <td>data science machine learning python r statist...</td>\n",
       "      <td>0.277834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>Associate/Principal Mechanical Engineer - Data...</td>\n",
       "      <td>Job Advert\\nWe have a fantastic opportunity fo...</td>\n",
       "      <td>Mechanical Engineering, Data Centre Design, Pr...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>job advert fantastic opportunity principal ass...</td>\n",
       "      <td>mechanical engineering data centre design proj...</td>\n",
       "      <td>0.170155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Robert Half partners exclusively with Envelop ...</td>\n",
       "      <td>Python, SQL, Tableau, Power BI, GCP, AWS, Azur...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>robert half partner exclusively envelop risk l...</td>\n",
       "      <td>python sql tableau power bi gcp aws azure data...</td>\n",
       "      <td>0.293336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>Customer Service Representative/Data Analyst/D...</td>\n",
       "      <td>Summary:\\nThe Data Analyst will be responsible...</td>\n",
       "      <td>Data Analysis, Statistical Analysis, Data Visu...</td>\n",
       "      <td>Data Analyst (BI)</td>\n",
       "      <td>summary data analyst responsible analyzing int...</td>\n",
       "      <td>data analysis statistical analysis data visual...</td>\n",
       "      <td>0.553164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4309 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_title  \\\n",
       "0                                Technical Data Analyst   \n",
       "1                    Data Center Engineer - Minneapolis   \n",
       "2                                          Data Analyst   \n",
       "3                    Data Engineer II - NBC Sports Next   \n",
       "4                 Data Analyst - Operational Assessment   \n",
       "...                                                 ...   \n",
       "4304                Data Science & Analytics Consultant   \n",
       "4305                              Senior Data Scientist   \n",
       "4306  Associate/Principal Mechanical Engineer - Data...   \n",
       "4307                              Senior Data Scientist   \n",
       "4308  Customer Service Representative/Data Analyst/D...   \n",
       "\n",
       "                                            job_summary  \\\n",
       "0     Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
       "1     Job Responsibilities:\\nDeployment / In-Scope C...   \n",
       "2     Success Factor knowledge\\nSchedule : Monday th...   \n",
       "3     Company Description\\nNBC Sports Next is where ...   \n",
       "4     National Grid Renewables is a leading North Am...   \n",
       "...                                                 ...   \n",
       "4304  Grow your career at a successful, Bristol base...   \n",
       "4305  To Apply for this Job Click Here\\nSENIOR DATA ...   \n",
       "4306  Job Advert\\nWe have a fantastic opportunity fo...   \n",
       "4307  Robert Half partners exclusively with Envelop ...   \n",
       "4308  Summary:\\nThe Data Analyst will be responsible...   \n",
       "\n",
       "                                             job_skills           job_type  \\\n",
       "0     KNIME, QlikView, SQL, MS Access, MS Excel, Log...  Data Analyst (BI)   \n",
       "1     Server, Storage, Backup, Networking, Virtualiz...      Data Engineer   \n",
       "2     Data Management, HR Data Retention Controls, C...  Data Analyst (BI)   \n",
       "3     Data Engineering, Data Warehousing, SQL, MySQL...      Data Engineer   \n",
       "4     Data Analyst, Operational Assessment, Wind Ene...  Data Analyst (BI)   \n",
       "...                                                 ...                ...   \n",
       "4304  Data analytics, Data science, SQL, Python, Tab...         Consultant   \n",
       "4305  Data Science, Machine Learning, Python, R, Sta...     Data Scientist   \n",
       "4306  Mechanical Engineering, Data Centre Design, Pr...      Data Engineer   \n",
       "4307  Python, SQL, Tableau, Power BI, GCP, AWS, Azur...     Data Scientist   \n",
       "4308  Data Analysis, Statistical Analysis, Data Visu...  Data Analyst (BI)   \n",
       "\n",
       "                                    cleaned_job_summary  \\\n",
       "0     choose jefferson health plan awardwinning notf...   \n",
       "1     job responsibility deployment inscope configur...   \n",
       "2     success factor knowledge schedule monday frida...   \n",
       "3     company description nbc sport next sport techn...   \n",
       "4     national grid renewables leading north america...   \n",
       "...                                                 ...   \n",
       "4304  grow career successful bristol based agency am...   \n",
       "4305  apply job click senior data scientist remote c...   \n",
       "4306  job advert fantastic opportunity principal ass...   \n",
       "4307  robert half partner exclusively envelop risk l...   \n",
       "4308  summary data analyst responsible analyzing int...   \n",
       "\n",
       "                                     cleaned_job_skills  relevancy_score  \n",
       "0     knime qlikview sql ms access ms excel logical ...         0.211659  \n",
       "1     server storage backup networking virtualizatio...         0.568367  \n",
       "2     data management hr data retention controls cal...         0.157747  \n",
       "3     data engineering data warehousing sql mysql po...         0.647218  \n",
       "4     data analyst operational assessment wind energ...         0.108068  \n",
       "...                                                 ...              ...  \n",
       "4304  data analytics data science sql python tableau...         0.164750  \n",
       "4305  data science machine learning python r statist...         0.277834  \n",
       "4306  mechanical engineering data centre design proj...         0.170155  \n",
       "4307  python sql tableau power bi gcp aws azure data...         0.293336  \n",
       "4308  data analysis statistical analysis data visual...         0.553164  \n",
       "\n",
       "[4309 rows x 7 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Read the text summaries\n",
    "with open('zero-shot-summaries.txt', 'r') as file:\n",
    "    summaries = file.read().splitlines()  # Assuming each line in the file is a separate summary\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fill NaN values in 'data[\"cleaned_job_summary\"]' and concatenate with summaries from the file\n",
    "summaries_filled = data[\"cleaned_job_summary\"].fillna(\"\")  # Fill NaN values in the summaries\n",
    "\n",
    "# Assuming that the number of summaries matches the number of rows in the 'cleaned_job_summary' column\n",
    "# Concatenate the original job summaries and the external summaries\n",
    "combined_text = summaries_filled.tolist() + summaries  # Concatenate lists of summaries\n",
    "\n",
    "# Create the TF-IDF matrix for the combined text\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Calculate cosine similarity between the original job summaries and the external summaries\n",
    "cosine_scores = cosine_similarity(tfidf_matrix[:len(data)], tfidf_matrix[len(data):])\n",
    "\n",
    "# The cosine_scores matrix contains the similarity between each original job summary and each external summary\n",
    "# You might want to choose the highest similarity score for each job summary\n",
    "relevancy_scores = cosine_scores.max(axis=1)  # Take the maximum similarity score for each job summary\n",
    "\n",
    "# Add relevancy scores to the dataset\n",
    "data[\"relevancy_score\"] = relevancy_scores\n",
    "\n",
    "# Optionally, save the updated data with relevancy scores to a new CSV file\n",
    "#data.to_csv('updated_data.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGgCAYAAABfSOayAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAy10lEQVR4nO3de1jUdd7/8dcIDAx5aHEFLNdg3RCpFFQQ7iv9udR6dW3uwdy6dgvbTFw7Uh6rlV017bBJaZamrscK12pRt9OWa7v3fW9tmrhtdgVsWeB6AkpNRYYZDt/fH17M7QQqAwPMZ+b5uK4u5HP4+sZ3M7z4fr8z2CzLsgQAAGCoHt1dAAAAQEcQZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjBbe3QV0tpEjR8rtdqtfv37dXQoAAGijL7/8Una7XcXFxRdcG/RnZlwulxoaGtq937IsuVwu8d6CgYseBT56FPjoUeALtR41NDTI5XK1aW3Qn5mJjY2VJL3zzjvt2l9bW6vS0lINGTJE0dHR/iwNfkKPAh89Cnz0KPCFWo+uueaaNq8N+jMzAAAguBFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzISgpiaru0vwmYk1AwC6Rnh3F4Cu16OHTQWFe3Sw6lR3l9ImA+J6adYtI7q7DABAgCLMhKiDVaf0+aET3V0GAAAdxmUmAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABitQ2Fm1apVmjRpktdYdXW1ZsyYoZEjR2rUqFGaOXOmjh075rWmsLBQ11xzjYYOHaqbb75ZJSUlXvMHDx7UtGnTNHz4cF199dVaunSpGhsbO1IqAAAIUu0OM4WFhVq6dKnXmNvt1u23367Dhw/r+eef1+rVq1VWVqYHHnjAs2br1q164okndN9992nLli0aMGCAJk+e7Ak89fX1mjJliiRp8+bNmj9/vv7whz9o+fLl7S0VAAAEMZ/DTFVVle644w4VFBQoISHBa+7111/XoUOH9OyzzyolJUXDhg3Tgw8+qPLyctXU1EiSVq5cqZycHP34xz/W9773PT366KNyOBx65ZVXJElvv/22Dh8+rCeeeEJJSUm69tprNWPGDG3cuFFut7vjXzEAAAgq4b5u+OSTTxQREaFXX31Vy5cv16FDhzxz7777rjIzM/Xtb3/bMzZ69Gjt2LFDknT06FFVVFQoKyvr/woID9fIkSO1e/duTZs2TcXFxbriiivUp08fz5rMzEzV1NSotLRUw4YN8/mLtCxLtbW1Pu+TJKfT6fXRdDabTQ6Ho7vLaBen0ynLslodP/sjAg89Cnz0KPCFWo8sy5LNZmvTWp/DTHZ2trKzs1udKy8v18iRI7V8+XJt27ZNDQ0NuvrqqzV79mz17t1blZWVkqT+/ft77YuNjVVZWZkkqbKyUvHx8S3mJenIkSPtCjNut1ulpaU+7ztbRUVFh/YHCofDoZSUlO4uo13Ky8vP+yAOlh4FM3oU+OhR4AuVHrndbkVGRrZprc9h5nxqamq0bds2ZWVl6cknn9SJEyf02GOP6a677tILL7zg+UZkt9u99kVGRsrlckmS6urq1Lt37xbzkjxrfGW32zVkyJB27XU6naqoqFBCQoKxZzTO1taUG4gSExPPeWYmmHoUjOhR4KNHgS/UevTNrHA+fg0z4eHhio6O1pNPPqmIiAhJUp8+fXTjjTfq448/VlRUlCS1uPfF5XJ5GhMVFdXqvCRFR0e3qy6bzdbuvc0cDkeHj4GOudCDlx4FPnoU+OhR4AuVHvnyw7df32cmPj5eiYmJniAjSZdffrmkMy+3br68VF1d7bWvurpacXFxnmO0Ni/JswYAAKCZX8NMenq6ysrKVFdX5xn79NNPJUmXXXaZ+vbtq8TERO3atcsz39DQoOLiYqWnp3uOUVJS4nn1kyTt3LlTF110kZKTk/1ZLgAACAJ+DTM///nPFRYWppkzZ+qzzz7Tnj17lJ+fr1GjRumKK66QJN1+++1av369tm7dqn379unXv/616urq9LOf/UySdO2116pfv366//77VVZWph07duipp57S7bff7tP1MwAAEBr8es9MTEyMCgsL9dhjj+nGG2+U3W7XtddeqwcffNCz5qabbtKpU6e0dOlSff3117ryyiu1fv16xcTESDpzs++aNWu0YMEC3XTTTerTp49uvvlm3XXXXf4sFQAABIkOhZnHH3+8xVhCQoJWrVp13n1TpkzxvMtvay677DKtW7euI6UBAIAQwS+aBAAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgtA6FmVWrVmnSpEnnnM/Pz1d2drbXWFNTk5YtW6bRo0crNTVVU6dO1YEDB7zWlJaWKicnR6mpqcrOztbzzz/fkTIBAEAQa3eYKSws1NKlS885v2PHDr3yyistxlesWKFNmzZp4cKF2rx5s5qampSbmyu32y1JOn78uCZPnqyBAweqqKhId999twoKClRUVNTeUgEAQBDzOcxUVVXpjjvuUEFBgRISElpdU11drd/85jfKyMjwGne73Vq3bp3y8vI0duxYJScna8mSJaqsrNT27dslSS+//LIiIiL08MMPa9CgQZo4caJuu+02rV692vevDgAABD2fw8wnn3yiiIgIvfrqqxo2bFiLecuy9OCDD+onP/lJizBTVlam06dPKysryzPWu3dvpaSkaPfu3ZKk4uJiZWRkKDw83LMmMzNTFRUV+uqrr3wtFwAABLnwCy/xlp2d3eI+mLNt2LBBX375pVauXKlVq1Z5zVVWVkqS+vfv7zUeGxvrmausrFRSUlKLeUk6cuSIvv3tb/tasizLUm1trc/7JMnpdHp9NJ3NZpPD4ejuMtrF6XTKsqxWx8/+iMBDjwIfPQp8odYjy7Jks9natNbnMHM+ZWVlevbZZ1VYWCi73d5ivrkB35yLjIzUiRMnJEl1dXWtzkuSy+VqV11ut1ulpaXt2tusoqKiQ/sDhcPhUEpKSneX0S7l5eXnfRAHS4+CGT0KfPQo8IVKj9xut+f7/4X4Lcy4XC7NmjVLd955p5KTk1tdExUV5Smw+c/Ne5vPFkRFRXluBj57XpKio6PbVZvdbteQIUPatdfpdKqiokIJCQnGntE4W1tTbiBKTEw855mZYOpRMKJHgY8eBb5Q61FrJ0XOxW9h5qOPPtJnn32mZ599VsuXL5ck1dfXq6GhQWlpafr973/vubxUXV2tgQMHevZWV1dr8ODBkqT4+HhVV1d7Hbv587i4uHbVZrPZ2h2Emjkcjg4fAx1zoQcvPQp89Cjw0aPAFyo98uWHb7+FmaFDh3pekdTshRde0Pbt2/XCCy8oLi5OPXr0UM+ePbVr1y5PmDl58qRKSkqUk5MjSUpPT9fmzZvV2NiosLAwSdLOnTuVmJiovn37+qtcAAAQJPwWZqKionTZZZd5jfXp00fh4eFe4zk5OSooKFBMTIwuvfRSLV68WPHx8Ro3bpwkaeLEiVqzZo3mzp2r3Nxc7d27Vxs2bNCCBQv8VSoAAAgifr0BuC3y8vLU0NCg/Px81dXVKT09XWvXrlVERIQkqW/fvlqzZo0eeeQRTZgwQf369dOcOXM0YcKEri4VAAAYoENh5vHHHz/v/L333qt7773XaywsLEyzZ8/W7Nmzz7lv6NCheumllzpSGgAACBH8okkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKN1KMysWrVKkyZN8hr761//qokTJyotLU3Z2dn63e9+p7q6Os+8y+XSggULlJWVpbS0NM2cOVPHjh3zOsb777+vG264QcOGDdN1112nN954oyNlAgCAINbuMFNYWKilS5d6jRUXF+uee+7RD37wA23dulXz5s3Tm2++qQULFnjWzJ8/X++++66eeeYZbdy4UV988YXy8vI8859//rmmTZum0aNHa8uWLbrxxhs1Z84cvf/+++0tFQAABLFwXzdUVVVp3rx52rVrlxISErzmNm/erFGjRumOO+6QJCUkJGj69OnKz8/XggULdPz4cW3btk0rV67UyJEjJUlPPfWUrrvuOn344YdKS0vTxo0bNXjwYE2fPl2SNGjQIJWUlGjNmjXKysrq4JcLAACCjc9nZj755BNFRETo1Vdf1bBhw7zmbr/9dj3wwAPef0GPHqqvr1dNTY327NkjScrMzPTMJyYmKi4uTrt375Z05uzON0NLZmam9uzZI8uyfC0XAAAEOZ/PzGRnZys7O7vVuZSUFK/P6+vrtWHDBl155ZWKiYlRVVWVvvWtbykyMtJrXWxsrCorKyVJlZWVio+PbzHvdDp1/PhxxcTE+FqyLMtSbW2tz/skyel0en00nc1mk8Ph6O4y2sXpdLYaaIOtR8GIHgU+ehT4Qq1HlmXJZrO1aa3PYaatGhoaNGfOHH322WcqLCyUdKYBdru9xdrIyEi5XC5JUl1dXYs1zZ+73e521eJ2u1VaWtquvc0qKio6tD9QOByOFqHTFOXl5ed9EAdLj4IZPQp89CjwhUqP3G53i5Mf59IpYaampkb333+/PvjgAz377LMaOnSoJCkqKqrVQOJyuTxnCyIjI1usaf68vWcU7Ha7hgwZ0q69TqdTFRUVSkhIMPaMxtnamnIDUWJi4jnPzARTj4IRPQp89CjwhVqPWjv5cS5+DzPV1dWaOnWqDh06pLVr1yo9Pd0zFx8fr6+//lput9uryOrqasXFxUmS+vfvr+rq6hbHjI6OVq9evdpVk81mU3R0dLv2NnM4HB0+BjrmQg9eehT46FHgo0eBL1R65MsP335907wTJ07ol7/8pY4dO6bCwkKvICNJI0aMUFNTk+dGYOnMpYOqqirP2pEjR+qDDz7w2rdz504NHz5cPXrwHn8AAMCbX9PBY489pgMHDmjx4sWKiYnRl19+6fmvsbFRcXFxuv7665Wfn69du3Zp7969mjFjhjIyMpSamipJmjRpkvbu3auCggJ9/vnnWrdund566y3l5ub6s1QAABAk/HaZqbGxUW+++abq6+v1y1/+ssX8O++8owEDBmjhwoV69NFHdc8990iSxowZo/z8fM+6yy+/XCtWrNDixYu1ceNGDRgwQIsXL+Y9ZgAAQKs6FGYef/xxz5/DwsK0d+/eC+6Jjo7WokWLtGjRonOuGTNmjMaMGdOR0gAAQIjgJhQAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKN1KMysWrVKkyZN8horLS1VTk6OUlNTlZ2dreeff95rvqmpScuWLdPo0aOVmpqqqVOn6sCBAz4dAwAAoFm7w0xhYaGWLl3qNXb8+HFNnjxZAwcOVFFRke6++24VFBSoqKjIs2bFihXatGmTFi5cqM2bN6upqUm5ublyu91tPgYAAECzcF83VFVVad68edq1a5cSEhK85l5++WVFRETo4YcfVnh4uAYNGqT9+/dr9erVmjhxotxut9atW6dZs2Zp7NixkqQlS5Zo9OjR2r59u8aPH3/BYwAAAJzN5zDzySefKCIiQq+++qqWL1+uQ4cOeeaKi4uVkZGh8PD/O2xmZqZWrVqlr776SocPH9bp06eVlZXlme/du7dSUlK0e/dujR8//oLH+Pa3v+3zF2lZlmpra33eJ0lOp9Pro+lsNpscDkd3l9EuTqdTlmW1On72RwQeehT46FHgC7UeWZYlm83WprU+h5ns7GxlZ2e3OldZWamkpCSvsdjYWEnSkSNHVFlZKUnq379/izXNcxc6RnvCjNvtVmlpqc/7zlZRUdGh/YHC4XAoJSWlu8tol/Ly8vM+iIOlR8GMHgU+ehT4QqVHbrdbkZGRbVrrc5g5n7q6Otntdq+x5kJcLpfnG1Fra06cONGmY7SH3W7XkCFD2rXX6XSqoqJCCQkJxp7ROFtbU24gSkxMPOeZmWDqUTCiR4GPHgW+UOvRN7PA+fg1zERFRXlu5G3WHECio6MVFRUl6Uzaav5z85rmxlzoGO1hs9navbeZw+Ho8DHQMRd68NKjwEePAh89Cnyh0iNffvj26/vMxMfHq7q62mus+fO4uDjP5aXW1sTFxbXpGAAAAGfza5hJT0/Xnj171NjY6BnbuXOnEhMT1bdvXyUnJ6tnz57atWuXZ/7kyZMqKSlRenp6m44BAABwNr+GmYkTJ6qmpkZz587Vvn37tGXLFm3YsEHTpk2TdOb6V05OjgoKCvTOO++orKxM06dPV3x8vMaNG9emYwAAAJzNr/fM9O3bV2vWrNEjjzyiCRMmqF+/fpozZ44mTJjgWZOXl6eGhgbl5+errq5O6enpWrt2rSIiItp8DAAAgGYdCjOPP/54i7GhQ4fqpZdeOueesLAwzZ49W7Nnzz7nmgsdAwAAoBm/aBIAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGRjPZrPJ4XAY/Us0AQDt59c3zQM6w8W9ItXUZKlHj9bDisPhUEpKShdXdWHnqxkA4D+EGQS8no4I9ehhU0HhHh2sOtXd5bTJgLhemnXLiO4uAwBCAmEGxjhYdUqfHzrR3WUAAAIM98wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaH4PMw0NDXr66af1/e9/X2lpabrlllv0r3/9yzNfWlqqnJwcpaamKjs7W88//7zX/qamJi1btkyjR49Wamqqpk6dqgMHDvi7TAAAECT8Hmaee+45vfLKK1q4cKG2bdumxMRE5ebmqrq6WsePH9fkyZM1cOBAFRUV6e6771ZBQYGKioo8+1esWKFNmzZp4cKF2rx5s5qampSbmyu32+3vUgEAQBDwe5jZsWOHxo8fr6uvvlqXXXaZHnzwQZ06dUr/+te/9PLLLysiIkIPP/ywBg0apIkTJ+q2227T6tWrJUlut1vr1q1TXl6exo4dq+TkZC1ZskSVlZXavn27v0sFAABBwO9hpm/fvvrb3/6mgwcPqrGxUS+99JLsdruSk5NVXFysjIwMhYeHe9ZnZmaqoqJCX331lcrKynT69GllZWV55nv37q2UlBTt3r3b36UCAIAgEH7hJb6ZO3eu7rvvPl1zzTUKCwtTjx499Mwzz2jgwIGqrKxUUlKS1/rY2FhJ0pEjR1RZWSlJ6t+/f4s1zXPtYVmWamtr27XX6XR6fTSdzWaTw+Ho7jJChtPplGVZ3V1Gtwu2x1EwokeBL9R6ZFmWbDZbm9b6Pczs27dPvXr10vLlyxUXF6dXXnlFs2bN0osvvqi6ujrZ7Xav9ZGRkZIkl8vlaVBra06cONHumtxut0pLS9u9X5IqKio6tD9QOBwOpaSkdHcZIaO8vDxknnjaIlgeR8GMHgW+UOmR2+32ZIQL8WuYOXLkiGbOnKkNGzZo5MiRkqSrrrpK+/bt0zPPPKOoqKgWN/K6XC5JUnR0tKKioiSd+QKa/9y8piNnE+x2u4YMGdKuvU6nUxUVFUpISAiKMxptTbnwj8TERM7MKPgeR8GIHgW+UOvRN09snI9fw8xHH32k+vp6XXXVVV7jw4YN0//+7//qkksuUXV1tddc8+dxcXFqaGjwjA0cONBrzeDBg9tdl81mU3R0dLv3S2fOaHT0GAg9ofCE4wseR4GPHgW+UOmRLz98+/UG4Pj4eEnSv//9b6/xTz/9VAkJCUpPT9eePXvU2Njomdu5c6cSExPVt29fJScnq2fPntq1a5dn/uTJkyopKVF6ero/SwUAAEHCr2Fm6NChGjFihB544AHt3LlTFRUVWrp0qd5//3396le/0sSJE1VTU6O5c+dq37592rJlizZs2KBp06ZJOnNKKScnRwUFBXrnnXdUVlam6dOnKz4+XuPGjfNnqQAAIEj49TJTjx499Nxzz2np0qV66KGHdOLECSUlJWnDhg0aNmyYJGnNmjV65JFHNGHCBPXr109z5szRhAkTPMfIy8tTQ0OD8vPzVVdXp/T0dK1du1YRERH+LBUAAAQJv7+aqU+fPpo3b57mzZvX6vzQoUP10ksvnXN/WFiYZs+erdmzZ/u7NAAAEIT4RZMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEbrlDCzbds2/fCHP9RVV12l66+/Xn/+8589cwcPHtS0adM0fPhwXX311Vq6dKkaGxu99hcWFuqaa67R0KFDdfPNN6ukpKQzygQAAEHA72HmT3/6k+bOnatbbrlFb7zxhsaPH68ZM2boww8/VH19vaZMmSJJ2rx5s+bPn68//OEPWr58uWf/1q1b9cQTT+i+++7Tli1bNGDAAE2ePFnHjh3zd6kAACAIhPvzYJZl6emnn9att96qW265RZJ05513qri4WB988IEOHTqkw4cP6+WXX1afPn2UlJSko0eP6oknntAdd9whu92ulStXKicnRz/+8Y8lSY8++qiuvfZavfLKK5o2bZo/ywUAAEHAr2dmysvLdejQIf3oRz/yGl+7dq2mTZum4uJiXXHFFerTp49nLjMzUzU1NSotLdXRo0dVUVGhrKwsz3x4eLhGjhyp3bt3+7NUAAAQJPx6Zqa8vFySVFtbqylTpqikpEQDBgzQnXfeqezsbFVWVio+Pt5rT2xsrCTpyJEjCg8/U07//v1brCkrK2t3XZZlqba2tl17nU6n10fT2Ww2ORyO7i4jZDidTlmW1d1ldLtgexwFI3oU+EKtR5ZlyWaztWmtX8NMTU2NJOmBBx7QPffco1mzZuntt9/WXXfdpfXr16uurk69e/f22hMZGSlJcrlcngbZ7fYWa1wuV7vrcrvdKi0tbfd+SaqoqOjQ/kDhcDiUkpLS3WWEjPLy8pB54mmLYHkcBTN6FPhCpUdut9uTES7Er2EmIiJCkjRlyhRNmDBBkjRkyBCVlJRo/fr1ioqKktvt9trTHFKio6MVFRUlSa2u6cjZBLvdriFDhrRrr9PpVEVFhRISEoLijEZbUy78IzExkTMzCr7HUTCiR4Ev1Hr0zRMb5+PXMBMXFydJSkpK8hr/3ve+p//+7/9WRkaGPv30U6+56upqz97my0vV1dUaNGiQ15rmY7eHzWZTdHR0u/dLZ85odPQYCD2h8ITjCx5HgY8eBb5Q6ZEvP3z79QbgK664QhdddJE++ugjr/FPP/1UAwcOVHp6ukpKSjyXoyRp586duuiii5ScnKy+ffsqMTFRu3bt8sw3NDSouLhY6enp/iwVAAAECb+GmaioKOXm5mr58uV6/fXX9Z///EfPPfec3nvvPU2ePFnXXnut+vXrp/vvv19lZWXasWOHnnrqKd1+++2e00m333671q9fr61bt2rfvn369a9/rbq6Ov3sZz/zZ6kAACBI+PUykyTdddddcjgcWrJkiaqqqjRo0CA988wzGjVqlCRpzZo1WrBggW666Sb16dNHN998s+666y7P/ptuukmnTp3S0qVL9fXXX+vKK6/U+vXrFRMT4+9SAQBAEPB7mJGkyZMna/Lkya3OXXbZZVq3bt1590+ZMsXzTsEAAADnwy+aBAAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwWqeGmfLycqWlpWnLli2esdLSUuXk5Cg1NVXZ2dl6/vnnvfY0NTVp2bJlGj16tFJTUzV16lQdOHCgM8sEAAAG67QwU19fr1mzZqm2ttYzdvz4cU2ePFkDBw5UUVGR7r77bhUUFKioqMizZsWKFdq0aZMWLlyozZs3q6mpSbm5uXK73Z1VKgAAMFinhZlnnnlGPXv29Bp7+eWXFRERoYcffliDBg3SxIkTddttt2n16tWSJLfbrXXr1ikvL09jx45VcnKylixZosrKSm3fvr2zSgUAAAYL74yD7t69Wy+99JK2bdumsWPHesaLi4uVkZGh8PD/+2szMzO1atUqffXVVzp8+LBOnz6trKwsz3zv3r2VkpKi3bt3a/z48e2qx7IsrzNEvnA6nV4fTWez2eRwOLq7jJDhdDplWVZ3l9FmNputU47rdrvlcDjkdrs75e8w6d84UAXbc10wCrUeWZbV5ucLv4eZkydPas6cOcrPz1f//v295iorK5WUlOQ1FhsbK0k6cuSIKisrJanFvtjYWM9ce7jdbpWWlrZ7vyRVVFR0aH+gcDgcSklJ6e4yQkZ5ebkxTzwRERFKSblC4eFhfj+2w+HQxRdf7PfjSlJDQ6NKSj5RfX19pxw/1ATLc10wC5Ueud1uRUZGtmmt38PM/PnzlZaWph/96Ect5urq6mS3273Gmgt1uVyeJ/3W1pw4caLdNdntdg0ZMqRde51OpyoqKpSQkBAUZzQ66ydvtO673/2uMWcNbDabwsPDVFC4RwerTnV3OW0yIK6XZt0yQpdffrkx/86BKtie64JRqPXom1ngfPwaZrZt26bi4mK99tprrc5HRUW1uJHX5XJJkqKjoxUVFSXpTBpr/nPzmo40zmazKTo6ut37pTM/WXb0GAgdF/eKVFOT5fX/sSkOVp3S54fa/8NDdwiFJ/auwnNd4AuVHvnyw7dfw0xRUZGOHj3qdZ+MJM2bN09vvvmm4uPjVV1d7TXX/HlcXJwaGho8YwMHDvRaM3jwYH+WCnSqno4I9ehhM+osx/DkWN36Qy5BAjCPX8NMQUGB6urqvMbGjRunvLw8/fjHP9af/vQnbd68WY2NjQoLO3NdfufOnUpMTFTfvn3Vq1cv9ezZU7t27fKEmZMnT6qkpEQ5OTn+LBXoEiad5RgQ2/PCiwAgAPk1zMTFxbU63rdvX8XFxWnixIlas2aN5s6dq9zcXO3du1cbNmzQggULJJ25PpaTk6OCggLFxMTo0ksv1eLFixUfH69x48b5s1QAABAkOuWl2efSt29frVmzRo888ogmTJigfv36ac6cOZowYYJnTV5enhoaGpSfn6+6ujqlp6dr7dq1ioiI6MpSAQCAITo9zPz73//2+nzo0KF66aWXzrk+LCxMs2fP1uzZszu7NAAAEAT4RZMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAstlscjgcPv1yPyBQdOk7AAMApKYmSz16BFZocDgcSkk5/y8aDcS6AYkwAwBdzrTfqC5JA+J6adYtI7q7DKBVhBkA6AYm/UZ1INBxzwwAADAaYQaAsS7uFammJqu7ywDQzbjMBMBYPR0Rxt1/Mjw5Vrf+8Pw32gLwDWEGgPFMuv9kQGzP7i4BCDpcZgIAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwmt/DzNdff63f/va3GjNmjIYPH65f/OIXKi4u9sy///77uuGGGzRs2DBdd911euONN7z2u1wuLViwQFlZWUpLS9PMmTN17Ngxf5cJAACChN/DzIwZM/Thhx/qqaeeUlFRkYYMGaIpU6boiy++0Oeff65p06Zp9OjR2rJli2688UbNmTNH77//vmf//Pnz9e677+qZZ57Rxo0b9cUXXygvL8/fZQIAgCAR7s+D7d+/X++99542bdqkESNGSJJ+85vf6O9//7tee+01HT16VIMHD9b06dMlSYMGDVJJSYnWrFmjrKwsVVVVadu2bVq5cqVGjhwpSXrqqad03XXX6cMPP1RaWpo/ywUAAEHAr2dmvvWtb2n16tW66qqrPGM2m002m00nT55UcXGxsrKyvPZkZmZqz549sixLe/bs8Yw1S0xMVFxcnHbv3u3PUgEAQJDw65mZ3r176//9v//nNfb2229r//79+vWvf62tW7cqPj7eaz42NlZOp1PHjx9XVVWVvvWtbykyMrLFmsrKynbXZVmWamtr27XX6XR6fTSdzWaTw+Ho7jIAGMrpdMqyrO4uIyQF2/ejC7EsSzabrU1r/Rpmvumf//ynHnroIY0bN05jx45VXV2d7Ha715rmz91ut5xOZ4t5SYqMjJTL5Wp3HW63W6Wlpe3eL0kVFRWtjkdERCg8vFP/Gf0qKipK3/3ud7u7DACGKi8vD5lvpoHqXN+Pgo3b7W5xcuNcOu278I4dOzRr1iwNHz5cBQUFks6EErfb7bWu+XOHw6GoqKgW89KZVzh15GyC3W7XkCFD2rXX6XSqoqJCCQkJLWqw2WyyR0YqrAevcAcQGhITEzkz003O9/0oGLV2cuNcOiXMvPjii3rkkUd03XXX6Xe/+52noP79+6u6utprbXV1taKjo9WrVy/Fx8fr66+/ltvt9voiqqurFRcX1+56bDaboqOj271fOhO2znWMgsI9Olh1qkPH7yrDk2N16w9TursMAIYKhW+ige5834+CSVsvMUmdEGY2bdqkhQsXatKkSZo7d65XMSNHjtQHH3zgtX7nzp0aPny4evTooREjRqipqUl79uzx3ChcXl6uqqoqpaen+7tUvzlYdUqfHzrR3WW0yYDYnt1dAgAAfuXX6yPl5eV69NFH9YMf/EDTpk3TV199pS+//FJffvmlTp06pUmTJmnv3r0qKCjQ559/rnXr1umtt95Sbm6uJCkuLk7XX3+98vPztWvXLu3du1czZsxQRkaGUlNT/VkqAAAIEn49M/P222+rvr5ef/nLX/SXv/zFa27ChAl6/PHHtWLFCi1evFgbN27UgAEDtHjxYq+Xay9cuFCPPvqo7rnnHknSmDFjlJ+f788yAQBAEPFrmLnjjjt0xx13nHfNmDFjNGbMmHPOR0dHa9GiRVq0aJE/SwMAAEGKl+EAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAC7o4l6RamqyursMn5lYM3wX3t0FAAACX09HhHr0sKmgcI8OVp3q7nLaZEBcL826ZUR3l4EuQJgBALTZwapT+vzQie4uA/DCZSYAAGA0wgwAADAaYQYAABgtIMNMU1OTli1bptGjRys1NVVTp07VgQMHurssAAAQgAIyzKxYsUKbNm3SwoULtXnzZjU1NSk3N1dut7u7SwMAAAEm4MKM2+3WunXrlJeXp7Fjxyo5OVlLlixRZWWltm/f3t3lAQAMEWzvjWOz2eRwOGSz2bq4osAXcC/NLisr0+nTp5WVleUZ6927t1JSUrR7926NHz++G6sDAJjCxPfGGZIYo6k/uarVOYfDoZSUlC6uqG2amiz16NF9IctmWVZAxdbt27fr3nvv1UcffaSoqCjP+H333ae6ujqtWrXKp+NdddVVamxsVHx8fLvqsSxL9fX1ioiIaDUN22w2nahxqaExoP4ZzykyIkw9oyOouZNRc9eg5q5jYt0m13zaWa9GQ84qhfWw6SJHhPwdJyorKxUWFqaPP/74gmsD7syM0+mUJNntdq/xyMhInTjh+xs1RUZGyu12t/u0nM1mU2Rk5HnX9Ol5/vlARM1dg5q7BjV3HRPrNrHmixwR3V2Cz/x9+Ss8PLxFFjjnWr/+zX7QfDbG7XZ7nZlxuVxyOBw+H6+4uNhvtQEAgMATcDcA9+/fX5JUXV3tNV5dXa24uLjuKAkAAASwgAszycnJ6tmzp3bt2uUZO3nypEpKSpSent6NlQEAgEAUcJeZ7Ha7cnJyVFBQoJiYGF166aVavHix4uPjNW7cuO4uDwAABJiACzOSlJeXp4aGBuXn56uurk7p6elau3atIiLMuyEKAAB0roB7aTYAAIAvAu6eGQAAAF8QZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjBbyYaapqUnLli3T6NGjlZqaqqlTp+rAgQPnXH/8+HHNnDlT6enpysjI0IIFCzy/6Rudw9ceffbZZ/rVr36lUaNGKSsrS3l5eTp8+HAXVhx6fO3R2V599VUNHjxYBw8e7OQqQ5uvPaqvr9eTTz7pWZ+Tk6PS0tIurDj0+Nqjo0ePaubMmcrMzNSoUaM0ffp0VVVVdWHFgSPkw8yKFSu0adMmLVy4UJs3b1ZTU5Nyc3PldrtbXZ+Xl6f9+/drw4YNevrpp/U///M/mj9/ftcWHWJ86dHx48c1efJkRUVF6YUXXtDvf/97HTt2TLm5uXK5XN1QfWjw9XHU7NChQ3r44Ye7qMrQ5muP5s+fry1btujRRx9VUVGRYmJiNHXqVJ06daqLKw8dvvbo/vvv1+HDh7V+/XqtX79ehw8f1t13393FVQcIK4S5XC4rLS3NKiws9IydOHHCGjp0qPXaa6+1WP/Pf/7TSkpKsvbt2+cZ+/vf/24NHjzYqqys7JKaQ42vPXr55ZettLQ0y+l0esYOHz5sJSUlWf/4xz+6pOZQ42uPmjU2Nlq/+MUvrFtvvdVKSkqyDhw40BXlhiRfe/Sf//zHGjx4sPW3v/3Na/33v/99HkedxNcenThxwkpKSrLeeecdz9iOHTuspKQk6/jx411RckAJ6TMzZWVlOn36tLKysjxjvXv3VkpKinbv3t1ifXFxsfr166dBgwZ5xjIyMmSz2bRnz54uqTnU+NqjrKwsrVixQlFRUZ6xHj3O/G9+8uTJzi84BPnao2YrV65UfX29pk2b1hVlhjRfe/Tee++pV69eGjNmjNf6v/71r17HgP/42qOoqChddNFF2rZtm2pqalRTU6M//elPSkxMVO/evbuy9IAQkL9osqtUVlZKkvr37+81Hhsb65k7W1VVVYu1drtdF198sY4cOdJ5hYYwX3s0YMAADRgwwGts9erVioqKUnp6eucVGsJ87ZEk7d27V+vWrdMf//jHkL3G35V87VF5ebm+853vaPv27Vq9erWqqqqUkpKiBx980OuHOfiPrz2y2+16/PHH9dvf/lYjR46UzWZTbGysXnzxRc8PcKEk9L7iszTfuGu3273GIyMjW72/wul0tlh7vvXoOF979E0vvPCCXnzxRc2aNUsxMTGdUmOo87VHtbW1mjVrlmbNmqWEhISuKDHk+dqjmpoa7d+/XytWrNCMGTP03HPPKTw8XDfffLOOHj3aJTWHGl97ZFmWSktLlZaWpsLCQm3cuFGXXHKJ7rrrLtXU1HRJzYEkpMNM86WIb95c5XK55HA4Wl3f2o1YLpdL0dHRnVNkiPO1R80sy9LSpUu1aNEi3XnnnZo0aVKn1hnKfO3RokWLlJiYqJ///OddUh9871F4eLhqamq0ZMkSXX311Ro6dKiWLFkiSdq6dWvnFxyCfO3Rn//8Z7344otavHixRowYoYyMDK1cuVKHDh3SH//4xy6pOZCEdJhpPp1XXV3tNV5dXa24uLgW6+Pj41usdbvd+vrrrxUbG9t5hYYwX3sknXlJ6ezZs7Vy5Uo99NBDuv/++zu7zJDma4+Kior0j3/8Q2lpaUpLS9PUqVMlSePHj9fKlSs7v+AQ1J7nuvDwcK9LSlFRUfrOd77DS+g7ia89Ki4uVmJionr27OkZ69OnjxITE7V///7OLTYAhXSYSU5OVs+ePbVr1y7P2MmTJ1VSUtLq/RXp6emqrKz0+h/lgw8+kCSNGDGi8wsOQb72SJLmzJmjt956S08++aRuu+22Lqo0dPnao+3bt+v111/Xtm3btG3bNi1atEjSmXubOFvTOdrzXNfQ0KCPP/7YM1ZXV6cDBw7osssu65KaQ42vPYqPj9f+/fu9LkHV1tbq4MGDIXn5NqRvALbb7crJyVFBQYFiYmJ06aWXavHixYqPj9e4cePU2NioY8eOqVevXoqKitKwYcM0fPhwTZ8+XfPnz1dtba1++9vf6qc//ek5zxKgY3zt0ZYtW/Tmm29qzpw5ysjI0Jdffuk5VvMa+JevPfrmN8PmmxsvueQSXXzxxd3wFQQ/X3s0cuRI/dd//ZceeOABPfzww7r44ou1bNkyhYWF6Sc/+Ul3fzlBydce/fSnP9XatWt1//3367777pMkLV26VJGRkbrhhhu6+avpBt392vDu1tDQYD3xxBNWZmamlZqaak2dOtXzfhcHDhywkpKSrKKiIs/6r776yrr33nut1NRUa9SoUda8efOsurq67io/JPjSo8mTJ1tJSUmt/nd2H+Ffvj6OzrZz507eZ6YL+NqjU6dOWfPmzbNGjRplDRs2zJo8ebL12WefdVf5IcHXHu3bt8+aNm2alZGRYWVmZlr33HNPyD6ObJZlWd0dqAAAANorpO+ZAQAA5iPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDR/j/f3PE6EYXf2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['relevancy_score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2605923005441716)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['relevancy_score']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Pretrained Transformer (OPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating summary: Torch not compiled with CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the OPT model and tokenizer\n",
    "model_name = \"facebook/opt-2.7b\"  # You can adjust the size (e.g., opt-1.3b, opt-6.7b)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define a summarization prompt\n",
    "def generate_summary(text, max_length=100):\n",
    "    prompt = f\"Summarize the following text:\\n\\n{text}\\n\\nSummary:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n",
    "    \n",
    "    # Generate the summary\n",
    "    outputs = model.generate(inputs.input_ids, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the generated summary\n",
    "    return summary.replace(prompt, \"\").strip()\n",
    "\n",
    "# Test with a sample input\n",
    "test_text = (\n",
    "    \"Artificial intelligence (AI) refers to the simulation of human intelligence in machines \"\n",
    "    \"that are programmed to think and learn. These machines are capable of performing tasks \"\n",
    "    \"that typically require human intelligence, such as visual perception, speech recognition, \"\n",
    "    \"decision-making, and language translation.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    summary = generate_summary(test_text, max_length=50)\n",
    "    print(\"Generated Summary:\", summary)\n",
    "except Exception as e:\n",
    "    print(\"Error generating summary:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTSUM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-512_A-8\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"return_dict\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
      "  \"_name_or_path\": \"google/bert_uncased_L-4_H-512_A-8\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"return_dict\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 0/431...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverzhou/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1399: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (30). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 100/431...\n",
      "Processing text 200/431...\n",
      "Processing text 300/431...\n",
      "Processing text 400/431...\n",
      "ROUGE Scores with BERTSUM: {'rouge1': np.float64(6.0), 'rouge2': np.float64(2.2), 'rougeL': np.float64(5.9), 'rougeLsum': np.float64(5.9)}\n",
      "Original Text: role data analyst location hartford ct raleigh nc duration fulltime job description least year experience working healthcare business data analyst health plan member enrollment benefit plan configuration provider setup contract setup billing payment ee claim processing edi transaction medicare medicaid commercial health plan cob accumulator least year experience requirement elicitation technique like jadsessions workshop interview survey etc hedis knowledgeable data analyst least year experience creating technical requirement specification based architecturedesign detailing processe least year experience agile methodology preferably agile scrum business analyst understanding u healthcare data thanks regard sheebakavipriya process specialist talent acquisition north america infy hr e sheebakavipriyapinfosyscom w wwwinfosyscom show show less\n",
      "Reference Summary: Data Analyst (BI)\n",
      "Generated Summary (BERTSUM): job description least year experience working healthcare business data analyst at the job description. sheebakavipriya process specialist talent acquisition north america infy\n",
      "--------------------------------------------------\n",
      "Original Text: recruiting scratch recruiting scratch premier talent firm focus placing best product manager software hardware talent innovative company team remote work team across united state help hire work company funded best investor including sequoia capital lightspeed venture tiger global management az accel dfj httpswwwrecruitingfromscratchcom hybrid role based palo alto san francisco chicago office require office tuesday thursday whats interesting role believe ai revolutionize dating industry data engineer lead responsible building high quality ml datasets scale used train ml model power aicentric feature pivotal role opportunity build foundational tool data pipeline ingest normalize clean valuable data would fundamental ml engineer build ai tool including recommendation llm ad visual search growthnotifications trust safety whats job looking exceptional data engineer passionate data ai value bring company love working data ops scale committed hard work necessary continuously improve ml data pipeline position responsible establishing executing strategy organization ml data engine initial focus agile ml data ops includes identification infrastructure component data stack used design implementation pipeline data system team automation workflow data enrichment monitoring tool ai model tech lead specialized data engineering expected code contribute stack responsibility dive dataset design implement scale data prepost processing pipeline ml model work applied ml solution area data mining cleaning normalizing modeling selfmotivated seeking solution correct path isnt always known collaborate engineer conceptualizing planning implementing data engineering initiative working different stakeholder design build data platform framework processing high volume data real time well batch used across engineering team build data processing stream cleaning modeling text data llm research evaluate new technology big data space guide continuous improvement collaborate multifunctional team help tune performance large data application work privacy security team data governance risk compliance initiative work initiative ensure stability performance reliability data infrastructure well love bachelor computer science mathematics physic related field year experience data engineer building productionlevel prepostprocessing data pipeline mldl model including year technical leadership experience experience statistical analysis visualization datasets using panda r experience designing building highly available distributed system data extraction ingestion normalization processing large data set real time well batch used across engineering team using orchestration framework like airflow kubeflow pipeline tool demonstrated prior experience creating data pipeline text data set nlp large language model ability produce wellengineered software including appropriate automated test suite technical documentation operational strategy excellent coding skill python java bash sql expertise git version control experience using big data technology snowflake airflow kubernetes docker helm spark pyspark experience public cloud environment aws gcp azure significant experience relational database query authoring sql well nosql database like dynamodb etc experience building maintaining etl managing highquality reliable etl pipeline well really swoon year experience technical leadership building data engineering pipeline ai previous experience building data pipeline conversational ai apis recommender system experience distributed system microservices experience kubernetes building docker image experience building streamprocessing system using solution kafka storm sparkstreaming strong understanding applied machine learning topic familiar legal compliance data management tool data classification retention consistent track record managing implementing complex data project youll love u mission impact worldleading lgbtq social networking service role impact life million lgbtq people around world multiple location hiring someone role based ideally san francisco palo alto family insurance insurance premium coverage health dental vision partial coverage dependent retirement saving generous k plan match immediate vest u compensation industrycompetitive compensation eligibility company bonus equity program queerinclusive benefit industryleading genderaffirming offering cost coverage access included health monthly stipend hrt additional benefit flexible vacation policy monthly stipend cell phone internet wellness food onetime homeoffice setup stipend companysponsored event base pay range usd httpswwwrecruitingfromscratchcom show show less\n",
      "Reference Summary: Data Engineer\n",
      "Generated Summary (BERTSUM): recruiting scratch premier talent firm focus placing best product manager software hardware hardware hardware talent innovative company team remote work team across united state help hire work company funded\n",
      "--------------------------------------------------\n",
      "Original Text: aurora co icr opportunity available experienced motivated data scientist bayesian statistic background essential job responsibility data scientist expected work independently complex technical task require indepth data analysis methodology datainformation collection develop unique technical solution application intelligence field participate member multidisciplinary team analyze satisfy customer requirement develop implement validate document present finding specialized analysis software tool model required effectively handle concurrent technical task conflicting priority approach difficult problem enthusiasm creativity ability change focus necessary travel required skill qualification active top secret security clearance ssbi experience bayesian statistic time series analysis master degree statistic minimum two year professional experience phd statistic related field experience computational analysis tool developing software least one following programing language python preferred r c matlab experience developing applying advanced statisticalmachine learning model algorithm one following classification clustering anomaly detection density estimation data mining pattern recognition knowledge discovery experience extracting processing structuredunstructured data various source eg database text file web preparing data analysis collaborate others multidisciplinary team environment accomplish research goal ability work effectively smallteam setting solve complex problem ability desire obtain substantial domain knowledge field application ability communicate effectively subject matter expert proficient verbal written communication skill collaborate effectively team environment present explain technical information customer desired qualification experience intelligence community broad knowledge statistical analysis ml method problemsolving skill experience spatial statistic multivariate statistic gaussian process random forest support vector machine natural language processing neural network proficient python jupyter markdown experience working database sql andor elk stack experience creating data visualization dashboard position offer comprehensive benefit package includes company equity retirement plan companypaid health care benefit flexible paid time policy opportunity raise bonus year icr inc considers several factor extending job offer including limited candidate key skill relevant work experience education training certification show show less\n",
      "Reference Summary: Statistician\n",
      "Generated Summary (BERTSUM): aurora co icr opportunity available experienced motivated data scientist bayesian statistic background essential job responsibility data scientist expected work independently complex technical task require indept\n",
      "--------------------------------------------------\n",
      "Original Text: flexible work arrangement hybrid month program participant experience technically challenging handson six month rotation three core function pjm system operation system planning market well shorter rotation many support function including compliance information technology member service risk security program designed build fundamental understanding operation power grid realtime system operation perspective thorough knowledge wholesale market operate critical knowledge longterm infrastructure planning process position start june essential function corporate rotation program participant receive handson engineering experience support largest rtoiso participant receive exposure support senior executive leader assignment roundtable discussion participate formal mentoring partnership receive ongoing learning opportunity well interface program manager monitor progress development required characteristic qualification b degree engineering electrical engineering electrical power system engineering data science computer science economics mathematics information technology cyber security data science year experience gpa higher scale ability produce highquality work product attention detail experience quantitative qualitative analysis ability use mathematical electrical theory ability troubleshoot provide technical support show show less\n",
      "Reference Summary: Data Engineer\n",
      "Generated Summary (BERTSUM): flexible work arrangement hybrid month program participant experience technically challenging handson six month rotation three core function pjm system planning market well shorter rotation many support function\n",
      "--------------------------------------------------\n",
      "Original Text: data analyst leatherhead uk salary data analyst want use skill make real impact education world enjoy seeing work bringing people data together best way person want move forward greenfield space could role client really making life teacher child better within education know important best support possible time mean youll opportunity part something truly amazing helping support life thousand people program ensure key guidance structure always provided involved forever learning adapting create best future role see thick key asset bring data together work youll part help understand define strategy vision going forward allowing work greenfield environment data support youll glue really help create future role truly proud looking experience utilising analysing large data set ability clean define show data database design modelling experience working crm environment ability confidence liaise multiple department stakeholder sale andor marketing experience would desirable someone passionate great thing data youre looking part something amazing make real difference hit apply button show show less\n",
      "Reference Summary: Data Analyst (BI)\n",
      "Generated Summary (BERTSUM): data analyst leatherhead uk salary data analyst want use skill make real impact education world. youll opportunity part something truly amazing helping support life thousand people\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load a BERT-based encoder-decoder model for summarization\n",
    "model_name = \"mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = EncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to summarize text using the encoder-decoder model\n",
    "def bertsum_summarize(text, max_length=30):\n",
    "    try:\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        # Decode the generated summary\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error during BERTSUM summarization: {e}\")\n",
    "        return \"Error during summarization\"\n",
    "\n",
    "# Generate summaries for test data\n",
    "candidate_summaries = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing text {i}/{len(texts)}...\")\n",
    "    candidate_summaries.append(bertsum_summarize(text))\n",
    "\n",
    "# Save candidate summaries\n",
    "with open(\"bertsum-summaries.txt\", \"w\") as file:\n",
    "    for summary in candidate_summaries:\n",
    "        file.write(summary + \"\\n\")\n",
    "\n",
    "# Evaluate using ROUGE\n",
    "rouge_scores = calc_rouge_scores(candidate_summaries, ref_summaries)\n",
    "print(\"ROUGE Scores with BERTSUM:\", rouge_scores)\n",
    "\n",
    "# Output a few results for inspection\n",
    "for i in range(5):\n",
    "    print(f\"Original Text: {texts[i]}\")\n",
    "    print(f\"Reference Summary: {ref_summaries[i]}\")\n",
    "    print(f\"Generated Summary (BERTSUM): {candidate_summaries[i]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oliverzhou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/oliverzhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for LDA Summarization: {'rouge1': np.float64(1.7), 'rouge2': np.float64(0.0), 'rougeL': np.float64(1.4), 'rougeLsum': np.float64(1.7)}\n",
      "                               job_title  \\\n",
      "0                 Technical Data Analyst   \n",
      "1     Data Center Engineer - Minneapolis   \n",
      "2                           Data Analyst   \n",
      "3     Data Engineer II - NBC Sports Next   \n",
      "4  Data Analyst - Operational Assessment   \n",
      "\n",
      "                                         job_summary  \\\n",
      "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
      "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
      "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
      "3  Company Description\\nNBC Sports Next is where ...   \n",
      "4  National Grid Renewables is a leading North Am...   \n",
      "\n",
      "                              lda_summary  \n",
      "0     analysis science work business team  \n",
      "1         technology team year skill work  \n",
      "2         technology team year skill work  \n",
      "3     analysis science work business team  \n",
      "4  business opportunity product work team  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from evaluate import load\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['tokenized_summary'] = data['cleaned_job_summary'].apply(\n",
    "    lambda x: [word for word in word_tokenize(x) if word not in stop_words]\n",
    ")\n",
    "\n",
    "# Convert tokenized summaries back to strings\n",
    "data['processed_summary'] = data['tokenized_summary'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Vectorization using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "doc_term_matrix = vectorizer.fit_transform(data['processed_summary'])\n",
    "\n",
    "# Fit LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_model.fit(doc_term_matrix)\n",
    "\n",
    "# Extract topics for each document\n",
    "def get_topics_per_doc(lda_model, doc_term_matrix, feature_names, num_words=5):\n",
    "    \"\"\"\n",
    "    Get the top words representing each topic in each document.\n",
    "    \"\"\"\n",
    "    topics = []\n",
    "    for topic_weights in lda_model.transform(doc_term_matrix):\n",
    "        topic = topic_weights.argmax()\n",
    "        top_words = [feature_names[i] for i in lda_model.components_[topic].argsort()[-num_words:]]\n",
    "        topics.append(' '.join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "data['lda_summary'] = get_topics_per_doc(lda_model, doc_term_matrix, feature_names)\n",
    "\n",
    "# Evaluate using ROUGE\n",
    "metric = load(\"rouge\")\n",
    "\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores for candidate summaries against reference summaries.\n",
    "    \"\"\"\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    return {key: round(value * 100, 1) for key, value in result.items()}\n",
    "\n",
    "# Compute ROUGE scores\n",
    "lda_candidates = data['lda_summary'].tolist()\n",
    "reference_summaries = data['job_summary'].tolist()\n",
    "\n",
    "rouge_scores = calc_rouge_scores(lda_candidates, reference_summaries)\n",
    "print(\"ROUGE Scores for LDA Summarization:\", rouge_scores)\n",
    "\n",
    "# Display the first few results\n",
    "print(data[['job_title', 'job_summary', 'lda_summary']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach combines extractive summarization using TF-IDF cosine similarity and abstractive summarization using a pre-trained T5 transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/oliverzhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Improved Summarization: {'rouge1': np.float64(15.9), 'rouge2': np.float64(9.0), 'rougeL': np.float64(15.8), 'rougeLsum': np.float64(15.8)}\n",
      "                               job_title  \\\n",
      "0                 Technical Data Analyst   \n",
      "1     Data Center Engineer - Minneapolis   \n",
      "2                           Data Analyst   \n",
      "3     Data Engineer II - NBC Sports Next   \n",
      "4  Data Analyst - Operational Assessment   \n",
      "\n",
      "                                         job_summary  \\\n",
      "0  Why Choose Jefferson Health Plans?\\nWe are an ...   \n",
      "1  Job Responsibilities:\\nDeployment / In-Scope C...   \n",
      "2  Success Factor knowledge\\nSchedule : Monday th...   \n",
      "3  Company Description\\nNBC Sports Next is where ...   \n",
      "4  National Grid Renewables is a leading North Am...   \n",
      "\n",
      "                                   generated_summary  \n",
      "0  jefferson health plan awardwinning notforprofi...  \n",
      "1  job responsibility deployment inscope configur...  \n",
      "2  success factor knowledge schedule monday frida...  \n",
      "3  nbc sport next sport technology intersect subd...  \n",
      "4  national grid renewables develops project corp...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from evaluate import load\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data['cleaned_job_summary'] = data['cleaned_job_summary'].fillna(\"\")\n",
    "\n",
    "# Step 1: Extractive Summarization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(data['cleaned_job_summary'])\n",
    "\n",
    "def extract_key_sentences(text, num_sentences=3):\n",
    "    \"\"\"\n",
    "    Extract top sentences based on TF-IDF cosine similarity scores.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return ' '.join(sentences)  # Return all sentences if fewer than the threshold\n",
    "    \n",
    "    # Calculate sentence vectors\n",
    "    sentence_vectors = vectorizer.transform(sentences)\n",
    "    similarity_scores = cosine_similarity(sentence_vectors, tfidf_matrix)\n",
    "    \n",
    "    # Rank sentences by their average similarity score\n",
    "    ranked_indices = similarity_scores.mean(axis=1).argsort()[::-1][:num_sentences]\n",
    "    return ' '.join([sentences[i] for i in ranked_indices])\n",
    "\n",
    "# Extract key sentences\n",
    "data['key_sentences'] = data['cleaned_job_summary'].apply(extract_key_sentences)\n",
    "\n",
    "# Step 2: Abstractive Summarization using T5\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def generate_summary(text, max_length=50):\n",
    "    \"\"\"\n",
    "    Generate abstractive summaries using T5.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = model.generate(inputs.input_ids, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "        return \"Error during summarization\"\n",
    "\n",
    "# Apply abstractive summarization on key sentences\n",
    "data['generated_summary'] = data['key_sentences'].apply(generate_summary)\n",
    "\n",
    "# Evaluate using ROUGE\n",
    "metric = load(\"rouge\")\n",
    "\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores for candidate summaries against reference summaries.\n",
    "    \"\"\"\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    return {key: round(value * 100, 1) for key, value in result.items()}\n",
    "\n",
    "# Compute ROUGE scores\n",
    "candidates = data['generated_summary'].tolist()\n",
    "references = data['job_summary'].tolist()\n",
    "rouge_scores = calc_rouge_scores(candidates, references)\n",
    "print(\"ROUGE Scores for Improved Summarization:\", rouge_scores)\n",
    "\n",
    "# Display results\n",
    "print(data[['job_title', 'job_summary', 'generated_summary']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strengths of the Approach:\n",
    "\n",
    "The hybrid extractive-abstractive method outperforms simpler LDA-based summarization (e.g., previous ROUGE-1 ~1.7).\n",
    "Combining relevance filtering (TF-IDF) and abstractive refinement (T5) provides a more aligned and coherent summary.\n",
    "\n",
    "T5 abstractive summarization improves fluency, making the summaries more human-like compared to pure extractive methods.\n",
    "\n",
    "ROUGE-L scores suggest the generated summaries capture the structure and phrasing of the reference summaries to a reasonable degree.\n",
    "\n",
    "-------------\n",
    "\n",
    "Limitations:\n",
    "\n",
    "A ROUGE-2 score of 9.0 suggests the method struggles to consistently capture semantic pairings and context.\n",
    "The extractive step might omit key relational phrases that the abstractive model doesn't reconstruct.\n",
    "\n",
    "If the reference summaries are verbose or not concise, this can lower the scores.\n",
    "ROUGE might not fully capture semantic equivalence or rephrased content.\n",
    "\n",
    "------------\n",
    "The hybrid extractive-abstractive summarization approach shows significant improvement with ROUGE-1 and ROUGE-L nearing 16%. While there's room for improvement, the current results demonstrate a good balance between relevance and readability. Further refinement of extractive techniques and model tuning can yield even better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
